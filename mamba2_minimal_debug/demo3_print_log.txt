[Mamba2LMHeadModel] Loading pre-trained model from HuggingFace ID: state-spaces/mamba2-370m
[Config] Initialized Mamba2Config with d_model=1024, n_layer=48, d_state=128, d_conv=4, expand=2, headdim=64, chunk_size=64, vocab_size=50288, pad_vocab_size_multiple=16
[Config] Computed d_inner=2048, nheads=32
[Mamba2LMHeadModel] Loaded state dict.
[Mamba2LMHeadModel] Initializing backbone...
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0097,  0.0170, -0.0016, -0.0097, -0.0070], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.1960,  0.2384, -0.4554,  0.2425,  0.2545], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9069e+06,  4.5553e-41,  1.8049e-34,  0.0000e+00,  2.2975e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0022e-22,  7.9050e+31],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([1.3107e+05, 2.0204e-39, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0185, -0.0065,  0.0070, -0.0180,  0.0123], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0344,  0.0196,  0.0415,  0.0130,  0.0308], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0070,  0.0285, -0.0087, -0.0259,  0.0126], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0468, -0.0010, -0.0026,  0.0265,  0.0246], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0003,  0.0163,  0.0172, -0.0113, -0.0322], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-2.4207e-02, -1.3365e-02, -2.5711e-02,  1.5917e-05, -4.1625e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0255, -0.0004,  0.0223, -0.0082, -0.0305], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0059,  0.0068,  0.0188, -0.0193, -0.0169], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([0.1707, 0.2567, 0.2350, 0.2218, 0.1143], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([1.9067e-34, 0.0000e+00, 1.8911e-34, 0.0000e+00, 8.9683e-44],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9075e+06,  4.5553e-41, -7.9075e+06,  4.5553e-41,  1.9067e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([1.0042e-35, 0.0000e+00, 2.6736e+14, 4.5553e-41, 1.4013e-45],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0101,  0.0126, -0.0126,  0.0056, -0.0128], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0184, -0.0379, -0.0200, -0.0258, -0.0124], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0086,  0.0152, -0.0065,  0.0145,  0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0265,  0.0018,  0.0061, -0.0246,  0.0498], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0047,  0.0197,  0.0055,  0.0081,  0.0070], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0181, -0.0086, -0.0021,  0.0149, -0.0144], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0296, -0.0108,  0.0210,  0.0093, -0.0124], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0114,  0.0175,  0.0019, -0.0261,  0.0041], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.1202,  0.3874, -0.0234,  0.3526, -0.2700], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9069e+06,  4.5553e-41, -7.9069e+06,  4.5553e-41,  1.1212e+29],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0027,  0.0134, -0.0021,  0.0035, -0.0044], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0043, -0.0259,  0.0182, -0.0273,  0.0286], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0259,  0.0061,  0.0316, -0.0240, -0.0025], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0051,  0.0028, -0.0124, -0.0107, -0.0171], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0064,  0.0100,  0.0416,  0.0029,  0.0143], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0004,  0.0104, -0.0165, -0.0213, -0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0240, -0.0305, -0.0355,  0.0030, -0.0161], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0187, -0.0169, -0.0161,  0.0253,  0.0247], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.3827,  0.2615,  0.2461, -0.4328, -0.4420], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([2.6713e+14, 4.5553e-41, 2.6652e+14, 4.5553e-41, 5.7145e-42],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41, -2.0968e+06],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0089, -0.0120, -0.0062, -0.0122, -0.0024], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0022, -0.0072,  0.0080, -0.0075, -0.0216], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0013,  0.0195, -0.0167, -0.0120,  0.0023], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0085,  0.0125, -0.0087,  0.0338,  0.0301], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0086,  0.0196,  0.0021, -0.0149, -0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0250, -0.0172, -0.0033, -0.0088, -0.0064], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0256,  0.0101,  0.0004,  0.0403, -0.0223], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0309, -0.0073, -0.0176, -0.0184,  0.0021], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.0138, -0.3637,  0.1162, -0.1436, -0.4179], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9069e+06,  4.5553e-41, -7.9069e+06,  4.5553e-41,  2.9147e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([1.0042e-35, 0.0000e+00, 2.6738e+14, 4.5553e-41, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.1771e-34, 0.0000e+00, 2.1770e-34, 0.0000e+00, 3.8115e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0004, -0.0120,  0.0026,  0.0004,  0.0132], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([0.0189, 0.0151, 0.0208, 0.0198, 0.0227], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([0.0256, 0.0102, 0.0268, 0.0408, 0.0030], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0039, -0.0086,  0.0387,  0.0219,  0.0033], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0151,  0.0285, -0.0217, -0.0340,  0.0465], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0163,  0.0287, -0.0075,  0.0033, -0.0080], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0267, -0.0145,  0.0143,  0.0338,  0.0081], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0098,  0.0076, -0.0260, -0.0265, -0.0197], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.0849,  0.2629, -0.1336,  0.0850, -0.4710], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([2.1857e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2421e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9073e+06,  4.5553e-41, -7.9073e+06,  4.5553e-41,  1.9954e-42],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0154, -0.0045,  0.0101, -0.0065, -0.0029], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0038, -0.0067,  0.0047, -0.0008, -0.0190], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0235, -0.0158, -0.0079,  0.0053,  0.0188], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0290, -0.0145, -0.0300,  0.0440, -0.0033], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0299,  0.0145, -0.0051,  0.0125, -0.0223], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0087,  0.0687, -0.0086,  0.0280, -0.0333], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0111,  0.0411,  0.0221, -0.0328, -0.0219], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0183,  0.0089, -0.0134,  0.0233,  0.0216], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.3325, -0.2948, -0.1538,  0.1876,  0.1513], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0.0000e+00, 0.0000e+00, 1.9093e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.3133e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9954e-42],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([0.0112, 0.0202, 0.0089, 0.0088, 0.0154], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0232,  0.0085,  0.0135,  0.0254,  0.0109], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0033,  0.0038,  0.0192, -0.0301,  0.0383], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0024,  0.0191,  0.0007, -0.0055, -0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0095, -0.0387, -0.0135,  0.0251, -0.0218], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0106, -0.0333, -0.0034,  0.0078, -0.0437], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0121, -0.0244,  0.0230,  0.0188, -0.0211], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([0.0133, 0.0091, 0.0171, 0.0171, 0.0089], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.1926,  0.1177, -0.3749, -0.1303, -0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41,  2.3290e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41, -2.0968e+06],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41, -2.0968e+06],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0120, -0.0161,  0.0037,  0.0149, -0.0037], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0142,  0.0057,  0.0051, -0.0157, -0.0322], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0021,  0.0234, -0.0059, -0.0026, -0.0151], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-3.7242e-03, -1.6917e-06,  6.1969e-03,  2.6672e-03,  3.4887e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0319, -0.0067,  0.0145, -0.0040,  0.0237], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0014, -0.0171,  0.0022, -0.0066, -0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0112, -0.0238, -0.0101, -0.0336, -0.0040], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0223,  0.0144,  0.0040, -0.0134,  0.0207], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.3313, -0.4645, -0.1496,  0.0368,  0.1481], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([1.0042e-35, 0.0000e+00, 2.6743e+14, 4.5553e-41, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41,  2.3784e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([1.0042e-35, 0.0000e+00, 2.6745e+14, 4.5553e-41, 1.4013e-45],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0136,  0.0008, -0.0186, -0.0011, -0.0020], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0155,  0.0088,  0.0065, -0.0603, -0.0068], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0264,  0.0106, -0.0134, -0.0181, -0.0154], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0260,  0.0050, -0.0129,  0.0258, -0.0032], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0017,  0.0294, -0.0630,  0.0300, -0.0206], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0149, -0.0012, -0.0182, -0.0425, -0.0241], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0289,  0.0052, -0.0138, -0.0015,  0.0154], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0052,  0.0080,  0.0040, -0.0229, -0.0283], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.4695, -0.2032,  0.4825,  0.3193, -0.1196], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([2.3445e-34, 0.0000e+00, 2.3450e-34, 0.0000e+00, 2.9147e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9070e+06,  4.5553e-41,  2.3429e-34,  0.0000e+00,  4.4842e-44],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41,  0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0089,  0.0111, -0.0179,  0.0029,  0.0003], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0441,  0.0061, -0.0031, -0.0174, -0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0230, -0.0041, -0.0003, -0.0195, -0.0051], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0161, -0.0038, -0.0282,  0.0102,  0.0300], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0029, -0.0303, -0.0037,  0.0066, -0.0071], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0139, -0.0016, -0.0022, -0.0293, -0.0019], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0150,  0.0148, -0.0169,  0.0075, -0.0107], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0175, -0.0244, -0.0170, -0.0198, -0.0049], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.2724, -0.1745, -0.0830,  0.0354,  0.4721], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.3614e-34, 0.0000e+00, 2.4072e-34, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0208, -0.0005,  0.0182,  0.0147,  0.0002], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0032, -0.0220,  0.0057, -0.0003,  0.0130], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0070,  0.0110,  0.0055,  0.0145,  0.0047], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0081,  0.0094, -0.0016,  0.0057,  0.0036], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0284, -0.0080, -0.0113,  0.0106,  0.0463], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0069,  0.0230,  0.0242,  0.0016,  0.0273], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0166, -0.0215,  0.0272,  0.0189,  0.0495], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0138, -0.0037,  0.0068, -0.0230,  0.0093], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.2286, -0.1593, -0.4818, -0.0109,  0.0195], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9069e+06,  4.5553e-41,  2.3781e-34,  0.0000e+00,  2.4101e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0.0000e+00, 0.0000e+00, 2.3777e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.4073e-34, 0.0000e+00, 2.3781e-34, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0095, -0.0006,  0.0132,  0.0030, -0.0005], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0055, -0.0077,  0.0092, -0.0049, -0.0364], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0351,  0.0048,  0.0044, -0.0284,  0.0143], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0150, -0.0055, -0.0262,  0.0125,  0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0112,  0.0004,  0.0316,  0.0231,  0.0203], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0042, -0.0068, -0.0490, -0.0091,  0.0063], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0268, -0.0235, -0.0299,  0.0095, -0.0280], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0164, -0.0229, -0.0232,  0.0081,  0.0070], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.0742, -0.0620,  0.4723, -0.4035, -0.0041], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9069e+06,  4.5553e-41, -7.9069e+06,  4.5553e-41,  2.4246e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0024, -0.0184, -0.0202,  0.0107, -0.0135], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0337,  0.0130, -0.0067, -0.0109, -0.0523], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0387,  0.0090,  0.0009, -0.0102, -0.0093], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0196, -0.0129,  0.0223, -0.0029, -0.0122], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0042,  0.0073,  0.0258,  0.0011, -0.0222], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0024,  0.0110, -0.0050,  0.0188, -0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0105, -0.0289, -0.0134,  0.0086, -0.0025], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0073,  0.0134,  0.0116,  0.0014, -0.0056], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.1330,  0.4770, -0.1549, -0.2558,  0.2700], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0.0000e+00, 0.0000e+00, 2.3924e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([1.1272e+29, 4.5553e-41, 1.5289e-38, 0.0000e+00, 1.1810e+29],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0.0000e+00, 0.0000e+00, 2.4564e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0078, -0.0061, -0.0211, -0.0146, -0.0209], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0169,  0.0009,  0.0299, -0.0042,  0.0310], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0095,  0.0182, -0.0318,  0.0416,  0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0379, -0.0178, -0.0073,  0.0241,  0.0067], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0145, -0.0031,  0.0138, -0.0054,  0.0265], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0206,  0.0447, -0.0032, -0.0276, -0.0181], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0308,  0.0113,  0.0050, -0.0227,  0.0074], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0175, -0.0284, -0.0072, -0.0043,  0.0209], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.2565, -0.4026, -0.0178, -0.2374, -0.2840], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9070e+06,  4.5553e-41, -7.9070e+06,  4.5553e-41,  2.3927e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9069e+06,  4.5553e-41, -7.9069e+06,  4.5553e-41,  0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0136,  0.0211,  0.0165,  0.0131, -0.0008], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0217, -0.0179, -0.0121, -0.0030,  0.0115], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0132, -0.0388,  0.0344, -0.0047,  0.0255], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-2.6720e-05, -3.3293e-02,  1.0416e-02,  2.1347e-02, -4.1453e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0618,  0.0198,  0.0154, -0.0018,  0.0324], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0267,  0.0114, -0.0083,  0.0051,  0.0040], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0209, -0.0146, -0.0066,  0.0236, -0.0330], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0220, -0.0049, -0.0138, -0.0277, -0.0129], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.1318, -0.0468,  0.0351,  0.4276,  0.1381], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9071e+06,  4.5553e-41,  2.4702e-34,  0.0000e+00, -2.0968e+06],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0.0000e+00, 0.0000e+00, 2.4408e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.4877e-34, 0.0000e+00, 2.4711e-34, 0.0000e+00, 4.7084e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0065,  0.0108, -0.0025,  0.0081, -0.0028], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0016, -0.0029,  0.0156, -0.0048,  0.0463], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0020,  0.0065,  0.0142,  0.0253,  0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0017, -0.0130,  0.0147,  0.0070, -0.0051], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0230,  0.0187,  0.0333,  0.0040, -0.0201], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0101, -0.0051,  0.0130,  0.0339, -0.0515], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0176, -0.0145,  0.0037, -0.0137, -0.0080], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0222, -0.0220,  0.0043,  0.0053,  0.0266], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.4646,  0.0432,  0.1065, -0.0071, -0.3232], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([1.0042e-35, 0.0000e+00, 2.7004e+14, 4.5553e-41, 1.4013e-45],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0.0000e+00, 0.0000e+00, 2.4731e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([5.3810e-43, 0.0000e+00, 1.3452e-43, 0.0000e+00, 4.3813e-41],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0159, -0.0029,  0.0174,  0.0170,  0.0196], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0447, -0.0196,  0.0600,  0.0090, -0.0196], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-8.0004e-06,  1.9814e-02,  2.3039e-02,  1.5732e-02,  1.4750e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0004,  0.0046, -0.0454,  0.0116, -0.0113], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0102,  0.0143,  0.0295, -0.0391, -0.0285], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0125,  0.0044, -0.0355, -0.0015,  0.0180], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0060, -0.0252, -0.0108, -0.0011, -0.0016], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0230, -0.0237,  0.0287,  0.0137,  0.0249], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.2918, -0.1369,  0.3007,  0.0852,  0.2507], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0.0000e+00, 0.0000e+00, 2.3457e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.4707e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0018, -0.0169,  0.0192, -0.0136,  0.0107], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0180, -0.0165,  0.0022,  0.0058, -0.0237], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0101,  0.0081, -0.0214,  0.0311, -0.0278], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0153, -0.0044, -0.0200,  0.0445,  0.0089], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0006,  0.0033, -0.0096,  0.0116,  0.0130], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0027,  0.0087, -0.0298, -0.0403,  0.0158], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0084,  0.0048, -0.0305, -0.0203, -0.0565], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0027,  0.0183,  0.0115, -0.0213, -0.0129], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.4898, -0.0915,  0.2183, -0.1010, -0.0050], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([1.3706e+29, 4.5553e-41, 1.5289e-38, 0.0000e+00, 1.1386e+29],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41,  2.4403e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([1.0042e-35, 0.0000e+00, 2.7007e+14, 4.5553e-41, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0151, -0.0098,  0.0197, -0.0074,  0.0059], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0092,  0.0145, -0.0477, -0.0187, -0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-1.9583e-03,  3.1097e-04, -3.3834e-03,  5.7076e-05,  1.9191e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0104,  0.0055,  0.0045, -0.0376,  0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0069, -0.0128, -0.0043, -0.0008,  0.0142], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0349, -0.0250, -0.0191,  0.0153, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0215,  0.0220,  0.0056, -0.0097, -0.0324], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0103, -0.0104, -0.0072, -0.0124, -0.0144], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.1809, -0.2200,  0.2336, -0.4922,  0.2829], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9071e+06,  4.5553e-41,  2.4416e-34,  0.0000e+00,  2.5189e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0.0000e+00, 0.0000e+00, 2.5186e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9075e+06,  4.5553e-41, -7.9075e+06,  4.5553e-41,  2.5512e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0150, -0.0053,  0.0201,  0.0003, -0.0049], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0232, -0.0015, -0.0249,  0.0074,  0.0192], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0216,  0.0335,  0.0114, -0.0090,  0.0303], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0052,  0.0022,  0.0085, -0.0184,  0.0035], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0166,  0.0169, -0.0365,  0.0069,  0.0201], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0130, -0.0076, -0.0182, -0.0110,  0.0348], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0003, -0.0086, -0.0128, -0.0162,  0.0075], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0253, -0.0105,  0.0194,  0.0014, -0.0027], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.3070,  0.0620, -0.0900,  0.1696,  0.0345], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([1.0042e-35, 0.0000e+00, 2.7011e+14, 4.5553e-41, 1.4013e-45],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41,  2.5199e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.5141e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0154, -0.0042,  0.0161,  0.0064, -0.0200], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0091, -0.0288, -0.0247,  0.0072, -0.0155], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0100,  0.0236, -0.0274,  0.0037,  0.0177], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([0.0130, 0.0077, 0.0194, 0.0201, 0.0160], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0009, -0.0142,  0.0154, -0.0178,  0.0054], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0070,  0.0340,  0.0034, -0.0107, -0.0417], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0331, -0.0178, -0.0220, -0.0058,  0.0275], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0133,  0.0030,  0.0185, -0.0162,  0.0190], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.3795,  0.4253,  0.1588, -0.2287, -0.0609], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0.0000e+00, 0.0000e+00, 2.3439e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([1.1809e+29, 4.5553e-41, 1.5289e-38, 0.0000e+00, 2.7216e+14],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0074, -0.0037, -0.0024, -0.0053,  0.0151], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0087,  0.0038,  0.0175, -0.0196, -0.0059], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0322,  0.0050, -0.0269, -0.0413, -0.0105], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([0.0076, 0.0119, 0.0153, 0.0020, 0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0032, -0.0005, -0.0194,  0.0070,  0.0343], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0016, -0.0536,  0.0274,  0.0021, -0.0125], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0001,  0.0083,  0.0126,  0.0158,  0.0426], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0299, -0.0183,  0.0287,  0.0210,  0.0145], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.0286, -0.1667, -0.4988,  0.1299, -0.1406], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9069e+06,  4.5553e-41,  2.5672e-34,  0.0000e+00,  2.5826e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.5830e-34, 0.0000e+00, 2.5820e-34, 0.0000e+00, 3.4295e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0178,  0.0039,  0.0214, -0.0023,  0.0201], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0041, -0.0041,  0.0317, -0.0223, -0.0117], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0124,  0.0429, -0.0011, -0.0198,  0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0096, -0.0025,  0.0196,  0.0072,  0.0330], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0008, -0.0133, -0.0106,  0.0219,  0.0141], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0308,  0.0062, -0.0065,  0.0131,  0.0733], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0096,  0.0259, -0.0082, -0.0162, -0.0144], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0035, -0.0292,  0.0240, -0.0067, -0.0190], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.0523, -0.1175,  0.2412, -0.4812, -0.0546], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([2.5670e-34, 0.0000e+00, 2.4868e-34, 0.0000e+00, 1.1210e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0145, -0.0108,  0.0206,  0.0211, -0.0092], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0051,  0.0189, -0.0098, -0.0147,  0.0117], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0030, -0.0118,  0.0205,  0.0246, -0.0464], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0155,  0.0192,  0.0149,  0.0500, -0.0135], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0085, -0.0206, -0.0313, -0.0224, -0.0247], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0016,  0.0183, -0.0295, -0.0115,  0.0141], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0147, -0.0008, -0.0094, -0.0083,  0.0344], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0009,  0.0027,  0.0207,  0.0186, -0.0311], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.0245, -0.3522, -0.2474,  0.2992,  0.1977], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([2.4092e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([2.7394e+14, 4.5553e-41, 1.5289e-38, 0.0000e+00, 1.1809e+29],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0.0000e+00, 0.0000e+00, 2.5495e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0010, -0.0120,  0.0012,  0.0210,  0.0039], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0286,  0.0476, -0.0307,  0.0114, -0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0243, -0.0304,  0.0176, -0.0055,  0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0161, -0.0272, -0.0183,  0.0162,  0.0336], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0455, -0.0004,  0.0043, -0.0442, -0.0258], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0326,  0.0149, -0.0303, -0.0199, -0.0117], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0191, -0.0102, -0.0234, -0.0309, -0.0264], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0033,  0.0191,  0.0290, -0.0201, -0.0069], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.4283, -0.2825, -0.1975, -0.3032, -0.0806], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([ 2.4874e-34,  0.0000e+00, -7.9069e+06,  4.5553e-41,  8.9683e-44],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.1738e-34, 0.0000e+00, 2.5653e-34, 0.0000e+00, 4.2599e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0111,  0.0004,  0.0047,  0.0087, -0.0078], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0008,  0.0330,  0.0050,  0.0075, -0.0072], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0030,  0.0129,  0.0061, -0.0213, -0.0086], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0175, -0.0136, -0.0149, -0.0016, -0.0158], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0123,  0.0295,  0.0119, -0.0224,  0.0240], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0206, -0.0070,  0.0021, -0.0296,  0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0435,  0.0061,  0.0179, -0.0147, -0.0186], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0132, -0.0039, -0.0067,  0.0018,  0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.2975,  0.4998, -0.1774,  0.4410, -0.0892], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([1.4013e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9070e+06,  4.5553e-41, -7.9070e+06,  4.5553e-41,  2.6406e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0136,  0.0167, -0.0126,  0.0178, -0.0060], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0419,  0.0018, -0.0538,  0.0397, -0.0189], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0095,  0.0089, -0.0278, -0.0058,  0.0225], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0221, -0.0172,  0.0061, -0.0193, -0.0059], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0151, -0.0037, -0.0044,  0.0027,  0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([0.0016, 0.0050, 0.0291, 0.0328, 0.0180], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0113, -0.0217,  0.0097,  0.0079, -0.0113], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0256,  0.0125, -0.0007, -0.0272, -0.0217], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.3962,  0.2873, -0.2834,  0.2611,  0.3018], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([2.6713e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1568e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.5667e-34, 0.0000e+00, 2.6609e-34, 0.0000e+00, 4.4142e-41],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0113,  0.0206, -0.0109, -0.0167,  0.0076], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0038,  0.0109, -0.0063,  0.0030,  0.0358], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0216, -0.0021,  0.0050,  0.0052,  0.0207], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0173,  0.0247, -0.0236,  0.0208,  0.0301], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0005,  0.0071,  0.0049, -0.0106, -0.0126], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0217, -0.0036,  0.0086, -0.0298, -0.0392], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0427, -0.0183,  0.0149, -0.0192, -0.0186], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0247,  0.0067, -0.0132,  0.0103,  0.0179], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.4305, -0.3457, -0.3026,  0.1298, -0.2936], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([ 2.4557e-34,  0.0000e+00, -7.9069e+06,  4.5553e-41,  3.5873e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9071e+06,  4.5553e-41,  2.5191e-34,  0.0000e+00,  2.6936e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9069e+06,  4.5553e-41,  2.6751e-34,  0.0000e+00,  2.6936e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0010, -0.0118, -0.0024, -0.0042,  0.0217], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0053, -0.0036, -0.0097, -0.0122, -0.0285], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0162, -0.0299,  0.0009, -0.0004, -0.0235], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0233,  0.0134,  0.0178,  0.0154, -0.0059], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0002, -0.0114,  0.0022, -0.0049, -0.0148], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0238,  0.0177, -0.0015,  0.0128,  0.0042], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0282, -0.0079,  0.0447, -0.0124,  0.0156], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0100, -0.0047, -0.0165, -0.0288, -0.0159], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.3134, -0.2257, -0.4361, -0.1751, -0.3062], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0.0000e+00, 0.0000e+00, 2.6591e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0.0000e+00, 0.0000e+00, 2.6606e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0011, -0.0047,  0.0105, -0.0043, -0.0201], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0246, -0.0211,  0.0239, -0.0047, -0.0305], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0157,  0.0093,  0.0229, -0.0418, -0.0290], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0074,  0.0005,  0.0147,  0.0560,  0.0091], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0358, -0.0116,  0.0382, -0.0498,  0.0174], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0062,  0.0101, -0.0137,  0.0397, -0.0199], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0485, -0.0047, -0.0261,  0.0238,  0.0191], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0095, -0.0106, -0.0246,  0.0115, -0.0065], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.2964,  0.3740, -0.2714, -0.3431,  0.3193], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41,  2.6920e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0202,  0.0191, -0.0216, -0.0129,  0.0098], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0230,  0.0060, -0.0119, -0.0169,  0.0152], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0015,  0.0037,  0.0196, -0.0064, -0.0246], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0172, -0.0504,  0.0005,  0.0145,  0.0127], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0081, -0.0022,  0.0073, -0.0156, -0.0117], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0118,  0.0426,  0.0077, -0.0001,  0.0089], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0237,  0.0169, -0.0142,  0.0109, -0.0069], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0206,  0.0212,  0.0032,  0.0096, -0.0142], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.0138,  0.3932, -0.0175, -0.1516,  0.2209], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([1.0042e-35, 0.0000e+00, 1.1713e+29, 4.5553e-41, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0.0000e+00, 0.0000e+00, 2.6767e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0014, -0.0081, -0.0069, -0.0192,  0.0132], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0443,  0.0169, -0.0063,  0.0136,  0.0021], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0116,  0.0188,  0.0519, -0.0078, -0.0069], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0155,  0.0180, -0.0146, -0.0092, -0.0560], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0033,  0.0015, -0.0144, -0.0018, -0.0023], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0026, -0.0229, -0.0302, -0.0057,  0.0182], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0008,  0.0122, -0.0052, -0.0377,  0.0142], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0124, -0.0127, -0.0244, -0.0140,  0.0102], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.2986,  0.4146,  0.4941,  0.3920, -0.0656], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41, -2.0968e+06],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0212,  0.0069,  0.0171, -0.0162,  0.0015], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0248, -0.0086, -0.0035,  0.0133,  0.0241], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0016,  0.0114,  0.0149,  0.0150, -0.0165], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0152, -0.0046,  0.0001, -0.0186,  0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0076, -0.0215,  0.0071,  0.0288,  0.0264], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0010,  0.0006,  0.0116, -0.0342,  0.0333], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0064,  0.0075, -0.0182,  0.0210, -0.0054], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0167, -0.0058, -0.0063, -0.0216, -0.0134], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.0844, -0.1817, -0.3635, -0.0391, -0.3560], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41, -2.0968e+06],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([1.0042e-35, 0.0000e+00, 1.1918e+29, 4.5553e-41, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([1.0042e-35, 0.0000e+00, 1.1920e+29, 4.5553e-41, 1.4013e-45],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0185,  0.0186,  0.0118,  0.0143, -0.0124], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0055,  0.0072, -0.0176,  0.0227, -0.0132], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0289, -0.0226, -0.0288, -0.0176, -0.0125], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0074,  0.0241,  0.0096, -0.0020,  0.0042], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0106, -0.0074, -0.0012, -0.0460,  0.0104], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0094,  0.0086, -0.0164, -0.0310,  0.0254], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0040, -0.0028, -0.0202, -0.0056, -0.0168], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0060,  0.0174, -0.0137,  0.0174, -0.0085], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.3391, -0.4737, -0.1417,  0.2335,  0.2177], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9071e+06,  4.5553e-41,  2.6745e-34,  0.0000e+00, -2.0968e+06],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0.0000e+00, 0.0000e+00, 2.4557e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9075e+06,  4.5553e-41, -7.9075e+06,  4.5553e-41,  2.7875e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0101,  0.0187,  0.0109,  0.0160, -0.0111], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0026, -0.0035, -0.0073, -0.0073,  0.0139], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0078, -0.0291,  0.0128,  0.0040, -0.0212], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0403,  0.0175, -0.0150,  0.0125, -0.0242], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0161,  0.0253,  0.0024, -0.0024,  0.0391], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0037,  0.0125,  0.0109,  0.0058, -0.0197], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0259, -0.0221, -0.0178,  0.0009,  0.0163], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0225,  0.0079, -0.0240,  0.0006, -0.0222], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.4652,  0.1857,  0.1385, -0.2428,  0.4650], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41, -2.0968e+06],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0.0000e+00, 0.0000e+00, 2.4700e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0042,  0.0146, -0.0135, -0.0075,  0.0089], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0378,  0.0428, -0.0173,  0.0344, -0.0268], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0167, -0.0118, -0.0069, -0.0135, -0.0274], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0217, -0.0213,  0.0030, -0.0131, -0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0054,  0.0182,  0.0363, -0.0166,  0.0054], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0107, -0.0146, -0.0104, -0.0257, -0.0108], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0021, -0.0072, -0.0464,  0.0381, -0.0098], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0067, -0.0219, -0.0039,  0.0002, -0.0049], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.2156, -0.0010,  0.0633, -0.3324, -0.2830], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([2.1600e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0.0000e+00, 0.0000e+00, 2.7228e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41,  2.7846e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0092,  0.0059,  0.0197,  0.0047, -0.0124], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0061, -0.0368, -0.0549,  0.0218,  0.0322], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0243, -0.0318,  0.0024,  0.0232,  0.0248], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0166,  0.0131, -0.0019,  0.0109, -0.0080], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0077,  0.0232,  0.0335, -0.0025, -0.0079], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0062, -0.0120, -0.0310,  0.0278,  0.0065], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0133,  0.0002,  0.0158,  0.0109,  0.0308], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0162, -0.0177,  0.0044,  0.0144,  0.0265], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.1921,  0.3035, -0.0647, -0.2799, -0.3450], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([2.7847e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([4.5919e-41, 4.1478e-43, 0.0000e+00, 0.0000e+00, 8.9683e-44],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0.0000e+00, 0.0000e+00, 2.8182e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0181,  0.0104, -0.0092,  0.0200,  0.0096], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0281,  0.0127,  0.0116,  0.0004,  0.0102], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0255, -0.0142,  0.0451,  0.0298,  0.0343], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0063, -0.0106, -0.0381,  0.0078, -0.0219], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0220, -0.0052,  0.0109, -0.0050,  0.0220], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0030, -0.0302,  0.0458, -0.0056, -0.0041], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0407,  0.0187, -0.0176, -0.0377, -0.0030], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0124, -0.0014,  0.0215, -0.0147, -0.0295], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.1424, -0.1750,  0.2636,  0.2907, -0.3324], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41, -2.0968e+06],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9069e+06,  4.5553e-41,  2.7843e-34,  0.0000e+00,  2.8178e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9075e+06,  4.5553e-41,  2.8499e-34,  0.0000e+00,  0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([0.0169, 0.0130, 0.0144, 0.0026, 0.0015], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0109,  0.0184,  0.0123, -0.0009, -0.0138], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0002,  0.0249,  0.0036, -0.0372,  0.0099], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0096,  0.0019, -0.0046, -0.0086, -0.0087], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0045, -0.0430,  0.0011, -0.0262, -0.0064], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0164,  0.0041,  0.0294,  0.0328,  0.0129], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0132,  0.0208, -0.0252,  0.0253, -0.0174], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0311, -0.0188,  0.0161,  0.0102, -0.0236], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.1814, -0.1226,  0.1953,  0.2520, -0.4264], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([2.8157e-34, 0.0000e+00, 2.8321e-34, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0.0000e+00, 0.0000e+00, 2.7078e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41,  2.8325e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0138, -0.0182, -0.0124, -0.0037, -0.0041], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0190,  0.0237, -0.0066,  0.0160, -0.0225], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0290,  0.0002, -0.0260, -0.0063, -0.0144], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0167, -0.0243, -0.0110,  0.0126,  0.0128], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([0.0107, 0.0184, 0.0084, 0.0008, 0.0064], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0286, -0.0159,  0.0319,  0.0189, -0.0208], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0482,  0.0344, -0.0369,  0.0097, -0.0062], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0235, -0.0057, -0.0196,  0.0295, -0.0205], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.1225, -0.4162, -0.2181,  0.3502,  0.1372], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([2.8165e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([1.0042e-35, 0.0000e+00, 1.2011e+29, 4.5553e-41, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0.0000e+00, 0.0000e+00, 2.8504e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0111, -0.0131,  0.0117,  0.0126,  0.0219], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0024, -0.0042, -0.0202,  0.0022,  0.0255], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([0.0227, 0.0337, 0.0086, 0.0097, 0.0521], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0029, -0.0144,  0.0022,  0.0090, -0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0015,  0.0028, -0.0100, -0.0141, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0231, -0.0065,  0.0081, -0.0405, -0.0231], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0037, -0.0146,  0.0122,  0.0079, -0.0364], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0274,  0.0068,  0.0032,  0.0219,  0.0125], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.1019,  0.2837, -0.4480,  0.4585, -0.0405], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0.0000e+00, 0.0000e+00, 2.8799e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.8606e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0096, -0.0043,  0.0045,  0.0082,  0.0056], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0184, -0.0031, -0.0159, -0.0021, -0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0003, -0.0165, -0.0224, -0.0120, -0.0145], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0033,  0.0008,  0.0425, -0.0022, -0.0082], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0086,  0.0034,  0.0030, -0.0212,  0.0085], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0054, -0.0221,  0.0379,  0.0206, -0.0277], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0235,  0.0354,  0.0306,  0.0085,  0.0171], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0128,  0.0148,  0.0153,  0.0273,  0.0223], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.2069,  0.0417,  0.4278, -0.2887,  0.1987], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41,  2.8954e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([1.0042e-35, 0.0000e+00, 1.2013e+29, 4.5553e-41, 1.4013e-45],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([2.9123e-34, 0.0000e+00, 2.8959e-34, 0.0000e+00, 1.1210e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0053, -0.0089, -0.0111,  0.0056, -0.0176], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0516, -0.0349, -0.0040, -0.0128, -0.0118], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0004,  0.0180, -0.0154, -0.0045, -0.0343], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0030, -0.0266, -0.0053,  0.0174, -0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0157,  0.0089, -0.0014, -0.0198,  0.0074], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([ 0.0146,  0.0067, -0.0177, -0.0275,  0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0062, -0.0015,  0.0217,  0.0293,  0.0255], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0265, -0.0129, -0.0281, -0.0202, -0.0181], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.2558, -0.2003, -0.4440,  0.0347, -0.1611], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([2.4081e-34, 0.0000e+00, 2.9110e-34, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([1.0042e-35, 0.0000e+00, 1.2016e+29, 4.5553e-41, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 0.0029, -0.0095,  0.0200,  0.0163,  0.0019], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0061, -0.0005,  0.0352,  0.0137, -0.0154], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0030,  0.0415,  0.0541, -0.0234,  0.0072], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0290, -0.0022,  0.0053, -0.0190, -0.0110], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0116,  0.0175, -0.0051,  0.0126,  0.0209], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([0.0020, 0.0036, 0.0065, 0.0069, 0.0113], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0079,  0.0144,  0.0053,  0.0104, -0.0198], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0270,  0.0066, -0.0032, -0.0187,  0.0290], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.4890, -0.2349, -0.2031,  0.0541,  0.3828], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0.0000e+00, 0.0000e+00, 2.9100e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0.0000e+00, 0.0000e+00, 2.5174e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([1.1809e+29, 4.5553e-41, 1.5289e-38, 0.0000e+00, 2.7238e+14],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0214,  0.0002,  0.0136, -0.0159,  0.0011], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([ 0.0138, -0.0114,  0.0098, -0.0041,  0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0317, -0.0320, -0.0292,  0.0221,  0.0201], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0261, -0.0075, -0.0118,  0.0305, -0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0242,  0.0216,  0.0144, -0.0067, -0.0175], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0042,  0.0070, -0.0099, -0.0129,  0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0028,  0.0009,  0.0057, -0.0281, -0.0075], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([ 0.0309,  0.0068, -0.0308, -0.0113, -0.0189], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.4400,  0.3825,  0.1379,  0.3914, -0.1672], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0.0000e+00, 0.0000e+00, 2.8650e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9069e+06,  4.5553e-41, -7.9069e+06,  4.5553e-41,  0.0000e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([ 3.3200e-03,  2.7316e-06, -7.9791e-03,  1.7568e-02,  1.3994e-02],
       grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0152, -0.0020,  0.0053,  0.0089,  0.0043], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0047,  0.0059,  0.0007,  0.0009, -0.0198], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([-0.0023, -0.0398,  0.0299,  0.0369,  0.0205], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0289, -0.0080, -0.0020, -0.0083, -0.0067], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0136, -0.0070,  0.0221, -0.0110, -0.0187], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([-0.0137, -0.0009,  0.0011,  0.0115,  0.0235], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0102, -0.0117, -0.0298,  0.0224,  0.0083], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([-0.2468,  0.2685,  0.2953, -0.4840, -0.3450], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0.0000e+00, 0.0000e+00, 2.9100e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9073e+06,  4.5553e-41, -7.9073e+06,  4.5553e-41,  1.4013e-45],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([0.0000e+00, 0.0000e+00, 2.9606e-34, 0.0000e+00, 1.0042e-35],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([-0.0093, -0.0205,  0.0143, -0.0170,  0.0048], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0210,  0.0262, -0.0141,  0.0187, -0.0147], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([ 0.0316, -0.0165, -0.0119, -0.0026,  0.0028], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0443,  0.0234,  0.0090, -0.0146, -0.0021], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([ 0.0084, -0.0086,  0.0242,  0.0053,  0.0023], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0024, -0.0076, -0.0081,  0.0075,  0.0409], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0299, -0.0018, -0.0030,  0.0214,  0.0262], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2] Initializing Mamba2 mixer...
  [Mamba2] d_in_proj: 4384
  [Mamba2] Initialized in_proj with input_dim=1024, output_dim=4384
  [Mamba2] in_proj.weight shape: torch.Size([4384, 1024])
  [Mamba2] in_proj.weight sample values: tensor([-0.0045,  0.0157,  0.0271,  0.0120, -0.0136], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized conv1d with in_channels=2304, out_channels=2304, kernel_size=4
  [Mamba2] conv1d.weight shape: torch.Size([2304, 1, 4])
  [Mamba2] conv1d.weight sample values: tensor([ 0.0611,  0.1943,  0.4986,  0.2485, -0.2254], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized dt_bias with shape: torch.Size([32])
  [Mamba2] dt_bias sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log with shape: torch.Size([32])
  [Mamba2] A_log sample values: tensor([-7.9071e+06,  4.5553e-41, -7.9071e+06,  4.5553e-41, -2.0968e+06],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized D with shape: torch.Size([32])
  [Mamba2] D sample values: tensor([-7.9069e+06,  4.5553e-41,  2.9440e-34,  0.0000e+00,  2.9443e-34],
       grad_fn=<SliceBackward0>)
  [Mamba2] Initialized A_log and D parameters.
[RMSNorm] Initialized RMSNorm with d=2048, eps=1e-05
[RMSNorm] weight shape: torch.Size([2048])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
  [Mamba2] Initialized RMSNorm.
  [Mamba2] Initialized out_proj.
  [Mamba2] out_proj.weight shape: torch.Size([1024, 2048])
  [Mamba2] out_proj.weight sample values: tensor([0.0113, 0.0024, 0.0146, 0.0095, 0.0086], grad_fn=<SliceBackward0>)
[Mamba2] Initializing parameters with normal distribution.
  [Mamba2] dt_bias after init: tensor([-0.0133,  0.0253,  0.0234, -0.0351,  0.0090], grad_fn=<SliceBackward0>)
  [Mamba2] A_log after init: tensor([-0.0011, -0.0237,  0.0007,  0.0053,  0.0179], grad_fn=<SliceBackward0>)
  [Mamba2] D after init: tensor([ 0.0092,  0.0292,  0.0028, -0.0352, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj.weight after init: tensor([-0.0086, -0.0038,  0.0367,  0.0336,  0.0383], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d.weight after init: tensor([-0.0001, -0.0139, -0.0241,  0.0193, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] out_proj.weight after init: tensor([ 0.0337,  0.0201,  0.0104, -0.0256,  0.0014], grad_fn=<SliceBackward0>)
[Mamba2] Parameters initialized.
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[RMSNorm] Initialized RMSNorm with d=1024, eps=1e-05
[RMSNorm] weight shape: torch.Size([1024])
[RMSNorm] weight sample values: tensor([1., 1., 1., 1., 1.], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Initialized embedding with vocab_size=50288 and d_model=1024
[Mamba2LMHeadModel] Initialized layer 1/48
[Mamba2LMHeadModel] Initialized layer 2/48
[Mamba2LMHeadModel] Initialized layer 3/48
[Mamba2LMHeadModel] Initialized layer 4/48
[Mamba2LMHeadModel] Initialized layer 5/48
[Mamba2LMHeadModel] Initialized layer 6/48
[Mamba2LMHeadModel] Initialized layer 7/48
[Mamba2LMHeadModel] Initialized layer 8/48
[Mamba2LMHeadModel] Initialized layer 9/48
[Mamba2LMHeadModel] Initialized layer 10/48
[Mamba2LMHeadModel] Initialized layer 11/48
[Mamba2LMHeadModel] Initialized layer 12/48
[Mamba2LMHeadModel] Initialized layer 13/48
[Mamba2LMHeadModel] Initialized layer 14/48
[Mamba2LMHeadModel] Initialized layer 15/48
[Mamba2LMHeadModel] Initialized layer 16/48
[Mamba2LMHeadModel] Initialized layer 17/48
[Mamba2LMHeadModel] Initialized layer 18/48
[Mamba2LMHeadModel] Initialized layer 19/48
[Mamba2LMHeadModel] Initialized layer 20/48
[Mamba2LMHeadModel] Initialized layer 21/48
[Mamba2LMHeadModel] Initialized layer 22/48
[Mamba2LMHeadModel] Initialized layer 23/48
[Mamba2LMHeadModel] Initialized layer 24/48
[Mamba2LMHeadModel] Initialized layer 25/48
[Mamba2LMHeadModel] Initialized layer 26/48
[Mamba2LMHeadModel] Initialized layer 27/48
[Mamba2LMHeadModel] Initialized layer 28/48
[Mamba2LMHeadModel] Initialized layer 29/48
[Mamba2LMHeadModel] Initialized layer 30/48
[Mamba2LMHeadModel] Initialized layer 31/48
[Mamba2LMHeadModel] Initialized layer 32/48
[Mamba2LMHeadModel] Initialized layer 33/48
[Mamba2LMHeadModel] Initialized layer 34/48
[Mamba2LMHeadModel] Initialized layer 35/48
[Mamba2LMHeadModel] Initialized layer 36/48
[Mamba2LMHeadModel] Initialized layer 37/48
[Mamba2LMHeadModel] Initialized layer 38/48
[Mamba2LMHeadModel] Initialized layer 39/48
[Mamba2LMHeadModel] Initialized layer 40/48
[Mamba2LMHeadModel] Initialized layer 41/48
[Mamba2LMHeadModel] Initialized layer 42/48
[Mamba2LMHeadModel] Initialized layer 43/48
[Mamba2LMHeadModel] Initialized layer 44/48
[Mamba2LMHeadModel] Initialized layer 45/48
[Mamba2LMHeadModel] Initialized layer 46/48
[Mamba2LMHeadModel] Initialized layer 47/48
[Mamba2LMHeadModel] Initialized layer 48/48
[Mamba2LMHeadModel] Initialized LM Head and tied weights with embedding.
[Mamba2LMHeadModel] Model loaded and set to evaluation mode.
[Mamba2LMHeadModel] Loaded model parameters:
  backbone.embedding.weight: torch.Size([50288, 1024])
    Sample values from backbone.embedding.weight: tensor([0.3008, 0.0156, 0.4475, 0.4497, 0.1058], grad_fn=<SliceBackward0>)
On a dark September night, a fierce storm jolted Florida with winds and torrential rainfall. Less than two weeks later, Hurricane Milton has roared through the state, mercilessly hampering recovery efforts already underway.

After Helene’s strong winds, heavy rains and a wall of water took 20 lives in the state along its path from south to north, Milton has claimed at least 17 more, bringing the ocean’s fury ashore with several feet of storm surge, three months worth of rain in three hours to some areas and a deadly tornado outbreak as it churned from west to east.

The trail of destruction all the way from the [Mamba2LMHeadModel] Forward pass input_ids shape: torch.Size([1, 128])
[Mamba2LMHeadModel] input_ids sample values: tensor([2374,  247, 3644, 4397, 2360])
[Mamba2LMHeadModel] Initialized hidden states.
[Mamba2LMHeadModel] Embedding output shape: torch.Size([1, 128, 1024])
[Mamba2LMHeadModel] Embedding sample values: tensor([-0.1198,  0.1678, -0.0842, -0.1382, -0.0211], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 1/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.0286, 0.0390, 0.0291, 0.0359, 0.0356], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([5.9138, 5.0622, 5.8642, 5.2736, 5.2993], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1700,  0.3032, -0.1311, -0.1676, -0.0280], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4384, -1.0011, -1.2129, -1.1530, -1.4844], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.7343, -0.3889, -0.3806,  1.1947, -0.0583], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.7343, -0.3889, -0.3806,  1.1947, -0.0583], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.0564,  0.2630, -0.0153, -0.3015,  0.1282], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([0.3913, 0.1041, 0.2110, 0.2442, 0.1081], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.0813, 0.0376, 0.0300, 0.0332, 0.0250], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.3370,  0.5484, -0.2702,  0.5399,  0.0341], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0215, -0.0079,  0.0597, -0.0916, -0.0848], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0215, -0.0079,  0.0597, -0.0916, -0.0848], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-2.7835e-01, -8.9747e-02, -1.5882e-02,  6.4479e-01, -1.6734e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2780,  0.0072, -0.0579, -0.2133,  0.0037], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0215, -0.0079,  0.0597, -0.0916, -0.0848], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0017, -0.0006,  0.0049, -0.0075, -0.0069], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.0357, -0.0376, -0.0364, -0.0383, -0.0371], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-2.7835e-01, -8.9747e-02, -1.5882e-02,  6.4479e-01, -1.6734e-04],
       grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2780,  0.0072, -0.0579, -0.2133,  0.0037], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0357, -0.0383, -0.0307, -0.0332, -0.0380], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0357, -0.0740, -0.1047, -0.1379, -0.1759], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0357, -0.0383, -0.0307, -0.0332, -0.0380], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0357, -0.0357, -0.0357, -0.0357, -0.0357], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0006, -0.0002,  0.0017, -0.0026, -0.0024], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.1417, 0.1472, 0.1518, 0.1570, 0.1630], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-1.3265e-02, -6.4438e-04,  5.3973e-04,  3.1684e-02, -5.4222e-05],
       grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -1.9897, -2.0509,  0.0000, -2.4565], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.9897, -1.9897], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.9897,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.9897,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -1.9897,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.1367, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0183, -0.0039, -0.0007,  0.0442, -0.0009], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9650, 0.9287, 0.9006, 0.8712, 0.8387], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0006, -0.0002,  0.0017, -0.0026, -0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0006, -0.0002,  0.0017, -0.0026, -0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0183, -0.0039, -0.0007,  0.0442, -0.0009], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.0374, -0.0138,  0.1040, -0.1598, -0.1479], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.0374, -0.0138,  0.1040, -0.1598, -0.1479], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0089,  0.0022, -0.0161, -0.1465,  0.0042], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.0716, 4.5939, 0.1746, 0.0703, 0.1203], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([3.7364, 0.4666, 2.3931, 3.7710, 2.8828], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0298,  0.0060, -0.0443, -0.3312,  0.0485], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0298,  0.0060, -0.0443, -0.3312,  0.0485], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.0295, -0.3889,  0.5596,  0.0537, -0.2493], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.3370,  0.5484, -0.2702,  0.5399,  0.0341], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0183, -0.0039, -0.0007,  0.0442, -0.0009], grad_fn=<SliceBackward0>)
  [Layer 1] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 1] Output sample values after mixer: tensor([-0.0295, -0.3889,  0.5596,  0.0537, -0.2493], grad_fn=<SliceBackward0>)
  [Layer 1] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 1] Residual connection sample values: tensor([-0.1493, -0.2211,  0.4754, -0.0845, -0.2704], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 2/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.3171, 0.0773, 2.1721, 1.6462, 1.0812], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.7758, 3.5968, 0.6785, 0.7794, 0.9617], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1531, -0.1905,  0.3780, -0.0912, -0.2525], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-12.6926, -19.4296,  -0.2289,  -2.1057,  -5.0389],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 3.7991, -0.2007, -2.5527,  1.1519,  0.4516], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 3.7991, -0.2007, -2.5527,  1.1519,  0.4516], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 1.0059,  0.2662, -0.8131, -1.0745, -0.0869], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 0.0050,  0.6400,  1.6249,  0.5161, -0.4492], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.0506, 0.0653, 0.1192, 0.1029, 0.0365], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 1.2845,  0.5080,  1.0932, -0.6335, -0.6967], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0254, -0.0153,  0.0019, -0.0894,  0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0254, -0.0153,  0.0019, -0.0894,  0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0013, -0.0509,  0.0465, -0.0128, -0.0390], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.0795,  0.4715, -0.2456,  0.0901,  0.3952], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0254, -0.0153,  0.0019, -0.0894,  0.0017], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 1.2845e-03, -7.7532e-04,  9.6734e-05, -4.5249e-03,  8.6232e-05],
       grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.6426, -1.2688, -0.0273, -0.2166, -0.1841], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0013, -0.0509,  0.0465, -0.0128, -0.0390], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.0795,  0.4715, -0.2456,  0.0901,  0.3952], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.6426, -0.3443, -3.0066, -2.0929, -2.0833], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.6426, -0.9869, -3.9935, -6.0864, -8.1697], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.6426, -0.3443, -3.0066, -2.0929, -2.0833], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.6426, -0.6426, -0.6426, -0.6426, -0.6426], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 9.5211e-05, -5.7470e-05,  7.1704e-06, -3.3541e-04,  6.3919e-06],
       grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([7.9975e-39, 1.1285e-38, 2.2817e-37, 1.8501e-36, 1.4857e-35],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0004,  0.0006,  0.0008, -0.0009, -0.0011], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([   0.0000,  -88.3642,  -93.1676,    0.0000, -137.8583],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -88.3642, -88.3642],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -88.3642,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -88.3642,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -88.3642,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 4.2063e-39, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-6.4442e-05,  8.6591e-04, -9.2185e-04, -6.9880e-04,  4.8483e-04],
       grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([5.2595e-01, 3.7273e-01, 1.8435e-02, 2.2736e-03, 2.8311e-04],
       grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 9.5211e-05, -5.7470e-05,  7.1704e-06, -3.3541e-04,  6.3919e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 9.5211e-05, -5.7470e-05,  7.1704e-06, -3.3541e-04,  6.3919e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-6.4442e-05,  8.6591e-04, -9.2185e-04, -6.9880e-04,  4.8483e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.0170, -0.0103,  0.0013, -0.0599,  0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.0170, -0.0103,  0.0013, -0.0599,  0.0011], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0632,  0.0009, -0.0002, -0.0524,  0.0003], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 5.8625, 18.3550,  7.3942,  5.2129, 11.5425], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.4130, 0.2334, 0.3678, 0.4380, 0.2943], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0497,  0.0010, -0.0002, -0.0345,  0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0497,  0.0010, -0.0002, -0.0345,  0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([0.2281, 0.1646, 0.0746, 0.3084, 0.0736], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 1.2845,  0.5080,  1.0932, -0.6335, -0.6967], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-6.4442e-05,  8.6591e-04, -9.2185e-04, -6.9880e-04,  4.8483e-04],
       grad_fn=<SliceBackward0>)
  [Layer 2] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 2] Output sample values after mixer: tensor([0.2281, 0.1646, 0.0746, 0.3084, 0.0736], grad_fn=<SliceBackward0>)
  [Layer 2] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 2] Residual connection sample values: tensor([ 0.0789, -0.0565,  0.5500,  0.2239, -0.1969], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 3/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.8194, 0.1788, 2.2876, 1.7750, 1.5697], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.1047, 2.3646, 0.6612, 0.7506, 0.7982], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0756, -0.0455,  0.3942,  0.2298, -0.1802], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-20.9265,  -0.8803,  -0.6735,  -0.6461,  -0.2726],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-1.0730, -0.5554,  0.0647,  0.6970,  1.4762], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-1.0730, -0.5554,  0.0647,  0.6970,  1.4762], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.1058, -1.1216, -1.8151,  1.4390,  0.8499], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([-0.2486,  1.4643,  0.8281,  1.4508,  2.2240], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.0098, 0.0208, 0.0001, 0.0221, 0.0914], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 1.1285, -0.3213,  0.1588, -2.0180,  0.3493], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0298, -0.0323, -0.0045, -0.0356, -0.0376], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0298, -0.0323, -0.0045, -0.0356, -0.0376], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.2740, -0.0228,  0.0077,  0.0569,  0.3353], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2633,  0.7560,  0.2425,  0.7770,  0.1688], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0298, -0.0323, -0.0045, -0.0356, -0.0376], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-2.9270e-04, -3.1629e-04, -4.4566e-05, -3.4919e-04, -3.6912e-04],
       grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-2.0523e-01, -1.8285e-02, -6.9444e-05, -1.4306e-02, -2.4919e-02],
       grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.2740, -0.0228,  0.0077,  0.0569,  0.3353], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2633,  0.7560,  0.2425,  0.7770,  0.1688], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.2052, -0.5049, -0.2066, -0.5886, -0.1520], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.2052, -0.7102, -0.9167, -1.5054, -1.6574], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.2052, -0.5049, -0.2066, -0.5886, -0.1520], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.2052, -0.2052, -0.2052, -0.2052, -0.2052], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0009, -0.0010, -0.0001, -0.0011, -0.0011], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([1.4320e-12, 2.3726e-12, 2.9171e-12, 5.2551e-12, 6.1178e-12],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0013, -0.0002,  0.0001, -0.0002,  0.0004], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -27.4772, -36.5182,   0.0000,  -0.8758],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -27.4772, -27.4772],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -27.4772,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -27.4772,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -27.4772,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 1.1663e-12, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0010, -0.0007, -0.0014, -0.0003,  0.0009], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.8145, 0.4916, 0.3998, 0.2219, 0.1906], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0009, -0.0010, -0.0001, -0.0011, -0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0009, -0.0010, -0.0001, -0.0011, -0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0010, -0.0007, -0.0014, -0.0003,  0.0009], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0221, -0.0239, -0.0034, -0.0264, -0.0279], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0221, -0.0239, -0.0034, -0.0264, -0.0279], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0060,  0.0048, -0.0001, -0.0123, -0.0335], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 5.5880, 10.5941,  5.7412,  6.1640,  7.8345], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.4230, 0.3072, 0.4173, 0.4028, 0.3573], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 4.5808e-03,  3.2706e-03, -6.0038e-05, -7.2938e-03, -2.9590e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 4.5808e-03,  3.2706e-03, -6.0038e-05, -7.2938e-03, -2.9590e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.3072,  0.2183, -0.1187,  0.0266,  0.1890], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 1.1285, -0.3213,  0.1588, -2.0180,  0.3493], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0010, -0.0007, -0.0014, -0.0003,  0.0009], grad_fn=<SliceBackward0>)
  [Layer 3] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 3] Output sample values after mixer: tensor([ 0.3072,  0.2183, -0.1187,  0.0266,  0.1890], grad_fn=<SliceBackward0>)
  [Layer 3] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 3] Residual connection sample values: tensor([ 0.3860,  0.1618,  0.4312,  0.2504, -0.0078], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 4/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.9027, 0.2867, 2.5008, 1.9233, 1.7604], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.0525, 1.8676, 0.6324, 0.7211, 0.7537], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2385,  0.0866,  0.2172,  0.1645, -0.0046], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4907, -0.5048, -0.6491, -0.5552, -0.4657], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.7889, -1.5078, -1.0588, -0.9625,  0.4654], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.7889, -1.5078, -1.0588, -0.9625,  0.4654], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 1.0282, -0.3769, -1.5826, -0.0265,  0.5038], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([2.8056, 2.1581, 1.1814, 2.3263, 1.2434], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.5653, 0.4106, 0.2497, 0.3456, 0.8566], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.1175, -0.5864, -2.3341, -0.8082, -0.7744], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0183,  0.0218,  0.0657, -0.0332,  0.1461], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0183,  0.0218,  0.0657, -0.0332,  0.1461], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.2779,  0.4112, -0.0281, -0.0243, -0.0358], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2723, -0.0352, -0.1912, -0.0750,  0.5312], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0183,  0.0218,  0.0657, -0.0332,  0.1461], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0103,  0.0123,  0.0372, -0.0188,  0.0826], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.2774, -0.2073, -0.1621, -0.1919, -0.3989], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.2779,  0.4112, -0.0281, -0.0243, -0.0358], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2723, -0.0352, -0.1912, -0.0750,  0.5312], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.2774, -0.0693, -0.1043, -0.1604, -0.1293], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.2774, -0.3467, -0.4510, -0.6114, -0.7406], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.2774, -0.0693, -0.1043, -0.1604, -0.1293], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.2774, -0.2774, -0.2774, -0.2774, -0.2774], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0041,  0.0049,  0.0147, -0.0074,  0.0328], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.0126, 0.0135, 0.0150, 0.0176, 0.0200], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0253, -0.0014,  0.0006,  0.0028, -0.0016], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -4.6525, -2.6343,  0.0000, -4.8027], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -4.6525, -4.6525], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -4.6525,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -4.6525,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -4.6525,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.0095, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0286, -0.0033, -0.0004,  0.0013,  0.0006], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.7578, 0.7070, 0.6370, 0.5426, 0.4768], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0041,  0.0049,  0.0147, -0.0074,  0.0328], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0041,  0.0049,  0.0147, -0.0074,  0.0328], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0286, -0.0033, -0.0004,  0.0013,  0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0162,  0.0193,  0.0583, -0.0295,  0.1297], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0162,  0.0193,  0.0583, -0.0295,  0.1297], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0040, -0.0053, -0.0159,  0.0078,  0.0371], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 6.9588,  5.5733,  2.4337, 17.1741,  3.7927], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.3791, 0.4236, 0.6410, 0.2413, 0.5135], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0046, -0.0065, -0.0163,  0.0088,  0.0304], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0046, -0.0065, -0.0163,  0.0088,  0.0304], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.2637, -0.1758, -0.0487,  0.1710,  0.4516], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.1175, -0.5864, -2.3341, -0.8082, -0.7744], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0286, -0.0033, -0.0004,  0.0013,  0.0006], grad_fn=<SliceBackward0>)
  [Layer 4] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 4] Output sample values after mixer: tensor([ 0.2637, -0.1758, -0.0487,  0.1710,  0.4516], grad_fn=<SliceBackward0>)
  [Layer 4] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 4] Residual connection sample values: tensor([ 0.6497, -0.0140,  0.3826,  0.4214,  0.4438], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 5/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1.0184, 0.5775, 2.6760, 2.0786, 3.3042], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.9909, 1.3159, 0.6113, 0.6936, 0.5501], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.5328, -0.0097,  0.2312,  0.3446,  0.3453], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0759, -0.5319, -0.0470, -1.4939, -3.6258], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.9197, -2.5052,  1.3588,  0.5769, -1.4252], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.9197, -2.5052,  1.3588,  0.5769, -1.4252], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-1.6494, -1.4315, -0.6716, -1.4167, -0.3159], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 3.9664,  2.7326,  4.0852,  0.5752, -0.1199], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([2.3031, 0.1962, 1.1725, 0.0248, 0.0144], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-1.0936e+00,  2.0139e-03, -6.2855e-01, -2.4791e+00,  2.1692e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.1837, -0.2152, -0.0510,  0.1045,  0.0215], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.1837, -0.2152, -0.0510,  0.1045,  0.0215], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0307, -0.1030, -0.2765, -0.0032, -0.0663], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.0016, -0.2341, -0.2750, -0.2350, -0.1333], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.1837, -0.2152, -0.0510,  0.1045,  0.0215], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.4232, -0.4957, -0.1174,  0.2407,  0.0496], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.1748, -0.1043, -0.0551, -0.0371, -0.0522], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0307, -0.1030, -0.2765, -0.0032, -0.0663], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.0016, -0.2341, -0.2750, -0.2350, -0.1333], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.1748, -0.0925, -0.0712, -0.0980, -0.1027], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.1748, -0.2673, -0.3385, -0.4365, -0.5392], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.1748, -0.0925, -0.0712, -0.0980, -0.1027], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.1748, -0.1748, -0.1748, -0.1748, -0.1748], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.5726, -0.6706, -0.1589,  0.3257,  0.0671], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.0396, 0.0435, 0.0467, 0.0515, 0.0571], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0065, -0.0635,  0.4514,  0.0417,  0.1598], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -3.4028, -1.5727,  0.0000, -2.1165], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -3.4028, -3.4028], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -3.4028,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -3.4028,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -3.4028,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.0333, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0367, -0.0067,  0.5545,  0.0619, -0.0145], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.8396, 0.7654, 0.7128, 0.6463, 0.5832], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.5726, -0.6706, -0.1589,  0.3257,  0.0671], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.5726, -0.6706, -0.1589,  0.3257,  0.0671], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0367, -0.0067,  0.5545,  0.0619, -0.0145], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.8311, -0.9735, -0.2306,  0.4729,  0.0974], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.8311, -0.9735, -0.2306,  0.4729,  0.0974], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.2179,  0.1841, -0.2493,  0.1747, -0.0269], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([41.5496, 27.7531, 15.7524, 28.3842, 12.6339], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1551, 0.1898, 0.2520, 0.1877, 0.2813], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0112,  0.0100, -0.0277,  0.0213, -0.0036], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0112,  0.0100, -0.0277,  0.0213, -0.0036], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.1417,  0.0921,  0.1259,  0.3432,  0.0533], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-1.0936e+00,  2.0139e-03, -6.2855e-01, -2.4791e+00,  2.1692e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0367, -0.0067,  0.5545,  0.0619, -0.0145], grad_fn=<SliceBackward0>)
  [Layer 5] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 5] Output sample values after mixer: tensor([-0.1417,  0.0921,  0.1259,  0.3432,  0.0533], grad_fn=<SliceBackward0>)
  [Layer 5] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 5] Residual connection sample values: tensor([0.5080, 0.0781, 0.5085, 0.7646, 0.4971], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 6/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1.2070, 0.8380, 3.3193, 2.2938, 4.2212], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.9102, 1.0924, 0.5489, 0.6603, 0.4867], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([0.3389, 0.0430, 0.2644, 0.4890, 0.2963], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5110, -0.2862, -0.5421, -0.3954, -0.5986], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-2.1899,  0.1114,  1.0467, -0.1627, -1.9528], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-2.1899,  0.1114,  1.0467, -0.1627, -1.9528], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 4.8780, -0.4891,  0.7435, -2.9951,  1.1080], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([1.7433, 2.4544, 1.6957, 1.5721, 1.4285], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.6540, 0.8897, 0.3777, 0.5404, 0.3481], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.7951,  1.2019, -2.3852,  0.1846,  0.6422], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0140,  0.0039,  0.1069, -0.0673,  0.1280], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0140,  0.0039,  0.1069, -0.0673,  0.1280], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0928,  0.0951, -0.2783,  0.0311, -0.1567], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.1282, -0.0187, -0.2707, -0.1462, -0.0837], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0140,  0.0039,  0.1069, -0.0673,  0.1280], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0091,  0.0026,  0.0699, -0.0440,  0.0837], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.3342, -0.2546, -0.2048, -0.2137, -0.2084], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0928,  0.0951, -0.2783,  0.0311, -0.1567], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.1282, -0.0187, -0.2707, -0.1462, -0.0837], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.3342, -0.3424, -0.2414, -0.2667, -0.1258], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.3342, -0.6766, -0.9180, -1.1847, -1.3106], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.3342, -0.3424, -0.2414, -0.2667, -0.1258], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.3342, -0.3342, -0.3342, -0.3342, -0.3342], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0133,  0.0037,  0.1014, -0.0638,  0.1213], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([6.7830e-07, 9.5526e-07, 1.2161e-06, 1.5879e-06, 1.8008e-06],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0048,  0.0136, -0.0533,  0.0004,  0.0184], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -14.5379, -11.4525,   0.0000, -11.8543],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -14.5379, -14.5379],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -14.5379,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -14.5379,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -14.5379,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 4.8561e-07, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0062, -0.0066, -0.0185,  0.0121,  0.0156], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.7159, 0.5083, 0.3993, 0.3058, 0.2697], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0133,  0.0037,  0.1014, -0.0638,  0.1213], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0133,  0.0037,  0.1014, -0.0638,  0.1213], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0062, -0.0066, -0.0185,  0.0121,  0.0156], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.0293,  0.0082,  0.2240, -0.1411,  0.2682], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.0293,  0.0082,  0.2240, -0.1411,  0.2682], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0065,  0.0005,  0.1736,  0.0105, -0.0651], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([102.9821,  17.6653,  18.3691,  28.6909,  21.3529],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0985, 0.2379, 0.2333, 0.1867, 0.2164], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0018,  0.0001,  0.0452,  0.0034, -0.0152], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0018,  0.0001,  0.0452,  0.0034, -0.0152], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.3342, -0.1787, -0.3073, -0.2176,  0.2047], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.7951,  1.2019, -2.3852,  0.1846,  0.6422], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0062, -0.0066, -0.0185,  0.0121,  0.0156], grad_fn=<SliceBackward0>)
  [Layer 6] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 6] Output sample values after mixer: tensor([ 0.3342, -0.1787, -0.3073, -0.2176,  0.2047], grad_fn=<SliceBackward0>)
  [Layer 6] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 6] Residual connection sample values: tensor([ 0.8422, -0.1006,  0.2012,  0.5470,  0.7018], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 7/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1.3227, 1.2450, 3.6595, 2.4625, 4.4771], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.8695, 0.8962, 0.5227, 0.6373, 0.4726], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.5331, -0.0517,  0.1005,  0.3495,  0.3853], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-6.5957e-02, -4.5478e+00, -5.8281e+00, -4.2034e-01, -1.9005e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-1.0558, -0.1673, -1.3200, -0.7076, -1.1298], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-1.0558, -0.1673, -1.3200, -0.7076, -1.1298], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-1.2302,  0.9789, -1.7090,  1.2475,  0.4022], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([7.0868, 3.2145, 1.8581, 2.1811, 4.3195], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([6.6501, 0.6089, 0.2129, 0.8433, 2.8351], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.3527, -2.2187, -1.9645, -2.8754, -0.8467], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.1164,  0.0611, -0.1757,  0.0979,  0.0038], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.1164,  0.0611, -0.1757,  0.0979,  0.0038], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0085, -0.0006, -0.0166, -0.0093, -0.0100], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.0617, -0.0432, -0.0254, -0.0119,  0.0227], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.1164,  0.0611, -0.1757,  0.0979,  0.0038], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.7740,  0.4066, -1.1686,  0.6514,  0.0252], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.4386, -2.7693, -1.2406, -0.3545, -0.0054], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0085, -0.0006, -0.0166, -0.0093, -0.0100], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.0617, -0.0432, -0.0254, -0.0119,  0.0227], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.4386, -0.0980, -0.0843, -0.0390, -0.0487], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.4386, -0.5366, -0.6209, -0.6600, -0.7086], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.4386, -0.0980, -0.0843, -0.0390, -0.0487], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.4386, -0.4386, -0.4386, -0.4386, -0.4386], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0880,  0.0462, -0.1329,  0.0741,  0.0029], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.0417, 0.0460, 0.0500, 0.0520, 0.0546], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0093,  0.0027, -0.0148,  0.0206,  0.0678], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000,  -3.6159,  -1.9060,   0.0000, -35.6745],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -3.6159, -3.6159], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -3.6159,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -3.6159,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -3.6159,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.0269, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0866,  0.0324, -0.0286,  0.0375,  0.1092], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.6449, 0.5847, 0.5374, 0.5169, 0.4923], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0880,  0.0462, -0.1329,  0.0741,  0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0880,  0.0462, -0.1329,  0.0741,  0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0866,  0.0324, -0.0286,  0.0375,  0.1092], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.3579,  0.1880, -0.5404,  0.3012,  0.0117], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.3579,  0.1880, -0.5404,  0.3012,  0.0117], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0975, -0.0144,  0.1504, -0.0704, -0.0032], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([14.1837,  7.7730,  7.1276,  9.2120,  3.7971], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2655, 0.3587, 0.3746, 0.3295, 0.5132], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0309, -0.0055,  0.0345, -0.0196, -0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0309, -0.0055,  0.0345, -0.0196, -0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.0924, -0.1412, -0.1255, -0.2991,  0.2160], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.3527, -2.2187, -1.9645, -2.8754, -0.8467], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0866,  0.0324, -0.0286,  0.0375,  0.1092], grad_fn=<SliceBackward0>)
  [Layer 7] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 7] Output sample values after mixer: tensor([-0.0924, -0.1412, -0.1255, -0.2991,  0.2160], grad_fn=<SliceBackward0>)
  [Layer 7] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 7] Residual connection sample values: tensor([ 0.7499, -0.2419,  0.0757,  0.2480,  0.9178], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 8/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1.6008, 1.3938, 4.1485, 3.5577, 5.7720], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.7904, 0.8470, 0.4910, 0.5302, 0.4162], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.5663, -0.1367,  0.0400,  0.1824,  0.5809], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6851, -0.1380, -0.4118, -0.2678, -0.1244], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-2.5206,  0.3025,  0.8428,  0.2330, -0.3747], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-2.5206,  0.3025,  0.8428,  0.2330, -0.3747], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 1.7425, -1.8359,  2.7381, -2.0786, -1.2886], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([3.1816, 3.7145, 3.4075, 3.8241, 3.8442], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.3769, 5.0384, 2.5341, 3.1464, 4.9500], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-1.0655, -2.1382, -1.6702,  0.1199,  1.4567], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.1355,  0.3331,  0.1223, -0.1350, -0.1198], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.1355,  0.3331,  0.1223, -0.1350, -0.1198], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0370,  0.1029, -0.0365, -0.0100, -0.0047], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2182,  0.0113, -0.0370, -0.0430, -0.0470], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.1355,  0.3331,  0.1223, -0.1350, -0.1198], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0511,  0.1255,  0.0461, -0.0509, -0.0451], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.2582, -0.6953, -1.0435, -0.8427, -0.6159], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0370,  0.1029, -0.0365, -0.0100, -0.0047], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2182,  0.0113, -0.0370, -0.0430, -0.0470], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.2582, -1.0192, -0.2820, -0.0568, -0.0346], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.2582, -1.2775, -1.5595, -1.6163, -1.6509], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.2582, -1.0192, -0.2820, -0.0568, -0.0346], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.2582, -0.2582, -0.2582, -0.2582, -0.2582], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0117,  0.0286,  0.0105, -0.0116, -0.0103], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([2.1696e-06, 6.0119e-06, 7.9706e-06, 8.4364e-06, 8.7334e-06],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0026, -0.0283, -0.0038,  0.0205,  0.0070], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -13.2992,  -7.0173,   0.0000, -37.1952],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -13.2992, -13.2992],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -13.2992,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -13.2992,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -13.2992,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 1.6758e-06, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0126,  0.0208,  0.0075,  0.0160, -0.0017], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.7724, 0.2787, 0.2102, 0.1986, 0.1919], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0117,  0.0286,  0.0105, -0.0116, -0.0103], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0117,  0.0286,  0.0105, -0.0116, -0.0103], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0126,  0.0208,  0.0075,  0.0160, -0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.5220,  1.2832,  0.4712, -0.5202, -0.4614], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.5220,  1.2832,  0.4712, -0.5202, -0.4614], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0979,  0.2232,  0.2776, -0.0676,  0.0704], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([112.9296,  91.6895,  87.3977,  78.5868,  50.5674],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0941, 0.1044, 0.1070, 0.1128, 0.1406], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0213,  0.0257,  0.0984, -0.0204,  0.0146], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0213,  0.0257,  0.0984, -0.0204,  0.0146], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.1551, -0.1782, -0.0570, -0.1370,  0.2786], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-1.0655, -2.1382, -1.6702,  0.1199,  1.4567], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0126,  0.0208,  0.0075,  0.0160, -0.0017], grad_fn=<SliceBackward0>)
  [Layer 8] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 8] Output sample values after mixer: tensor([-0.1551, -0.1782, -0.0570, -0.1370,  0.2786], grad_fn=<SliceBackward0>)
  [Layer 8] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 8] Residual connection sample values: tensor([ 0.5947, -0.4201,  0.0187,  0.1110,  1.1964], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 9/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1.8363, 1.8540, 4.9367, 4.0755, 6.8254], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.7380, 0.7344, 0.4501, 0.4953, 0.3828], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.4037, -0.2204,  0.0094,  0.0755,  0.7074], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1701, -0.1135, -0.1054, -0.5864, -0.1497], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-2.9915,  1.7963,  0.8149, -3.8458, -3.2366], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-2.9915,  1.7963,  0.8149, -3.8458, -3.2366], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.5634,  3.7571, -0.2162,  1.1134, -0.0962], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([3.7637, 4.6013, 4.9421, 3.3625, 3.4078], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([4.1959, 5.4115, 6.7313, 2.0178, 3.6279], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 1.5564,  2.5571, -0.6423,  0.8244,  1.8412], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.1399,  0.2735, -0.0098,  0.0449, -0.0166], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.1399,  0.2735, -0.0098,  0.0449, -0.0166], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.1852,  0.0395,  0.0778, -0.2771, -0.2349], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.0031, -0.2747,  0.1724, -0.0909, -0.0355], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.1399,  0.2735, -0.0098,  0.0449, -0.0166], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.5870,  1.1477, -0.0413,  0.1884, -0.0695], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.7136, -0.6143, -0.7095, -1.1833, -0.5429], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.1852,  0.0395,  0.0778, -0.2771, -0.2349], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.0031, -0.2747,  0.1724, -0.0909, -0.0355], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.7136, -0.7474, -0.5562, -0.6661, -0.2375], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.7136, -1.4611, -2.0173, -2.6834, -2.9209], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.7136, -0.7474, -0.5562, -0.6661, -0.2375], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.7136, -0.7136, -0.7136, -0.7136, -0.7136], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0640, -0.1252,  0.0045, -0.0206,  0.0076], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([1.9090e-15, 4.0310e-15, 7.0305e-15, 1.3685e-14, 1.7354e-14],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0707,  0.0186, -0.1185,  0.1158,  0.0087], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -34.6058, -33.6640,   0.0000, -30.7926],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -34.6058, -34.6058],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -34.6058,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -34.6058,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -34.6058,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 9.3515e-16, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0827, -0.2881, -0.0985,  0.5054,  0.4394], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.4899, 0.2320, 0.1330, 0.0683, 0.0539], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0640, -0.1252,  0.0045, -0.0206,  0.0076], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0640, -0.1252,  0.0045, -0.0206,  0.0076], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0827, -0.2881, -0.0985,  0.5054,  0.4394], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.3108,  0.6077, -0.0219,  0.0998, -0.0368], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.3108,  0.6077, -0.0219,  0.0998, -0.0368], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0445,  0.9363, -0.0124, -0.0080,  0.0045], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([37.6054, 44.4704, 51.8645, 35.0517, 25.0892], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1631, 0.1500, 0.1389, 0.1689, 0.1996], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0063,  0.2471, -0.0022, -0.0016,  0.0009], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0063,  0.2471, -0.0022, -0.0016,  0.0009], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.6412, -0.4104,  0.0233, -0.4571,  0.3146], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 1.5564,  2.5571, -0.6423,  0.8244,  1.8412], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0827, -0.2881, -0.0985,  0.5054,  0.4394], grad_fn=<SliceBackward0>)
  [Layer 9] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 9] Output sample values after mixer: tensor([ 0.6412, -0.4104,  0.0233, -0.4571,  0.3146], grad_fn=<SliceBackward0>)
  [Layer 9] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 9] Residual connection sample values: tensor([ 1.2360, -0.8305,  0.0420, -0.3461,  1.5110], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 10/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([2.3121, 2.4652, 5.4788, 4.8531, 8.2392], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.6577, 0.6369, 0.4272, 0.4539, 0.3484], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.8021, -0.4118,  0.0203, -0.2209,  0.8302], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0854, -0.0771, -0.0845, -0.0547, -0.0697], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-1.9963, -1.2883,  1.2612, -2.3474, -0.8940], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-1.9963, -1.2883,  1.2612, -2.3474, -0.8940], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 3.2111,  0.2778, -0.0888,  5.4533,  1.7911], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 3.7970,  4.7383,  4.2964,  5.1841, 10.3825], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([ 4.8837,  2.4890,  2.0751,  6.2855, 10.1079], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.6577, -1.7999, -1.7704, -3.1215, -1.5575], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.1951, -0.0227, -0.0108,  1.1815, -0.1257], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.1951, -0.0227, -0.0108,  1.1815, -0.1257], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0168,  0.0359,  0.0447, -0.1788, -0.0354], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2160, -0.2637, -0.1261, -0.2495, -0.2694], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.1951, -0.0227, -0.0108,  1.1815, -0.1257], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.9530, -0.1108, -0.0526,  5.7700, -0.6138], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.4168, -0.1919, -0.1754, -0.3437, -0.7042], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0168,  0.0359,  0.0447, -0.1788, -0.0354], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2160, -0.2637, -0.1261, -0.2495, -0.2694], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.4168, -0.3688, -0.3288, -0.3837, -0.2012], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.4168, -0.7857, -1.1145, -1.4982, -1.6994], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.4168, -0.3688, -0.3288, -0.3837, -0.2012], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.4168, -0.4168, -0.4168, -0.4168, -0.4168], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.8934, -0.1038, -0.0493,  5.4088, -0.5753], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([2.3040e-08, 3.3317e-08, 4.6289e-08, 6.7937e-08, 8.3079e-08],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.2329, -0.1855,  0.0112,  0.1907, -0.0735], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -18.0029, -14.0079,   0.0000,  -3.3606],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -18.0029, -18.0029],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -18.0029,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -18.0029,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -18.0029,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 1.5186e-08, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0241, -0.8618,  0.0502,  0.4646,  0.1069], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.6591, 0.4558, 0.3281, 0.2235, 0.1828], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.8934, -0.1038, -0.0493,  5.4088, -0.5753], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.8934, -0.1038, -0.0493,  5.4088, -0.5753], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0241, -0.8618,  0.0502,  0.4646,  0.1069], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-1.8435, -0.2143, -0.1017, 11.1616, -1.1873], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-1.8435, -0.2143, -0.1017, 11.1616, -1.1873], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.4401,  0.0597, -0.1000, -2.2866,  0.3081], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([308.9697, 288.9635, 286.4846, 163.3535, 176.1174],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0569, 0.0588, 0.0591, 0.0782, 0.0754], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0153,  0.0044, -0.0081, -0.1430,  0.0234], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0153,  0.0044, -0.0081, -0.1430,  0.0234], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.2689, -0.5812,  0.2777, -0.7230,  0.2876], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.6577, -1.7999, -1.7704, -3.1215, -1.5575], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0241, -0.8618,  0.0502,  0.4646,  0.1069], grad_fn=<SliceBackward0>)
  [Layer 10] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 10] Output sample values after mixer: tensor([ 0.2689, -0.5812,  0.2777, -0.7230,  0.2876], grad_fn=<SliceBackward0>)
  [Layer 10] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 10] Residual connection sample values: tensor([ 1.5049, -1.4117,  0.3197, -1.0691,  1.7986], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 11/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 2.8073,  3.0899,  6.9916,  7.3429, 12.0506], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.5968, 0.5689, 0.3782, 0.3690, 0.2881], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.6486, -0.4937,  0.1085, -0.5032,  0.6861], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2593, -0.1261, -0.1036, -0.2378, -0.4305], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 2.5168, -1.2347, -0.5302,  1.4704, -2.4432], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 2.5168, -1.2347, -0.5302,  1.4704, -2.4432], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.8521, -1.0097, -2.3287, -1.4686,  0.5468], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([2.4208, 8.8165, 6.6715, 3.4671, 2.6430], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([1.2763, 6.2014, 4.8686, 3.2737, 2.7626], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.7890,  0.3704,  2.1559,  0.6833, -0.6695], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0595,  0.2048,  0.4417,  0.1933,  0.1197], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0595,  0.2048,  0.4417,  0.1933,  0.1197], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.2775,  0.0072, -0.0466, -0.2460,  0.0211], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2767, -0.2713,  0.1278,  0.0572, -0.2546], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0595,  0.2048,  0.4417,  0.1933,  0.1197], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0759,  0.2613,  0.5637,  0.2468,  0.1528], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.3310, -0.7823, -0.5042, -0.7783, -1.1893], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.2775,  0.0072, -0.0466, -0.2460,  0.0211], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2767, -0.2713,  0.1278,  0.0572, -0.2546], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.3310, -0.0643, -0.0035, -0.0276, -0.1668], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.3310, -0.3953, -0.3988, -0.4264, -0.5933], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.3310, -0.0643, -0.0035, -0.0276, -0.1668], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.3310, -0.3310, -0.3310, -0.3310, -0.3310], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0616,  0.2119,  0.4571,  0.2001,  0.1239], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.0112, 0.0120, 0.0120, 0.0123, 0.0146], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.1225,  0.0167,  0.0226, -0.0803,  0.0323], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -4.8217, -3.2683,  0.0000, -2.8607], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -4.8217, -4.8217], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -4.8217,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -4.8217,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -4.8217,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.0081, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.1859,  0.0106,  0.0185, -0.0871,  0.1165], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.7182, 0.6735, 0.6711, 0.6528, 0.5525], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0616,  0.2119,  0.4571,  0.2001,  0.1239], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0616,  0.2119,  0.4571,  0.2001,  0.1239], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.1859,  0.0106,  0.0185, -0.0871,  0.1165], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.1261, -0.4339, -0.9359, -0.4097, -0.2537], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.1261, -0.4339, -0.9359, -0.4097, -0.2537], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.2937,  0.1207,  0.1838, -0.4899,  0.0495], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([44.0246, 30.7744, 30.7007, 25.3164, 12.3374], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1507, 0.1803, 0.1805, 0.1987, 0.2847], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0155,  0.0473,  0.1291, -0.0647,  0.0076], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0155,  0.0473,  0.1291, -0.0647,  0.0076], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.6630,  0.4218, -0.2308, -0.0657, -0.1812], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.7890,  0.3704,  2.1559,  0.6833, -0.6695], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.1859,  0.0106,  0.0185, -0.0871,  0.1165], grad_fn=<SliceBackward0>)
  [Layer 11] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 11] Output sample values after mixer: tensor([-0.6630,  0.4218, -0.2308, -0.0657, -0.1812], grad_fn=<SliceBackward0>)
  [Layer 11] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 11] Residual connection sample values: tensor([ 0.8419, -0.9899,  0.0889, -1.1348,  1.6174], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 12/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 3.3136,  4.3127,  7.7944,  8.2705, 13.4147], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.5493, 0.4815, 0.3582, 0.3477, 0.2730], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2965, -0.2777,  0.0228, -0.4532,  0.4820], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1609, -0.1475, -0.2713, -0.1155, -0.0902], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-2.0309, -2.8131,  1.5870, -0.9669, -0.5957], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-2.0309, -2.8131,  1.5870, -0.9669, -0.5957], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.7558,  0.9996,  0.1295, -0.1917, -0.6383], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([1.8005, 3.9658, 1.7827, 0.8060, 8.7906], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([2.4169, 3.7360, 2.6060, 2.2538, 6.1658], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.1816, -0.5676,  0.6179, -2.6214,  0.5762], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0450, -0.2329, -0.0394, -0.0432, -0.0252], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0450, -0.2329, -0.0394, -0.0432, -0.0252], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0097, -0.2644,  0.1933,  0.3735,  0.0232], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.1801, -0.2344, -0.1981, -0.2633,  0.7612], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0450, -0.2329, -0.0394, -0.0432, -0.0252], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.1088, -0.5629, -0.0953, -0.1043, -0.0608], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.3888, -0.5510, -0.7069, -0.2604, -0.5559], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0097, -0.2644,  0.1933,  0.3735,  0.0232], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.1801, -0.2344, -0.1981, -0.2633,  0.7612], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.3888, -0.3874, -0.3997, -0.3746, -0.2194], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.3888, -0.7762, -1.1759, -1.5505, -1.7700], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.3888, -0.3874, -0.3997, -0.3746, -0.2194], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.3888, -0.3888, -0.3888, -0.3888, -0.3888], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.1185, -0.6132, -0.1038, -0.1136, -0.0663], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([7.7160e-09, 1.1367e-08, 1.6952e-08, 2.4656e-08, 3.0706e-08],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0559, -0.0139,  0.0410, -0.1072, -0.0190], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -19.0688, -16.3647,   0.0000, -12.9559],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -19.0688, -19.0688],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -19.0688,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -19.0688,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -19.0688,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 5.2304e-09, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0191,  0.2447,  0.0695,  0.0653, -0.0096], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.6779, 0.4601, 0.3085, 0.2121, 0.1703], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.1185, -0.6132, -0.1038, -0.1136, -0.0663], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.1185, -0.6132, -0.1038, -0.1136, -0.0663], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0191,  0.2447,  0.0695,  0.0653, -0.0096], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.1916, -0.9912, -0.1677, -0.1837, -0.1071], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.1916, -0.9912, -0.1677, -0.1837, -0.1071], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0451,  0.1579, -0.2210,  0.0489,  0.0227], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([71.1954, 58.7371, 50.5841, 38.3054, 26.1922], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1185, 0.1305, 0.1406, 0.1616, 0.1954], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0081,  0.0166, -0.0455,  0.0190,  0.0035], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0081,  0.0166, -0.0455,  0.0190,  0.0035], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.1974, -0.6923,  0.3134, -0.2587, -0.0098], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.1816, -0.5676,  0.6179, -2.6214,  0.5762], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0191,  0.2447,  0.0695,  0.0653, -0.0096], grad_fn=<SliceBackward0>)
  [Layer 12] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 12] Output sample values after mixer: tensor([-0.1974, -0.6923,  0.3134, -0.2587, -0.0098], grad_fn=<SliceBackward0>)
  [Layer 12] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 12] Residual connection sample values: tensor([ 0.6445, -1.6822,  0.4023, -1.3935,  1.6077], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 13/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 4.0750,  4.7799,  8.5992,  9.7163, 16.4852], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.4954, 0.4574, 0.3410, 0.3208, 0.2463], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1726, -0.3678,  0.0837, -0.4014,  0.3861], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0234, -1.0903, -0.5085, -0.6785, -0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.5339, -0.2758, -2.7528, -1.5597, -0.2673], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.5339, -0.2758, -2.7528, -1.5597, -0.2673], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.6050, -1.5175, -0.2687, -0.3032, -0.7960], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 2.4213,  0.3042,  0.7623, -0.1611,  0.7021], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.4746, 0.0136, 0.0182, 0.0045, 0.2869], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 1.2613,  0.1104,  0.2791, -0.4165,  0.0063], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0411, -0.0482,  0.0023, -0.0129, -0.0902], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0411, -0.0482,  0.0023, -0.0129, -0.0902], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0117, -0.1379,  0.2391, -0.1315, -0.0225], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.0208, -0.0071,  0.7881,  0.2825, -0.1084], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0411, -0.0482,  0.0023, -0.0129, -0.0902], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0195, -0.0229,  0.0011, -0.0061, -0.0428], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.0111, -0.0148, -0.0092, -0.0030, -0.0072], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0117, -0.1379,  0.2391, -0.1315, -0.0225], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.0208, -0.0071,  0.7881,  0.2825, -0.1084], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0111, -0.0065, -0.0020, -0.0048, -0.0047], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0111, -0.0176, -0.0196, -0.0244, -0.0292], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0111, -0.0065, -0.0020, -0.0048, -0.0047], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0111, -0.0111, -0.0111, -0.0111, -0.0111], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0118, -0.0138,  0.0007, -0.0037, -0.0259], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.7069, 0.7115, 0.7129, 0.7164, 0.7198], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0024,  0.1026, -0.2163, -0.0289, -0.0160], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -0.3580, -0.2394,  0.0000, -0.7910], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.3580, -0.3580], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.3580,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.3580,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -0.3580,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.6991, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0933,  0.1015, -0.2838,  0.0239, -0.0602], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9890, 0.9826, 0.9806, 0.9759, 0.9713], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0118, -0.0138,  0.0007, -0.0037, -0.0259], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0118, -0.0138,  0.0007, -0.0037, -0.0259], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0933,  0.1015, -0.2838,  0.0239, -0.0602], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0071, -0.0083,  0.0004, -0.0022, -0.0155], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0071, -0.0083,  0.0004, -0.0022, -0.0155], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 1.3923e-03,  9.8481e-04, -6.6341e-05,  5.9858e-04,  1.7939e-03],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1.5761, 0.9717, 0.6615, 0.7482, 0.5064], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.7965, 1.0144, 1.2295, 1.1561, 1.4052], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 5.5613e-04,  2.6027e-04, -5.9397e-05,  1.2656e-03,  8.2328e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 5.5613e-04,  2.6027e-04, -5.9397e-05,  1.2656e-03,  8.2328e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.3484,  0.2106,  0.2283,  0.2822, -0.9076], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 1.2613,  0.1104,  0.2791, -0.4165,  0.0063], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0933,  0.1015, -0.2838,  0.0239, -0.0602], grad_fn=<SliceBackward0>)
  [Layer 13] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 13] Output sample values after mixer: tensor([-0.3484,  0.2106,  0.2283,  0.2822, -0.9076], grad_fn=<SliceBackward0>)
  [Layer 13] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 13] Residual connection sample values: tensor([ 0.2961, -1.4715,  0.6306, -1.1113,  0.7001], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 14/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 4.8518,  5.9280, 10.3045, 11.5673, 20.7253], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.4540, 0.4107, 0.3115, 0.2940, 0.2197], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0639, -0.2740,  0.1148, -0.2712,  0.1414], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-7.2745, -0.0385, -2.2024, -0.0138, -5.3378], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.2738,  0.0347, -1.6256, -0.2466, -0.6287], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.2738,  0.0347, -1.6256, -0.2466, -0.6287], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.7421, -1.2104,  0.9867, -0.1826,  0.5618], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([1.5139, 1.1357, 1.4540, 2.0233, 0.9023], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.0901, 0.1751, 0.0494, 0.3271, 0.0397], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 1.7219,  1.0343, -0.9049,  1.7297, -0.3704], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.1278, -0.1382,  0.0376,  0.0006, -0.0771], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.1278, -0.1382,  0.0376,  0.0006, -0.0771], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.1670, -0.0922,  0.0211, -0.0209, -0.0390], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.1775, -0.2009,  0.0298, -0.1920, -0.0217], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.1278, -0.1382,  0.0376,  0.0006, -0.0771], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 1.1514e-02, -1.2457e-02,  3.3847e-03,  5.1942e-05, -6.9499e-03],
       grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.6556, -0.0068, -0.1088, -0.0045, -0.2118], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.1670, -0.0922,  0.0211, -0.0209, -0.0390], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.1775, -0.2009,  0.0298, -0.1920, -0.0217], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.6556, -2.9824, -0.7692, -0.7737, -0.2603], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.6556, -3.6380, -4.4073, -5.1809, -5.4412], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.6556, -2.9824, -0.7692, -0.7737, -0.2603], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.6556, -0.6556, -0.6556, -0.6556, -0.6556], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 1.6690e-02, -1.8057e-02,  4.9063e-03,  7.5292e-05, -1.0074e-02],
       grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([7.5803e-12, 1.4960e-10, 3.2285e-10, 6.9985e-10, 9.0788e-10],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0015,  0.0012, -0.0008,  0.0011, -0.0014], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -26.2611, -21.8401,   0.0000,  -0.3179],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -26.2611, -26.2611],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -26.2611,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -26.2611,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -26.2611,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 3.9351e-12, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-5.5004e-04, -1.1122e-03,  5.5212e-04,  2.9094e-05,  7.2752e-04],
       grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.5191, 0.0263, 0.0122, 0.0056, 0.0043], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 1.6690e-02, -1.8057e-02,  4.9063e-03,  7.5292e-05, -1.0074e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 1.6690e-02, -1.8057e-02,  4.9063e-03,  7.5292e-05, -1.0074e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-5.5004e-04, -1.1122e-03,  5.5212e-04,  2.9094e-05,  7.2752e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.1172, -0.1268,  0.0345,  0.0005, -0.0708], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.1172, -0.1268,  0.0345,  0.0005, -0.0708], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-1.3867e-02, -2.2388e-03, -9.2118e-03, -5.7200e-05,  1.5473e-02],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.7851, 0.4304, 0.3406, 0.2356, 0.1023], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.1286, 1.5242, 1.7135, 2.0601, 3.1270], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0369, -0.0042, -0.0117, -0.0001,  0.0362], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0369, -0.0042, -0.0117, -0.0001,  0.0362], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.7113,  0.2970,  0.9587,  0.0975, -0.8468], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 1.7219,  1.0343, -0.9049,  1.7297, -0.3704], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-5.5004e-04, -1.1122e-03,  5.5212e-04,  2.9094e-05,  7.2752e-04],
       grad_fn=<SliceBackward0>)
  [Layer 14] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 14] Output sample values after mixer: tensor([-0.7113,  0.2970,  0.9587,  0.0975, -0.8468], grad_fn=<SliceBackward0>)
  [Layer 14] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 14] Residual connection sample values: tensor([-0.4151, -1.1745,  1.5892, -1.0137, -0.1467], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 15/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 6.9048,  7.0991, 12.8111, 14.8257, 26.3397], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.3806, 0.3753, 0.2794, 0.2597, 0.1948], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0961, -0.2237,  0.3039, -0.2782, -0.0317], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.4414, -0.0592, -0.7390, -0.0051, -0.0087], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.1726, -2.3674,  1.6572, -1.5534, -5.2250], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.1726, -2.3674,  1.6572, -1.5534, -5.2250], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.3190,  0.5486, -1.5145, -1.7222,  0.1132], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([1.0657, 9.7007, 1.9992, 0.9395, 1.9326], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.1705, 9.1457, 0.1514, 0.1195, 0.7099], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 1.2414,  1.7406, -0.4331, -1.1423, -1.4087], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.1288, -0.0434,  0.9041,  0.0507, -0.0068], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.1288, -0.0434,  0.9041,  0.0507, -0.0068], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0119,  0.0093, -0.0033, -0.0028, -0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.0250, -0.1124, -0.0200, -0.0492, -0.0333], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.1288, -0.0434,  0.9041,  0.0507, -0.0068], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0220, -0.0074,  0.1542,  0.0087, -0.0012], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.4163, -0.5418, -0.1119, -0.0006, -0.0062], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0119,  0.0093, -0.0033, -0.0028, -0.0012], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.0250, -0.1124, -0.0200, -0.0492, -0.0333], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.4163, -1.2381, -0.3427, -0.8929, -0.3804], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.4163, -1.6544, -1.9971, -2.8901, -3.2705], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.4163, -1.2381, -0.3427, -0.8929, -0.3804], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.4163, -0.4163, -0.4163, -0.4163, -0.4163], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0059, -0.0020,  0.0413,  0.0023, -0.0003], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([1.1001e-22, 3.7945e-22, 5.3454e-22, 1.3055e-21, 1.9098e-21],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0008, -0.0006, -0.0009,  0.0005,  0.0007], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -50.9778, -37.3725,   0.0000,  -5.4521],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -50.9778, -50.9778],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -50.9778,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -50.9778,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -50.9778,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 7.2550e-23, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([0.0018, 0.0062, 0.0039, 0.0010, 0.0036], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.6595, 0.1912, 0.1357, 0.0556, 0.0380], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0059, -0.0020,  0.0413,  0.0023, -0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0059, -0.0020,  0.0413,  0.0023, -0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([0.0018, 0.0062, 0.0039, 0.0010, 0.0036], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.2358, -0.0795,  1.6558,  0.0929, -0.0124], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.2358, -0.0795,  1.6558,  0.0929, -0.0124], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 1.8600e-02,  1.6122e-02,  2.3045e+00, -2.5206e-02,  3.4681e-04],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([3.5573, 2.9584, 3.0766, 2.4277, 1.2008], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.5302, 0.5814, 0.5701, 0.6418, 0.9126], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 2.1785e-02,  1.3782e-02,  5.7900e-01, -1.6640e-02,  4.1444e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 2.1785e-02,  1.3782e-02,  5.7900e-01, -1.6640e-02,  4.1444e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.4965, -0.1770,  0.5400,  0.0121,  0.6607], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 1.2414,  1.7406, -0.4331, -1.1423, -1.4087], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([0.0018, 0.0062, 0.0039, 0.0010, 0.0036], grad_fn=<SliceBackward0>)
  [Layer 15] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 15] Output sample values after mixer: tensor([-0.4965, -0.1770,  0.5400,  0.0121,  0.6607], grad_fn=<SliceBackward0>)
  [Layer 15] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 15] Residual connection sample values: tensor([-0.9116, -1.3515,  2.1292, -1.0016,  0.5140], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 16/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 7.6773,  8.6365, 14.9184, 17.1009, 29.8558], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.3609, 0.3403, 0.2589, 0.2418, 0.1830], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1485, -0.1820,  0.2672, -0.2070,  0.0792], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.1349e-03, -3.0370e-03, -2.7156e+00, -4.1511e-03, -4.2926e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 0.3227,  1.2846, -5.1683,  1.8774, -0.5865], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 0.3227,  1.2846, -5.1683,  1.8774, -0.5865], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-1.0393,  0.7194, -0.1939, -3.5391, -0.5716], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 1.9858,  0.2591, -0.7195,  2.0055, -0.3634], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.4746, 0.0850, 0.0116, 0.1852, 0.0008], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.6860,  0.3611,  0.2483,  1.2534, -0.3168], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0017, -0.0533,  0.0627, -0.0254,  0.0060], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0017, -0.0533,  0.0627, -0.0254,  0.0060], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0110,  0.0071, -0.0046, -0.0025, -0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.0294, -0.0669, -0.0767, -0.0787, -0.0736], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0017, -0.0533,  0.0627, -0.0254,  0.0060], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0008, -0.0253,  0.0298, -0.0120,  0.0028], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.0005, -0.0003, -0.0314, -0.0008, -0.0003], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0110,  0.0071, -0.0046, -0.0025, -0.0013], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.0294, -0.0669, -0.0767, -0.0787, -0.0736], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0005, -0.0021, -0.0001, -0.0003, -0.0010], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0005, -0.0027, -0.0028, -0.0031, -0.0040], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0005, -0.0021, -0.0001, -0.0003, -0.0010], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0005, -0.0005, -0.0005, -0.0005, -0.0005], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-2.5205e-05, -7.8327e-04,  9.2091e-04, -3.7273e-04,  8.8001e-05],
       grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.9497, 0.9517, 0.9518, 0.9521, 0.9530], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0087,  0.0393,  0.0213,  0.0086,  0.0068], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -0.0522, -0.0484,  0.0000, -0.0664], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.0522, -0.0522], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.0522,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.0522,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -0.0522,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.9492, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0028,  0.1109,  0.0340,  0.0024,  0.0055], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9995, 0.9973, 0.9972, 0.9969, 0.9960], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-2.5205e-05, -7.8327e-04,  9.2091e-04, -3.7273e-04,  8.8001e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-2.5205e-05, -7.8327e-04,  9.2091e-04, -3.7273e-04,  8.8001e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0028,  0.1109,  0.0340,  0.0024,  0.0055], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.0004,  0.0116, -0.0137,  0.0055, -0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.0004,  0.0116, -0.0137,  0.0055, -0.0013], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([7.0020e-05, 1.1696e-02, 3.9995e-04, 9.0072e-03, 2.7378e-04],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.2581, 0.1369, 0.1219, 0.1197, 0.0457], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.9683, 2.7026, 2.8637, 2.8897, 4.6763], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([6.0432e-05, 5.7470e-03, 7.9107e-04, 3.1013e-03, 2.7971e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([6.0432e-05, 5.7470e-03, 7.9107e-04, 3.1013e-03, 2.7971e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.1374,  0.7501, -0.5650,  0.1031,  0.1388], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.6860,  0.3611,  0.2483,  1.2534, -0.3168], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0028,  0.1109,  0.0340,  0.0024,  0.0055], grad_fn=<SliceBackward0>)
  [Layer 16] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 16] Output sample values after mixer: tensor([ 0.1374,  0.7501, -0.5650,  0.1031,  0.1388], grad_fn=<SliceBackward0>)
  [Layer 16] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 16] Residual connection sample values: tensor([-0.7742, -0.6015,  1.5642, -0.8985,  0.6528], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 17/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 8.6789,  9.4069, 16.3357, 18.8320, 32.6971], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.3394, 0.3260, 0.2474, 0.2304, 0.1749], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1775, -0.1186,  0.3083, -0.2360,  0.1378], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3863, -0.8773, -1.4027, -0.6828, -0.3905], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-2.9998, -0.7258,  0.0111, -2.5419, -1.7176], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-2.9998, -0.7258,  0.0111, -2.5419, -1.7176], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.2545,  0.4274, -1.1495,  0.0742, -0.9357], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([1.4183, 3.1297, 1.6428, 2.5631, 3.1554], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.4809, 1.0915, 0.5413, 1.5474, 2.2839], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.6258,  1.0799, -0.4500,  0.2817, -2.2508], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0603,  0.0112, -0.1579,  0.0261, -0.0645], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0603,  0.0112, -0.1579,  0.0261, -0.0645], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0068,  0.0496, -0.2780, -0.0451,  0.1260], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.0841,  0.2549, -0.2737, -0.2084, -0.0320], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0603,  0.0112, -0.1579,  0.0261, -0.0645], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0290,  0.0054, -0.0759,  0.0126, -0.0310], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.6667, -0.9576, -0.7593, -1.0565, -0.8918], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0068,  0.0496, -0.2780, -0.0451,  0.1260], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.0841,  0.2549, -0.2737, -0.2084, -0.0320], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.6667, -1.7750, -0.5749, -0.5272, -0.7907], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.6667, -2.4417, -3.0165, -3.5437, -4.3344], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.6667, -1.7750, -0.5749, -0.5272, -0.7907], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.6667, -0.6667, -0.6667, -0.6667, -0.6667], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0135,  0.0025, -0.0354,  0.0059, -0.0145], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([2.0436e-28, 1.2058e-27, 2.1425e-27, 3.6298e-27, 8.0032e-27],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0011,  0.0011,  0.0135,  0.0049, -0.0038], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -64.4243, -73.1318,   0.0000, -29.7139],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -64.4243, -64.4243],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -64.4243,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -64.4243,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -64.4243,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0492e-28, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0139, -0.0107,  0.0331,  0.0104,  0.0213], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.5134, 0.0870, 0.0490, 0.0289, 0.0131], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0135,  0.0025, -0.0354,  0.0059, -0.0145], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0135,  0.0025, -0.0354,  0.0059, -0.0145], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0139, -0.0107,  0.0331,  0.0104,  0.0213], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.1724,  0.0320, -0.4513,  0.0747, -0.1844], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.1724,  0.0320, -0.4513,  0.0747, -0.1844], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0245, -0.0076, -0.0025, -0.0139,  0.0482], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([15.8805,  9.5662,  8.0912,  7.9845,  3.3898], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2509, 0.3233, 0.3516, 0.3539, 0.5431], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0120, -0.0038, -0.0013, -0.0090,  0.0288], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0120, -0.0038, -0.0013, -0.0090,  0.0288], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 1.0521, -0.1036, -0.1847, -0.5898, -0.0895], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.6258,  1.0799, -0.4500,  0.2817, -2.2508], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0139, -0.0107,  0.0331,  0.0104,  0.0213], grad_fn=<SliceBackward0>)
  [Layer 17] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 17] Output sample values after mixer: tensor([ 1.0521, -0.1036, -0.1847, -0.5898, -0.0895], grad_fn=<SliceBackward0>)
  [Layer 17] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 17] Residual connection sample values: tensor([ 0.2779, -0.7051,  1.3795, -1.4882,  0.5633], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 18/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 9.9130, 10.9300, 19.5048, 23.4651, 36.1093], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.3176, 0.3025, 0.2264, 0.2064, 0.1664], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0423, -0.0929,  0.1791, -0.2756,  0.0760], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.3195e-03, -6.5336e+00, -1.4897e+01, -1.3796e-03, -2.0873e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 0.2998,  0.8725, -0.6228,  1.0622, -2.2547], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 0.2998,  0.8725, -0.6228,  1.0622, -2.2547], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.6609,  1.3204,  2.1790, -0.1010,  0.9613], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 3.1536,  1.9867,  1.4733,  4.2468, -0.6388], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([1.4576, 3.1422, 2.9721, 2.2089, 0.0747], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.3418,  0.3794,  0.0273,  0.2538,  0.3518], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0522, -0.2782, -0.1867,  0.0094, -0.0135], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0522, -0.2782, -0.1867,  0.0094, -0.0135], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0066,  0.0018, -0.0178,  0.0049, -0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.1219, -0.0943, -0.0951, -0.0570, -0.0249], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0522, -0.2782, -0.1867,  0.0094, -0.0135], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0762, -0.4055, -0.2721,  0.0137, -0.0197], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-3.3810e-03, -2.0530e+01, -4.4276e+01, -3.0474e-03, -1.5592e-04],
       grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0066,  0.0018, -0.0178,  0.0049, -0.0011], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.1219, -0.0943, -0.0951, -0.0570, -0.0249], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0034, -0.0006, -0.0013, -0.0006, -0.0007], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0034, -0.0040, -0.0053, -0.0059, -0.0066], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0034, -0.0006, -0.0013, -0.0006, -0.0007], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0034, -0.0034, -0.0034, -0.0034, -0.0034], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0208, -0.1108, -0.0743,  0.0037, -0.0054], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.9268, 0.9274, 0.9285, 0.9291, 0.9297], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0149, -0.0302,  0.0747,  0.0543, -0.0241], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000e+00, -7.9395e-02, -9.9504e-02,  0.0000e+00, -1.9261e+03],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.0794, -0.0794], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.0794,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.0794,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -0.0794,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.9237, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0020, -0.0087,  0.0935, -0.0382,  0.0123], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9966, 0.9960, 0.9947, 0.9942, 0.9935], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0208, -0.1108, -0.0743,  0.0037, -0.0054], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0208, -0.1108, -0.0743,  0.0037, -0.0054], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0020, -0.0087,  0.0935, -0.0382,  0.0123], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0167, -0.0888, -0.0596,  0.0030, -0.0043], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0167, -0.0888, -0.0596,  0.0030, -0.0043], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0029, -0.0546,  0.0130,  0.0024,  0.0009], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 5.8694,  7.3547, 10.8466, 14.9020,  5.3111], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.4128, 0.3687, 0.3036, 0.2590, 0.4339], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0058, -0.0272,  0.0058,  0.0025,  0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0058, -0.0272,  0.0058,  0.0025,  0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.0895, -0.2016,  0.1567, -0.1480,  0.4902], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.3418,  0.3794,  0.0273,  0.2538,  0.3518], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0020, -0.0087,  0.0935, -0.0382,  0.0123], grad_fn=<SliceBackward0>)
  [Layer 18] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 18] Output sample values after mixer: tensor([ 0.0895, -0.2016,  0.1567, -0.1480,  0.4902], grad_fn=<SliceBackward0>)
  [Layer 18] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 18] Residual connection sample values: tensor([ 0.3674, -0.9066,  1.5362, -1.6363,  1.0535], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 19/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([11.2488, 11.9229, 22.1693, 25.8545, 39.6390], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2982, 0.2896, 0.2124, 0.1967, 0.1588], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0653, -0.1338,  0.2292, -0.3597,  0.1663], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1739, -1.5063, -1.5725, -0.1983, -0.0768], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.0245, -0.8327, -0.4350, -1.6171, -1.5430], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.0245, -0.8327, -0.4350, -1.6171, -1.5430], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.4549, -0.1167, -0.4621, -1.3342, -0.4863], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([4.3059, 3.4403, 4.1322, 3.3594, 4.9877], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([5.2681, 2.4156, 3.1880, 4.5217, 4.1837], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.1823, -0.5119, -1.3610, -1.4364, -1.3586], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0137, -0.0043, -0.0566,  0.2275, -0.0413], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0137, -0.0043, -0.0566,  0.2275, -0.0413], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0114, -0.1198, -0.2766, -0.0961, -0.0763], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.1539, -0.0333, -0.1224, -0.0247,  0.1117], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0137, -0.0043, -0.0566,  0.2275, -0.0413], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0719, -0.0225, -0.2982,  1.1982, -0.2177], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.9163, -3.6387, -5.0130, -0.8965, -0.3214], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0114, -0.1198, -0.2766, -0.0961, -0.0763], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.1539, -0.0333, -0.1224, -0.0247,  0.1117], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.9163, -0.6656, -0.4539, -0.4593, -0.3307], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.9163, -1.5819, -2.0358, -2.4951, -2.8258], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.9163, -0.6656, -0.4539, -0.4593, -0.3307], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.9163, -0.9163, -0.9163, -0.9163, -0.9163], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0484, -0.0151, -0.2006,  0.8060, -0.1465], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([4.2000e-13, 8.1714e-13, 1.2865e-12, 2.0366e-12, 2.8347e-12],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0152,  0.1502, -0.0631,  0.0055,  0.0272], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([   0.0000,  -29.4149,  -30.0832,    0.0000, -101.5224],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -29.4149, -29.4149],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -29.4149,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -29.4149,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -29.4149,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 1.6799e-13, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0074,  0.0346, -0.0783,  0.0637, -0.0637], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.4000, 0.2056, 0.1306, 0.0825, 0.0593], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0484, -0.0151, -0.2006,  0.8060, -0.1465], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0484, -0.0151, -0.2006,  0.8060, -0.1465], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0074,  0.0346, -0.0783,  0.0637, -0.0637], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0692, -0.0216, -0.2868,  1.1524, -0.2094], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0692, -0.0216, -0.2868,  1.1524, -0.2094], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0008,  0.0055,  0.0490, -0.3086,  0.0569], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([26.8197, 17.1668, 15.1059, 10.4448,  6.2641], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1931, 0.2414, 0.2573, 0.3094, 0.3995], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0002,  0.0021,  0.0227, -0.0589,  0.0402], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0002,  0.0021,  0.0227, -0.0589,  0.0402], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.7205,  0.0249, -0.2862, -0.6518, -0.0344], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.1823, -0.5119, -1.3610, -1.4364, -1.3586], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0074,  0.0346, -0.0783,  0.0637, -0.0637], grad_fn=<SliceBackward0>)
  [Layer 19] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 19] Output sample values after mixer: tensor([ 0.7205,  0.0249, -0.2862, -0.6518, -0.0344], grad_fn=<SliceBackward0>)
  [Layer 19] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 19] Residual connection sample values: tensor([ 1.0880, -0.8817,  1.2500, -2.2881,  1.0191], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 20/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([12.9465, 15.1459, 26.4940, 30.2481, 45.8823], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2779, 0.2570, 0.1943, 0.1818, 0.1476], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1115, -0.0827,  0.1174, -0.2871,  0.1021], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.0858e-01, -2.9306e+00, -5.2962e+00, -1.2326e+01, -8.1593e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.5659, -1.0491,  0.1820, -0.5317, -0.1058], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.5659, -1.0491,  0.1820, -0.5317, -0.1058], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.5645, -0.7653,  0.1127,  1.0085,  0.7340], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 1.9252,  1.7576, -0.5412,  1.3008,  0.9575], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.0476, 0.1434, 0.0350, 0.2554, 0.1064], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 1.1222,  1.2875, -0.8696,  0.8534,  0.0166], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0540,  0.0741, -0.0653,  0.0944,  0.0182], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0540,  0.0741, -0.0653,  0.0944,  0.0182], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-1.7065e-03,  1.8858e-05, -3.4978e-03, -9.0871e-03, -7.9460e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.1374, -0.0962, -0.1690, -0.1568,  0.2256], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0540,  0.0741, -0.0653,  0.0944,  0.0182], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0026,  0.0035, -0.0031,  0.0045,  0.0009], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-1.4702e-02, -4.2032e-01, -1.8549e-01, -3.1486e+00, -8.6806e-04],
       grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-1.7065e-03,  1.8858e-05, -3.4978e-03, -9.0871e-03, -7.9460e-03],
       grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.1374, -0.0962, -0.1690, -0.1568,  0.2256], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0147, -0.0015, -0.0028, -0.0006, -0.0017], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0147, -0.0162, -0.0191, -0.0196, -0.0213], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0147, -0.0015, -0.0028, -0.0006, -0.0017], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0147, -0.0147, -0.0147, -0.0147, -0.0147], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-3.9049e-06, -5.3649e-06,  4.7275e-06, -6.8312e-06, -1.3148e-06],
       grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.7770, 0.7781, 0.7803, 0.7808, 0.7821], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0002, -0.0002,  0.0004,  0.0002, -0.0003], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000,  -0.2671,  -0.1985,   0.0000, -16.8422],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.2671, -0.2671], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.2671,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.2671,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -0.2671,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.7656, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-1.6985e-04, -2.9668e-04, -2.1619e-04,  6.3830e-06, -6.2588e-05],
       grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9854, 0.9839, 0.9811, 0.9805, 0.9789], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-3.9049e-06, -5.3649e-06,  4.7275e-06, -6.8312e-06, -1.3148e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-3.9049e-06, -5.3649e-06,  4.7275e-06, -6.8312e-06, -1.3148e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-1.6985e-04, -2.9668e-04, -2.1619e-04,  6.3830e-06, -6.2588e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.0444,  0.0610, -0.0537,  0.0776,  0.0149], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.0444,  0.0610, -0.0537,  0.0776,  0.0149], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0091, -0.0166, -0.0053, -0.0153, -0.0007], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.1213, 0.0577, 0.0477, 0.0442, 0.0218], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([2.8713, 4.1628, 4.5759, 4.7538, 6.7781], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0654, -0.1027, -0.0227, -0.1069, -0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0654, -0.1027, -0.0227, -0.1069, -0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.4201, -1.0349,  0.2851, -0.4384, -0.3212], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 1.1222,  1.2875, -0.8696,  0.8534,  0.0166], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-1.6985e-04, -2.9668e-04, -2.1619e-04,  6.3830e-06, -6.2588e-05],
       grad_fn=<SliceBackward0>)
  [Layer 20] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 20] Output sample values after mixer: tensor([ 0.4201, -1.0349,  0.2851, -0.4384, -0.3212], grad_fn=<SliceBackward0>)
  [Layer 20] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 20] Residual connection sample values: tensor([ 1.5080, -1.9166,  1.5351, -2.7265,  0.6979], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 21/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([14.2056, 16.7363, 28.8536, 32.1309, 51.6530], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2653, 0.2444, 0.1862, 0.1764, 0.1391], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2022, -0.2325,  0.1908, -0.4323,  0.0900], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3228, -0.3764, -0.1595, -0.1054, -0.3757], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.0990, -0.8384, -1.8348, -0.0380, -0.7905], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.0990, -0.8384, -1.8348, -0.0380, -0.7905], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.6126,  0.0227,  0.5934, -1.7850,  0.1984], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([1.8948, 2.4238, 3.8695, 7.6721, 2.9606], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([2.1033, 2.2867, 4.1032, 7.0836, 2.7304], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 2.2801,  0.2690, -1.6583, -0.2675,  1.4411], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0816, -0.0435, -0.0119,  0.2401, -0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0816, -0.0435, -0.0119,  0.2401, -0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.2749, -0.0984, -0.0429, -0.0982,  0.0082], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.0668, -0.0661, -0.0738, -0.0846, -0.2659], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0816, -0.0435, -0.0119,  0.2401, -0.0004], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.1717, -0.0916, -0.0250,  0.5051, -0.0008], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.6789, -0.8607, -0.6543, -0.7466, -1.0258], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.2749, -0.0984, -0.0429, -0.0982,  0.0082], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.0668, -0.0661, -0.0738, -0.0846, -0.2659], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.6789, -0.9370, -0.3349, -0.1864, -0.3336], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.6789, -1.6159, -1.9508, -2.1372, -2.4707], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.6789, -0.9370, -0.3349, -0.1864, -0.3336], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.6789, -0.6789, -0.6789, -0.6789, -0.6789], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0284, -0.0151, -0.0041,  0.0835, -0.0001], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([1.3994e-11, 3.5719e-11, 4.9926e-11, 6.0156e-11, 8.3973e-11],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([0.0468, 0.1062, 0.0292, 0.0450, 0.0094], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -25.6713, -22.5332,   0.0000, -29.0122],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -25.6713, -25.6713],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -25.6713,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -25.6713,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -25.6713,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 7.0976e-12, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([0.1281, 0.1284, 0.0231, 0.1116, 0.0096], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.5072, 0.1987, 0.1422, 0.1180, 0.0845], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0284, -0.0151, -0.0041,  0.0835, -0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0284, -0.0151, -0.0041,  0.0835, -0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([0.1281, 0.1284, 0.0231, 0.1116, 0.0096], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.2009, -0.1071, -0.0292,  0.5910, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.2009, -0.1071, -0.0292,  0.5910, -0.0010], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0095,  0.0271,  0.0074, -0.0110,  0.0002], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([4.8128, 2.7295, 3.5117, 3.1758, 1.5654], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.4558, 0.6053, 0.5336, 0.5611, 0.7993], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0090,  0.0325,  0.0100, -0.0105,  0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0090,  0.0325,  0.0100, -0.0105,  0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.1468, -0.9651, -0.8512, -0.7054, -0.0471], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 2.2801,  0.2690, -1.6583, -0.2675,  1.4411], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([0.1281, 0.1284, 0.0231, 0.1116, 0.0096], grad_fn=<SliceBackward0>)
  [Layer 21] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 21] Output sample values after mixer: tensor([-0.1468, -0.9651, -0.8512, -0.7054, -0.0471], grad_fn=<SliceBackward0>)
  [Layer 21] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 21] Residual connection sample values: tensor([ 1.3612, -2.8817,  0.6839, -3.4319,  0.6508], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 22/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([15.7150, 18.4927, 31.0681, 35.8866, 59.1389], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2523, 0.2325, 0.1794, 0.1669, 0.1300], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1776, -0.3477,  0.0826, -0.5288,  0.0822], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0709, -0.0702, -0.0699, -0.0895, -0.3897], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 0.2106,  0.1640,  0.0406, -3.6609, -0.2006], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 0.2106,  0.1640,  0.0406, -3.6609, -0.2006], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 1.1112, -0.9185, -0.8812,  0.4522, -0.4514], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([3.9999, 3.5419, 4.6451, 6.7442, 2.5250], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([3.6008, 3.7070, 2.6210, 5.8043, 2.6460], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.7631, -0.2586, -0.6772, -1.7266,  0.5110], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0095,  0.0525,  0.0098,  0.0398, -0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0095,  0.0525,  0.0098,  0.0398, -0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0634, -0.0201, -0.0150,  0.0268,  0.0089], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2288, -0.1563, -0.0196,  0.1843,  0.1359], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0095,  0.0525,  0.0098,  0.0398, -0.0012], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0342,  0.1889,  0.0352,  0.1434, -0.0044], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.2553, -0.2603, -0.1833, -0.5192, -1.0311], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0634, -0.0201, -0.0150,  0.0268,  0.0089], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2288, -0.1563, -0.0196,  0.1843,  0.1359], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.2553, -0.0540, -0.0282, -0.0258, -0.0978], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.2553, -0.3093, -0.3376, -0.3634, -0.4612], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.2553, -0.0540, -0.0282, -0.0258, -0.0978], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.2553, -0.2553, -0.2553, -0.2553, -0.2553], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0182,  0.1003,  0.0187,  0.0761, -0.0024], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.0199, 0.0210, 0.0216, 0.0221, 0.0244], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0653,  0.0855,  0.0502, -0.0499,  0.0770], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -4.1743, -2.7132,  0.0000, -3.7201], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -4.1743, -4.1743], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -4.1743,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -4.1743,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -4.1743,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.0154, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0118,  0.0442,  0.0208,  0.0044,  0.0535], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.7747, 0.7339, 0.7135, 0.6953, 0.6306], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0182,  0.1003,  0.0187,  0.0761, -0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0182,  0.1003,  0.0187,  0.0761, -0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0118,  0.0442,  0.0208,  0.0044,  0.0535], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.0018,  0.0099,  0.0018,  0.0075, -0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.0018,  0.0099,  0.0018,  0.0075, -0.0002], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 2.0800e-04,  8.7486e-04,  3.8120e-05, -6.8665e-04,  2.0903e-05],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([14.6590,  7.2653,  7.9586,  6.9721,  3.7084], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2612, 0.3710, 0.3545, 0.3787, 0.5193], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 1.4356e-04,  2.6153e-04,  2.6311e-05, -7.0406e-04,  1.3766e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 1.4356e-04,  2.6153e-04,  2.6311e-05, -7.0406e-04,  1.3766e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.4123, -0.9452,  0.4040,  0.3172,  0.3559], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.7631, -0.2586, -0.6772, -1.7266,  0.5110], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0118,  0.0442,  0.0208,  0.0044,  0.0535], grad_fn=<SliceBackward0>)
  [Layer 22] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 22] Output sample values after mixer: tensor([ 0.4123, -0.9452,  0.4040,  0.3172,  0.3559], grad_fn=<SliceBackward0>)
  [Layer 22] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 22] Residual connection sample values: tensor([ 1.7735, -3.8269,  1.0879, -3.1146,  1.0066], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 23/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([17.1245, 21.2194, 35.8037, 37.7311, 62.2666], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2417, 0.2171, 0.1671, 0.1628, 0.1267], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1884, -0.3673,  0.1099, -0.4068,  0.0995], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1232, -0.2255, -0.2420, -0.0956, -0.2396], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 0.1430,  0.8022, -0.8056, -0.6780, -0.2219], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 0.1430,  0.8022, -0.8056, -0.6780, -0.2219], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.2875, -0.4444,  0.9695,  0.6605, -0.1214], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([2.2796, 2.2383, 2.0201, 2.5253, 1.9157], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.5475, 1.1777, 1.0107, 0.6757, 0.8323], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.3716, -0.2201, -2.9223, -0.9369, -0.3473], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0059, -0.0118, -0.0468,  0.0094, -0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0059, -0.0118, -0.0468,  0.0094, -0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.3652,  0.0474, -0.0122,  0.2125,  0.0198], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.1976,  0.3795, -0.0290,  0.0951, -0.0404], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0059, -0.0118, -0.0468,  0.0094, -0.0012], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0032, -0.0065, -0.0256,  0.0051, -0.0007], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.0675, -0.2656, -0.2446, -0.0646, -0.1994], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.3652,  0.0474, -0.0122,  0.2125,  0.0198], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.1976,  0.3795, -0.0290,  0.0951, -0.0404], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0675, -0.0220, -0.0168, -0.0243, -0.0313], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0675, -0.0895, -0.1062, -0.1305, -0.1619], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0675, -0.0220, -0.0168, -0.0243, -0.0313], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0675, -0.0675, -0.0675, -0.0675, -0.0675], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0024, -0.0049, -0.0194,  0.0039, -0.0005], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.1807, 0.1847, 0.1878, 0.1924, 0.1986], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0234, -0.0012, -0.0087,  0.0277,  0.0030], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -1.7785, -1.1299,  0.0000, -7.3776], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.7785, -1.7785], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.7785,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.7785,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -1.7785,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.1689, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0270, -0.0024,  0.0003,  0.0616, -0.0141], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9348, 0.9144, 0.8992, 0.8776, 0.8506], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0024, -0.0049, -0.0194,  0.0039, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0024, -0.0049, -0.0194,  0.0039, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0270, -0.0024,  0.0003,  0.0616, -0.0141], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0022, -0.0043, -0.0172,  0.0034, -0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0022, -0.0043, -0.0172,  0.0034, -0.0004], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-1.6577e-04, -2.4060e-03,  4.2717e-03, -7.8375e-04,  4.3970e-05],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.4339, 0.3771, 0.5725, 0.7346, 0.3041], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.5181, 1.6284, 1.3216, 1.1668, 1.8133], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0002, -0.0109,  0.0318, -0.0059,  0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0002, -0.0109,  0.0318, -0.0059,  0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.2819, -0.1194,  0.3791,  0.0270, -0.2985], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.3716, -0.2201, -2.9223, -0.9369, -0.3473], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0270, -0.0024,  0.0003,  0.0616, -0.0141], grad_fn=<SliceBackward0>)
  [Layer 23] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 23] Output sample values after mixer: tensor([ 0.2819, -0.1194,  0.3791,  0.0270, -0.2985], grad_fn=<SliceBackward0>)
  [Layer 23] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 23] Residual connection sample values: tensor([ 2.0555, -3.9463,  1.4669, -3.0876,  0.7081], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 24/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([17.7438, 21.8396, 37.2831, 38.9221, 64.3330], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2374, 0.2140, 0.1638, 0.1603, 0.1247], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2695, -0.4593,  0.1855, -0.4646,  0.0855], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6296, -0.1967, -0.1434, -0.1402, -0.2238], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-1.1596, -0.5239,  1.7184, -0.6401,  0.5500], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-1.1596, -0.5239,  1.7184, -0.6401,  0.5500], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-1.3616,  0.2121,  0.4027, -0.1699, -0.0431], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([2.8095, 3.1168, 3.7477, 1.8948, 2.3567], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([3.0160, 3.2790, 3.5461, 2.7348, 1.9807], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-1.0317,  0.5313, -0.1848, -0.1602, -0.4936], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.4719,  0.0648,  0.0194, -0.0563,  0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.4719,  0.0648,  0.0194, -0.0563,  0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0726, -0.0941, -0.0325, -0.0321,  0.1207], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.0139,  0.0211, -0.2444, -0.0611, -0.2722], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.4719,  0.0648,  0.0194, -0.0563,  0.0092], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 1.4232,  0.1956,  0.0587, -0.1698,  0.0278], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-1.8989, -0.6450, -0.5084, -0.3834, -0.4433], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0726, -0.0941, -0.0325, -0.0321,  0.1207], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.0139,  0.0211, -0.2444, -0.0611, -0.2722], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-1.8989, -1.4157, -0.7571, -0.6599, -0.5864], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-1.8989, -3.3146, -4.0718, -4.7317, -5.3180], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-1.8989, -1.4157, -0.7571, -0.6599, -0.5864], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-1.8989, -1.8989, -1.8989, -1.8989, -1.8989], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.4185,  0.0575,  0.0172, -0.0499,  0.0082], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([3.4076e-20, 1.4037e-19, 2.9929e-19, 5.7901e-19, 1.0408e-18],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0085, -0.0030, -0.0089,  0.0026, -0.0015], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -46.7246, -37.0324,   0.0000, -19.2264],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -46.7246, -46.7246],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -46.7246,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -46.7246,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -46.7246,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 5.1021e-21, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 1.0623e-01, -1.9638e-02,  6.8724e-03,  3.2378e-02, -9.8225e-06],
       grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.1497, 0.0363, 0.0170, 0.0088, 0.0049], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.4185,  0.0575,  0.0172, -0.0499,  0.0082], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.4185,  0.0575,  0.0172, -0.0499,  0.0082], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 1.0623e-01, -1.9638e-02,  6.8724e-03,  3.2378e-02, -9.8225e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 2.7298,  0.3751,  0.1125, -0.3256,  0.0533], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 2.7298,  0.3751,  0.1125, -0.3256,  0.0533], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.7557, -0.0731,  0.1639,  0.0720,  0.0186], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([15.1539,  8.0685,  8.9045,  8.4660,  4.5046], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2569, 0.3520, 0.3351, 0.3437, 0.4712], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2142, -0.0647,  0.1276,  0.0416,  0.0100], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.2142, -0.0647,  0.1276,  0.0416,  0.0100], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.8734, -1.5446,  0.7562, -0.2424,  0.2637], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-1.0317,  0.5313, -0.1848, -0.1602, -0.4936], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 1.0623e-01, -1.9638e-02,  6.8724e-03,  3.2378e-02, -9.8225e-06],
       grad_fn=<SliceBackward0>)
  [Layer 24] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 24] Output sample values after mixer: tensor([ 0.8734, -1.5446,  0.7562, -0.2424,  0.2637], grad_fn=<SliceBackward0>)
  [Layer 24] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 24] Residual connection sample values: tensor([ 2.9289, -5.4909,  2.2231, -3.3300,  0.9718], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 25/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([19.9409, 26.0204, 40.0457, 40.8294, 71.0309], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2239, 0.1960, 0.1580, 0.1565, 0.1187], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2519, -0.4383,  0.1782, -0.3279,  0.0783], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1626, -0.3327, -0.3294, -0.2016, -0.1541], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.7391, -0.5179, -0.6866, -0.3955, -0.7710], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.7391, -0.5179, -0.6866, -0.3955, -0.7710], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.3333,  0.7416, -0.5091, -0.0120, -0.4469], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([2.0857, 1.1208, 0.6112, 2.0219, 2.4696], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([1.9966, 0.8332, 0.5619, 1.6387, 2.2192], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.0622, -0.0075, -0.1695,  0.0134,  0.2790], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0519, -0.0114,  0.1147, -0.0508, -0.0437], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0519, -0.0114,  0.1147, -0.0508, -0.0437], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0146, -0.0132, -0.0100, -0.0222, -0.0315], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.1804, -0.0567, -0.2322, -0.2606, -0.0188], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0519, -0.0114,  0.1147, -0.0508, -0.0437], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.1037, -0.0228,  0.2291, -0.1014, -0.0872], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.3247, -0.2772, -0.1851, -0.3303, -0.3420], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0146, -0.0132, -0.0100, -0.0222, -0.0315], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.1804, -0.0567, -0.2322, -0.2606, -0.0188], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.3247, -0.2433, -0.1608, -0.1870, -0.1576], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.3247, -0.5680, -0.7288, -0.9158, -1.0734], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.3247, -0.2433, -0.1608, -0.1870, -0.1576], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.3247, -0.3247, -0.3247, -0.3247, -0.3247], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0054, -0.0012,  0.0119, -0.0053, -0.0045], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([4.0499e-05, 5.1655e-05, 6.0669e-05, 7.3142e-05, 8.5625e-05],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0057,  0.0001,  0.0129,  0.0068, -0.0030], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -10.4389,  -7.6603,   0.0000, -12.3111],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -10.4389, -10.4389],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -10.4389,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -10.4389,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -10.4389,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 2.9271e-05, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0028,  0.0008, -0.0033,  0.0016, -0.0099], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.7228, 0.5667, 0.4825, 0.4002, 0.3419], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0054, -0.0012,  0.0119, -0.0053, -0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0054, -0.0012,  0.0119, -0.0053, -0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0028,  0.0008, -0.0033,  0.0016, -0.0099], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0531, -0.0117,  0.1173, -0.0519, -0.0446], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0531, -0.0117,  0.1173, -0.0519, -0.0446], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0127,  0.0023, -0.0270,  0.0083,  0.0109], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.4430, 0.2046, 0.2573, 0.3130, 0.1606], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.5024, 2.2105, 1.9712, 1.7875, 2.4955], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0663,  0.0092, -0.0922,  0.0158,  0.0322], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0663,  0.0092, -0.0922,  0.0158,  0.0322], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.6240, -0.6897,  0.4104, -0.1761,  0.8997], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.0622, -0.0075, -0.1695,  0.0134,  0.2790], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0028,  0.0008, -0.0033,  0.0016, -0.0099], grad_fn=<SliceBackward0>)
  [Layer 25] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 25] Output sample values after mixer: tensor([-0.6240, -0.6897,  0.4104, -0.1761,  0.8997], grad_fn=<SliceBackward0>)
  [Layer 25] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 25] Residual connection sample values: tensor([ 2.3048, -6.1806,  2.6335, -3.5061,  1.8715], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 26/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([22.0520, 29.0875, 43.3109, 45.9146, 79.8315], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2129, 0.1854, 0.1520, 0.1476, 0.1119], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2346, -0.5861,  0.2626, -0.4287,  0.1822], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3298, -0.0634, -0.2289, -0.1264, -0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-1.2820,  1.7342, -1.4831,  1.2545,  0.0460], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-1.2820,  1.7342, -1.4831,  1.2545,  0.0460], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.5988,  1.2541,  0.8694, -1.0698, -1.0107], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([2.9486, 7.3457, 4.6504, 3.7171, 7.1817], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([2.7256, 5.7862, 6.0054, 4.8025, 6.8322], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.2224, -0.8596,  0.4920, -1.0918,  1.5441], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0269,  0.2016, -0.0921, -0.1461, -0.2094], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0269,  0.2016, -0.0921, -0.1461, -0.2094], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0274,  0.0315, -0.0448, -0.0599, -0.0400], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.3766, -0.1774, -0.1515, -0.1617,  0.0695], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0269,  0.2016, -0.0921, -0.1461, -0.2094], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0734,  0.5494, -0.2510, -0.3982, -0.5707], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.8988, -0.3670, -1.3745, -0.6070, -0.3992], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0274,  0.0315, -0.0448, -0.0599, -0.0400], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.3766, -0.1774, -0.1515, -0.1617,  0.0695], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.8988, -0.8061, -0.5693, -0.4238, -0.4632], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.8988, -1.7049, -2.2741, -2.6980, -3.1612], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.8988, -0.8061, -0.5693, -0.4238, -0.4632], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.8988, -0.8988, -0.8988, -0.8988, -0.8988], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0643,  0.4812, -0.2198, -0.3487, -0.4999], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([5.4952e-13, 1.2304e-12, 2.1741e-12, 3.3217e-12, 5.2789e-12],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.2137, -0.0035, -0.0778, -0.0129, -0.0099], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -29.1285, -26.5165,   0.0000,  -4.5514],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -29.1285, -29.1285],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -29.1285,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -29.1285,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -29.1285,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 2.2368e-13, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0141,  0.0329, -0.0192, -0.0231, -0.0267], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.4071, 0.1818, 0.1029, 0.0673, 0.0424], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0643,  0.4812, -0.2198, -0.3487, -0.4999], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0643,  0.4812, -0.2198, -0.3487, -0.4999], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0141,  0.0329, -0.0192, -0.0231, -0.0267], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.1729,  1.2941, -0.5913, -0.9379, -1.3444], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.1729,  1.2941, -0.5913, -0.9379, -1.3444], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0481,  1.9075,  0.1622, -0.9155, -0.0317], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([13.1918, 11.7223, 14.7884, 15.8170,  6.3020], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2753, 0.2921, 0.2600, 0.2514, 0.3983], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0314,  0.8673,  0.0974, -0.6040, -0.0154], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0314,  0.8673,  0.0974, -0.6040, -0.0154], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.9409,  0.1054, -0.4180,  0.7947,  0.5719], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.2224, -0.8596,  0.4920, -1.0918,  1.5441], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0141,  0.0329, -0.0192, -0.0231, -0.0267], grad_fn=<SliceBackward0>)
  [Layer 26] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 26] Output sample values after mixer: tensor([-0.9409,  0.1054, -0.4180,  0.7947,  0.5719], grad_fn=<SliceBackward0>)
  [Layer 26] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 26] Residual connection sample values: tensor([ 1.3640, -6.0752,  2.2155, -2.7114,  2.4435], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 27/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([23.6881, 33.3177, 47.6611, 52.5854, 92.5546], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2055, 0.1732, 0.1448, 0.1379, 0.1039], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1168, -0.4952,  0.1830, -0.2683,  0.2107], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5626, -0.0303, -0.7559, -1.1613, -0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.8228, -0.4448,  1.4390,  0.4261,  0.2643], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.8228, -0.4448,  1.4390,  0.4261,  0.2643], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-1.4378,  0.1608,  0.0262,  3.1256,  0.2117], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([0.1944, 1.4779, 2.1231, 2.0555, 0.9034], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.0926, 0.1822, 0.0753, 0.4856, 0.0765], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.5601,  0.0666, -0.4002,  0.9614,  0.7037], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.2111, -0.0015, -0.0241, -0.2149,  0.0117], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.2111, -0.0015, -0.0241, -0.2149,  0.0117], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0249, -0.0906, -0.0160,  0.0019, -0.0363], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2277,  0.0760, -0.1365, -0.1812, -0.1611], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.2111, -0.0015, -0.0241, -0.2149,  0.0117], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0195, -0.0001, -0.0022, -0.0199,  0.0011], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.0521, -0.0055, -0.0569, -0.5639, -0.0031], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0249, -0.0906, -0.0160,  0.0019, -0.0363], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2277,  0.0760, -0.1365, -0.1812, -0.1611], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0521, -0.0992, -0.0889, -0.0732, -0.1002], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0521, -0.1513, -0.2402, -0.3134, -0.4136], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0521, -0.0992, -0.0889, -0.0732, -0.1002], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0521, -0.0521, -0.0521, -0.0521, -0.0521], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0178, -0.0001, -0.0020, -0.0182,  0.0010], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.0008, 0.0009, 0.0010, 0.0011, 0.0012], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0019, -0.0323, -0.0187,  0.0051,  0.0093], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -7.1560, -6.8780,  0.0000, -0.1575], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -7.1560, -7.1560], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -7.1560,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -7.1560,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -7.1560,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 7.8017e-04, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0007, -0.0106, -0.0056, -0.0090, -0.0042], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9492, 0.8596, 0.7865, 0.7309, 0.6613], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0178, -0.0001, -0.0020, -0.0182,  0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0178, -0.0001, -0.0020, -0.0182,  0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0007, -0.0106, -0.0056, -0.0090, -0.0042], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.4376, -0.0031, -0.0499, -0.4454,  0.0243], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.4376, -0.0031, -0.0499, -0.4454,  0.0243], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1099,  0.0005, -0.0581, -0.1148,  0.0036], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1.7976, 0.7704, 0.7628, 0.7561, 0.4250], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.7459, 1.1393, 1.1449, 1.1500, 1.5339], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1882,  0.0007, -0.1129, -0.0575,  0.0090], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.1882,  0.0007, -0.1129, -0.0575,  0.0090], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.1824,  0.7463,  0.2206, -0.3826, -0.1010], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.5601,  0.0666, -0.4002,  0.9614,  0.7037], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0007, -0.0106, -0.0056, -0.0090, -0.0042], grad_fn=<SliceBackward0>)
  [Layer 27] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 27] Output sample values after mixer: tensor([-0.1824,  0.7463,  0.2206, -0.3826, -0.1010], grad_fn=<SliceBackward0>)
  [Layer 27] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 27] Residual connection sample values: tensor([ 1.1815, -5.3289,  2.4361, -3.0940,  2.3424], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 28/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([25.2346, 34.7517, 47.5278, 56.6890, 92.9867], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1991, 0.1696, 0.1451, 0.1328, 0.1037], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0839, -0.3641,  0.1701, -0.2568,  0.1611], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5442, -0.1843, -0.1064, -0.1124, -0.2523], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 0.3580, -1.3065,  0.2039, -0.0656,  0.1421], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 0.3580, -1.3065,  0.2039, -0.0656,  0.1421], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-1.9011, -0.4441, -0.1790,  0.5847, -1.5695], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([1.1365, 1.8451, 2.1716, 2.1829, 1.3403], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.4784, 1.6469, 2.6449, 2.5485, 1.2108], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.3739,  0.1485, -0.8534,  0.5593, -0.1374], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.2413, -0.0958, -0.0793, -0.1015, -0.1555], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.2413, -0.0958, -0.0793, -0.1015, -0.1555], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.2775,  0.0016,  0.0523,  0.0474, -0.1065], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.0172, -0.0801, -0.1154, -0.2119, -0.0227], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.2413, -0.0958, -0.0793, -0.1015, -0.1555], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.1154, -0.0458, -0.0379, -0.0485, -0.0744], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.2604, -0.3035, -0.2815, -0.2865, -0.3056], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.2775,  0.0016,  0.0523,  0.0474, -0.1065], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.0172, -0.0801, -0.1154, -0.2119, -0.0227], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.2604, -0.4533, -0.1702, -0.1323, -0.0907], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.2604, -0.7137, -0.8839, -1.0162, -1.1069], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.2604, -0.4533, -0.1702, -0.1323, -0.0907], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.2604, -0.2604, -0.2604, -0.2604, -0.2604], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0080, -0.0032, -0.0026, -0.0034, -0.0052], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([3.6679e-05, 5.7716e-05, 6.8424e-05, 7.8104e-05, 8.5522e-05],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0129, -0.0070, -0.0031,  0.0009, -0.0022], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -10.4737, -11.7637,   0.0000,  -9.8966],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -10.4737, -10.4737],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -10.4737,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -10.4737,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -10.4737,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 2.8271e-05, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0134, -0.0055,  0.0040, -0.0009,  0.0165], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.7708, 0.4898, 0.4132, 0.3620, 0.3306], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0080, -0.0032, -0.0026, -0.0034, -0.0052], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0080, -0.0032, -0.0026, -0.0034, -0.0052], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0134, -0.0055,  0.0040, -0.0009,  0.0165], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.4581, -0.1819, -0.1506, -0.1927, -0.2952], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.4581, -0.1819, -0.1506, -0.1927, -0.2952], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0965,  0.0506, -0.0169,  0.0061, -0.0225], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.3619, 0.1609, 0.2382, 0.2554, 0.1047], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.6622, 2.4930, 2.0489, 1.9788, 3.0906], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.3272,  0.1612, -0.0514,  0.0215, -0.0918], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.3272,  0.1612, -0.0514,  0.0215, -0.0918], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.4783, -1.3292,  0.7245,  0.4275,  0.4977], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.3739,  0.1485, -0.8534,  0.5593, -0.1374], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0134, -0.0055,  0.0040, -0.0009,  0.0165], grad_fn=<SliceBackward0>)
  [Layer 28] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 28] Output sample values after mixer: tensor([-0.4783, -1.3292,  0.7245,  0.4275,  0.4977], grad_fn=<SliceBackward0>)
  [Layer 28] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 28] Residual connection sample values: tensor([ 0.7032, -6.6581,  3.1606, -2.6665,  2.8401], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 29/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 28.8510,  42.3346,  62.6905,  64.0425, 102.9493],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1862, 0.1537, 0.1263, 0.1250, 0.0986], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0576, -0.5387,  0.2610, -0.2700,  0.2338], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6542, -0.1369, -1.4589, -0.3682, -0.1218], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.6494, -0.7484, -0.8180, -1.6960, -0.4910], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.6494, -0.7484, -0.8180, -1.6960, -0.4910], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.7918, -0.6095,  0.6781,  0.0799,  1.8618], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([1.7715, 2.0127, 2.2136, 1.5659, 2.1732], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.4120, 0.3539, 0.6459, 0.4191, 1.3793], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.7403,  0.2795, -0.4068,  0.7908, -0.8444], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0782,  0.0316, -0.1304,  0.2065,  1.2343], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0782,  0.0316, -0.1304,  0.2065,  1.2343], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0076, -0.0238, -0.0135, -0.0321, -0.0101], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.0102,  0.1101, -0.0818, -0.0669, -0.0447], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0782,  0.0316, -0.1304,  0.2065,  1.2343], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0322,  0.0130, -0.0537,  0.0851,  0.5085], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.2695, -0.0485, -0.9423, -0.1543, -0.1680], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0076, -0.0238, -0.0135, -0.0321, -0.0101], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.0102,  0.1101, -0.0818, -0.0669, -0.0447], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.2695, -0.3994, -0.1310, -0.1295, -0.3066], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.2695, -0.6689, -0.7999, -0.9294, -1.2360], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.2695, -0.3994, -0.1310, -0.1295, -0.3066], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.2695, -0.2695, -0.2695, -0.2695, -0.2695], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0034,  0.0014, -0.0057,  0.0091,  0.0543], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([1.0024e-05, 1.4945e-05, 1.7037e-05, 1.9393e-05, 2.6352e-05],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0054,  0.0022,  0.0071,  0.0032,  0.0014], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -11.7800,  -8.7791,   0.0000,  -1.8582],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -11.7800, -11.7800],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -11.7800,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -11.7800,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -11.7800,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 7.6561e-06, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 8.9399e-03,  5.5751e-05,  4.5479e-04, -2.4119e-03,  2.3020e-03],
       grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.7638, 0.5123, 0.4494, 0.3948, 0.2905], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0034,  0.0014, -0.0057,  0.0091,  0.0543], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0034,  0.0014, -0.0057,  0.0091,  0.0543], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 8.9399e-03,  5.5751e-05,  4.5479e-04, -2.4119e-03,  2.3020e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.1348,  0.0545, -0.2250,  0.3563,  2.1291], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.1348,  0.0545, -0.2250,  0.3563,  2.1291], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0300, -0.0131,  0.0563, -0.0936, -0.3969], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.6353, 0.3726, 0.4998, 0.6318, 0.2938], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.2546, 1.6382, 1.4145, 1.2580, 1.8449], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1232, -0.0420,  0.1348, -0.2751, -0.1806], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.1232, -0.0420,  0.1348, -0.2751, -0.1806], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.6073,  0.2403, -0.4424,  0.0482, -0.6453], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.7403,  0.2795, -0.4068,  0.7908, -0.8444], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 8.9399e-03,  5.5751e-05,  4.5479e-04, -2.4119e-03,  2.3020e-03],
       grad_fn=<SliceBackward0>)
  [Layer 29] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 29] Output sample values after mixer: tensor([-0.6073,  0.2403, -0.4424,  0.0482, -0.6453], grad_fn=<SliceBackward0>)
  [Layer 29] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 29] Residual connection sample values: tensor([ 0.0959, -6.4178,  2.7182, -2.6183,  2.1948], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 30/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 31.6723,  47.6483,  66.7994,  72.0659, 107.5005],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1777, 0.1449, 0.1224, 0.1178, 0.0964], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0069, -0.4441,  0.1917, -0.2167,  0.1546], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2038, -0.3668, -0.2078, -0.0952, -0.4265], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.1432,  0.6518,  0.3721,  0.0553, -0.4612], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.1432,  0.6518,  0.3721,  0.0553, -0.4612], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 1.3087, -0.5168, -1.0296, -0.0433, -0.4982], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([3.0070, 2.7914, 2.8957, 4.2348, 2.7074], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([2.7058, 1.6810, 2.4057, 2.1050, 1.6794], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.4493,  0.0491,  0.4507, -1.0557,  1.0380], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0159,  0.0270,  0.4866,  0.0304, -0.0423], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0159,  0.0270,  0.4866,  0.0304, -0.0423], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0345, -0.0113, -0.0019,  0.0284, -0.2137], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2263, -0.2130, -0.2473, -0.2632, -0.2686], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0159,  0.0270,  0.4866,  0.0304, -0.0423], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0430,  0.0730,  1.3166,  0.0823, -0.1145], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.5513, -0.6166, -0.4999, -0.2004, -0.7163], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0345, -0.0113, -0.0019,  0.0284, -0.2137], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2263, -0.2130, -0.2473, -0.2632, -0.2686], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.5513, -0.4829, -0.2327, -0.2371, -0.1976], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.5513, -1.0343, -1.2670, -1.5041, -1.7016], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.5513, -0.4829, -0.2327, -0.2371, -0.1976], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.5513, -0.5513, -0.5513, -0.5513, -0.5513], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0143,  0.0243,  0.4384,  0.0274, -0.0381], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([4.0180e-06, 6.5126e-06, 8.2189e-06, 1.0418e-05, 1.2694e-05],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0135, -0.0232,  0.0238, -0.0044,  0.0434], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -12.9761, -10.5716,   0.0000, -13.4475],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -12.9761, -12.9761],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -12.9761,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -12.9761,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -12.9761,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 2.3151e-06, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0126, -0.0099,  0.0026, -0.0170,  0.0507], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.5762, 0.3555, 0.2817, 0.2222, 0.1824], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0143,  0.0243,  0.4384,  0.0274, -0.0381], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0143,  0.0243,  0.4384,  0.0274, -0.0381], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0126, -0.0099,  0.0026, -0.0170,  0.0507], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.0169,  0.0288,  0.5187,  0.0324, -0.0451], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.0169,  0.0288,  0.5187,  0.0324, -0.0451], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0011,  0.0123,  0.1143,  0.0009,  0.0080], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1.0285, 0.5719, 0.5558, 0.7349, 0.3971], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.9861, 1.3224, 1.3413, 1.1665, 1.5870], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0028,  0.0336,  0.1884,  0.0025,  0.0081], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0028,  0.0336,  0.1884,  0.0025,  0.0081], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-1.2345,  1.6444,  2.4469,  0.1317, -3.1087], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.4493,  0.0491,  0.4507, -1.0557,  1.0380], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0126, -0.0099,  0.0026, -0.0170,  0.0507], grad_fn=<SliceBackward0>)
  [Layer 30] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 30] Output sample values after mixer: tensor([-1.2345,  1.6444,  2.4469,  0.1317, -3.1087], grad_fn=<SliceBackward0>)
  [Layer 30] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 30] Residual connection sample values: tensor([-1.1387, -4.7735,  5.1651, -2.4867, -0.9139], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 31/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 40.6517,  57.0460,  73.0427,  76.1923, 120.3470],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1568, 0.1324, 0.1170, 0.1146, 0.0912], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0493, -0.2097,  0.2247, -0.1220, -0.0396], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-9.5766e-03, -1.0642e-02, -2.6350e+01, -6.4468e+02, -1.6547e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 0.5821,  1.8678,  0.0656, -0.1337, -0.5580], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 0.5821,  1.8678,  0.0656, -0.1337, -0.5580], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.5959,  0.6663,  0.2863,  0.4053, -0.7354], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([1.2798, 0.8178, 2.3257, 1.7935, 0.7624], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.1563, 0.1276, 2.9309, 2.8851, 0.1301], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-9.1698e-02, -1.1497e-01,  7.8174e-01, -2.0686e-01, -2.9716e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0549, -0.0498, -0.0345, -0.0863, -0.2314], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0549, -0.0498, -0.0345, -0.0863, -0.2314], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0045,  0.0030, -0.0009, -0.0080, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.1030, -0.0227, -0.0160, -0.1181, -0.1009], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0549, -0.0498, -0.0345, -0.0863, -0.2314], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0086, -0.0078, -0.0054, -0.0135, -0.0362], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-1.4968e-03, -1.3575e-03, -7.7230e+01, -1.8600e+03, -2.1523e-03],
       grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0045,  0.0030, -0.0009, -0.0080, -0.0005], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.1030, -0.0227, -0.0160, -0.1181, -0.1009], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0015, -0.0006, -0.0036, -0.0042, -0.0043], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0015, -0.0021, -0.0057, -0.0099, -0.0142], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0015, -0.0006, -0.0036, -0.0042, -0.0043], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0015, -0.0015, -0.0015, -0.0015, -0.0015], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0019, -0.0017, -0.0012, -0.0030, -0.0080], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.8922, 0.8927, 0.8959, 0.8997, 0.9036], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0198, -0.0144,  0.0143,  0.0124,  0.0049], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -0.1156, -0.1076,  0.0000, -0.1572], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.1156, -0.1156], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.1156,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.1156,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -0.1156,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.8908, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0166, -0.0109,  0.0083,  0.0153,  0.0055], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9985, 0.9979, 0.9943, 0.9902, 0.9859], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0019, -0.0017, -0.0012, -0.0030, -0.0080], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0019, -0.0017, -0.0012, -0.0030, -0.0080], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0166, -0.0109,  0.0083,  0.0153,  0.0055], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([0.0050, 0.0045, 0.0031, 0.0078, 0.0210], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([0.0050, 0.0045, 0.0031, 0.0078, 0.0210], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0019,  0.0073,  0.0001, -0.0005, -0.0043], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.0750, 0.0479, 0.0650, 0.0813, 0.0423], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([3.6521, 4.5691, 3.9219, 3.5061, 4.8626], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0271,  0.0962,  0.0014, -0.0288, -0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0271,  0.0962,  0.0014, -0.0288, -0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.6963, -0.4460,  1.3751,  0.1956,  1.7108], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-9.1698e-02, -1.1497e-01,  7.8174e-01, -2.0686e-01, -2.9716e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0166, -0.0109,  0.0083,  0.0153,  0.0055], grad_fn=<SliceBackward0>)
  [Layer 31] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 31] Output sample values after mixer: tensor([-0.6963, -0.4460,  1.3751,  0.1956,  1.7108], grad_fn=<SliceBackward0>)
  [Layer 31] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 31] Residual connection sample values: tensor([-1.8350, -5.2195,  6.5402, -2.2910,  0.7969], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 32/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 48.1578,  67.6200,  80.7858,  81.0009, 150.2119],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1441, 0.1216, 0.1113, 0.1111, 0.0816], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1236, -0.3441,  0.4282, -0.1799,  0.0545], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0662, -0.0811, -0.5879, -0.0956, -0.5448], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.9168, -0.3439,  1.2470,  0.5351,  0.3717], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.9168, -0.3439,  1.2470,  0.5351,  0.3717], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 1.1497, -1.2051, -0.5481, -0.6549, -0.5793], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([2.4854, 1.5227, 2.1919, 1.4928, 2.0910], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([3.0705, 2.2633, 1.7375, 1.9762, 2.0335], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.1108, -0.4183, -0.1900, -1.0760, -1.2735], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0166, -0.1689,  0.0073, -0.0212, -0.0142], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0166, -0.1689,  0.0073, -0.0212, -0.0142], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.1552, -0.0820,  0.0623,  0.1783,  0.0306], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2201, -0.0676, -0.2706, -0.2723, -0.0235], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0166, -0.1689,  0.0073, -0.0212, -0.0142], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0510, -0.5188,  0.0223, -0.0651, -0.0437], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.2033, -0.1836, -1.0214, -0.1889, -1.1078], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.1552, -0.0820,  0.0623,  0.1783,  0.0306], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2201, -0.0676, -0.2706, -0.2723, -0.0235], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.2033, -0.1000, -0.0790, -0.1997, -0.1817], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.2033, -0.3033, -0.3823, -0.5820, -0.7637], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.2033, -0.1000, -0.0790, -0.1997, -0.1817], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.2033, -0.2033, -0.2033, -0.2033, -0.2033], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0353, -0.3592,  0.0154, -0.0451, -0.0303], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.0009, 0.0010, 0.0011, 0.0013, 0.0016], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0218, -0.0904,  0.0350, -0.0118,  0.0471], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -7.1980, -6.1616,  0.0000, -8.4119], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -7.1980, -7.1980], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -7.1980,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -7.1980,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -7.1980,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 7.4811e-04, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.1104, -0.0562,  0.0580,  0.4658,  0.2323], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.8160, 0.7384, 0.6823, 0.5588, 0.4659], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0353, -0.3592,  0.0154, -0.0451, -0.0303], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0353, -0.3592,  0.0154, -0.0451, -0.0303], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.1104, -0.0562,  0.0580,  0.4658,  0.2323], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.0349, -0.3553,  0.0153, -0.0446, -0.0299], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.0349, -0.3553,  0.0153, -0.0446, -0.0299], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0091,  0.0507,  0.0148, -0.0150, -0.0066], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([6.4448, 3.7731, 4.1791, 5.3685, 3.2595], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.3939, 0.5148, 0.4892, 0.4316, 0.5539], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0041,  0.0488,  0.0142, -0.0091, -0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0041,  0.0488,  0.0142, -0.0091, -0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.2214, -0.0509,  0.1997, -0.7745,  0.2912], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.1108, -0.4183, -0.1900, -1.0760, -1.2735], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.1104, -0.0562,  0.0580,  0.4658,  0.2323], grad_fn=<SliceBackward0>)
  [Layer 32] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 32] Output sample values after mixer: tensor([-0.2214, -0.0509,  0.1997, -0.7745,  0.2912], grad_fn=<SliceBackward0>)
  [Layer 32] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 32] Residual connection sample values: tensor([-2.0564, -5.2703,  6.7399, -3.0655,  1.0881], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 33/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 53.2313,  89.8450,  90.9575,  88.8262, 173.6218],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1371, 0.1055, 0.1049, 0.1061, 0.0759], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1355, -0.3391,  0.4416, -0.2121,  0.0725], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-13.0444,  -1.3850,  -0.1668,  -0.2359,  -5.2550],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.8947, -1.0003,  0.8939, -1.3316, -2.9363], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.8947, -1.0003,  0.8939, -1.3316, -2.9363], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 1.8577,  0.2748, -0.8903, -2.5122, -1.2575], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([1.3495, 2.6759, 1.5307, 1.2631, 1.4389], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.0533, 0.0679, 0.2337, 0.1743, 0.0346], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.8459,  1.0038, -0.1889,  0.2802,  0.4499], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.1047,  0.0153, -0.0689, -0.2530, -0.1219], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.1047,  0.0153, -0.0689, -0.2530, -0.1219], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0626, -0.0086,  0.0289,  0.0235, -0.0121], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.0531,  0.5600,  0.0742, -0.2468,  0.0303], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.1047,  0.0153, -0.0689, -0.2530, -0.1219], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0056,  0.0008, -0.0037, -0.0135, -0.0065], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.6957, -0.0940, -0.0390, -0.0411, -0.1819], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0626, -0.0086,  0.0289,  0.0235, -0.0121], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.0531,  0.5600,  0.0742, -0.2468,  0.0303], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.6957, -2.2322, -0.5550, -0.1404, -0.3163], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.6957, -2.9279, -3.4830, -3.6234, -3.9397], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.6957, -2.2322, -0.5550, -0.1404, -0.3163], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.6957, -0.6957, -0.6957, -0.6957, -0.6957], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0016,  0.0002, -0.0010, -0.0038, -0.0018], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([2.6722e-11, 2.4906e-10, 4.3386e-10, 4.9926e-10, 6.8502e-10],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 6.8905e-05,  3.6818e-04, -1.2978e-03,  1.7304e-04,  8.1445e-04],
       grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -25.0413, -29.4589,   0.0000,  -1.8701],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -25.0413, -25.0413],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -25.0413,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -25.0413,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -25.0413,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 1.3327e-11, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0011, -0.0015,  0.0008,  0.0002,  0.0012], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.4987, 0.0535, 0.0307, 0.0267, 0.0195], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0016,  0.0002, -0.0010, -0.0038, -0.0018], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0016,  0.0002, -0.0010, -0.0038, -0.0018], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0011, -0.0015,  0.0008,  0.0002,  0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.1137,  0.0167, -0.0748, -0.2749, -0.1324], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.1137,  0.0167, -0.0748, -0.2749, -0.1324], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0295, -0.0045, -0.0475,  0.0765,  0.0196], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.1972, 0.1035, 0.1299, 0.1509, 0.0775], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([2.2521, 3.1087, 2.7750, 2.5738, 3.5921], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1833, -0.0270, -0.3897,  0.5277,  0.1529], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.1833, -0.0270, -0.3897,  0.5277,  0.1529], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-4.0814,  0.4228,  1.6429,  2.9963,  1.0145], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.8459,  1.0038, -0.1889,  0.2802,  0.4499], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0011, -0.0015,  0.0008,  0.0002,  0.0012], grad_fn=<SliceBackward0>)
  [Layer 33] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 33] Output sample values after mixer: tensor([-4.0814,  0.4228,  1.6429,  2.9963,  1.0145], grad_fn=<SliceBackward0>)
  [Layer 33] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 33] Residual connection sample values: tensor([-6.1377, -4.8475,  8.3828, -0.0692,  2.1026], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 34/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 71.5780, 113.0256, 105.3941,  97.5969, 209.1425],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1182, 0.0941, 0.0974, 0.1012, 0.0691], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3080, -0.2396,  0.4374, -0.0035,  0.1078], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2225, -0.1537, -0.8169, -0.8591, -2.0730], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 0.2377, -0.7373,  0.0595, -1.5824, -1.6021], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 0.2377, -0.7373,  0.0595, -1.5824, -1.6021], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.0172, -0.1943,  0.6265,  0.1283,  1.5318], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([2.1881, 3.1850, 1.6153, 2.8059, 1.1317], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.1112, 0.1599, 0.7269, 1.0055, 0.4671], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.4163, -0.4572, -0.3540,  0.2165, -1.3237], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0228, -0.0105, -0.0814, -0.0499,  0.1838], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0228, -0.0105, -0.0814, -0.0499,  0.1838], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0125, -0.0069, -0.0547,  0.0430,  0.0191], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2227, -0.0872,  0.0820,  0.0554, -0.1843], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0228, -0.0105, -0.0814, -0.0499,  0.1838], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0025, -0.0012, -0.0091, -0.0056,  0.0204], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.0247, -0.0246, -0.5938, -0.8639, -0.9682], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0125, -0.0069, -0.0547,  0.0430,  0.0191], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2227, -0.0872,  0.0820,  0.0554, -0.1843], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0247, -0.0166, -0.0129, -0.0126, -0.0659], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0247, -0.0413, -0.0542, -0.0668, -0.1327], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0247, -0.0166, -0.0129, -0.0126, -0.0659], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0247, -0.0247, -0.0247, -0.0247, -0.0247], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0005, -0.0002, -0.0019, -0.0011,  0.0042], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.3206, 0.3260, 0.3302, 0.3344, 0.3572], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0002,  0.0059,  0.0027, -0.0038,  0.0092], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -1.1622, -0.3993,  0.0000, -0.5883], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.1622, -1.1622], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.1622,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.1622,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -1.1622,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.3128, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0028,  0.0075,  0.0032, -0.0064,  0.0100], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9756, 0.9595, 0.9473, 0.9354, 0.8757], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0005, -0.0002, -0.0019, -0.0011,  0.0042], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0005, -0.0002, -0.0019, -0.0011,  0.0042], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0028,  0.0075,  0.0032, -0.0064,  0.0100], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0455, -0.0209, -0.1620, -0.0993,  0.3657], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0455, -0.0209, -0.1620, -0.0993,  0.3657], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0060,  0.0050, -0.0050,  0.0268, -0.0983], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.3215, 0.1885, 0.2337, 0.2841, 0.1294], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.7635, 2.3030, 2.0686, 1.8762, 2.7795], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0285,  0.0131, -0.0196,  0.1248, -0.4877], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0285,  0.0131, -0.0196,  0.1248, -0.4877], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-2.0076,  2.4123, -0.4993,  0.4183,  1.9619], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.4163, -0.4572, -0.3540,  0.2165, -1.3237], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0028,  0.0075,  0.0032, -0.0064,  0.0100], grad_fn=<SliceBackward0>)
  [Layer 34] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 34] Output sample values after mixer: tensor([-2.0076,  2.4123, -0.4993,  0.4183,  1.9619], grad_fn=<SliceBackward0>)
  [Layer 34] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 34] Residual connection sample values: tensor([-8.1453, -2.4353,  7.8835,  0.3491,  4.0645], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 35/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 84.9632, 161.5400, 131.8596, 120.0407, 239.3059],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.1085, 0.0787, 0.0871, 0.0913, 0.0646], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4962, -0.1472,  0.4732,  0.0227,  0.2461], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2054, -0.1417, -0.1071, -0.1460, -0.2581], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.9372, -0.4153,  0.2774, -1.9265, -0.5059], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.9372, -0.4153,  0.2774, -1.9265, -0.5059], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.9990, -0.5467,  1.0078,  0.1722, -1.8275], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([3.7652, 3.4731, 6.3414, 3.6281, 2.6399], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([5.3257, 5.6485, 6.6708, 5.9666, 3.0370], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.3390, -0.0787,  1.6062, -0.9954, -1.5988], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.1063, -0.0688,  0.0165,  0.0035, -0.1966], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.1063, -0.0688,  0.0165,  0.0035, -0.1966], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.2277, -0.0613,  0.1099,  0.0144, -0.1635], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.1140, -0.1984, -0.2768, -0.2379, -0.1706], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.1063, -0.0688,  0.0165,  0.0035, -0.1966], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.5662, -0.3663,  0.0878,  0.0189, -1.0471], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-1.0937, -0.8003, -0.7142, -0.8714, -0.7838], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.2277, -0.0613,  0.1099,  0.0144, -0.1635], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.1140, -0.1984, -0.2768, -0.2379, -0.1706], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-1.0937, -1.1345, -0.9443, -0.5903, -0.5475], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-1.0937, -2.2282, -3.1724, -3.7627, -4.3102], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-1.0937, -1.1345, -0.9443, -0.5903, -0.5475], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-1.0937, -1.0937, -1.0937, -1.0937, -1.0937], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.4078, -0.2639,  0.0632,  0.0136, -0.7542], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([2.3936e-19, 7.4431e-19, 1.9136e-18, 3.4532e-18, 5.9701e-18],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0408, -0.0136,  0.0399,  0.0177, -0.0400], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -43.9700, -39.6951,   0.0000, -35.9535],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -43.9700, -43.9700],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -43.9700,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -43.9700,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -43.9700,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 8.0183e-20, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0245,  0.0078, -0.0313, -0.0773, -0.0766], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.3350, 0.1077, 0.0419, 0.0232, 0.0134], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.4078, -0.2639,  0.0632,  0.0136, -0.7542], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.4078, -0.2639,  0.0632,  0.0136, -0.7542], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0245,  0.0078, -0.0313, -0.0773, -0.0766], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.6862, -0.4440,  0.1064,  0.0229, -1.2691], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.6862, -0.4440,  0.1064,  0.0229, -1.2691], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1810,  0.0733,  0.0168, -0.0056,  0.2415], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([11.6647,  8.7432, 11.4063, 21.6874,  5.7799], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.2928, 0.3382, 0.2961, 0.2147, 0.4159], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2016,  0.0792,  0.0063, -0.0090,  0.2253], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.2016,  0.0792,  0.0063, -0.0090,  0.2253], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.3030, -4.8012,  2.4270,  1.9512, -0.1520], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.3390, -0.0787,  1.6062, -0.9954, -1.5988], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0245,  0.0078, -0.0313, -0.0773, -0.0766], grad_fn=<SliceBackward0>)
  [Layer 35] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 35] Output sample values after mixer: tensor([ 0.3030, -4.8012,  2.4270,  1.9512, -0.1520], grad_fn=<SliceBackward0>)
  [Layer 35] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 35] Residual connection sample values: tensor([-7.8423, -7.2365, 10.3105,  2.3003,  3.9125], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 36/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([105.9307, 197.9669, 168.8234, 172.6384, 303.8418],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0972, 0.0711, 0.0770, 0.0761, 0.0574], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3810, -0.3594,  0.5038,  0.1193,  0.1947], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.8655, -5.6378, -3.8976, -2.4260, -3.6937], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.1375,  0.4696, -1.5243, -0.7977, -1.1167], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.1375,  0.4696, -1.5243, -0.7977, -1.1167], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.2164, -0.3784, -0.3787, -1.9546, -0.8333], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([0.2129, 0.4435, 1.6392, 1.1331, 1.7147], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.0858, 0.0266, 0.0902, 0.1182, 0.1307], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.2693, -2.1991,  0.7234,  1.8071,  0.4005], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0051, -0.0929, -0.0785, -0.2101, -0.0675], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0051, -0.0929, -0.0785, -0.2101, -0.0675], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0047,  0.3870, -0.1318,  0.3688, -0.0249], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.1590,  0.1770, -0.1931,  0.0539,  0.0761], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0051, -0.0929, -0.0785, -0.2101, -0.0675], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0004, -0.0080, -0.0067, -0.0180, -0.0058], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.2460, -0.1497, -0.3514, -0.2867, -0.4827], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0047,  0.3870, -0.1318,  0.3688, -0.0249], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.1590,  0.1770, -0.1931,  0.0539,  0.0761], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.2460, -0.5235, -0.1935, -0.3238, -0.2954], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.2460, -0.7694, -0.9630, -1.2868, -1.5822], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.2460, -0.5235, -0.1935, -0.3238, -0.2954], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.2460, -0.2460, -0.2460, -0.2460, -0.2460], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0004, -0.0075, -0.0064, -0.0170, -0.0055], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([2.9959e-11, 5.0568e-11, 6.1366e-11, 8.4832e-11, 1.1398e-10],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0055, -0.0016,  0.0014,  0.0009,  0.0068], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -24.4771, -23.9135,   0.0000, -31.4770],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -24.4771, -24.4771],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -24.4771,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -24.4771,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -24.4771,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 2.3427e-11, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0093,  0.0034, -0.0047,  0.0123, -0.0078], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.7820, 0.4633, 0.3818, 0.2762, 0.2055], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0004, -0.0075, -0.0064, -0.0170, -0.0055], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0004, -0.0075, -0.0064, -0.0170, -0.0055], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0093,  0.0034, -0.0047,  0.0123, -0.0078], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0161, -0.2923, -0.2471, -0.6613, -0.2125], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0161, -0.2923, -0.2471, -0.6613, -0.2125], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0010, -0.0844,  0.0673,  0.1638,  0.0585], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1.1991, 0.6562, 0.9453, 1.5500, 0.5925], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.9132, 1.2345, 1.0285, 0.8032, 1.2991], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0018, -0.3157,  0.1739,  0.4511,  0.1834], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0018, -0.3157,  0.1739,  0.4511,  0.1834], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.1266,  2.6885, -1.5395,  0.4957,  1.1785], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.2693, -2.1991,  0.7234,  1.8071,  0.4005], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0093,  0.0034, -0.0047,  0.0123, -0.0078], grad_fn=<SliceBackward0>)
  [Layer 36] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 36] Output sample values after mixer: tensor([ 0.1266,  2.6885, -1.5395,  0.4957,  1.1785], grad_fn=<SliceBackward0>)
  [Layer 36] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 36] Residual connection sample values: tensor([-7.7157, -4.5480,  8.7710,  2.7959,  5.0910], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 37/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([121.7926, 239.5199, 194.2362, 178.1382, 335.3855],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0906, 0.0646, 0.0718, 0.0749, 0.0546], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3371, -0.2040,  0.4020,  0.1251,  0.2282], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.8179, -31.1699, -39.0195,  -0.4619,  -0.6477],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 0.2204, -0.4700,  0.7782, -1.7263, -4.0411], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 0.2204, -0.4700,  0.7782, -1.7263, -4.0411], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.1321,  0.3858,  0.9655, -0.6414,  1.6738], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 1.4510,  2.4426, -0.1958, -2.3554,  0.5486], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([2.6917e-03, 8.0175e-02, 2.7493e-03, 7.0321e-05, 2.8651e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.6022, -0.1325, -0.6262, -0.6172,  1.6055], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0524, -0.0770, -0.1445,  0.0974,  0.1119], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0524, -0.0770, -0.1445,  0.0974,  0.1119], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0462, -0.1381,  0.0324, -0.0042, -0.0202], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2528, -0.1998, -0.0490, -0.1801, -0.2494], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0524, -0.0770, -0.1445,  0.0974,  0.1119], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0001, -0.0002, -0.0004,  0.0003,  0.0003], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-4.8931e-03, -2.4991e+00, -1.0728e-01, -3.2479e-05, -1.8557e-03],
       grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0462, -0.1381,  0.0324, -0.0042, -0.0202], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2528, -0.1998, -0.0490, -0.1801, -0.2494], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0049, -0.0040, -0.0127, -0.0008, -0.0016], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0049, -0.0089, -0.0216, -0.0224, -0.0240], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0049, -0.0040, -0.0127, -0.0008, -0.0016], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0049, -0.0049, -0.0049, -0.0049, -0.0049], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0007, -0.0011, -0.0021,  0.0014,  0.0016], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.8299, 0.8332, 0.8439, 0.8445, 0.8459], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0002,  0.0003, -0.0006,  0.0013, -0.0007], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000,  -0.1914,  -0.0715,   0.0000, -27.5000],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.1914, -0.1914], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.1914,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.1914,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -0.1914,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.8258, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0004,  0.0003, -0.0006,  0.0009, -0.0006], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9951, 0.9912, 0.9786, 0.9778, 0.9763], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0007, -0.0011, -0.0021,  0.0014,  0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0007, -0.0011, -0.0021,  0.0014,  0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0004,  0.0003, -0.0006,  0.0009, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0967, -0.1420, -0.2668,  0.1798,  0.2066], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0967, -0.1420, -0.2668,  0.1798,  0.2066], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0118,  0.0257, -0.1423, -0.0469, -0.0144], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.4260, 0.2277, 0.3707, 0.5601, 0.1864], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.5321, 2.0958, 1.6423, 1.3361, 2.3161], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0674,  0.1060, -0.5522, -0.2879, -0.0473], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0674,  0.1060, -0.5522, -0.2879, -0.0473], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.0109,  3.3226,  0.1642, -0.3744,  3.4032], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.6022, -0.1325, -0.6262, -0.6172,  1.6055], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0004,  0.0003, -0.0006,  0.0009, -0.0006], grad_fn=<SliceBackward0>)
  [Layer 37] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 37] Output sample values after mixer: tensor([-0.0109,  3.3226,  0.1642, -0.3744,  3.4032], grad_fn=<SliceBackward0>)
  [Layer 37] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 37] Residual connection sample values: tensor([-7.7266, -1.2254,  8.9353,  2.4216,  8.4941], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 38/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([151.2274, 324.9774, 292.8695, 288.6132, 398.0114],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0813, 0.0555, 0.0584, 0.0589, 0.0501], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3221, -0.0511,  0.3707,  0.0978,  0.3565], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1704, -2.0832, -0.1351, -0.4124, -3.5315], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.6544, -2.5974,  2.4645,  1.3625,  0.1116], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.6544, -2.5974,  2.4645,  1.3625,  0.1116], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.0442, -0.8275, -0.9599,  0.6596, -0.6605], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([2.4270, 1.5871, 3.8413, 1.8266, 1.9932], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([2.6975, 0.4797, 3.8152, 1.1491, 0.5645], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 1.2567,  0.2020,  1.5038,  1.7691, -0.7121], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0058,  0.0601, -0.0783, -0.0783,  0.0283], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0058,  0.0601, -0.0783, -0.0783,  0.0283], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0178, -0.0401,  0.0621,  0.0075, -0.0456], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2605, -0.0331, -0.2567, -0.2781, -0.1892], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0058,  0.0601, -0.0783, -0.0783,  0.0283], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0155,  0.1621, -0.2112, -0.2113,  0.0764], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.4597, -0.9993, -0.5153, -0.4739, -1.9936], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0178, -0.0401,  0.0621,  0.0075, -0.0456], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2605, -0.0331, -0.2567, -0.2781, -0.1892], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.4597, -0.3218, -0.2057, -0.1769, -0.1444], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.4597, -0.7815, -0.9873, -1.1642, -1.3086], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.4597, -0.3218, -0.2057, -0.1769, -0.1444], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.4597, -0.4597, -0.4597, -0.4597, -0.4597], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0048,  0.0499, -0.0649, -0.0650,  0.0235], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([4.0258e-07, 5.5543e-07, 6.8230e-07, 8.1434e-07, 9.4087e-07],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0591,  0.0534, -0.0104,  0.0049, -0.0205], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -15.1851, -10.4702,   0.0000, -53.7913],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -15.1851, -15.1851],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -15.1851,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -15.1851,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -15.1851,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 2.5422e-07, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0154,  0.1634,  0.0083,  0.0087, -0.0769], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.6315, 0.4577, 0.3726, 0.3122, 0.2702], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0048,  0.0499, -0.0649, -0.0650,  0.0235], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0048,  0.0499, -0.0649, -0.0650,  0.0235], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0154,  0.1634,  0.0083,  0.0087, -0.0769], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0056,  0.0587, -0.0764, -0.0765,  0.0277], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0056,  0.0587, -0.0764, -0.0765,  0.0277], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0013, -0.0106, -0.1736, -0.0830,  0.0016], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1.0764, 0.7171, 0.9849, 0.9284, 0.5189], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.9639, 1.1809, 1.0076, 1.0378, 1.3882], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0038, -0.0216, -0.3924, -0.3745,  0.0051], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.0038, -0.0216, -0.3924, -0.3745,  0.0051], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-6.8768,  2.1168, -0.6958,  1.0777,  5.9779], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 1.2567,  0.2020,  1.5038,  1.7691, -0.7121], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0154,  0.1634,  0.0083,  0.0087, -0.0769], grad_fn=<SliceBackward0>)
  [Layer 38] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 38] Output sample values after mixer: tensor([-6.8768,  2.1168, -0.6958,  1.0777,  5.9779], grad_fn=<SliceBackward0>)
  [Layer 38] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 38] Residual connection sample values: tensor([-14.6034,   0.8914,   8.2395,   3.4993,  14.4721],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 39/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([211.4003, 415.2824, 392.1935, 344.0588, 461.4543],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0688, 0.0491, 0.0505, 0.0539, 0.0466], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3811,  0.0253,  0.2268,  0.1010,  0.3963], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.7351e+02, -2.3790e+00, -2.6079e-03, -1.4979e+00, -6.3307e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 0.1652, -0.2081, -1.1273,  0.3140, -0.7206], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 0.1652, -0.2081, -1.1273,  0.3140, -0.7206], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.6287,  0.6753, -0.4296,  0.0158, -0.0904], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([0.8937, 2.0914, 0.7724, 1.9138, 1.2255], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.5628, 1.2544, 0.5027, 0.6482, 0.0301], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.8729,  1.1085,  0.1630,  2.4910, -0.0803], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0991, -0.0804, -0.0341,  0.3423, -0.0144], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0991, -0.0804, -0.0341,  0.3423, -0.0144], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0139, -0.0125, -0.2113,  0.3766, -0.0040], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2592, -0.2753, -0.0005, -0.0906, -0.2756], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0991, -0.0804, -0.0341,  0.3423, -0.0144], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0558, -0.0453, -0.0192,  0.1926, -0.0081], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-9.7661e+01, -2.9842e+00, -1.3110e-03, -9.7087e-01, -1.9032e-03],
       grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0139, -0.0125, -0.2113,  0.3766, -0.0040], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2592, -0.2753, -0.0005, -0.0906, -0.2756], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([ -97.6615, -184.9597, -172.2362, -234.7260,  -83.6666],
       grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([ -97.6615, -282.6212, -454.8574, -689.5833, -773.2499],
       grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([ -97.6615, -184.9597, -172.2362, -234.7260,  -83.6666],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-97.6615, -97.6615, -97.6615, -97.6615, -97.6615],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0135, -0.0110, -0.0046,  0.0467, -0.0020], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0004, -0.0003,  0.0054,  0.0006, -0.0007], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([     0.0000, -12888.4590, -14467.5234,      0.0000,   -238.7257],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([     0.0000,      0.0000,      0.0000, -12888.4590, -12888.4590],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([     0.0000,      0.0000,      0.0000, -12888.4590,      0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([     0.0000,      0.0000,      0.0000, -12888.4590,      0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([     0.0000,        -inf,        -inf, -12888.4590,      0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1., 0., 0., 0., 1.], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0008,  0.0067, -0.0620, -0.0063, -0.0205], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([3.8536e-43, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0135, -0.0110, -0.0046,  0.0467, -0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0135, -0.0110, -0.0046,  0.0467, -0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0008,  0.0067, -0.0620, -0.0063, -0.0205], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.4617, -0.3748, -0.1588,  1.5954, -0.0669], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.4617, -0.3748, -0.1588,  1.5954, -0.0669], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0413, 0.0349, 0.0438, 0.2895, 0.0158], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1.1614, 0.9806, 1.1579, 1.7022, 0.7111], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.9279, 1.0098, 0.9293, 0.7665, 1.1859], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([0.1791, 0.1436, 0.1704, 1.0985, 0.0722], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([0.1791, 0.1436, 0.1704, 1.0985, 0.0722], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-1.9852, -2.6191, -2.5719, -2.9016,  0.9449], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.8729,  1.1085,  0.1630,  2.4910, -0.0803], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0008,  0.0067, -0.0620, -0.0063, -0.0205], grad_fn=<SliceBackward0>)
  [Layer 39] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 39] Output sample values after mixer: tensor([-1.9852, -2.6191, -2.5719, -2.9016,  0.9449], grad_fn=<SliceBackward0>)
  [Layer 39] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 39] Residual connection sample values: tensor([-16.5887,  -1.7276,   5.6676,   0.5977,  15.4170],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 40/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([260.4179, 568.4227, 522.6315, 448.6772, 617.4924],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0620, 0.0419, 0.0437, 0.0472, 0.0402], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.5052, -0.0561,  0.1804,  0.0174,  0.4861], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5267, -0.6301, -0.3878, -2.7909, -0.4284], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.7110, -0.6988,  0.4122,  1.4752, -1.5577], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.7110, -0.6988,  0.4122,  1.4752, -1.5577], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.5858,  0.2901, -0.1950, -0.4723,  1.8232], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 1.4016,  1.1214,  2.0715, -4.3946,  2.5290], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([7.0681e-02, 3.9239e-02, 2.0127e-01, 7.5139e-05, 1.8523e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-1.2147, -1.4282, -1.8997, -0.4070,  0.1403], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.1361, -0.0483, -0.0518,  0.0389,  0.1815], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.1361, -0.0483, -0.0518,  0.0389,  0.1815], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0262, -0.1990, -0.0324, -0.0007, -0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2478, -0.2784, -0.2543, -0.1988,  0.2277], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.1361, -0.0483, -0.0518,  0.0389,  0.1815], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0096, -0.0034, -0.0037,  0.0028,  0.0128], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.0372, -0.0247, -0.0781, -0.0002, -0.0794], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0262, -0.1990, -0.0324, -0.0007, -0.0004], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2478, -0.2784, -0.2543, -0.1988,  0.2277], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0372, -0.0383, -0.0149, -0.0559, -0.0497], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0372, -0.0755, -0.0904, -0.1463, -0.1960], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0372, -0.0383, -0.0149, -0.0559, -0.0497], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0372, -0.0372, -0.0372, -0.0372, -0.0372], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0039, -0.0014, -0.0015,  0.0011,  0.0052], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.0015, 0.0016, 0.0016, 0.0017, 0.0018], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0136, -0.0652, -0.0126, -0.0034, -0.0013], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -6.5261, -3.7687,  0.0000, -2.2236], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -6.5261, -6.5261], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -6.5261,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -6.5261,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -6.5261,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.0015, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0063, -0.0361, -0.0074, -0.0005, -0.0028], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9635, 0.9273, 0.9136, 0.8639, 0.8220], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0039, -0.0014, -0.0015,  0.0011,  0.0052], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0039, -0.0014, -0.0015,  0.0011,  0.0052], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0063, -0.0361, -0.0074, -0.0005, -0.0028], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.3408, -0.1210, -0.1297,  0.0975,  0.4544], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.3408, -0.1210, -0.1297,  0.0975,  0.4544], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0798,  0.0281, -0.0322,  0.1170, -0.1231], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.3574, 0.2489, 0.2675, 0.2604, 0.2484], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([1.6726, 2.0044, 1.9333, 1.9596, 2.0063], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.4281,  0.1783, -0.2080,  0.5979, -1.0363], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.4281,  0.1783, -0.2080,  0.5979, -1.0363], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-0.5732,  0.2422,  1.4520, -0.5162, -1.2351], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-1.2147, -1.4282, -1.8997, -0.4070,  0.1403], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0063, -0.0361, -0.0074, -0.0005, -0.0028], grad_fn=<SliceBackward0>)
  [Layer 40] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 40] Output sample values after mixer: tensor([-0.5732,  0.2422,  1.4520, -0.5162, -1.2351], grad_fn=<SliceBackward0>)
  [Layer 40] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 40] Residual connection sample values: tensor([-17.1619,  -1.4854,   7.1196,   0.0815,  14.1819],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 41/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([325.2652, 703.1840, 694.5063, 596.7444, 787.0551],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0554, 0.0377, 0.0379, 0.0409, 0.0356], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3325, -0.0308,  0.1423,  0.0016,  0.2753], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.0531, -1.1356, -0.8719, -1.5713, -1.7431], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.9711, -2.1777, -0.5535, -0.5512,  0.3656], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.9711, -2.1777, -0.5535, -0.5512,  0.3656], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.0080,  0.6754, -0.0864, -0.8471,  0.4774], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 1.2977, -1.0375, -0.6153,  1.2040,  0.4634], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.2385, 0.0794, 0.0567, 0.3705, 0.1272], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-7.3550e-01, -7.8717e-01, -2.1742e-01, -6.7051e-01, -6.6325e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0165,  0.0691, -0.0095,  0.0222, -0.0541], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0165,  0.0691, -0.0095,  0.0222, -0.0541], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0320,  0.0859,  0.0531, -0.0324,  0.0283], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.1488,  0.0920, -0.0165, -0.1109, -0.2108], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0165,  0.0691, -0.0095,  0.0222, -0.0541], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0039,  0.0165, -0.0023,  0.0053, -0.0129], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.2512, -0.0901, -0.0494, -0.5822, -0.2218], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0320,  0.0859,  0.0531, -0.0324,  0.0283], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.1488,  0.0920, -0.0165, -0.1109, -0.2108], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.2512, -0.3266, -0.1818, -0.0903, -0.2335], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.2512, -0.5778, -0.7595, -0.8498, -1.0833], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.2512, -0.3266, -0.1818, -0.0903, -0.2335], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.2512, -0.2512, -0.2512, -0.2512, -0.2512], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0009,  0.0037, -0.0005,  0.0012, -0.0029], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([6.2523e-09, 8.6672e-09, 1.0395e-08, 1.1377e-08, 1.4370e-08],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 5.4051e-05,  1.8474e-03, -6.1763e-04, -2.4021e-04,  2.0611e-03],
       grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -19.1415, -18.3057,   0.0000, -24.3013],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -19.1415, -19.1415],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -19.1415,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -19.1415,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -19.1415,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 4.8636e-09, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0022,  0.0012, -0.0026, -0.0008, -0.0004], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.7779, 0.5612, 0.4679, 0.4275, 0.3385], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0009,  0.0037, -0.0005,  0.0012, -0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0009,  0.0037, -0.0005,  0.0012, -0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0022,  0.0012, -0.0026, -0.0008, -0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0220,  0.0921, -0.0126,  0.0295, -0.0721], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0220,  0.0921, -0.0126,  0.0295, -0.0721], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0059, -0.0204,  0.0026, -0.0059, -0.0156], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.0331, 0.0216, 0.0243, 0.0220, 0.0207], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([5.4967, 6.7990, 6.4178, 6.7356, 6.9437], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1031, -0.4795,  0.0517, -0.1466, -0.3564], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.1031, -0.4795,  0.0517, -0.1466, -0.3564], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 1.1132, -1.2454, -0.1997,  1.7897, -2.2428], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-7.3550e-01, -7.8717e-01, -2.1742e-01, -6.7051e-01, -6.6325e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0022,  0.0012, -0.0026, -0.0008, -0.0004], grad_fn=<SliceBackward0>)
  [Layer 41] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 41] Output sample values after mixer: tensor([ 1.1132, -1.2454, -0.1997,  1.7897, -2.2428], grad_fn=<SliceBackward0>)
  [Layer 41] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 41] Residual connection sample values: tensor([-16.0487,  -2.7308,   6.9199,   1.8712,  11.9391],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 42/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([397.3999, 843.7455, 872.1212, 763.7553, 971.5054],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0502, 0.0344, 0.0339, 0.0362, 0.0321], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2899, -0.0530,  0.1336,  0.0338,  0.2269], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.2458, -1.7474, -3.3797, -1.2264, -1.3705], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 0.0765, -0.4178, -0.2091, -0.4562, -0.8935], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 0.0765, -0.4178, -0.2091, -0.4562, -0.8935], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.1383,  0.0186, -0.1239,  0.1622, -0.4456], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 1.4703, -0.0339,  0.5593,  0.9346,  0.5472], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.3886, 0.1263, 0.2172, 0.0521, 0.1303], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.3257,  0.8732, -0.1302,  0.8538,  1.6889], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0242, -0.0158,  0.0158, -0.0175, -0.0734], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0242, -0.0158,  0.0158, -0.0175, -0.0734], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0669, -0.0188,  0.0263, -0.0562, -0.0305], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.0836, -0.1657, -0.1820, -0.2665, -0.2677], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0242, -0.0158,  0.0158, -0.0175, -0.0734], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0094, -0.0061,  0.0061, -0.0068, -0.0285], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.8728, -0.2206, -0.7341, -0.0639, -0.1785], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0669, -0.0188,  0.0263, -0.0562, -0.0305], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.0836, -0.1657, -0.1820, -0.2665, -0.2677], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.8728, -1.2190, -0.5353, -0.4224, -0.8127], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.8728, -2.0918, -2.6272, -3.0495, -3.8622], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.8728, -1.2190, -0.5353, -0.4224, -0.8127], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.8728, -0.8728, -0.8728, -0.8728, -0.8728], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0032, -0.0021,  0.0021, -0.0023, -0.0097], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([6.5155e-18, 2.2048e-17, 3.7658e-17, 5.7451e-17, 1.2949e-16],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0026,  0.0057,  0.0022,  0.0009,  0.0011], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -40.4451, -35.9316,   0.0000, -10.7847],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -40.4451, -40.4451],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -40.4451,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -40.4451,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -40.4451,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 2.7220e-18, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 1.4413e-03, -2.4239e-04,  5.4825e-03,  1.2289e-05,  5.6738e-04],
       grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.4178, 0.1235, 0.0723, 0.0474, 0.0210], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0032, -0.0021,  0.0021, -0.0023, -0.0097], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0032, -0.0021,  0.0021, -0.0023, -0.0097], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 1.4413e-03, -2.4239e-04,  5.4825e-03,  1.2289e-05,  5.6738e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0363, -0.0237,  0.0237, -0.0262, -0.1100], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0363, -0.0237,  0.0237, -0.0262, -0.1100], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0014,  0.0039, -0.0022,  0.0046,  0.0286], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.0463, 0.0313, 0.0281, 0.0293, 0.0272], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([4.6490, 5.6551, 5.9650, 5.8420, 6.0640], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0263,  0.0688, -0.0400,  0.0848,  0.3554], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0263,  0.0688, -0.0400,  0.0848,  0.3554], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 1.1654,  0.2566,  0.4756,  0.4317, -0.0140], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.3257,  0.8732, -0.1302,  0.8538,  1.6889], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 1.4413e-03, -2.4239e-04,  5.4825e-03,  1.2289e-05,  5.6738e-04],
       grad_fn=<SliceBackward0>)
  [Layer 42] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 42] Output sample values after mixer: tensor([ 1.1654,  0.2566,  0.4756,  0.4317, -0.0140], grad_fn=<SliceBackward0>)
  [Layer 42] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 42] Residual connection sample values: tensor([-14.8834,  -2.4742,   7.3955,   2.3029,  11.9251],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 43/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 464.5074,  979.4279,  992.4741,  875.7867, 1131.2755],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0464, 0.0320, 0.0317, 0.0338, 0.0297], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2440, -0.0444,  0.1270,  0.0377,  0.1987], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.7046, -2.6553, -8.2110, -2.2382, -4.0926], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([ 0.1004, -0.8687, -0.2662, -1.0835,  0.6500], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([ 0.1004, -0.8687, -0.2662, -1.0835,  0.6500], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.7941, -0.1676,  0.2518, -0.7859, -0.5792], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([-0.3553, -1.2465, -0.1714,  1.1803,  1.9811], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.0436, 0.0235, 0.0530, 0.8690, 0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-1.0569,  0.2067,  0.2408, -0.4484, -0.0486], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0771, -0.0150, -0.0383, -0.0862, -0.0523], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0771, -0.0150, -0.0383, -0.0862, -0.0523], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0208,  0.0944, -0.0104, -0.1486,  0.0741], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2394, -0.2235, -0.2018, -0.2639, -0.1532], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0771, -0.0150, -0.0383, -0.0862, -0.0523], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0034, -0.0007, -0.0017, -0.0038, -0.0023], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.1615, -0.0623, -0.4348, -1.9449, -0.0378], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0208,  0.0944, -0.0104, -0.1486,  0.0741], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2394, -0.2235, -0.2018, -0.2639, -0.1532], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.1615, -0.7256, -0.3723, -0.2481, -0.3258], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.1615, -0.8870, -1.2594, -1.5075, -1.8333], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.1615, -0.7256, -0.3723, -0.2481, -0.3258], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.1615, -0.1615, -0.1615, -0.1615, -0.1615], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([4.6613e-04, 9.0419e-05, 2.3159e-04, 5.2083e-04, 3.1573e-04],
       grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([1.0625e-11, 2.1951e-11, 3.1853e-11, 4.0822e-11, 5.6545e-11],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0026, -0.0005, -0.0079,  0.0070, -0.0044], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -25.4293, -27.1550,   0.0000, -23.6899],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -25.4293, -25.4293],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -25.4293,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -25.4293,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -25.4293,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 9.0409e-12, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0001, -0.0004,  0.0001,  0.0010, -0.0009], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.8509, 0.4119, 0.2838, 0.2215, 0.1599], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([4.6613e-04, 9.0419e-05, 2.3159e-04, 5.2083e-04, 3.1573e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([4.6613e-04, 9.0419e-05, 2.3159e-04, 5.2083e-04, 3.1573e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0001, -0.0004,  0.0001,  0.0010, -0.0009], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.1268, -0.0246, -0.0630, -0.1416, -0.0859], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.1268, -0.0246, -0.0630, -0.1416, -0.0859], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0067,  0.0063,  0.0073,  0.0388, -0.0367], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.0214, 0.0161, 0.0159, 0.0153, 0.0143], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([6.8408, 7.8715, 7.9307, 8.0820, 8.3739], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1182,  0.1496,  0.1380,  0.7414, -0.7242], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.1182,  0.1496,  0.1380,  0.7414, -0.7242], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.2670,  5.3394, -2.3417,  1.0379, -2.0268], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-1.0569,  0.2067,  0.2408, -0.4484, -0.0486], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0001, -0.0004,  0.0001,  0.0010, -0.0009], grad_fn=<SliceBackward0>)
  [Layer 43] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 43] Output sample values after mixer: tensor([ 0.2670,  5.3394, -2.3417,  1.0379, -2.0268], grad_fn=<SliceBackward0>)
  [Layer 43] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 43] Residual connection sample values: tensor([-14.6164,   2.8652,   5.0538,   3.3408,   9.8983],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 44/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 513.9665, 1120.6575, 1114.2848,  988.9713, 1256.0491],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0441, 0.0299, 0.0300, 0.0318, 0.0282], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2308,  0.0468,  0.0827,  0.0516,  0.1582], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-4.6876, -0.9753, -0.8255, -1.2938, -0.4953], grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.7900, -0.3806, -0.7463, -0.2795, -0.7692], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.7900, -0.3806, -0.7463, -0.2795, -0.7692], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.4424,  0.4801, -0.7744, -0.1705, -0.1470], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([-0.5680, -0.4001,  0.0260,  1.0172,  2.6850], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.0575, 0.0300, 0.0252, 0.1207, 0.1081], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.8732,  0.0825, -0.4715,  0.2910,  0.7828], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0335, -0.0731, -0.0799,  0.0084, -0.0103], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0335, -0.0731, -0.0799,  0.0084, -0.0103], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.0691, -0.2516, -0.2764,  0.1262,  0.0392], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([ 0.0323, -0.2784, -0.1869, -0.0366, -0.1061], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0335, -0.0731, -0.0799,  0.0084, -0.0103], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0019, -0.0042, -0.0046,  0.0005, -0.0006], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.2694, -0.0292, -0.0208, -0.1562, -0.0535], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.0691, -0.2516, -0.2764,  0.1262,  0.0392], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([ 0.0323, -0.2784, -0.1869, -0.0366, -0.1061], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.2694, -2.6923, -1.1187, -0.8228, -1.2155], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.2694, -2.9617, -4.0804, -4.9032, -6.1186], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.2694, -2.6923, -1.1187, -0.8228, -1.2155], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.2694, -0.2694, -0.2694, -0.2694, -0.2694], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-3.5620e-04, -7.7827e-04, -8.5031e-04,  8.9060e-05, -1.0929e-04],
       grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([4.8195e-27, 7.1163e-26, 2.1783e-25, 4.9595e-25, 1.6723e-24],
       grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0011,  0.0020,  0.0025, -0.0006,  0.0004], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([  0.0000, -60.8665, -81.3599,   0.0000,  -5.1017],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([  0.0000,   0.0000,   0.0000, -60.8665, -60.8665],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([  0.0000,   0.0000,   0.0000, -60.8665,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([  0.0000,   0.0000,   0.0000, -60.8665,   0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([  0.0000,     -inf,     -inf, -60.8665,   0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 3.6815e-27, 1.0000e+00],
       grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-0.0007, -0.0002, -0.0003,  0.0005,  0.0003], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.7639, 0.0517, 0.0169, 0.0074, 0.0022], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-3.5620e-04, -7.7827e-04, -8.5031e-04,  8.9060e-05, -1.0929e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-3.5620e-04, -7.7827e-04, -8.5031e-04,  8.9060e-05, -1.0929e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0007, -0.0002, -0.0003,  0.0005,  0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0585, -0.1278, -0.1396,  0.0146, -0.0179], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0585, -0.1278, -0.1396,  0.0146, -0.0179], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0144,  0.0197,  0.0335, -0.0018,  0.0044], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.0260, 0.0195, 0.0213, 0.0194, 0.0193], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([6.2005, 7.1656, 6.8461, 7.1787, 7.2042], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2882,  0.3614,  0.7772, -0.0351,  0.0854], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.2882,  0.3614,  0.7772, -0.0351,  0.0854], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-2.0572,  1.4712, -0.0196,  2.1690, -4.5078], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.8732,  0.0825, -0.4715,  0.2910,  0.7828], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-0.0007, -0.0002, -0.0003,  0.0005,  0.0003], grad_fn=<SliceBackward0>)
  [Layer 44] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 44] Output sample values after mixer: tensor([-2.0572,  1.4712, -0.0196,  2.1690, -4.5078], grad_fn=<SliceBackward0>)
  [Layer 44] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 44] Residual connection sample values: tensor([-16.6736,   4.3364,   5.0342,   5.5098,   5.3905],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 45/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 572.0784, 1236.6699, 1257.1388, 1134.4493, 1378.8713],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0418, 0.0284, 0.0282, 0.0297, 0.0269], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2992,  0.0840,  0.0949,  0.0992,  0.0980], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3039e+00, -3.9385e-02, -6.8874e+00, -8.0559e-01, -1.9935e+03],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.0543, -2.2511,  0.3491, -0.5143, -1.2086], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.0543, -2.2511,  0.3491, -0.5143, -1.2086], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.2335, -0.5761,  1.6011,  0.2882,  0.2301], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([0.8364, 1.8154, 0.7268, 2.6490, 2.8122], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.0051, 0.1088, 0.0159, 0.0089, 0.2787], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.0515, -0.2140,  1.3554, -0.1891,  1.5986], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0173,  0.1071,  0.1436, -0.0544,  0.0136], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0173,  0.1071,  0.1436, -0.0544,  0.0136], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0141, -0.0660,  0.0218, -0.2567,  0.0704], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2113, -0.1358, -0.0972,  0.1125, -0.1960], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0173,  0.1071,  0.1436, -0.0544,  0.0136], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 8.8720e-05,  5.4780e-04,  7.3442e-04, -2.7828e-04,  6.9544e-05],
       grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-6.6701e-03, -4.2859e-03, -1.0960e-01, -7.1351e-03, -5.5556e+02],
       grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0141, -0.0660,  0.0218, -0.2567,  0.0704], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2113, -0.1358, -0.0972,  0.1125, -0.1960], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.0067, -0.0233, -0.0686, -0.0530, -0.0037], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.0067, -0.0300, -0.0986, -0.1516, -0.1553], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.0067, -0.0233, -0.0686, -0.0530, -0.0037], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.0067, -0.0067, -0.0067, -0.0067, -0.0067], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 1.4539e-05,  8.9770e-05,  1.2035e-04, -4.5603e-05,  1.1396e-05],
       grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.5712, 0.5847, 0.6262, 0.6603, 0.6627], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([ 0.0016,  0.0011,  0.0014, -0.0010,  0.0020], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -0.5666, -0.4287,  0.0000, -0.1120], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.5666, -0.5666], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.5666,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -0.5666,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -0.5666,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.5674, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([0.0017, 0.0010, 0.0012, 0.0002, 0.0016], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.9934, 0.9705, 0.9061, 0.8594, 0.8562], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 1.4539e-05,  8.9770e-05,  1.2035e-04, -4.5603e-05,  1.1396e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 1.4539e-05,  8.9770e-05,  1.2035e-04, -4.5603e-05,  1.1396e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([0.0017, 0.0010, 0.0012, 0.0002, 0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.0450,  0.2780,  0.3727, -0.1412,  0.0353], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.0450,  0.2780,  0.3727, -0.1412,  0.0353], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0012, -0.0596,  0.0763,  0.0272, -0.0098], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.1334, 0.0888, 0.0911, 0.0944, 0.0910], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([2.7383, 3.3559, 3.3125, 3.2554, 3.3155], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0126, -0.4751,  0.7259,  0.2449, -0.1060], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0126, -0.4751,  0.7259,  0.2449, -0.1060], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 0.0220, -1.7728,  0.8987, -2.1144,  3.3858], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.0515, -0.2140,  1.3554, -0.1891,  1.5986], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([0.0017, 0.0010, 0.0012, 0.0002, 0.0016], grad_fn=<SliceBackward0>)
  [Layer 45] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 45] Output sample values after mixer: tensor([ 0.0220, -1.7728,  0.8987, -2.1144,  3.3858], grad_fn=<SliceBackward0>)
  [Layer 45] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 45] Residual connection sample values: tensor([-16.6516,   2.5636,   5.9329,   3.3954,   8.7763],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 46/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 667.9835, 1383.3658, 1431.9539, 1298.4899, 1524.8961],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0387, 0.0269, 0.0264, 0.0278, 0.0256], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2625,  0.0435,  0.0986,  0.0545,  0.1370], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.4426,  -0.9830, -10.1590,  -1.3638,  -1.7559],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-2.3493,  0.3054,  0.4333,  0.9005,  1.4524], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-2.3493,  0.3054,  0.4333,  0.9005,  1.4524], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.2644,  0.8882, -0.0250, -0.7398, -0.8077], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([2.6568, 1.7104, 1.5531, 0.6841, 2.3595], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.1184, 0.0748, 0.0051, 0.0257, 0.1095], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.6570,  0.9929,  0.3296,  1.3961, -0.5382], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0359, -0.0903,  0.1087,  0.0693,  0.0673], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0359, -0.0903,  0.1087,  0.0693,  0.0673], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([-0.0332,  0.0510, -0.0237,  0.1014, -0.0884], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.0217, -0.0986, -0.1544, -0.0609,  0.2023], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0359, -0.0903,  0.1087,  0.0693,  0.0673], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0043, -0.0107,  0.0129,  0.0082,  0.0080], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-0.1708, -0.0735, -0.0523, -0.0351, -0.1923], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([-0.0332,  0.0510, -0.0237,  0.1014, -0.0884], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.0217, -0.0986, -0.1544, -0.0609,  0.2023], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.1708, -0.0336, -0.0080, -0.0093, -0.0537], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.1708, -0.2044, -0.2124, -0.2217, -0.2754], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.1708, -0.0336, -0.0080, -0.0093, -0.0537], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.1708, -0.1708, -0.1708, -0.1708, -0.1708], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0005, -0.0012,  0.0015,  0.0010,  0.0009], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.1436, 0.1485, 0.1497, 0.1511, 0.1594], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-9.2096e-04, -6.6477e-05, -2.5276e-04,  3.7155e-04, -5.7043e-04],
       grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -2.1118, -1.2172,  0.0000, -1.5334], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -2.1118, -2.1118], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -2.1118,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -2.1118,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -2.1118,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.1210, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-2.5793e-03,  3.1650e-04, -4.3921e-05,  4.1268e-04, -8.4070e-04],
       grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.8430, 0.8151, 0.8087, 0.8012, 0.7593], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0005, -0.0012,  0.0015,  0.0010,  0.0009], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0005, -0.0012,  0.0015,  0.0010,  0.0009], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-2.5793e-03,  3.1650e-04, -4.3921e-05,  4.1268e-04, -8.4070e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.0445, -0.1119,  0.1347,  0.0859,  0.0834], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.0445, -0.1119,  0.1347,  0.0859,  0.0834], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0091, -0.0197,  0.0354,  0.0550,  0.0982], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.0233, 0.0148, 0.0147, 0.0158, 0.0167], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([6.5497, 8.2254, 8.2480, 7.9560, 7.7357], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2652, -0.5326,  0.8177,  1.2574,  2.2434], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.2652, -0.5326,  0.8177,  1.2574,  2.2434], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 3.2580,  2.3641, -1.9811, -2.1300, -8.8954], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.6570,  0.9929,  0.3296,  1.3961, -0.5382], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-2.5793e-03,  3.1650e-04, -4.3921e-05,  4.1268e-04, -8.4070e-04],
       grad_fn=<SliceBackward0>)
  [Layer 46] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 46] Output sample values after mixer: tensor([ 3.2580,  2.3641, -1.9811, -2.1300, -8.8954], grad_fn=<SliceBackward0>)
  [Layer 46] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 46] Residual connection sample values: tensor([-13.3936,   4.9277,   3.9518,   1.2654,  -0.1191],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 47/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([ 787.0050, 1601.9227, 1638.6891, 1457.2729, 1582.6539],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0356, 0.0250, 0.0247, 0.0262, 0.0251], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1750,  0.0671,  0.0527,  0.0156, -0.0016], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-5.7667e+01, -2.2024e+00, -3.8371e+00, -4.6046e-02, -2.0700e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.4615, -0.0217, -1.0009, -1.4065, -0.7849], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.4615, -0.0217, -1.0009, -1.4065, -0.7849], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([ 0.2890,  0.3018, -0.8769,  0.5763, -0.4619], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([0.9694, 1.3739, 1.1800, 5.3687, 2.3307], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([0.1178, 0.0174, 0.0416, 1.5768, 0.0412], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([ 0.1456, -1.1730,  0.1793, -0.7106, -0.1141], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([-0.0360,  0.0332, -0.0776, -0.0454, -0.0370], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([-0.0360,  0.0332, -0.0776, -0.0454, -0.0370], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.2073,  0.0412,  0.0135,  0.0215, -0.2754], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.2294, -0.2541,  0.2287, -0.2751, -0.2780], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([-0.0360,  0.0332, -0.0776, -0.0454, -0.0370], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([-0.0042,  0.0039, -0.0091, -0.0053, -0.0044], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-6.7920, -0.0384, -0.1595, -0.0726, -0.0852], grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.2073,  0.0412,  0.0135,  0.0215, -0.2754], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.2294, -0.2541,  0.2287, -0.2751, -0.2780], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-6.7920, -8.8501, -5.5480, -4.3517, -1.9894], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([ -6.7920, -15.6420, -21.1901, -25.5418, -27.5312],
       grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-6.7920, -8.8501, -5.5480, -4.3517, -1.9894], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-6.7920, -6.7920, -6.7920, -6.7920, -6.7920], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([-0.0009,  0.0009, -0.0020, -0.0012, -0.0010], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([-0.0002,  0.0001,  0.0001, -0.0002, -0.0011], grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([   0.0000, -621.9715, -681.7658,    0.0000,   -2.5202],
       grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([   0.0000,    0.0000,    0.0000, -621.9715, -621.9715],
       grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([   0.0000,    0.0000,    0.0000, -621.9715,    0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([   0.0000,    0.0000,    0.0000, -621.9715,    0.0000],
       grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([   0.0000,      -inf,      -inf, -621.9715,    0.0000],
       grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1., 0., 0., 0., 1.], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([ 0.0031,  0.0002, -0.0002, -0.0010, -0.0041], grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([1.1227e-03, 1.6097e-07, 6.2700e-10, 8.0790e-12, 1.1050e-12],
       grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([-0.0009,  0.0009, -0.0020, -0.0012, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([-0.0009,  0.0009, -0.0020, -0.0012, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0031,  0.0002, -0.0002, -0.0010, -0.0041], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([-0.0577,  0.0531, -0.1243, -0.0727, -0.0593], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([-0.0577,  0.0531, -0.1243, -0.0727, -0.0593], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0103, -0.0006,  0.0334,  0.0201,  0.0146], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.0160, 0.0121, 0.0122, 0.0147, 0.0151], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([7.8974, 9.0964, 9.0671, 8.2500, 8.1439], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2772, -0.0170,  0.9136,  0.7879,  0.4607], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([ 0.2772, -0.0170,  0.9136,  0.7879,  0.4607], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([ 5.4903, 15.9799, 10.8418,  4.9777,  2.0866], grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([ 0.1456, -1.1730,  0.1793, -0.7106, -0.1141], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([ 0.0031,  0.0002, -0.0002, -0.0010, -0.0041], grad_fn=<SliceBackward0>)
  [Layer 47] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 47] Output sample values after mixer: tensor([ 5.4903, 15.9799, 10.8418,  4.9777,  2.0866], grad_fn=<SliceBackward0>)
  [Layer 47] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 47] Residual connection sample values: tensor([-7.9034, 20.9076, 14.7936,  6.2431,  1.9675], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 48/48
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([1125.6147, 2176.7820, 2100.0359, 1869.2756, 2177.0610],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0298, 0.0214, 0.0218, 0.0231, 0.0214], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0860,  0.2454,  0.1716,  0.0662,  0.0221], grad_fn=<SliceBackward0>)
[Mamba2] Performing full forward pass.
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.7304,  -7.3891,  -3.3797,  -1.8028, -17.7601],
       grad_fn=<SliceBackward0>)
  [Mamba2] in_proj output shape: torch.Size([1, 128, 4384])
  [Mamba2] in_proj output sample values: tensor([-0.0624,  0.1885, -0.0106, -0.5325, -1.5893], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes -> z: torch.Size([1, 128, 2048]), xBC: torch.Size([1, 128, 2304]), dt: torch.Size([1, 128, 32])
  [Mamba2] z sample values: tensor([-0.0624,  0.1885, -0.0106, -0.5325, -1.5893], grad_fn=<SliceBackward0>)
  [Mamba2] xBC sample values: tensor([-0.1209,  0.4365,  0.8124, -1.2286,  0.4128], grad_fn=<SliceBackward0>)
  [Mamba2] dt sample values: tensor([ 2.0409, -1.8138,  1.5886,  1.9794,  0.9637], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus shape: torch.Size([1, 128, 32])
  [Mamba2] dt after softplus sample values: tensor([8.5186e-02, 3.5037e-05, 3.0997e-02, 1.3202e-01, 2.3196e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] conv_state shape after padding: torch.Size([1, 2304, 4])
  [Mamba2] conv_state after padding sample values: tensor([-0.0353,  0.6851,  1.5801,  0.2603, -0.0403], grad_fn=<SliceBackward0>)
  [Mamba2] conv1d output shape: torch.Size([1, 128, 2304])
  [Mamba2] conv1d output sample values: tensor([ 0.0114,  0.0182,  0.0388, -0.0997, -0.0086], grad_fn=<SliceBackward0>)
  [Mamba2] Split conv1d output -> x: torch.Size([1, 128, 2048]), B: torch.Size([1, 128, 128]), C: torch.Size([1, 128, 128])
  [Mamba2] x sample values: tensor([ 0.0114,  0.0182,  0.0388, -0.0997, -0.0086], grad_fn=<SliceBackward0>)
  [Mamba2] B sample values: tensor([ 0.1696, -0.0624, -0.2783,  0.0091, -0.0358], grad_fn=<SliceBackward0>)
  [Mamba2] C sample values: tensor([-0.0251, -0.0157, -0.2482,  0.0004, -0.0422], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange shape: torch.Size([1, 128, 32, 64])
  [Mamba2] x after rearrange sample values: tensor([ 0.0114,  0.0182,  0.0388, -0.0997, -0.0086], grad_fn=<SliceBackward0>)
[ssd] Starting SSD computation...
[ssd] Rearranging tensors into chunks.
  [ssd] After chunking shapes -> x: torch.Size([1, 2, 64, 32, 64]), A: torch.Size([1, 2, 64, 32]), B: torch.Size([1, 2, 64, 1, 128]), C: torch.Size([1, 2, 64, 1, 128])
  [ssd] x after chunking sample values: tensor([ 0.0010,  0.0016,  0.0033, -0.0085, -0.0007], grad_fn=<SliceBackward0>)
  [ssd] A after chunking sample values: tensor([-1.4740e-01, -2.5889e-04, -1.0476e-01, -2.3800e-01, -4.1196e+00],
       grad_fn=<SliceBackward0>)
  [ssd] B after chunking sample values: tensor([ 0.1696, -0.0624, -0.2783,  0.0091, -0.0358], grad_fn=<SliceBackward0>)
  [ssd] C after chunking sample values: tensor([-0.0251, -0.0157, -0.2482,  0.0004, -0.0422], grad_fn=<SliceBackward0>)
  [ssd] A rearranged shape: torch.Size([1, 32, 2, 64])
  [ssd] A rearranged sample values: tensor([-0.1474, -0.0438, -0.0239, -0.0151, -0.0750], grad_fn=<SliceBackward0>)
  [ssd] A_cumsum shape: torch.Size([1, 32, 2, 64])
  [ssd] A_cumsum sample values: tensor([-0.1474, -0.1912, -0.2152, -0.2302, -0.3052], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 2, 64])
  [segsum] input sample values: tensor([-0.1474, -0.0438, -0.0239, -0.0151, -0.0750], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after repeating sample values: tensor([-0.1474, -0.1474, -0.1474, -0.1474, -0.1474], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x after masking sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] x_segsum sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 2, 64, 64])
  [segsum] Final masked x_segsum sample values: tensor([0., -inf, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
  [ssd] L shape: torch.Size([1, 32, 2, 64, 64])
  [ssd] L sample values: tensor([1., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y_diag shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_diag sample values: tensor([ 0.0001,  0.0002,  0.0005, -0.0012, -0.0001], grad_fn=<SliceBackward0>)
  [ssd] decay_states shape: torch.Size([1, 32, 2, 64])
  [ssd] decay_states sample values: tensor([0.1602, 0.1674, 0.1715, 0.1741, 0.1876], grad_fn=<SliceBackward0>)
  [ssd] states shape: torch.Size([1, 2, 32, 64, 128])
  [ssd] states sample values: tensor([3.7370e-05, 1.7952e-04, 1.6981e-03, 2.6057e-04, 3.8871e-05],
       grad_fn=<SliceBackward0>)
  [ssd] Initialized initial_states with zeros.
  [ssd] initial_states sample values: tensor([0., 0., 0., 0., 0.])
  [ssd] states after concatenation shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] states after concatenation sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
[segsum] Starting segsum computation with input shape: torch.Size([1, 32, 3])
  [segsum] input sample values: tensor([ 0.0000, -1.9786, -1.1661,  0.0000, -0.0664], grad_fn=<SliceBackward0>)
  [segsum] After repeating: torch.Size([1, 32, 3, 3])
  [segsum] x after repeating sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.9786, -1.9786], grad_fn=<SliceBackward0>)
  [segsum] Mask applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x after masking sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.9786,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Cumulative sum and masking applied, shape: torch.Size([1, 32, 3, 3])
  [segsum] x_segsum sample values: tensor([ 0.0000,  0.0000,  0.0000, -1.9786,  0.0000], grad_fn=<SliceBackward0>)
  [segsum] Final masked x_segsum shape: torch.Size([1, 32, 3, 3])
  [segsum] Final masked x_segsum sample values: tensor([ 0.0000,    -inf,    -inf, -1.9786,  0.0000], grad_fn=<SliceBackward0>)
  [ssd] decay_chunk shape: torch.Size([1, 32, 3, 3])
  [ssd] decay_chunk sample values: tensor([1.0000, 0.0000, 0.0000, 0.1383, 1.0000], grad_fn=<SliceBackward0>)
  [ssd] new_states shape: torch.Size([1, 3, 32, 64, 128])
  [ssd] new_states sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] states shape after splitting: torch.Size([1, 2, 32, 64, 128]), final_state shape: torch.Size([1, 32, 64, 128])
  [ssd] states after splitting sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] final_state sample values: tensor([-1.8676e-04,  6.9625e-04,  7.0894e-04, -2.5269e-04, -8.4911e-05],
       grad_fn=<SliceBackward0>)
  [ssd] state_decay_out shape: torch.Size([1, 32, 2, 64])
  [ssd] state_decay_out sample values: tensor([0.8629, 0.8259, 0.8064, 0.7943, 0.7369], grad_fn=<SliceBackward0>)
  [ssd] Y_off shape: torch.Size([1, 2, 64, 32, 64])
  [ssd] Y_off sample values: tensor([0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)
  [ssd] Y after adding Y_diag and Y_off shape: torch.Size([1, 128, 32, 64])
  [ssd] Y after adding Y_diag and Y_off sample values: tensor([ 0.0001,  0.0002,  0.0005, -0.0012, -0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] ssd output y shape: torch.Size([1, 128, 32, 64]), ssm_state shape: torch.Size([1, 32, 64, 128])
  [Mamba2] y sample values: tensor([ 0.0001,  0.0002,  0.0005, -0.0012, -0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-1.8676e-04,  6.9625e-04,  7.0894e-04, -2.5269e-04, -8.4911e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling shape: torch.Size([1, 128, 32, 64])
  [Mamba2] y after adding D scaling sample values: tensor([ 0.0164,  0.0262,  0.0556, -0.1430, -0.0124], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, l, d_inner): torch.Size([1, 128, 2048])
  [Mamba2] y after rearrange sample values: tensor([ 0.0164,  0.0262,  0.0556, -0.1430, -0.0124], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 128, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0005,  0.0027, -0.0003,  0.0282,  0.0033], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([0.0062, 0.0040, 0.0048, 0.0057, 0.0060], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([12.7329, 15.7363, 14.3897, 13.2334, 12.9310], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0224,  0.1364, -0.0140,  1.1876,  0.1910], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm shape: torch.Size([1, 128, 2048])
  [Mamba2] y after RMSNorm sample values: tensor([-0.0224,  0.1364, -0.0140,  1.1876,  0.1910], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj shape: torch.Size([1, 128, 1024])
  [Mamba2] y after out_proj sample values: tensor([-12.7849,  17.1269,  12.2498,  17.9172,   1.8878],
       grad_fn=<SliceBackward0>)
  [Mamba2] Updated InferenceCache: conv_state shape torch.Size([1, 2304, 4]), ssm_state shape torch.Size([1, 32, 64, 128])
  [Mamba2] conv_state sample values: tensor([-0.0353,  0.6851,  1.5801,  0.2603, -0.0403], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state sample values: tensor([-1.8676e-04,  6.9625e-04,  7.0894e-04, -2.5269e-04, -8.4911e-05],
       grad_fn=<SliceBackward0>)
  [Layer 48] Output shape after mixer: torch.Size([1, 128, 1024])
  [Layer 48] Output sample values after mixer: tensor([-12.7849,  17.1269,  12.2498,  17.9172,   1.8878],
       grad_fn=<SliceBackward0>)
  [Layer 48] Residual connection shape: torch.Size([1, 128, 1024])
  [Layer 48] Residual connection sample values: tensor([-20.6882,  38.0345,  27.0434,  24.1602,   3.8553],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 128, 1])
[RMSNorm] mean_sq sample values: tensor([2492.0974, 4342.6343, 3890.2183, 3314.2200, 4708.7739],
       grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 128, 1])
[RMSNorm] rsqrt sample values: tensor([0.0200, 0.0152, 0.0160, 0.0174, 0.0146], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 128, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4241,  1.1265,  0.6343,  0.4473,  0.0813], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Final backbone norm output shape: torch.Size([1, 128, 1024])
[Mamba2LMHeadModel] Final backbone norm output sample values: tensor([-0.4241,  1.1265,  0.6343,  0.4473,  0.0813], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Logits shape: torch.Size([1, 128, 50288])
[Mamba2LMHeadModel] Logits sample values: tensor([-62.0029, -73.2988, -61.8623, -59.2568, -62.8463],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Forward pass input_ids shape: torch.Size([1, 1])
[Mamba2LMHeadModel] input_ids sample values: tensor([12536])
[Mamba2LMHeadModel] Embedding output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Embedding sample values: tensor([-0.2208, -0.1057,  0.0284, -0.0912,  0.0545], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 1/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0416], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([4.9011], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2597, -0.1582,  0.0366, -0.0917,  0.0601], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4254, -0.8080, -0.1803, -0.5069, -0.3639], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4254, -0.8080, -0.1803, -0.5069, -0.3639], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0157,  0.1471, -0.1725,  0.5439,  0.2423], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.0159,  0.1882,  0.0573,  0.2027, -0.2126], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5484, -0.2702,  0.5399,  0.0157,  3.3068], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0646, -0.0686,  0.0618, -0.1243, -0.0772], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1072, -0.0762,  0.1745, -0.3338, -0.2744], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0565, -0.0366,  0.0948, -0.1393, -0.1185], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0565, -0.0366,  0.0948, -0.1393, -0.1185], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2687, -0.0338,  0.0031,  0.6463,  0.0569], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2483, -0.0315,  0.1485, -0.2709, -0.0424], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4384, -1.0011, -1.2129, -1.1530, -1.4844], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0566, 0.0408, 0.0258, 0.0319, 0.0182], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9755, 0.9600, 0.9692, 0.9639, 0.9734], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0565, -0.0366,  0.0948, -0.1393, -0.1185], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-8.5864e-04, -1.0804e-04,  1.0002e-05,  2.0648e-03,  1.8186e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0187, -0.0039, -0.0006,  0.0451, -0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1151, -0.0044,  0.2609, -0.3976, -0.3359], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2119, -0.0672,  0.4236, -0.6365, -0.5391], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2119, -0.0672,  0.4236, -0.6365, -0.5391], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0545,  0.0167, -0.0347,  0.1213,  0.0804], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2027], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.2211], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1083,  0.0275, -0.0569,  0.1630,  0.5534], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1083,  0.0275, -0.0569,  0.1630,  0.5534], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.5776,  0.5689, -0.2870, -0.8428,  0.4519], grad_fn=<SliceBackward0>)
  [Layer 1] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 1] Output sample values after mixer: tensor([ 0.5776,  0.5689, -0.2870, -0.8428,  0.4519], grad_fn=<SliceBackward0>)
  [Layer 1] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 1] Residual connection sample values: tensor([ 0.3567,  0.4632, -0.2587, -0.9341,  0.5064], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 2/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.3907], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.8480], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1747,  0.1905, -0.0982, -0.4811,  0.2258], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.5388, -1.3208, -1.4053,  2.8064, -1.8200], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.5388, -1.3208, -1.4053,  2.8064, -1.8200], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([0.6623, 0.4700, 1.7584, 0.5093, 1.0393], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.0074,  0.6332,  0.7258,  0.2743,  0.1985], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5080,  1.0932, -0.6335,  0.6623, -0.2406], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1459,  0.1155, -0.1365,  0.2021, -0.1198], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1365,  0.0855, -0.2483,  0.0581, -0.1164], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0729,  0.0446, -0.1088,  0.0299, -0.0548], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0729,  0.0446, -0.1088,  0.0299, -0.0548], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0057, -0.0246,  0.0488,  0.0020, -0.0264], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0294,  0.1550, -0.2292, -0.0058,  0.3076], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-12.6926, -19.4296,  -0.2289,  -2.1057,  -5.0389],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0500, 0.0649, 0.0502, 0.0817, 0.0687], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5300, 0.2835, 0.9886, 0.8420, 0.7074], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0729,  0.0446, -0.1088,  0.0299, -0.0548], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.0672e-05, -8.9570e-05,  1.7814e-04,  7.2200e-06, -9.6371e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.3483e-05,  3.6938e-04, -3.1046e-04, -3.6316e-04,  1.6060e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0034,  0.0014,  0.0020, -0.0031,  0.0014], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0452,  0.0312, -0.0705,  0.0168, -0.0351], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0452,  0.0312, -0.0705,  0.0168, -0.0351], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0123, -0.0087,  0.0195,  0.0444,  0.0089], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([16.6825], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2448], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0057, -0.0057,  0.0116,  0.0174,  0.0061], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0057, -0.0057,  0.0116,  0.0174,  0.0061], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0254,  0.0235,  0.1016,  0.0413, -0.1822], grad_fn=<SliceBackward0>)
  [Layer 2] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 2] Output sample values after mixer: tensor([ 0.0254,  0.0235,  0.1016,  0.0413, -0.1822], grad_fn=<SliceBackward0>)
  [Layer 2] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 2] Residual connection sample values: tensor([ 0.3821,  0.4867, -0.1571, -0.8928,  0.3242], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 3/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.4690], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.8251], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2737,  0.2925, -0.0841, -0.6845,  0.2216], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.8586, -1.9789, -0.7965, -3.5739,  0.2291], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.8586, -1.9789, -0.7965, -3.5739,  0.2291], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 2.5472, -0.5313, -0.6434, -1.3401, -3.4470], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.1676, 0.2362, 0.8646, 0.5741, 0.6496], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.3213,  0.1588, -2.0180,  2.5472, -0.2023], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1349, -0.1597,  0.1015, -0.2420,  0.0611], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0901, -0.2375,  0.0504, -0.2886, -0.0058], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0471, -0.1047,  0.0258, -0.1236, -0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0471, -0.1047,  0.0258, -0.1236, -0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2344, -0.1334, -0.0248,  0.1756, -0.1062], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2612,  0.8368,  0.9793,  0.4030,  0.1780], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-20.9265,  -0.8803,  -0.6735,  -0.6461,  -0.2726],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0148, 0.0061, 0.0001, 0.0093, 0.0196], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7332, 0.9946, 0.9999, 0.9940, 0.9947], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0471, -0.1047,  0.0258, -0.1236, -0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.6363e-04, -9.3126e-05, -1.7345e-05,  1.2259e-04, -7.4129e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 5.9204e-04, -5.7808e-04, -1.0453e-03, -8.3934e-05,  6.0580e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0120,  0.0211,  0.0098, -0.0050, -0.0246], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0214, -0.0532,  0.0282, -0.0928, -0.0267], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0214, -0.0532,  0.0282, -0.0928, -0.0267], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0055,  0.0128, -0.0070,  0.0090, -0.0034], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([10.1681], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3136], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0031,  0.0064, -0.0028,  0.0040, -0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0031,  0.0064, -0.0028,  0.0040, -0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1087,  0.2257, -0.4234,  0.3270, -0.0142], grad_fn=<SliceBackward0>)
  [Layer 3] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 3] Output sample values after mixer: tensor([-0.1087,  0.2257, -0.4234,  0.3270, -0.0142], grad_fn=<SliceBackward0>)
  [Layer 3] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 3] Residual connection sample values: tensor([ 0.2734,  0.7124, -0.5805, -0.5659,  0.3100], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 4/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.6123], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7875], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1264,  0.2852, -0.2188, -0.2781,  0.1348], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 3.0040, -0.1111, -2.2692,  0.0550,  0.9644], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 3.0040, -0.1111, -2.2692,  0.0550,  0.9644], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.7386,  0.5750,  0.3931, -0.5244,  2.2560], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.0590, 0.9566, 0.9339, 0.8439, 0.4031], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5864, -2.3341, -0.8082, -0.7386, -0.5216], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1829, -0.0275, -0.0610, -0.2560, -0.0890], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2050, -0.0150, -0.1014, -0.3207,  0.1701], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1130, -0.0074, -0.0481, -0.1349,  0.0922], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1130, -0.0074, -0.0481, -0.1349,  0.0922], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2774, -0.0139, -0.0898,  0.0365, -0.0133], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2670,  0.0268,  0.2644, -0.2278,  0.1814], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4907, -0.5048, -0.6491, -0.5552, -0.4657], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1244, 0.1421, 0.2001, 0.0896, 0.4605], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9408, 0.9308, 0.8782, 0.9515, 0.8070], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1130, -0.0074, -0.0481, -0.1349,  0.0922], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0039, -0.0002, -0.0013,  0.0005, -0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0309, -0.0033, -0.0016,  0.0017,  0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0876,  0.0246,  0.0199, -0.2526,  0.3784], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1625,  0.0196, -0.0121, -0.3421,  0.4396], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1625,  0.0196, -0.0121, -0.3421,  0.4396], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.4650, -0.0010,  0.0026, -0.0097,  0.3069], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([11.8085], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2910], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.4076, -0.0010,  0.0020, -0.0084,  0.1935], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.4076, -0.0010,  0.0020, -0.0084,  0.1935], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1983, -0.0011, -0.2260, -0.0629, -0.1777], grad_fn=<SliceBackward0>)
  [Layer 4] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 4] Output sample values after mixer: tensor([-0.1983, -0.0011, -0.2260, -0.0629, -0.1777], grad_fn=<SliceBackward0>)
  [Layer 4] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 4] Residual connection sample values: tensor([ 0.0752,  0.7113, -0.8065, -0.6288,  0.1323], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 5/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.7113], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7644], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0476,  0.3794, -0.3760, -0.3966,  0.0794], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5120, -2.9378, -2.9719, -0.8844, -1.3979], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5120, -2.9378, -2.9719, -0.8844, -1.3979], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2689, -3.9254, -3.6293,  2.0862, -0.0359], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.6891, 0.7501, 1.4433, 0.7668, 1.4497], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 2.0139e-03, -6.2855e-01, -2.4791e+00,  2.6888e-01, -1.6328e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.8456, -1.3173, -0.6703, -0.1769, -0.1513], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.9090, -1.5586, -0.6776, -0.1500, -0.1404], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2611, -0.2710, -0.2282, -0.0694, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2611, -0.2710, -0.2282, -0.0694, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0946,  0.0077, -0.2270, -0.0311, -0.0887], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0068,  0.6820, -0.2739, -0.2516, -0.1321], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0759, -0.5319, -0.0470, -1.4939, -3.6258], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6542, 0.0294, 0.1474, 0.0300, 0.0674], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9515, 0.9845, 0.9931, 0.9562, 0.7833], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2611, -0.2710, -0.2282, -0.0694, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0162, -0.0013,  0.0388,  0.0053,  0.0152], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0187, -0.0077,  0.5664,  0.0642,  0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-1.8993, -1.8063, -1.3771, -0.4272, -0.7437], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-2.2667, -2.1876, -1.6983, -0.5249, -0.8355], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-2.2667, -2.1876, -1.6983, -0.5249, -0.8355], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.4349, 0.3234, 0.2459, 0.1357, 0.2314], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([38.6645], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1608], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0231, 0.0182, 0.0283, 0.0172, 0.0318], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0231, 0.0182, 0.0283, 0.0172, 0.0318], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1645, -0.4799,  0.0607,  0.6610,  1.1744], grad_fn=<SliceBackward0>)
  [Layer 5] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 5] Output sample values after mixer: tensor([-0.1645, -0.4799,  0.0607,  0.6610,  1.1744], grad_fn=<SliceBackward0>)
  [Layer 5] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 5] Residual connection sample values: tensor([-0.0893,  0.2314, -0.7458,  0.0322,  1.3067], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 6/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.5946], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6208], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0407,  0.0870, -0.2645,  0.0140,  0.5312], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5206, -1.2159, -0.0081, -4.8775, -2.1924], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5206, -1.2159, -0.0081, -4.8775, -2.1924], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3888, -0.5116, -0.9520,  1.0169,  0.1483], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.1142, 0.1499, 0.8901, 1.3829, 1.6737], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.2019, -2.3852,  0.1846,  0.3888, -1.0449], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0151,  0.0049, -0.2941, -0.0071,  0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0321,  0.0189, -0.2129, -0.0188,  0.1393], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0158,  0.0096, -0.0952, -0.0093,  0.0745], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0158,  0.0096, -0.0952, -0.0093,  0.0745], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0764, -0.0740, -0.2579,  0.0425, -0.0142], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0064,  0.1170, -0.2759, -0.1678, -0.0610], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5110, -0.2862, -0.5421, -0.3954, -0.5986], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4002, 0.1338, 0.1865, 0.4657, 0.4266], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8151, 0.9624, 0.9038, 0.8318, 0.7746], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0158,  0.0096, -0.0952, -0.0093,  0.0745], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-4.8248e-04,  4.6775e-04,  1.6297e-03, -2.6882e-04,  8.9681e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0056, -0.0049, -0.0135,  0.0096,  0.0128], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0204,  0.0104, -0.0296, -0.0062,  0.0938], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0385,  0.0214, -0.1387, -0.0169,  0.1792], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0385,  0.0214, -0.1387, -0.0169,  0.1792], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0075, -0.0059,  0.0006,  0.0006, -0.0395], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([39.6293], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1589], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0034, -0.0026,  0.0002,  0.0003, -0.0148], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0034, -0.0026,  0.0002,  0.0003, -0.0148], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1063,  0.2269, -0.0645,  0.0832, -0.2035], grad_fn=<SliceBackward0>)
  [Layer 6] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 6] Output sample values after mixer: tensor([-0.1063,  0.2269, -0.0645,  0.0832, -0.2035], grad_fn=<SliceBackward0>)
  [Layer 6] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 6] Residual connection sample values: tensor([-0.1956,  0.4583, -0.8103,  0.1154,  1.1032], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 7/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.9216], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5850], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0833,  0.1585, -0.2722,  0.0496,  0.4075], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4595, -0.5341, -0.1130, -0.2849, -0.5027], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4595, -0.5341, -0.1130, -0.2849, -0.5027], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-3.0653, -2.1564,  1.2448,  0.1764,  0.1112], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.2736, 0.0623, 1.1141, 0.5357, 0.8248], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.2187, -1.9645, -2.8754, -3.0653, -0.1405], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.7298, -0.4243,  0.1901, -0.1245,  0.0757], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.7635, -0.4956,  0.0591, -0.1161,  0.0729], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2427, -0.1876,  0.0304, -0.0547,  0.0378], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2427, -0.1876,  0.0304, -0.0547,  0.0378], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1013, -0.0558, -0.0601,  0.1301,  0.0392], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0737,  0.1960,  0.0542,  0.0842,  0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-6.5957e-02, -4.5478e+00, -5.8281e+00, -4.2034e-01, -1.9005e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6143, 0.0352, 0.1068, 0.2275, 0.3965], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9603, 0.8520, 0.5366, 0.9088, 0.9992], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2427, -0.1876,  0.0304, -0.0547,  0.0378], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0151,  0.0083,  0.0090, -0.0194, -0.0059], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0982,  0.0394, -0.0185,  0.0166,  0.0990], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1842, -0.0909, -0.1843,  0.1023,  0.0117], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.7469, -0.5259, -0.1137, -0.0245,  0.0994], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.7469, -0.5259, -0.1137, -0.0245,  0.0994], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.2104,  0.1038,  0.0061,  0.0030, -0.0188], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([10.0134], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3160], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0794,  0.0473,  0.0017,  0.0010, -0.0136], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0794,  0.0473,  0.0017,  0.0010, -0.0136], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0607,  0.0076,  0.2797,  0.1164, -0.4752], grad_fn=<SliceBackward0>)
  [Layer 7] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 7] Output sample values after mixer: tensor([-0.0607,  0.0076,  0.2797,  0.1164, -0.4752], grad_fn=<SliceBackward0>)
  [Layer 7] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 7] Residual connection sample values: tensor([-0.2563,  0.4659, -0.5306,  0.2318,  0.6281], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 8/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3.4975], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5347], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1310,  0.1782, -0.1896,  0.1154,  0.2689], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0274, -2.2336, -1.6584, -1.3405, -2.3680], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0274, -2.2336, -1.6584, -1.3405, -2.3680], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-3.2333,  0.5374, -3.5372, -3.7460,  2.0593], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.9631, 3.8014, 3.1209, 1.5492, 2.7614], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.1382, -1.6702,  0.1199, -3.2333,  1.4291], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6501, -0.2469, -0.2708, -0.3859,  0.7964], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.7275, -0.1659, -0.2044, -0.4829,  0.7338], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2370, -0.0761, -0.0918, -0.1842,  0.4958], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2370, -0.0761, -0.0918, -0.1842,  0.4958], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0233, -0.0122,  0.0386, -0.1625, -0.1653], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0057, -0.0654, -0.0412,  0.5749, -0.2629], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6851, -0.1380, -0.4118, -0.2678, -0.1244], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3133, 5.1248, 2.2735, 1.1901, 3.8809], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8068, 0.4930, 0.3921, 0.7270, 0.6170], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2370, -0.0761, -0.0918, -0.1842,  0.4958], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0017,  0.0009, -0.0029,  0.0121,  0.0123], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0119,  0.0176,  0.0032,  0.0250,  0.0109], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0968, -0.0509,  0.0087, -0.0655,  0.0839], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.9894, -0.3374, -0.3370, -0.7595,  1.9512], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.9894, -0.3374, -0.3370, -0.7595,  1.9512], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0134,  0.0729,  0.0894,  0.2112, -0.3957], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([131.0760], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0873], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0027,  0.0078,  0.0294,  0.0592, -0.0760], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0027,  0.0078,  0.0294,  0.0592, -0.0760], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2497,  0.1479,  0.5805,  0.4020, -0.7849], grad_fn=<SliceBackward0>)
  [Layer 8] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 8] Output sample values after mixer: tensor([-0.2497,  0.1479,  0.5805,  0.4020, -0.7849], grad_fn=<SliceBackward0>)
  [Layer 8] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 8] Residual connection sample values: tensor([-0.5060,  0.6138,  0.0499,  0.6338, -0.1568], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 9/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.7374], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4594], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2138,  0.2005,  0.0156,  0.2686, -0.0577], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.1605, -1.1745, -3.2590, -1.8539,  0.6481], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.1605, -1.1745, -3.2590, -1.8539,  0.6481], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 2.8223, -3.0782,  2.8081,  0.4619,  0.2308], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.9097, 3.9186, 2.7403, 3.2557, 1.5431], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 2.5571, -0.6423,  0.8244,  2.8223,  4.6809], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6688, -0.9296, -0.5847,  0.2876,  0.3790], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.9222, -0.8391, -0.5889,  0.2943,  0.3603], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2624, -0.2532, -0.2102,  0.1686,  0.2123], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2624, -0.2532, -0.2102,  0.1686,  0.2123], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0572, -0.0020,  0.0435, -0.1778, -0.1561], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0597, -0.2772, -0.0709, -0.1199, -0.0798], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1701, -0.1135, -0.1054, -0.5864, -0.1497], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.4198, 4.7331, 4.5391, 1.9259, 1.8985], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6626, 0.5843, 0.6198, 0.3232, 0.7527], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2624, -0.2532, -0.2102,  0.1686,  0.2123], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0363,  0.0012, -0.0276,  0.1129,  0.0991], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0911, -0.1896, -0.0929,  0.4478,  0.3902], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3498, -0.0686, -0.1726,  0.0501,  0.2535], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-1.0528, -0.7470, -0.7358,  0.5020,  0.8223], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-1.0528, -0.7470, -0.7358,  0.5020,  0.8223], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.2351,  0.2071,  0.0887, -0.1260,  0.3499], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([64.7660], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1243], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0254,  0.0416,  0.0119, -0.0194,  0.0542], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0254,  0.0416,  0.0119, -0.0194,  0.0542], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4767, -0.0237, -0.6390,  0.1066, -0.4667], grad_fn=<SliceBackward0>)
  [Layer 9] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 9] Output sample values after mixer: tensor([-0.4767, -0.0237, -0.6390,  0.1066, -0.4667], grad_fn=<SliceBackward0>)
  [Layer 9] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 9] Residual connection sample values: tensor([-0.9827,  0.5902, -0.5891,  0.7404, -0.6235], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 10/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([5.2435], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4367], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4235,  0.1943, -0.1893,  0.3139, -0.2275], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.9678, -1.6664, -1.8269, -2.5282, -0.6811], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.9678, -1.6664, -1.8269, -2.5282, -0.6811], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8985, -0.8320, -0.6838,  3.9183,  0.9303], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.3462, 1.8889, 1.9794, 3.1512, 1.2852], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.7999, -1.7704, -3.1215, -0.8985, -0.3331], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.8833,  0.5665,  0.0054,  0.9874, -0.1943], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-1.0536,  0.5426, -0.0326,  1.5914, -0.1454], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2724,  0.3431, -0.0160,  1.3221, -0.0674], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2724,  0.3431, -0.0160,  1.3221, -0.0674], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1508,  0.6321,  0.1327, -0.1815,  0.3068], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0985, -0.1944, -0.2498, -0.2273, -0.0117], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0854, -0.0771, -0.0845, -0.0547, -0.0697], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.4573, 0.4944, 0.5227, 4.2649, 1.3210], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7445, 0.9626, 0.9568, 0.7920, 0.9121], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2724,  0.3431, -0.0160,  1.3221, -0.0674], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.1420, -0.5953, -0.1250,  0.1709, -0.2889], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.1600, -1.2368, -0.0876,  0.5168, -0.2093], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-2.4649,  0.9587, -1.1599, 15.8263,  1.2822], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-3.7912,  2.6294, -1.2379, 22.2640,  0.9539], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-3.7912,  2.6294, -1.2379, 22.2640,  0.9539], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 1.0102, -0.6963,  0.3135, -4.1599, -0.2183], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([360.9684], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0526], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0324, -0.0478,  0.0236, -0.2408, -0.0153], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0324, -0.0478,  0.0236, -0.2408, -0.0153], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2310, -0.4267, -0.0895,  0.0988, -0.2694], grad_fn=<SliceBackward0>)
  [Layer 10] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 10] Output sample values after mixer: tensor([ 0.2310, -0.4267, -0.0895,  0.0988, -0.2694], grad_fn=<SliceBackward0>)
  [Layer 10] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 10] Residual connection sample values: tensor([-0.7517,  0.1635, -0.6786,  0.8393, -0.8929], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 11/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([5.9064], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4115], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2234,  0.0394, -0.1587,  0.2723, -0.2348], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0108, -2.1150, -2.2390,  1.7730, -4.6664], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0108, -2.1150, -2.2390,  1.7730, -4.6664], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1301, -0.9644,  0.1809,  0.7641, -0.4326], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-2.9818, -1.3564,  0.2327,  2.8565,  2.0185], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3704,  2.1559,  0.6833, -0.1301, -0.8390], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0995,  0.1533, -0.1026, -0.1205,  0.1307], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2460,  0.3445, -0.0787, -0.0131,  0.2457], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1380,  0.2016, -0.0378, -0.0065,  0.1378], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1380,  0.2016, -0.0378, -0.0065,  0.1378], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2675,  0.0276, -0.1360,  0.1569, -0.0212], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1695, -0.2522, -0.0136, -0.0174, -0.2407], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2593, -0.1261, -0.1036, -0.2378, -0.4305], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0116, 0.0186, 0.1876, 2.6944, 2.1914], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9970, 0.9977, 0.9808, 0.5270, 0.3893], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1380,  0.2016, -0.0378, -0.0065,  0.1378], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-4.2733e-04,  4.4029e-05, -2.1729e-04,  2.5055e-04, -3.3875e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1858,  0.0106,  0.0182, -0.0865,  0.1161], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([0.2832, 0.3064, 0.2852, 0.1463, 0.4097], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1522, -0.3295,  0.4044,  0.1667, -0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1522, -0.3295,  0.4044,  0.1667, -0.0251], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0008,  0.0750, -0.0872,  0.2527,  0.0011], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([28.3969], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1877], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-5.4609e-05,  3.6566e-02, -7.6250e-02,  4.1539e-02,  2.0942e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-5.4609e-05,  3.6566e-02, -7.6250e-02,  4.1539e-02,  2.0942e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3402, -0.0566, -0.2892, -0.7546, -0.1884], grad_fn=<SliceBackward0>)
  [Layer 11] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 11] Output sample values after mixer: tensor([-0.3402, -0.0566, -0.2892, -0.7546, -0.1884], grad_fn=<SliceBackward0>)
  [Layer 11] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 11] Residual connection sample values: tensor([-1.0919,  0.1069, -0.9678,  0.0846, -1.0814], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 12/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([6.7273], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3855], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2699,  0.0210, -0.1743,  0.0237, -0.2262], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0445, -1.1142,  1.0958, -0.4318, -0.8673], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0445, -1.1142,  1.0958, -0.4318, -0.8673], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6272,  0.5299,  1.2895,  0.4932, -1.6306], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.6638, 1.6103, 1.2802, 2.0572, 0.3740], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5676,  0.6179, -2.6214, -0.6272,  0.0766], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6558, -0.6696, -0.2377,  0.0718,  1.3604], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.7230, -1.5041, -0.3024,  0.0276,  1.1937], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2362, -0.2735, -0.1285,  0.0140,  0.9161], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2362, -0.2735, -0.1285,  0.0140,  0.9161], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0332,  0.2437, -0.1428,  0.5046,  0.0376], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0395, -0.2626, -0.2737, -0.2770,  0.0884], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1609, -0.1475, -0.2713, -0.1155, -0.0902], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.2932, 1.5856, 2.1506, 3.4272, 0.0999], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6915, 0.7915, 0.5580, 0.6730, 0.9910], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2362, -0.2735, -0.1285,  0.0140,  0.9161], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0180, -0.1320,  0.0774, -0.2733, -0.0204], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0312,  0.0372,  0.1254, -0.2282, -0.0270], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.5019, -1.0304, -0.5413, -0.0362,  4.7239], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.8853, -1.4742, -0.7499, -0.0136,  6.2106], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.8853, -1.4742, -0.7499, -0.0136,  6.2106], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0201,  0.4059, -0.6159,  0.0023, -1.5934], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([54.1693], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1359], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0042,  0.0489, -0.1453,  0.0010, -0.2827], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0042,  0.0489, -0.1453,  0.0010, -0.2827], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2292, -0.1241,  0.0918, -0.1314,  0.5144], grad_fn=<SliceBackward0>)
  [Layer 12] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 12] Output sample values after mixer: tensor([-0.2292, -0.1241,  0.0918, -0.1314,  0.5144], grad_fn=<SliceBackward0>)
  [Layer 12] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 12] Residual connection sample values: tensor([-1.3211, -0.0173, -0.8760, -0.0468, -0.5670], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 13/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([7.3697], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3684], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2630, -0.0028, -0.1356, -0.0100, -0.1013], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6775, -0.4035, -0.6647, -2.7623, -2.0651], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6775, -0.4035, -0.6647, -2.7623, -2.0651], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2538, -0.0330,  1.9360,  0.4814,  0.2581], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.7773, 0.8168, 1.3897, 1.8348, 0.2878], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1104,  0.2791, -0.4165,  0.2538, -0.2704], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1650, -0.4102, -0.1294,  0.0474, -0.0592], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1030, -0.4289, -0.1215,  0.0357, -0.0896], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0541, -0.1691, -0.0571,  0.0182, -0.0428], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0541, -0.1691, -0.0571,  0.0182, -0.0428], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1024, -0.2223,  0.2008, -0.1162,  0.0490], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0443, -0.1783,  0.3154,  0.0909, -0.2246], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0234, -1.0903, -0.5085, -0.6785, -0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1110, 0.0225, 0.0337, 0.0325, 0.1985], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9974, 0.9757, 0.9830, 0.9782, 0.9950], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0541, -0.1691, -0.0571,  0.0182, -0.0428], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0006, -0.0013,  0.0012, -0.0007,  0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0924,  0.0999, -0.2819,  0.0231, -0.0597], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2498, -0.1548, -0.0572,  0.0037,  0.4076], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2560, -0.1353, -0.0507,  0.0016,  0.4126], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2560, -0.1353, -0.0507,  0.0016,  0.4126], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0584,  0.0219,  0.0114, -0.0003, -0.0959], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.2477], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.8952], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0262,  0.0065,  0.0115, -0.0006, -0.0495], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0262,  0.0065,  0.0115, -0.0006, -0.0495], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0638,  0.9104, -1.4420,  0.4427,  0.3134], grad_fn=<SliceBackward0>)
  [Layer 13] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 13] Output sample values after mixer: tensor([-0.0638,  0.9104, -1.4420,  0.4427,  0.3134], grad_fn=<SliceBackward0>)
  [Layer 13] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 13] Residual connection sample values: tensor([-1.3849,  0.8931, -2.3179,  0.3959, -0.2535], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 14/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([10.2221], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3128], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2058,  0.1146, -0.2908,  0.0666, -0.0353], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.2015,  0.6560, -0.4086, -0.1008,  0.4490], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.2015,  0.6560, -0.4086, -0.1008,  0.4490], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.3864,  0.4325, -0.3109,  0.6268,  0.2827], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.7531, 0.2588, 1.9548, 0.9222, 0.9627], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.0343, -0.9049,  1.7297, -0.3864,  0.4099], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0829, -0.1092, -0.4661, -0.1198, -0.0782], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1533, -0.1586, -0.6578, -0.1674, -0.0920], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0825, -0.0730, -0.2245, -0.0767, -0.0439], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0825, -0.0730, -0.2245, -0.0767, -0.0439], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0304,  0.0003,  0.2230, -0.0418, -0.1152], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1868, -0.0392,  0.2440, -0.2103, -0.1900], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-7.2745, -0.0385, -2.2024, -0.0138, -5.3378], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0431, 0.0766, 0.0802, 0.1210, 0.0421], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7307, 0.9971, 0.8381, 0.9983, 0.7988], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0825, -0.0730, -0.2245, -0.0767, -0.0439], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.0803e-04,  1.0780e-06,  7.9370e-04, -1.4876e-04, -4.0987e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0005, -0.0008,  0.0012, -0.0001,  0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0010, -0.0077, -0.0169, -0.0009, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0659, -0.0652, -0.1936, -0.0613, -0.0355], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0659, -0.0652, -0.1936, -0.0613, -0.0355], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0609, -0.0281,  0.0316,  0.0029, -0.0097], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2284], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.0925], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.3005, -0.0967,  0.0745,  0.0100, -0.0422], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.3005, -0.0967,  0.0745,  0.0100, -0.0422], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2833, -0.3511, -0.6479, -0.1684, -0.2928], grad_fn=<SliceBackward0>)
  [Layer 14] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 14] Output sample values after mixer: tensor([-0.2833, -0.3511, -0.6479, -0.1684, -0.2928], grad_fn=<SliceBackward0>)
  [Layer 14] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 14] Residual connection sample values: tensor([-1.6682,  0.5420, -2.9659,  0.2275, -0.5464], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 15/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([12.2866], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2853], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2895,  0.0774, -0.4251,  0.0468, -0.0885], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6531,  1.3139,  1.0847, -0.1482, -3.7886], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6531,  1.3139,  1.0847, -0.1482, -3.7886], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.1975,  0.0405, -0.4311,  0.0916, -0.6583], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.0210, 1.6035, 0.0300, 1.2816, 1.0875], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.7406, -0.4331, -1.1423,  0.1975, -1.4869], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0202,  0.0514, -0.0449,  0.0197,  0.0433], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3564,  0.0272,  1.2803,  0.4624,  0.0298], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1468,  0.0138,  1.0018,  0.2837,  0.0151], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1468,  0.0138,  1.0018,  0.2837,  0.0151], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0350, -0.0900, -0.0583, -0.0182, -0.1315], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0463, -0.1169,  0.1815, -0.0633, -0.0534], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.4414, -0.0592, -0.7390, -0.0051, -0.0087], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3943, 1.3488, 0.0226, 0.1644, 0.3674], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.3819, 0.9232, 0.9835, 0.9992, 0.9968], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1468,  0.0138,  1.0018,  0.2837,  0.0151], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0020,  0.0052,  0.0034,  0.0011,  0.0076], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0013,  0.0076,  0.0049,  0.0014,  0.0090], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0060,  0.0011,  0.0295,  0.0088,  0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2681,  0.0257,  1.8185,  0.5154,  0.0282], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2681,  0.0257,  1.8185,  0.5154,  0.0282], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0599,  0.0266,  1.4743, -0.0354, -0.0024], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([3.1613], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5624], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0745,  0.0242,  0.3929, -0.0248, -0.0030], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0745,  0.0242,  0.3929, -0.0248, -0.0030], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4741,  0.8466, -0.2759,  1.1607, -0.0520], grad_fn=<SliceBackward0>)
  [Layer 15] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 15] Output sample values after mixer: tensor([-0.4741,  0.8466, -0.2759,  1.1607, -0.0520], grad_fn=<SliceBackward0>)
  [Layer 15] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 15] Residual connection sample values: tensor([-2.1423,  1.3886, -3.2417,  1.3883, -0.5983], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 16/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([15.8026], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2516], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2433,  0.1303, -0.2835,  0.2000, -0.0642], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4715, -0.3326, -3.0790, -0.4675,  0.0052], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4715, -0.3326, -3.0790, -0.4675,  0.0052], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1357,  0.2263,  0.5287,  0.1810, -0.6118], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.3478, 1.6853, 0.8389, 4.1315, 0.6956], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3611,  0.2483,  1.2534, -0.1357, -0.0905], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1241, -0.0272, -0.0999,  0.2180,  0.1189], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1223, -0.0184,  0.0368,  0.1798,  0.1264], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0649, -0.0091,  0.0187,  0.0980,  0.0672], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0649, -0.0091,  0.0187,  0.0980,  0.0672], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1772, -0.0263,  0.1111, -0.0125, -0.0382], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0071, -0.0405, -0.1055, -0.2398, -0.1994], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.1349e-03, -3.0370e-03, -2.7156e+00, -4.1511e-03, -4.2926e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6272, 0.3143, 0.0538, 0.9953, 0.0023], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9993, 0.9990, 0.8641, 0.9959, 0.9990], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0649, -0.0091,  0.0187,  0.0980,  0.0672], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0072, -0.0011,  0.0045, -0.0005, -0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0044, 0.1097, 0.0385, 0.0019, 0.0039], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0147,  0.0091, -0.0292,  0.0577,  0.0308], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0298,  0.0113, -0.0336,  0.0350,  0.0151], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0298,  0.0113, -0.0336,  0.0350,  0.0151], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-8.6439e-03, -1.5642e-03,  4.5453e-03, -6.2942e-03,  3.9760e-05],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0913], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.3097], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-1.2544e-02, -1.2923e-03,  1.5117e-02, -3.6440e-03,  6.8301e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-1.2544e-02, -1.2923e-03,  1.5117e-02, -3.6440e-03,  6.8301e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.7958,  0.1269,  0.6846,  0.2538, -0.0891], grad_fn=<SliceBackward0>)
  [Layer 16] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 16] Output sample values after mixer: tensor([-0.7958,  0.1269,  0.6846,  0.2538, -0.0891], grad_fn=<SliceBackward0>)
  [Layer 16] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 16] Residual connection sample values: tensor([-2.9381,  1.5155, -2.5571,  1.6420, -0.6874], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 17/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([16.7520], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2443], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4848,  0.2152, -0.3627,  0.3105, -0.1045], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.8485, -3.3836, -1.3464, -2.3438, -2.0509], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.8485, -3.3836, -1.3464, -2.3438, -2.0509], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.7254, -1.4417, -1.2443,  0.3082, -0.1867], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.7874, 1.9769, 1.4480, 1.7233, 1.4029], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.0799, -0.4500,  0.2817, -1.7254, -1.0134], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3448, -0.0315, -0.3069,  0.0780, -0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4399, -0.0093, -0.4214,  0.1124,  0.0368], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1723, -0.0046, -0.1669,  0.0594,  0.0187], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1723, -0.0046, -0.1669,  0.0594,  0.0187], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1028,  0.0090, -0.2444,  0.0182, -0.1491], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1239, -0.0050, -0.2736, -0.1177,  0.0275], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3863, -0.8773, -1.4027, -0.6828, -0.3905], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6383, 0.4854, 0.4645, 0.9545, 0.9274], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4128, 0.6532, 0.5213, 0.5211, 0.6962], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1723, -0.0046, -0.1669,  0.0594,  0.0187], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0113, -0.0010,  0.0269, -0.0020,  0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0171, -0.0054,  0.0405,  0.0023,  0.0252], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1207, -0.0009, -0.0988,  0.0411,  0.0246], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.5746, -0.0131, -0.5385,  0.1975,  0.0740], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.5746, -0.0131, -0.5385,  0.1975,  0.0740], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1445,  0.0015,  0.1497, -0.0405, -0.0173], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([6.5507], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3907], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1102,  0.0011,  0.1226, -0.0409, -0.0161], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1102,  0.0011,  0.1226, -0.0409, -0.0161], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.9410,  1.0643, -0.1146,  0.9128, -1.1622], grad_fn=<SliceBackward0>)
  [Layer 17] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 17] Output sample values after mixer: tensor([-0.9410,  1.0643, -0.1146,  0.9128, -1.1622], grad_fn=<SliceBackward0>)
  [Layer 17] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 17] Residual connection sample values: tensor([-3.8791,  2.5798, -2.6717,  2.5549, -1.8496], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 18/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([19.7481], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2250], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4188,  0.2408, -0.2457,  0.3352, -0.1767], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4126, -0.7325, -0.0896, -0.5577,  0.0068], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4126, -0.7325, -0.0896, -0.5577,  0.0068], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1540, -1.2625, -0.3227, -0.5528, -0.5991], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.6984, 4.2483, 2.7286, 2.5518, 0.8860], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3794,  0.0273,  0.2538, -0.1540, -0.0720], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0163,  0.9319,  0.0731, -0.2154, -0.1009], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0257,  0.5339,  0.0844, -0.1849, -0.1531], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0130,  0.3366,  0.0440, -0.0839, -0.0707], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0130,  0.3366,  0.0440, -0.0839, -0.0707], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1585,  0.0008, -0.1362, -0.0695, -0.0114], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0707, -0.0519,  0.0939, -0.0233,  0.0119], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.3195e-03, -6.5336e+00, -1.4897e+01, -1.3796e-03, -2.0873e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5705, 5.3643, 4.1902, 0.9115, 0.3048], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9868e-01, 6.0080e-16, 7.7710e-28, 9.9874e-01, 9.9936e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0130,  0.3366,  0.0440, -0.0839, -0.0707], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.1751e-03,  5.9122e-06, -1.0095e-03, -5.1522e-04, -8.4509e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0031, -0.0086,  0.0923, -0.0386,  0.0122], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1518, -0.8691,  0.0906, -0.1457, -0.1678], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1529, -0.8958,  0.0871, -0.1390, -0.1622], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1529, -0.8958,  0.0871, -0.1390, -0.1622], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0251,  0.2130, -0.0037,  0.0282, -0.0006], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([5.3836], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4310], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0534,  0.1109, -0.0017,  0.0308, -0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0534,  0.1109, -0.0017,  0.0308, -0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4406,  0.1744,  0.2847,  0.1916, -1.1522], grad_fn=<SliceBackward0>)
  [Layer 18] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 18] Output sample values after mixer: tensor([-0.4406,  0.1744,  0.2847,  0.1916, -1.1522], grad_fn=<SliceBackward0>)
  [Layer 18] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 18] Residual connection sample values: tensor([-4.3197,  2.7542, -2.3870,  2.7465, -3.0019], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 19/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([22.7461], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2097], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.5400,  0.2859, -0.2505,  0.4246, -0.3331], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 3.0061, -0.7708, -0.7488,  0.2638,  0.2369], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 3.0061, -0.7708, -0.7488,  0.2638,  0.2369], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.2169, -0.1216,  0.4281,  1.5242, -0.8841], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.1586, 0.6776, 1.8030, 1.9394, 1.0995], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5119, -1.3610, -1.4364, -1.2169, -0.3156], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2538,  0.0979,  0.1205, -1.0074, -0.2188], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3053,  0.0984,  0.1067, -1.2150, -0.2199], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1295,  0.0516,  0.0562, -0.2780, -0.0979], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1295,  0.0516,  0.0562, -0.2780, -0.0979], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0513,  0.0561,  0.0954, -0.0715,  0.1564], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2074, -0.0434, -0.2099, -0.1289,  0.0159], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1739, -1.5063, -1.5725, -0.1983, -0.0768], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.2295, 0.4969, 1.1826, 3.1352, 0.8430], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6785, 0.4731, 0.1557, 0.5371, 0.9373], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1295,  0.0516,  0.0562, -0.2780, -0.0979], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0148, -0.0162, -0.0275,  0.0207, -0.0452], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0098,  0.0073, -0.0807,  0.0638, -0.0884], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.5824, -0.2819, -0.0107, -0.9996,  0.0425], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.7796, -0.2034,  0.0749, -1.4229, -0.1066], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.7796, -0.2034,  0.0749, -1.4229, -0.1066], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-2.2331,  0.0496, -0.0180, -0.2123, -0.0141], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([13.6136], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2710], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.7063,  0.0271, -0.0117, -0.0569, -0.0140], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.7063,  0.0271, -0.0117, -0.0569, -0.0140], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.5156, -0.9717,  1.2526,  1.1932, -0.7303], grad_fn=<SliceBackward0>)
  [Layer 19] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 19] Output sample values after mixer: tensor([ 1.5156, -0.9717,  1.2526,  1.1932, -0.7303], grad_fn=<SliceBackward0>)
  [Layer 19] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 19] Residual connection sample values: tensor([-2.8041,  1.7825, -1.1344,  3.9396, -3.7322], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 20/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([32.9610], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1742], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1802,  0.1048, -0.0668,  0.3098, -0.2343], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.9816, -0.2743,  0.8880, -0.1004,  0.4696], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.9816, -0.2743,  0.8880, -0.1004,  0.4696], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.2464, -0.3891, -1.3833, -0.4537, -0.0908], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.2272,  1.2624, -1.5314, -0.0235,  2.7742], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.2875, -0.8696,  0.8534,  1.2464, -0.5450], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2817,  0.0883, -0.5098, -0.0495, -0.0442], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2672,  0.0501, -0.6893, -0.0705, -0.0907], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1513,  0.0257, -0.2304, -0.0340, -0.0433], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1513,  0.0257, -0.2304, -0.0340, -0.0433], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0363,  0.0378,  0.0194,  0.0490,  0.0123], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0886, -0.0822, -0.0913,  0.0144, -0.0854], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.0858e-01, -2.9306e+00, -5.2962e+00, -1.2326e+01, -8.1593e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0089, 0.0898, 0.0132, 0.0746, 0.5250], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9973, 0.7686, 0.9327, 0.3989, 0.9957], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1513,  0.0257, -0.2304, -0.0340, -0.0433], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-4.8851e-05,  5.0903e-05,  2.6088e-05,  6.5880e-05,  1.6606e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.1824e-04, -2.4497e-04, -1.8951e-04,  7.2246e-05, -4.5811e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0006, -0.0012,  0.0026, -0.0028,  0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1239,  0.0199, -0.1868, -0.0307, -0.0336], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1239,  0.0199, -0.1868, -0.0307, -0.0336], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0331, -0.0024, -0.1175,  0.0015, -0.0097], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0285], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([5.9218], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.4915, -0.0301, -1.0332,  0.0211, -0.0917], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.4915, -0.0301, -1.0332,  0.0211, -0.0917], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.5254, -1.2776, -1.0974, -2.6844,  1.1696], grad_fn=<SliceBackward0>)
  [Layer 20] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 20] Output sample values after mixer: tensor([ 0.5254, -1.2776, -1.0974, -2.6844,  1.1696], grad_fn=<SliceBackward0>)
  [Layer 20] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 20] Residual connection sample values: tensor([-2.2787,  0.5049, -2.2318,  1.2553, -2.5626], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 21/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([37.7047], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1629], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1875,  0.0376, -0.1703,  0.1222, -0.2028], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.6044, -1.0447,  0.0254, -0.4583, -0.9944], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.6044, -1.0447,  0.0254, -0.4583, -0.9944], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5755,  0.1980,  0.5620, -0.4316, -0.3506], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([8.0141e-04, 2.1216e-01, 1.3053e+00, 3.1034e+00, 8.3922e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2690, -1.6583, -0.2675,  0.5755, -0.4131], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1437,  0.0681, -0.0951,  0.1581,  0.0352], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2138, -0.0294, -0.1208,  0.0601, -0.0188], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0955, -0.0145, -0.0568,  0.0309, -0.0093], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0955, -0.0145, -0.0568,  0.0309, -0.0093], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0916, -0.2171, -0.0532, -0.1152, -0.0239], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1046, -0.1115,  0.0014, -0.0278,  0.0274], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3228, -0.3764, -0.1595, -0.1054, -0.3757], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.7335, 0.6772, 1.7197, 2.5918, 1.0002], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7892, 0.7750, 0.7602, 0.7610, 0.6868], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0955, -0.0145, -0.0568,  0.0309, -0.0093], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([0.0064, 0.0152, 0.0037, 0.0081, 0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.1075, 0.1165, 0.0220, 0.0962, 0.0093], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2537, -0.1406, -0.0990,  0.0419,  0.3252], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.4556, -0.1712, -0.2190,  0.1073,  0.3055], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.4556, -0.1712, -0.2190,  0.1073,  0.3055], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1781,  0.0465, -0.0028, -0.0190, -0.0820], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.8857], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5887], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2182,  0.0721, -0.0049, -0.0234, -0.0869], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2182,  0.0721, -0.0049, -0.0234, -0.0869], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.6746, -3.4405, -0.1075,  0.1850,  1.3151], grad_fn=<SliceBackward0>)
  [Layer 21] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 21] Output sample values after mixer: tensor([ 1.6746, -3.4405, -0.1075,  0.1850,  1.3151], grad_fn=<SliceBackward0>)
  [Layer 21] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 21] Residual connection sample values: tensor([-0.6042, -2.9356, -2.3394,  1.4402, -1.2474], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 22/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([43.8113], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1511], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0472, -0.2121, -0.1692,  0.1329, -0.0944], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.5435,  1.6640,  1.2238, -1.3905,  1.4305], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.5435,  1.6640,  1.2238, -1.3905,  1.4305], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.3219,  1.2203, -0.1405,  1.3553,  0.9687], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.1945, -0.7671, -0.3822,  2.6645,  0.2115], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2586, -0.6772, -1.7266, -0.3219, -0.5129], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1824,  0.1005, -0.2502,  0.2841, -0.1620], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1742,  0.1650, -0.2376,  0.2658, -0.1614], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0795,  0.0893, -0.1047,  0.1504, -0.0742], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0795,  0.0893, -0.1047,  0.1504, -0.0742], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1849,  0.0124,  0.0320, -0.0935, -0.1140], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2107,  0.0152, -0.1534, -0.1603, -0.0754], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0709, -0.0702, -0.0699, -0.0895, -0.3897], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5837, 0.4281, 0.0803, 1.8861, 0.8309], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9595, 0.9704, 0.9944, 0.8447, 0.7234], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0795,  0.0893, -0.1047,  0.1504, -0.0742], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0086, -0.0006, -0.0015,  0.0043,  0.0053], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0028,  0.0419,  0.0185,  0.0086,  0.0567], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0110,  0.5139, -0.3008,  0.0133, -0.1393], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1482,  0.3600, -0.1202, -0.2460, -0.0114], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1482,  0.3600, -0.1202, -0.2460, -0.0114], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1884,  0.5036, -0.1137,  0.0682, -0.0131], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([3.7660], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5153], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2566,  0.2970, -0.1548,  0.1379, -0.0170], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.2566,  0.2970, -0.1548,  0.1379, -0.0170], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.4134,  3.0898,  2.8321, -1.5232, -3.6178], grad_fn=<SliceBackward0>)
  [Layer 22] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 22] Output sample values after mixer: tensor([ 1.4134,  3.0898,  2.8321, -1.5232, -3.6178], grad_fn=<SliceBackward0>)
  [Layer 22] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 22] Residual connection sample values: tensor([ 0.8092,  0.1542,  0.4928, -0.0829, -4.8653], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 23/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([52.9054], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1375], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0489,  0.0084,  0.0283, -0.0062, -0.2737], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.8555,  0.0227, -1.2409, -0.4983, -1.4283], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.8555,  0.0227, -1.2409, -0.4983, -1.4283], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([0.7956, 0.3186, 2.1228, 0.8755, 0.2470], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.9019, 1.9067, 1.7021, 0.7701, 1.6518], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2201, -2.9223, -0.9369,  0.7956,  0.2334], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.7424, -0.0501,  0.6212, -0.1446,  0.0436], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.7761, -0.0576,  0.5793, -0.1283,  0.0391], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2446, -0.0280,  0.3713, -0.0600,  0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2446, -0.0280,  0.3713, -0.0600,  0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([0.1649, 0.0212, 0.0126, 0.1154, 0.1159], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([0.0069, 0.1870, 0.0875, 0.0251, 0.2879], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1232, -0.2255, -0.2420, -0.0956, -0.2396], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1688, 0.9604, 0.8204, 0.1543, 0.6919], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9794, 0.8052, 0.8199, 0.9854, 0.8472], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2446, -0.0280,  0.3713, -0.0600,  0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0068, -0.0009, -0.0005, -0.0048, -0.0048], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0196, -0.0032, -0.0002,  0.0556, -0.0186], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1022,  0.0324,  0.3567, -0.0436,  0.0460], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1136,  0.0337,  0.3394, -0.0408,  0.0450], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1136,  0.0337,  0.3394, -0.0408,  0.0450], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0290,  0.0004, -0.0944,  0.0077, -0.0124], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3825], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.6168], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0461,  0.0019, -0.7486,  0.0612, -0.0551], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0461,  0.0019, -0.7486,  0.0612, -0.0551], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-3.0167, -2.5743,  3.2130,  1.8693,  0.0387], grad_fn=<SliceBackward0>)
  [Layer 23] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 23] Output sample values after mixer: tensor([-3.0167, -2.5743,  3.2130,  1.8693,  0.0387], grad_fn=<SliceBackward0>)
  [Layer 23] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 23] Residual connection sample values: tensor([-2.2075, -2.4201,  3.7058,  1.7864, -4.8265], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 24/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([64.4142], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1246], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1519, -0.1478,  0.2460,  0.1411, -0.3060], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5856,  1.3769,  1.0990, -1.1760, -0.3496], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5856,  1.3769,  1.0990, -1.1760, -0.3496], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2574, -2.2652, -1.5552, -0.2830,  1.2690], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.5294, 0.9650, 1.3411, 0.7966, 1.7687], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5313, -0.1848, -0.1602, -0.2574, -1.1127], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1190, -0.2642, -0.1835, -0.0694, -0.4667], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2459, -0.1668, -0.1857, -0.1485, -0.4598], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1380, -0.0765, -0.0842, -0.0687, -0.1780], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1380, -0.0765, -0.0842, -0.0687, -0.1780], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0545,  0.1279, -0.0048,  0.0678, -0.0067], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0578, -0.1693, -0.2694, -0.1152, -0.2619], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6296, -0.1967, -0.1434, -0.1402, -0.2238], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.0936, 1.3789, 1.3949, 1.7587, 1.4975], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5023, 0.7624, 0.8187, 0.7815, 0.7153], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1380, -0.0765, -0.0842, -0.0687, -0.1780], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0082,  0.0193, -0.0007,  0.0102, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0451,  0.0094,  0.0027,  0.0265, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1551, -0.0576, -0.0872, -0.0830, -0.2426], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.8311, -0.4321, -0.4999, -0.4197, -1.1142], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.8311, -0.4321, -0.4999, -0.4197, -1.1142], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.3126, -0.4750, -0.4120,  0.1164,  0.1611], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([4.9302], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4504], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1554, -0.7371, -0.5622,  0.1179,  0.1513], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1554, -0.7371, -0.5622,  0.1179,  0.1513], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1182,  0.0991,  0.3625,  0.8773,  2.0770], grad_fn=<SliceBackward0>)
  [Layer 24] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 24] Output sample values after mixer: tensor([-0.1182,  0.0991,  0.3625,  0.8773,  2.0770], grad_fn=<SliceBackward0>)
  [Layer 24] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 24] Residual connection sample values: tensor([-2.3257, -2.3210,  4.0683,  2.6636, -2.7495], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 25/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([77.7198], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1134], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1013, -0.0938,  0.1652,  0.1328, -0.1122], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.7044, -0.4180, -0.9958,  0.8757, -0.2592], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.7044, -0.4180, -0.9958,  0.8757, -0.2592], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0313,  0.2518,  0.6894, -1.2347, -1.4291], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.9454, 0.9426, 0.2095, 1.5028, 1.6156], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.0075, -0.1695,  0.0134,  0.0313, -0.0845], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0121, -0.0442, -0.1587, -0.6663, -0.2100], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0315, -0.0409, -0.0560, -0.7714, -0.2487], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0155, -0.0200, -0.0272, -0.2439, -0.1090], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0155, -0.0200, -0.0272, -0.2439, -0.1090], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0653, -0.0456, -0.1250, -0.0405, -0.0181], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2200, -0.2678, -0.2783,  0.9193, -0.1221], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1626, -0.3327, -0.3294, -0.2016, -0.1541], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.1101, 0.7364, 0.4085, 1.2437, 1.5021], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8348, 0.7827, 0.8741, 0.7782, 0.7934], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0155, -0.0200, -0.0272, -0.2439, -0.1090], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([0.0011, 0.0008, 0.0021, 0.0007, 0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0035,  0.0014, -0.0006,  0.0020, -0.0080], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0105, -0.0075, -0.0181, -0.2851, -0.0927], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0247, -0.0259, -0.0431, -0.5092, -0.1928], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0247, -0.0259, -0.0431, -0.5092, -0.1928], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0058,  0.0043,  0.0116, -0.3148,  0.0218], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2144], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.1594], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0432,  0.0253,  0.0569, -0.8677,  0.0924], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0432,  0.0253,  0.0569, -0.8677,  0.0924], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.8004,  0.8986,  2.2529,  1.5811, -2.6591], grad_fn=<SliceBackward0>)
  [Layer 25] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 25] Output sample values after mixer: tensor([-1.8004,  0.8986,  2.2529,  1.5811, -2.6591], grad_fn=<SliceBackward0>)
  [Layer 25] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 25] Residual connection sample values: tensor([-4.1262, -1.4223,  6.3211,  4.2447, -5.4086], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 26/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([94.4656], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1029], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2029, -0.0652,  0.3045,  0.2508, -0.2545], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1757,  0.2005, -0.9872, -0.2065, -0.0314], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1757,  0.2005, -0.9872, -0.2065, -0.0314], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0586, -1.1958,  0.4611, -0.6016, -1.8148], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.4737, 0.2179, 0.9372, 0.8846, 0.7856], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8596,  0.4920, -1.0918,  0.0586,  0.5256], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0368, -0.4079, -0.1085, -0.1644, -0.6572], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1278, -0.4618, -0.1338, -0.2277, -0.9250], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0598, -0.1785, -0.0624, -0.1010, -0.2626], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0598, -0.1785, -0.0624, -0.1010, -0.2626], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.2258,  0.0352, -0.0396,  0.1487,  0.0620], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0825, -0.2781,  0.1074,  0.0458,  0.0172], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3298, -0.0634, -0.2289, -0.1264, -0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.4502, 0.2316, 2.3862, 2.0933, 0.9341], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6199, 0.9854, 0.5792, 0.7675, 0.9469], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0598, -0.1785, -0.0624, -0.1010, -0.2626], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0196, -0.0031,  0.0034, -0.0129, -0.0054], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0108,  0.0174, -0.0084, -0.0272, -0.0219], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1687, -0.2930, -0.1247, -0.1853, -0.7007], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.4101, -1.0130, -0.3764, -0.5925, -1.7600], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.4101, -1.0130, -0.3764, -0.5925, -1.7600], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0329, -0.1117,  0.1009,  0.0549,  0.0272], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([5.1373], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4412], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0343, -0.0814,  0.0971,  0.0580,  0.0212], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0343, -0.0814,  0.0971,  0.0580,  0.0212], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.1080, -0.9626,  1.4924,  0.2690, -0.5361], grad_fn=<SliceBackward0>)
  [Layer 26] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 26] Output sample values after mixer: tensor([-1.1080, -0.9626,  1.4924,  0.2690, -0.5361], grad_fn=<SliceBackward0>)
  [Layer 26] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 26] Residual connection sample values: tensor([-5.2341, -2.3849,  7.8135,  4.5137, -5.9448], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 27/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([107.6871], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0964], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2102, -0.0912,  0.3028,  0.2095, -0.2404], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.1420,  0.5741, -0.3630,  0.1817,  0.6575], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.1420,  0.5741, -0.3630,  0.1817,  0.6575], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.7114, -0.7652,  0.7220,  0.0615,  0.5906], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.8890, -1.4031,  0.6516,  0.6439, -0.2634], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0666, -0.4002,  0.9614,  0.7114,  0.2481], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2190, -0.2183,  0.1499, -0.0286,  0.0695], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2356, -0.2700,  0.0948, -0.2288,  0.0714], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1040, -0.1169,  0.0497, -0.1014,  0.0370], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1040, -0.1169,  0.0497, -0.1014,  0.0370], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1335,  0.1323, -0.0016, -0.0190,  0.0706], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2284, -0.1491,  0.1899, -0.0212, -0.0817], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5626, -0.0303, -0.7559, -1.1613, -0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1776, 0.0111, 0.0178, 0.1418, 0.0244], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9049, 0.9997, 0.9866, 0.8482, 0.9990], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1040, -0.1169,  0.0497, -0.1014,  0.0370], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.4647e-03, -2.4427e-03,  3.0361e-05,  3.5043e-04, -1.3034e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0031, -0.0120, -0.0051, -0.0078, -0.0051], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0770, -0.0043,  0.0253, -0.1151,  0.0483], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2838, -0.2368,  0.1240, -0.3167,  0.1219], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2838, -0.2368,  0.1240, -0.3167,  0.1219], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.2457, -0.0870, -0.0185, -0.0314,  0.0528], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4232], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.5372], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.8676, -0.2417, -0.0740, -0.0324,  0.2702], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.8676, -0.2417, -0.0740, -0.0324,  0.2702], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0507, -1.0114,  1.3786,  0.1084, -1.0138], grad_fn=<SliceBackward0>)
  [Layer 27] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 27] Output sample values after mixer: tensor([-0.0507, -1.0114,  1.3786,  0.1084, -1.0138], grad_fn=<SliceBackward0>)
  [Layer 27] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 27] Residual connection sample values: tensor([-5.2848, -3.3963,  9.1921,  4.6221, -6.9586], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 28/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([105.8047], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0972], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1833, -0.1133,  0.3135,  0.1874, -0.2337], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.4287,  0.4793,  0.1450,  0.1147,  0.6293], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.4287,  0.4793,  0.1450,  0.1147,  0.6293], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0029,  0.0051, -0.4021, -0.3103, -1.1367], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.6388,  0.3935,  0.7190,  0.3624,  0.6057], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1485, -0.8534,  0.5593,  0.0029, -0.2397], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0178, -0.1335, -0.1593,  0.0835, -0.2763], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1457, -0.2229, -0.2885, -0.0066, -0.3420], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0675, -0.0991, -0.1236, -0.0033, -0.1420], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0675, -0.0991, -0.1236, -0.0033, -0.1420], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2436, -0.1149, -0.0570,  0.1007, -0.1240], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0274,  0.0532, -0.0817, -0.1014, -0.0388], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5442, -0.1843, -0.1064, -0.1124, -0.2523], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0989, 0.6839, 1.4014, 1.0678, 0.7563], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9476, 0.8816, 0.8614, 0.8869, 0.8263], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0675, -0.0991, -0.1236, -0.0033, -0.1420], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0016,  0.0008,  0.0004, -0.0007,  0.0008], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0143, -0.0044,  0.0042, -0.0015,  0.0165], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0159, -0.0457, -0.0280,  0.0092, -0.0175], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1419, -0.2305, -0.2586,  0.0031, -0.2824], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1419, -0.2305, -0.2586,  0.0031, -0.2824], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0392, -0.0682, -0.0201,  0.0002, -0.1159], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1557], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.5338], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2025, -0.3313, -0.0932,  0.0010, -0.7224], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.2025, -0.3313, -0.0932,  0.0010, -0.7224], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.3626, -4.1384,  0.7261, -0.1127, -1.3534], grad_fn=<SliceBackward0>)
  [Layer 28] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 28] Output sample values after mixer: tensor([ 2.3626, -4.1384,  0.7261, -0.1127, -1.3534], grad_fn=<SliceBackward0>)
  [Layer 28] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 28] Residual connection sample values: tensor([-2.9222, -7.5347,  9.9183,  4.5094, -8.3120], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 29/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([114.5679], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0934], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1202, -0.3059,  0.4111,  0.2292, -0.3433], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5584, -1.1416, -0.5691,  0.8100, -0.7100], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5584, -1.1416, -0.5691,  0.8100, -0.7100], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2165,  0.6881,  1.5605,  0.9274, -0.2653], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.1669, 0.4757, 1.8984, 1.0589, 1.1139], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2795, -0.4068,  0.7908,  0.2165, -0.3983], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0495, -0.1818, -0.4365, -0.1577,  0.3388], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0635, -0.2574, -0.5748,  0.2090,  1.8388], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0327, -0.1122, -0.2070,  0.1154,  1.5865], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0327, -0.1122, -0.2070,  0.1154,  1.5865], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.2211, -0.0732,  0.0230, -0.0949,  0.0882], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1040, -0.1037, -0.1541,  0.0770,  0.0683], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6542, -0.1369, -1.4589, -0.3682, -0.1218], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2457, 0.0874, 0.5081, 0.2727, 0.7082], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8515, 0.9881, 0.4765, 0.9045, 0.9174], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0327, -0.1122, -0.2070,  0.1154,  1.5865], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0018, -0.0006,  0.0002, -0.0008,  0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0094, -0.0005,  0.0006, -0.0028,  0.0027], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0013, -0.0359, -0.0423,  0.0657,  0.4348], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0538, -0.2245, -0.3903,  0.2596,  3.1016], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0538, -0.2245, -0.3903,  0.2596,  3.1016], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0191,  0.0620,  0.0803,  0.1455, -0.7258], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2768], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9008], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1187,  0.3010,  0.2911,  0.6479, -0.5005], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1187,  0.3010,  0.2911,  0.6479, -0.5005], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.0578, -1.4090,  2.6875,  1.5799, -1.0212], grad_fn=<SliceBackward0>)
  [Layer 29] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 29] Output sample values after mixer: tensor([ 1.0578, -1.4090,  2.6875,  1.5799, -1.0212], grad_fn=<SliceBackward0>)
  [Layer 29] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 29] Residual connection sample values: tensor([-1.8643, -8.9437, 12.6057,  6.0893, -9.3332], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 30/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([121.0820], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0909], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0691, -0.3165,  0.4548,  0.2578, -0.3363], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2982,  0.0376, -0.6968, -0.2939,  1.4564], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2982,  0.0376, -0.6968, -0.2939,  1.4564], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.9705, -0.9353, -1.4335, -0.7022, -0.6719], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.5934, -0.1059,  0.6125,  0.1495,  1.1796], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0491,  0.4507, -1.0557, -0.9705,  0.7463], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3558,  0.2128,  0.3895,  0.4371, -0.3027], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3986,  0.1709,  0.9646,  0.4866, -0.3952], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1601,  0.0928,  0.6985,  0.3013, -0.1591], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1601,  0.0928,  0.6985,  0.3013, -0.1591], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0314,  0.1130,  0.0306,  0.0650, -0.2267], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0164, -0.1085, -0.2480, -0.1929, -0.2524], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2038, -0.3668, -0.2078, -0.0952, -0.4265], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.8109, 0.2160, 0.7073, 0.1144, 0.6661], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8477, 0.9238, 0.8633, 0.9892, 0.7527], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1601,  0.0928,  0.6985,  0.3013, -0.1591], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0041, -0.0147, -0.0040, -0.0084,  0.0294], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0066, -0.0231, -0.0018, -0.0228,  0.0724], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1470, -0.0833,  1.4393,  0.2517, -0.3363], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1734, -0.0680,  1.5546,  0.3015, -0.3626], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1734, -0.0680,  1.5546,  0.3015, -0.3626], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0297, -0.0013, -0.3602, -0.0378, -0.4283], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5406], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.3601], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1011, -0.0049, -0.8191, -0.1428, -0.5927], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1011, -0.0049, -0.8191, -0.1428, -0.5927], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4417,  0.0228, -0.4585, -2.1116, -1.9287], grad_fn=<SliceBackward0>)
  [Layer 30] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 30] Output sample values after mixer: tensor([-0.4417,  0.0228, -0.4585, -2.1116, -1.9287], grad_fn=<SliceBackward0>)
  [Layer 30] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 30] Residual connection sample values: tensor([ -2.3060,  -8.9209,  12.1473,   3.9777, -11.2619],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 31/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([139.8074], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0846], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0539, -0.2113,  0.2849,  0.1052, -0.2635], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3429,  0.0403, -0.0796, -0.0731, -0.8363], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3429,  0.0403, -0.0796, -0.0731, -0.8363], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2253,  0.0287, -0.0767, -0.2831, -1.2075], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.0745, 2.1892, 1.3226, 0.6218, 0.7336], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1150,  0.7817, -0.2069, -0.2253, -0.0596], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0460, -0.0130,  0.0259,  0.1168, -0.9746], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0431,  0.0219,  0.0153,  0.0986, -1.0349], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0220,  0.0111,  0.0077,  0.0517, -0.2713], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0220,  0.0111,  0.0077,  0.0517, -0.2713], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0609,  0.0446, -0.0563,  0.0255,  0.0457], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1287, -0.0385, -0.1743, -0.1585,  0.0297], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-9.5766e-03, -1.0642e-02, -2.6350e+01, -6.4468e+02, -1.6547e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3181, 0.4293, 2.0158, 1.8307, 0.1266], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9696e-01, 9.9544e-01, 8.5297e-24, 0.0000e+00, 9.9791e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0220,  0.0111,  0.0077,  0.0517, -0.2713], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0004,  0.0003, -0.0004,  0.0002,  0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0161, -0.0105,  0.0079,  0.0155,  0.0058], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0053, -0.0315, -0.0140, -0.0505, -0.1397], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0081, -0.0329, -0.0149, -0.0570, -0.1056], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0081, -0.0329, -0.0149, -0.0570, -0.1056], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0012, -0.0007,  0.0006,  0.0020,  0.0267], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0407], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([4.9538], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0228, -0.0121,  0.0103,  0.1605,  0.1393], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0228, -0.0121,  0.0103,  0.1605,  0.1393], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-4.1058,  1.9447,  1.4522,  2.0967, -1.5552], grad_fn=<SliceBackward0>)
  [Layer 31] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 31] Output sample values after mixer: tensor([-4.1058,  1.9447,  1.4522,  2.0967, -1.5552], grad_fn=<SliceBackward0>)
  [Layer 31] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 31] Residual connection sample values: tensor([ -6.4118,  -6.9761,  13.5995,   6.0744, -12.8171],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 32/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([146.6607], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0826], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2475, -0.2636,  0.5102,  0.2733, -0.5020], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4322, -1.3849,  1.8788,  3.4904,  0.7898], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4322, -1.3849,  1.8788,  3.4904,  0.7898], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.3789,  0.2174,  1.5094, -2.1812,  0.4552], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.1089,  1.9346, -0.1779,  1.7628,  0.5308], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4183, -0.1900, -1.0760, -0.3789, -1.5951], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4130, -0.1140,  0.0282,  0.3131, -0.1468], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.3994, -0.4819,  0.0261,  0.2896, -0.1591], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.2390, -0.1840,  0.0132,  0.1656, -0.0732], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.2390, -0.1840,  0.0132,  0.1656, -0.0732], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1438,  0.2246,  0.1952, -0.0270,  0.0415], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2734, -0.2356, -0.2366, -0.2590,  0.5596], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0662, -0.0811, -0.5879, -0.0956, -0.5448], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.7150, 2.6396, 0.3632, 2.2129, 0.8735], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8355, 0.8072, 0.8078, 0.8093, 0.6214], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.2390, -0.1840,  0.0132,  0.1656, -0.0732], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0933,  0.1457,  0.1267, -0.0175,  0.0269], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0011,  0.0988,  0.1752,  0.3717,  0.2210], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 1.6051, -2.2995,  0.1848,  0.8600, -0.8015], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 1.5997, -2.2953,  0.1845,  0.8563, -0.7999], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 1.5997, -2.2953,  0.1845,  0.8563, -0.7999], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.4193,  0.6365,  0.3006,  2.9002, -0.4345], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([14.0384], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2669], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1260,  0.4154,  0.1956,  1.1822, -0.1996], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1260,  0.4154,  0.1956,  1.1822, -0.1996], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 3.6467,  5.1998,  0.1145,  3.1066, -1.6596], grad_fn=<SliceBackward0>)
  [Layer 32] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 32] Output sample values after mixer: tensor([ 3.6467,  5.1998,  0.1145,  3.1066, -1.6596], grad_fn=<SliceBackward0>)
  [Layer 32] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 32] Residual connection sample values: tensor([ -2.7651,  -1.7764,  13.7140,   9.1810, -14.4767],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 33/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([184.9245], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0735], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0977, -0.0613,  0.4821,  0.3409, -0.5175], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([0.5568, 1.9463, 2.5581, 0.5747, 0.0904], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([0.5568, 1.9463, 2.5581, 0.5747, 0.0904], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.7093, -0.1080,  1.9502,  0.8178,  1.1338], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.2244,  2.1833,  0.5856, -0.0945, -0.7775], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.0038, -0.1889,  0.2802, -0.7093,  0.3369], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1747, -0.0437,  0.2966,  0.2770,  0.2154], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4450, -0.0803,  0.2832,  0.1540,  0.1811], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1738, -0.0386,  0.1615,  0.0829,  0.0987], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1738, -0.0386,  0.1615,  0.0829,  0.0987], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2380,  0.2724,  0.0924, -0.0353, -0.1440], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0632,  0.2280,  0.0740, -0.2255,  0.1370], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-13.0444,  -1.3850,  -0.1668,  -0.2359,  -5.2550],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0042, 0.0420, 0.0974, 0.0478, 0.0038], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9471, 0.9435, 0.9839, 0.9888, 0.9801], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1738, -0.0386,  0.1615,  0.0829,  0.0987], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.7239e-04, -1.9729e-04, -6.6948e-05,  2.5560e-05,  1.0431e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0012, -0.0016,  0.0007,  0.0002,  0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0003, -0.0004,  0.0004, -0.0003,  0.0019], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1865, -0.0417,  0.1734,  0.0885,  0.1077], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1865, -0.0417,  0.1734,  0.0885,  0.1077], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0660, -0.0711,  0.4117,  0.0325,  0.0051], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1349], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.7226], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.4952, -0.5169,  4.0877,  0.2715,  0.0480], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.4952, -0.5169,  4.0877,  0.2715,  0.0480], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2816,  2.8402, -0.2306,  1.1501, -2.0597], grad_fn=<SliceBackward0>)
  [Layer 33] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 33] Output sample values after mixer: tensor([-0.2816,  2.8402, -0.2306,  1.1501, -2.0597], grad_fn=<SliceBackward0>)
  [Layer 33] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 33] Residual connection sample values: tensor([ -3.0467,   1.0638,  13.4835,  10.3311, -16.5363],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 34/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([235.2966], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0652], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0843,  0.0290,  0.3880,  0.2901, -0.4674], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.8896, -1.4449, -1.3331,  1.1233, -2.6363], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.8896, -1.4449, -1.3331,  1.1233, -2.6363], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6319, -1.0597, -1.1369, -0.0728, -1.8040], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.7329, 1.4517, 0.6564, 0.7870, 0.0936], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4572, -0.3540,  0.2165, -0.6319, -2.6236], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1295,  0.7009,  0.2703,  0.0154, -0.5970], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1729,  0.6037,  0.2363, -0.0657, -0.6710], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0790,  0.3903,  0.1320, -0.0318, -0.2270], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0790,  0.3903,  0.1320, -0.0318, -0.2270], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0383, -0.0087, -0.0409,  0.0821, -0.1406], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2212, -0.0492, -0.1151, -0.1049, -0.1763], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2225, -0.1537, -0.8169, -0.8591, -2.0730], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0720, 0.0302, 0.3433, 0.2072, 0.1913], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9841, 0.9954, 0.7554, 0.8370, 0.6726], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0790,  0.3903,  0.1320, -0.0318, -0.2270], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.1800e-04,  4.9458e-05,  2.3271e-04, -4.6675e-04,  7.9902e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0030,  0.0075,  0.0034, -0.0067,  0.0107], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0479,  0.1536,  0.0804, -0.0397, -0.0671], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2033,  0.9215,  0.3401, -0.1022, -0.5138], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2033,  0.9215,  0.3401, -0.1022, -0.5138], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0504, -0.2540, -0.0946, -0.0866,  0.0905], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1782], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.3686], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.3192, -0.8990, -0.5007, -0.5418,  0.6035], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.3192, -0.8990, -0.5007, -0.5418,  0.6035], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.4881, -1.7764,  0.7198, -4.4043,  1.7311], grad_fn=<SliceBackward0>)
  [Layer 34] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 34] Output sample values after mixer: tensor([ 0.4881, -1.7764,  0.7198, -4.4043,  1.7311], grad_fn=<SliceBackward0>)
  [Layer 34] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 34] Residual connection sample values: tensor([ -2.5586,  -0.7125,  14.2032,   5.9269, -14.8052],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 35/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([260.9423], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0619], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0889, -0.0246,  0.4864,  0.2196, -0.5115], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.0286, -1.1194, -1.3018, -1.2128, -0.6983], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.0286, -1.1194, -1.3018, -1.2128, -0.6983], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3614,  1.2329, -1.7463, -1.0016,  0.1336], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.0973,  1.1444, -0.2026,  1.3706,  1.5923], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.0787,  1.6062, -0.9954,  0.3614,  0.3781], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0550,  0.2737, -0.5017, -0.1690,  0.0400], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1065,  0.2520, -0.5291, -0.1938, -0.0722], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0504,  0.1418, -0.1962, -0.0875, -0.0348], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0504,  0.1418, -0.1962, -0.0875, -0.0348], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1869,  0.0297,  0.1602,  0.0447,  0.1541], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2046, -0.0072, -0.2466, -0.1306,  0.0137], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2054, -0.1417, -0.1071, -0.1460, -0.2581], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.7210, 3.3519, 0.7579, 3.7308, 2.0745], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5719, 0.6219, 0.9221, 0.5799, 0.5854], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0504,  0.1418, -0.1962, -0.0875, -0.0348], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0256, -0.0041, -0.0220, -0.0061, -0.0211], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0397,  0.0004, -0.0399, -0.0504, -0.0649], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1511,  0.4406, -0.2135, -0.6644, -0.6057], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2831,  0.8119, -0.7272, -0.8937, -0.6968], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2831,  0.8119, -0.7272, -0.8937, -0.6968], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.2145, -0.2237,  0.2024,  0.2484,  0.1616], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([9.5247], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3240], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2643, -0.2673,  0.0837,  0.4424,  0.1668], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2643, -0.2673,  0.0837,  0.4424,  0.1668], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3924,  1.4879, -0.3938, -4.3416,  1.2902], grad_fn=<SliceBackward0>)
  [Layer 35] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 35] Output sample values after mixer: tensor([-0.3924,  1.4879, -0.3938, -4.3416,  1.2902], grad_fn=<SliceBackward0>)
  [Layer 35] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 35] Residual connection sample values: tensor([ -2.9510,   0.7754,  13.8094,   1.5853, -13.5150],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 36/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([335.5466], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0546], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0806,  0.0216,  0.3791,  0.0462, -0.3779], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0125, -2.4205, -1.2638,  1.2846,  0.8678], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0125, -2.4205, -1.2638,  1.2846,  0.8678], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.9456,  1.5891, -0.5582, -0.5797, -2.8591], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.2137, 2.5303, 2.0135, 1.2344, 1.5848], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.1991,  0.7234,  1.8071,  0.9456,  0.3629], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3645,  0.3704, -0.1614, -0.1530, -0.4549], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3243,  0.2529, -0.2235, -0.2977, -0.4670], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1361,  0.1423, -0.0993, -0.1268, -0.1800], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1361,  0.1423, -0.0993, -0.1268, -0.1800], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0460,  0.0007,  0.1416, -0.1642,  0.0316], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1202,  0.2664, -0.1832, -0.0779, -0.1840], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.8655, -5.6378, -3.8976, -2.4260, -3.6937], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0859, 0.1963, 0.1285, 0.1300, 0.1156], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7818, 0.3306, 0.6059, 0.7295, 0.6523], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1361,  0.1423, -0.0993, -0.1268, -0.1800], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.3808e-04, -7.7512e-06, -1.6551e-03,  1.9188e-03, -3.6885e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0078,  0.0026, -0.0054,  0.0115, -0.0065], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0342,  0.0160, -0.0492, -0.0566, -0.0419], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3831,  0.4525, -0.3537, -0.4456, -0.5938], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3831,  0.4525, -0.3537, -0.4456, -0.5938], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0024, -0.0894,  0.0985, -0.4484, -0.3629], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6979], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1971], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0055, -0.4381,  0.3334, -1.6185, -1.4907], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0055, -0.4381,  0.3334, -1.6185, -1.4907], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 6.7530,  2.4847,  1.6865, -2.8053, -2.9051], grad_fn=<SliceBackward0>)
  [Layer 36] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 36] Output sample values after mixer: tensor([ 6.7530,  2.4847,  1.6865, -2.8053, -2.9051], grad_fn=<SliceBackward0>)
  [Layer 36] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 36] Residual connection sample values: tensor([  3.8020,   3.2601,  15.4959,  -1.2200, -16.4201],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 37/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([354.3915], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0531], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0974,  0.0857,  0.4164, -0.0320, -0.4314], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.9928, -0.0512,  0.2248,  1.5984, -1.0996], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.9928, -0.0512,  0.2248,  1.5984, -1.0996], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6494,  2.0781,  2.0335, -2.5341,  0.5701], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.9150, -0.9558,  2.8339, -0.5558,  0.1817], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1325, -0.6262, -0.6172, -0.6494,  1.6176], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1911, -0.7095, -0.6641,  0.6314, -0.2541], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1133, -0.7736, -0.7487,  0.6662, -0.3377], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0599, -0.2442, -0.2404,  0.4402, -0.1406], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0599, -0.2442, -0.2404,  0.4402, -0.1406], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2058,  0.1413, -0.0761, -0.0983, -0.0098], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2733, -0.2739, -0.2328, -0.2780, -0.2624], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.8179, -31.1699, -39.0195,  -0.4619,  -0.6477],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0016, 0.0028, 0.0554, 0.0004, 0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9971, 0.9168, 0.1151, 0.9998, 0.9987], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0599, -0.2442, -0.2404,  0.4402, -0.1406], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.9420e-05,  1.3333e-05, -7.1820e-06, -9.2735e-06, -9.2936e-07],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0004,  0.0004, -0.0006,  0.0009, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0005,  0.0013,  0.0017, -0.0016,  0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1092, -0.4460, -0.4386,  0.8046, -0.2569], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1092, -0.4460, -0.4386,  0.8046, -0.2569], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0293,  0.0111, -0.0548,  1.0698,  0.0706], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2369], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.0545], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2243,  0.0616, -0.2853,  8.8085,  0.3101], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2243,  0.0616, -0.2853,  8.8085,  0.3101], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 3.4910,  6.8152, -3.6283, -0.5021,  1.0235], grad_fn=<SliceBackward0>)
  [Layer 37] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 37] Output sample values after mixer: tensor([ 3.4910,  6.8152, -3.6283, -0.5021,  1.0235], grad_fn=<SliceBackward0>)
  [Layer 37] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 37] Residual connection sample values: tensor([  7.2930,  10.0753,  11.8677,  -1.7221, -15.3966],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 38/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([433.2452], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0480], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1796,  0.2482,  0.2909, -0.0411, -0.3818], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.2171, -2.0441,  0.2547, -2.1221, -1.2972], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.2171, -2.0441,  0.2547, -2.1221, -1.2972], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 2.6654, -0.7357, -1.3731,  1.1012,  3.0580], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.5690,  1.2961,  0.4846, -0.1466,  1.2423], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2020,  1.5038,  1.7691,  2.6654, -1.2254], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.9230,  0.4405,  0.0314, -0.4614,  0.2656], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.9253,  0.1512, -0.0587, -0.5046,  0.3586], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2627,  0.0813, -0.0285, -0.1900,  0.2111], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2627,  0.0813, -0.0285, -0.1900,  0.2111], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0772, -0.1877,  0.0273, -0.0182, -0.0855], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2778, -0.0345, -0.0932, -0.2763,  0.0488], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1704, -2.0832, -0.1351, -0.4124, -3.5315], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.1504, 0.3786, 0.9349, 0.2621, 0.3060], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8220, 0.4545, 0.8814, 0.8976, 0.3394], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2627,  0.0813, -0.0285, -0.1900,  0.2111], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0233,  0.0567, -0.0082,  0.0055,  0.0258], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0360,  0.1911, -0.0014,  0.0127, -0.0374], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3558, -0.5656, -0.2542, -0.2320,  1.0363], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3943, -0.5536, -0.2584, -0.2599,  1.0673], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3943, -0.5536, -0.2584, -0.2599,  1.0673], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0859,  0.1297, -0.0371,  0.0590, -0.2972], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.9126], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0468], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2832,  0.2881, -0.0910,  0.2892, -1.0073], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.2832,  0.2881, -0.0910,  0.2892, -1.0073], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([10.1072, -3.2991,  9.5215, -3.7130,  1.7609], grad_fn=<SliceBackward0>)
  [Layer 38] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 38] Output sample values after mixer: tensor([10.1072, -3.2991,  9.5215, -3.7130,  1.7609], grad_fn=<SliceBackward0>)
  [Layer 38] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 38] Residual connection sample values: tensor([ 17.4003,   6.7762,  21.3892,  -5.4351, -13.6357],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 39/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([496.5107], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0449], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2963,  0.1255,  0.3841, -0.1024, -0.2437], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4923,  0.2475, -0.3053, -2.1081, -0.3658], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4923,  0.2475, -0.3053, -2.1081, -0.3658], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6531, -0.0017,  1.4203, -0.2428,  0.6515], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.3590, -0.6496,  1.3493,  0.3784,  0.4891], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.1085,  0.1630,  2.4910, -0.6531,  0.7220], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1157, -0.0156,  0.2765, -0.0488,  0.1915], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0512, -0.0764,  0.2917,  0.4888,  0.1881], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0250, -0.0367,  0.1670,  0.3030,  0.1029], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0250, -0.0367,  0.1670,  0.3030,  0.1029], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0285,  0.0387, -0.1535, -0.0698, -0.0179], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.8923, -0.2785, -0.0139,  0.1268, -0.2280], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.7351e+02, -2.3790e+00, -2.6079e-03, -1.4979e+00, -6.3307e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3665, 0.1498, 0.7715, 0.1793, 0.0145], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([2.4012e-28, 7.0017e-01, 9.9799e-01, 7.6442e-01, 9.9908e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0250, -0.0367,  0.1670,  0.3030,  0.1029], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0003, -0.0004,  0.0014,  0.0006,  0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0003, -0.0004,  0.0014,  0.0006,  0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0005, -0.0007,  0.0032,  0.0058,  0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1134, -0.1669,  0.7588,  1.3767,  0.4674], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1134, -0.1669,  0.7588,  1.3767,  0.4674], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0347, -0.0232, -0.0983, -0.3143, -0.0700], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.9908], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0047], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1628, -0.1032, -0.4139, -1.2916, -0.3470], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1628, -0.1032, -0.4139, -1.2916, -0.3470], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ -0.2771,   2.3017,  11.8723,   1.3843, -10.8049],
       grad_fn=<SliceBackward0>)
  [Layer 39] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 39] Output sample values after mixer: tensor([ -0.2771,   2.3017,  11.8723,   1.3843, -10.8049],
       grad_fn=<SliceBackward0>)
  [Layer 39] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 39] Residual connection sample values: tensor([ 17.1232,   9.0779,  33.2615,  -4.0508, -24.4406],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 40/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([710.7412], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0375], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.3157,  0.1786,  0.6409, -0.0715, -0.4664], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.5985,  1.2316,  0.6915, -0.2830,  2.7258], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.5985,  1.2316,  0.6915, -0.2830,  2.7258], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.3095,  1.3096, -1.1752,  0.7882,  1.4017], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([3.1906, 0.5785, 0.7399, 1.4458, 1.4504], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.4282, -1.8997, -0.4070, -0.3095,  0.5469], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0477, -0.2405, -0.2270, -0.1404,  0.2396], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2836, -0.2890, -0.2987, -0.1519,  0.2411], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1618, -0.1238, -0.1272, -0.0702,  0.1350], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1618, -0.1238, -0.1272, -0.0702,  0.1350], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0406, -0.2639, -0.0143,  0.0139,  0.0273], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2497, -0.2515, -0.2441, -0.2784, -0.0409], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5267, -0.6301, -0.3878, -2.7909, -0.4284], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3634, 0.0230, 0.0572, 0.0255, 0.0669], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8258, 0.9856, 0.9781, 0.9313, 0.9717], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1618, -0.1238, -0.1272, -0.0702,  0.1350], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0024, -0.0155, -0.0008,  0.0008,  0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0028, -0.0453, -0.0069,  0.0004, -0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1040, -0.0586, -0.0655, -0.0204,  0.0557], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.5045, -0.3650, -0.3803, -0.1942,  0.3900], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.5045, -0.3650, -0.3803, -0.1942,  0.3900], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1356, -0.3479, -0.1752,  0.0236,  0.9977], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4364], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.5138], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.6585, -1.9998, -1.0253,  0.1092,  7.5985], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.6585, -1.9998, -1.0253,  0.1092,  7.5985], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ -2.0151,  -8.4371, -11.6379, -11.2839,  -9.6775],
       grad_fn=<SliceBackward0>)
  [Layer 40] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 40] Output sample values after mixer: tensor([ -2.0151,  -8.4371, -11.6379, -11.2839,  -9.6775],
       grad_fn=<SliceBackward0>)
  [Layer 40] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 40] Residual connection sample values: tensor([ 15.1081,   0.6408,  21.6236, -15.3346, -34.1181],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 41/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1088.6813], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0303], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1600,  0.0073,  0.2362, -0.1604, -0.3620], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.1182e+00, -1.9747e+00, -2.4793e-01,  1.6574e+00, -4.9940e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.1182e+00, -1.9747e+00, -2.4793e-01,  1.6574e+00, -4.9940e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.1127,  0.0712,  0.4148,  1.5420, -0.0706], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.0923, 0.5756, 0.4716, 1.5771, 0.9841], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.7872, -0.2174, -0.6705, -1.1127, -0.0974], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2742,  0.1065,  0.0943, -0.2635,  0.0149], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3059,  0.2289,  0.0944, -0.3562,  0.0053], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1297,  0.1275,  0.0494, -0.1467,  0.0027], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1297,  0.1275,  0.0494, -0.1467,  0.0027], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0932,  0.0008,  0.0375,  0.0352, -0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2726, -0.0219,  0.0026, -0.2370, -0.2712], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.0531, -1.1356, -0.8719, -1.5713, -1.7431], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4677, 0.3468, 0.1595, 0.5016, 0.2057], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6111, 0.6744, 0.8702, 0.4547, 0.6987], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1297,  0.1275,  0.0494, -0.1467,  0.0027], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 5.6568e-03, -5.1169e-05, -2.2731e-03, -2.1378e-03,  4.6844e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0070,  0.0007, -0.0039, -0.0026,  0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0238,  0.0266,  0.0130, -0.0329,  0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1897,  0.1896,  0.0762, -0.2206,  0.0049], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1897,  0.1896,  0.0762, -0.2206,  0.0049], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-1.5989e-01, -4.5645e-02, -8.2798e-03, -3.0704e-01, -1.2215e-06],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0216], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.8032], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-3.4821e+00, -1.3270e+00, -2.0782e-01, -9.3673e+00, -3.4605e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-3.4821e+00, -1.3270e+00, -2.0782e-01, -9.3673e+00, -3.4605e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-12.9226,   1.7398,   5.3808,  -1.9122,  -7.0007],
       grad_fn=<SliceBackward0>)
  [Layer 41] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 41] Output sample values after mixer: tensor([-12.9226,   1.7398,   5.3808,  -1.9122,  -7.0007],
       grad_fn=<SliceBackward0>)
  [Layer 41] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 41] Residual connection sample values: tensor([  2.1855,   2.3806,  27.0044, -17.2469, -41.1188],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 42/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1318.1115], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0275], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0217,  0.0254,  0.2864, -0.1708, -0.4291], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2933,  1.1890, -0.6834, -1.0726,  1.2573], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2933,  1.1890, -0.6834, -1.0726,  1.2573], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.7887,  0.0239, -0.9658, -0.4716,  0.3912], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.5814, -1.3209,  0.8738,  0.6869,  1.3908], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.8732, -0.1302,  0.8538,  0.7887,  1.9111], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1726,  0.0186,  0.2057,  0.0964,  0.0917], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1934, -0.0172,  0.2103,  0.0927,  0.0455], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0874, -0.0085,  0.1162,  0.0485,  0.0233], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0874, -0.0085,  0.1162,  0.0485,  0.0233], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1105, -0.0752,  0.0200, -0.0344, -0.0147], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.2642, -0.0155, -0.1589, -0.1825,  0.0269], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.2458, -1.7474, -3.3797, -1.2264, -1.3705], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1784, 0.0365, 0.2869, 0.0409, 0.2802], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6699, 0.9382, 0.3793, 0.9511, 0.6811], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0874, -0.0085,  0.1162,  0.0485,  0.0233], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0017,  0.0012, -0.0003,  0.0005,  0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0027, 0.0010, 0.0034, 0.0005, 0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0125,  0.0076,  0.0173,  0.0068,  0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1320, -0.0040,  0.1761,  0.0730,  0.0330], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1320, -0.0040,  0.1761,  0.0730,  0.0330], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0222, -0.0037, -0.0404, -0.0200,  0.0323], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0276], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.0129], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.5227, -0.0831, -0.9421, -0.4721,  0.5207], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.5227, -0.0831, -0.9421, -0.4721,  0.5207], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ -3.0776, -10.6420,  -3.2731,   1.3746,  -1.4243],
       grad_fn=<SliceBackward0>)
  [Layer 42] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 42] Output sample values after mixer: tensor([ -3.0776, -10.6420,  -3.2731,   1.3746,  -1.4243],
       grad_fn=<SliceBackward0>)
  [Layer 42] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 42] Residual connection sample values: tensor([ -0.8921,  -8.2614,  23.7313, -15.8722, -42.5431],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 43/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1546.0796], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0254], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0080, -0.0813,  0.2234, -0.1425, -0.3886], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.4921,  0.9751, -0.3053, -0.3498,  0.4222], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.4921,  0.9751, -0.3053, -0.3498,  0.4222], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.0125,  1.0407,  0.3975,  0.2083, -0.1507], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.7171,  0.4463, -0.6316,  0.3413, -0.2096], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2067,  0.2408, -0.4484, -0.0125,  0.2758], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0114, -0.1478, -0.0813,  0.0250, -0.0308], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0260, -0.2021, -0.1093, -0.0228, -0.0391], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0128, -0.0909, -0.0517, -0.0113, -0.0192], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0128, -0.0909, -0.0517, -0.0113, -0.0192], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0114,  0.0251,  0.1935, -0.2566,  0.3240], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1166, -0.0121,  0.5103, -0.2532, -0.0707], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.7046, -2.6553, -8.2110, -2.2382, -4.0926], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1224, 0.1213, 0.0338, 0.4689, 0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6355, 0.7246, 0.7580, 0.3501, 0.9958], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0128, -0.0909, -0.0517, -0.0113, -0.0192], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.7926e-05, -3.9430e-05, -3.0365e-04,  4.0260e-04, -5.0834e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0001, -0.0003, -0.0002,  0.0010, -0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0006, -0.0044, -0.0024,  0.0003, -0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0217, -0.1543, -0.0876, -0.0183, -0.0318], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0217, -0.1543, -0.0876, -0.0183, -0.0318], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0060, -0.1092,  0.0113,  0.0026, -0.0081], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0116], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([9.2873], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1430, -3.5154,  0.2923,  0.0685, -0.2175], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1430, -3.5154,  0.2923,  0.0685, -0.2175], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-5.5169,  8.8613, -3.8245,  4.3658,  3.1875], grad_fn=<SliceBackward0>)
  [Layer 43] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 43] Output sample values after mixer: tensor([-5.5169,  8.8613, -3.8245,  4.3658,  3.1875], grad_fn=<SliceBackward0>)
  [Layer 43] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 43] Residual connection sample values: tensor([ -6.4090,   0.5999,  19.9068, -11.5064, -39.3556],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 44/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1762.7230], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0238], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0546,  0.0053,  0.1760, -0.0959, -0.3396], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.8975,  0.1581, -0.6949, -0.1160,  0.8214], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.8975,  0.1581, -0.6949, -0.1160,  0.8214], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.7956, -0.8419, -0.4453, -0.4905,  0.4334], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.0167,  0.8326,  1.6328,  0.6365,  1.0510], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0825, -0.4715,  0.2910, -0.7956, -0.7062], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1638,  0.1818, -0.0642,  0.0869,  0.0764], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1423,  0.1248, -0.0929,  0.0737,  0.0830], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0661,  0.0663, -0.0443,  0.0382,  0.0432], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0661,  0.0663, -0.0443,  0.0382,  0.0432], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1483, -0.2136, -0.2337, -0.0274,  0.2325], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1123, -0.2776, -0.1829, -0.0440, -0.0557], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-4.6876, -0.9753, -0.8255, -1.2938, -0.4953], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0977, 0.0993, 0.1197, 0.0841, 0.0220], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6325, 0.9077, 0.9059, 0.8969, 0.9892], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0661,  0.0663, -0.0443,  0.0382,  0.0432], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0010,  0.0014,  0.0015,  0.0002, -0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0014,  0.0012,  0.0013,  0.0005, -0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0029,  0.0018, -0.0015,  0.0012,  0.0014], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1178,  0.1170, -0.0785,  0.0676,  0.0765], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1178,  0.1170, -0.0785,  0.0676,  0.0765], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0751,  0.0100,  0.0182, -0.0037,  0.0436], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0158], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([7.9628], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-1.9273,  0.2345,  0.5409, -0.0946,  1.0950], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-1.9273,  0.2345,  0.5409, -0.0946,  1.0950], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-2.4434, 11.2048,  1.6672,  0.5654, -8.8030], grad_fn=<SliceBackward0>)
  [Layer 44] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 44] Output sample values after mixer: tensor([-2.4434, 11.2048,  1.6672,  0.5654, -8.8030], grad_fn=<SliceBackward0>)
  [Layer 44] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 44] Residual connection sample values: tensor([ -8.8524,  11.8047,  21.5740, -10.9410, -48.1586],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 45/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1939.2917], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0227], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0863,  0.1242,  0.2209, -0.1070, -0.4755], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.0326, -2.4864, -0.8764, -0.6362, -1.1555], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.0326, -2.4864, -0.8764, -0.6362, -1.1555], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3072,  1.3222, -0.7467,  0.3185, -0.2304], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.1934, -1.1156,  0.0916, -0.3294,  0.1413], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2140,  1.3554, -0.1891,  0.3072,  1.0251], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0495,  0.1485, -0.1424, -0.0677, -0.0334], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0438,  0.4066, -0.1647, -0.1237, -0.0441], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0224,  0.2440, -0.0756, -0.0580, -0.0216], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0224,  0.2440, -0.0756, -0.0580, -0.0216], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0982,  0.0723, -0.0286, -0.1692, -0.0459], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1997, -0.0821, -0.1635, -0.0853, -0.1668], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3039e+00, -3.9385e-02, -6.8874e+00, -8.0559e-01, -1.9935e+03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0027, 0.0061, 0.0085, 0.0005, 0.0220], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9650e-01, 9.9976e-01, 9.4337e-01, 9.9964e-01, 9.0824e-20],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0224,  0.2440, -0.0756, -0.0580, -0.0216], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.9203e-06,  4.3565e-06, -1.7219e-06, -1.0197e-05, -2.7649e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0017, 0.0010, 0.0012, 0.0002, 0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0018,  0.0315, -0.0068, -0.0092,  0.0048], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0563,  0.6648, -0.2029, -0.1598, -0.0513], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0563,  0.6648, -0.2029, -0.1598, -0.0513], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0428, -0.1270,  0.0523,  0.0352,  0.0142], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0790], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.5587], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.5914, -1.3150,  0.6464,  0.4120,  0.1992], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.5914, -1.3150,  0.6464,  0.4120,  0.1992], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 3.3398, -0.6092,  1.0892, -7.2209, -7.0199], grad_fn=<SliceBackward0>)
  [Layer 45] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 45] Output sample values after mixer: tensor([ 3.3398, -0.6092,  1.0892, -7.2209, -7.0199], grad_fn=<SliceBackward0>)
  [Layer 45] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 45] Residual connection sample values: tensor([ -5.5125,  11.1955,  22.6632, -18.1619, -55.1785],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 46/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2191.2812], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0214], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0480,  0.1048,  0.2079, -0.1609, -0.4754], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4711, -1.1152, -0.2140,  0.3301, -0.3995], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4711, -1.1152, -0.2140,  0.3301, -0.3995], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3865, -0.0123,  1.6048,  0.0304,  0.5350], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.6489,  0.0266,  1.4141, -0.4563,  0.9683], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.9929, 0.3296, 1.3961, 0.3865, 0.5156], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0706,  0.0013,  0.3167, -0.0052, -0.0872], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0152, -0.0360,  0.5196, -0.0007, -0.0925], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0075, -0.0177,  0.3258, -0.0004, -0.0441], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0075, -0.0177,  0.3258, -0.0004, -0.0441], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2242, -0.0450,  0.0040, -0.0214, -0.1111], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0223,  0.2140, -0.1223, -0.0410, -0.0793], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.4426,  -0.9830, -10.1590,  -1.3638,  -1.7559],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0167, 0.0143, 0.0045, 0.0083, 0.0284], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9761, 0.9860, 0.9555, 0.9888, 0.9514], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0075, -0.0177,  0.3258, -0.0004, -0.0441], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.8248e-05,  5.6658e-06, -5.0218e-07,  2.6957e-06,  1.3992e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.4895e-03,  3.1461e-04, -4.3375e-05,  4.0553e-04, -8.0665e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-6.0264e-04, -4.1414e-06,  2.5806e-03,  3.8440e-04,  4.5421e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-9.8223e-03, -2.1646e-02,  4.0177e-01, -6.7320e-05, -5.3563e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-9.8223e-03, -2.1646e-02,  4.0177e-01, -6.7320e-05, -5.3563e-02],
       grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 1.7784e-03,  5.9602e-03, -3.8407e-02, -1.2931e-05,  8.5907e-03],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0114], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([9.3808], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 7.4161e-02,  2.3107e-01, -1.2702e+00, -4.2336e-04,  2.8111e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 7.4161e-02,  2.3107e-01, -1.2702e+00, -4.2336e-04,  2.8111e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 12.5072,  13.5607,  -3.6132,  -3.1452, -10.1442],
       grad_fn=<SliceBackward0>)
  [Layer 46] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 46] Output sample values after mixer: tensor([ 12.5072,  13.5607,  -3.6132,  -3.1452, -10.1442],
       grad_fn=<SliceBackward0>)
  [Layer 46] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 46] Residual connection sample values: tensor([  6.9947,  24.7562,  19.0501, -21.3071, -65.3227],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 47/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2522.0303], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0199], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0510,  0.1883,  0.1420, -0.1468, -0.4770], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1513,  0.6000, -0.8710, -1.4274, -0.0998], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1513,  0.6000, -0.8710, -1.4274, -0.0998], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2697,  0.4965,  0.9431, -0.5876, -0.6363], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.2083,  1.1652,  0.9174,  1.9097, -0.1886], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.1730,  0.1793, -0.7106,  0.2697,  0.0119], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0414,  0.0864,  0.1826,  0.1060, -0.1027], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0543,  0.1015,  0.1815,  0.1128, -0.1047], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0264,  0.0533,  0.0990,  0.0596, -0.0496], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0264,  0.0533,  0.0990,  0.0596, -0.0496], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0310,  0.0387,  0.0037, -0.0645, -0.1156], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2779, -0.2200,  0.4742, -0.2013, -0.2639], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-5.7667e+01, -2.2024e+00, -3.8371e+00, -4.6046e-02, -2.0700e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0378, 0.0142, 0.0321, 0.1140, 0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.1132, 0.9693, 0.8841, 0.9948, 0.9930], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0264,  0.0533,  0.0990,  0.0596, -0.0496], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 3.0977e-05, -3.8572e-05, -3.6719e-06,  6.4388e-05,  1.1532e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 3.7672e-04, -1.1111e-05, -2.7191e-05, -4.7758e-05, -3.5410e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0001,  0.0010,  0.0017,  0.0013, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0415,  0.0851,  0.1577,  0.0952, -0.0786], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0415,  0.0851,  0.1577,  0.0952, -0.0786], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0029,  0.0330, -0.0405, -0.0263,  0.0037], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0094], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([10.3085], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1021,  1.2828, -1.4458, -1.3434,  0.1537], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1021,  1.2828, -1.4458, -1.3434,  0.1537], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-15.5614,  46.2044,  -3.3851,  -6.2630, -20.8709],
       grad_fn=<SliceBackward0>)
  [Layer 47] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 47] Output sample values after mixer: tensor([-15.5614,  46.2044,  -3.3851,  -6.2630, -20.8709],
       grad_fn=<SliceBackward0>)
  [Layer 47] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 47] Residual connection sample values: tensor([ -8.5667,  70.9606,  15.6650, -27.5702, -86.1937],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 48/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3691.1182], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0165], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0515,  0.4600,  0.1003, -0.1615, -0.5358], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.7044, -1.5075, -0.6428, -1.1394,  0.1729], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.7044, -1.5075, -0.6428, -1.1394,  0.1729], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5810,  0.8314, -0.6023, -0.6723, -0.5261], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.3371, -3.5216,  0.2770,  1.8519,  0.3737], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.6851, 1.5801, 0.2603, 0.5810, 0.5533], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0933,  0.1307, -0.0697, -0.0788, -0.0828], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0893,  0.1002, -0.0818, -0.1589, -0.1651], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0427,  0.0526, -0.0392, -0.0731, -0.0758], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0427,  0.0526, -0.0392, -0.0731, -0.0758], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0085,  0.2599, -0.2517, -0.0351, -0.0886], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0867, -0.0436, -0.2730, -0.0460,  0.0374], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.7304,  -7.3891,  -3.3797,  -1.8028, -17.7601],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.6052e-02, 6.3512e-06, 8.4459e-03, 1.1710e-01, 1.3517e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9726, 1.0000, 0.9719, 0.8097, 0.0907], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0427,  0.0526, -0.0392, -0.0731, -0.0758], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 5.8536e-06, -1.7802e-04,  1.7239e-04,  2.4023e-05,  6.0714e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.7579e-04,  4.9916e-04,  8.6191e-04, -2.2175e-04, -2.1871e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0004,  0.0011, -0.0014, -0.0065, -0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0611,  0.0759, -0.0572, -0.1106, -0.1122], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0611,  0.0759, -0.0572, -0.1106, -0.1122], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0142, -0.0208,  0.0127,  0.0305, -0.0105], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0033], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([17.4711], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.8825, -1.4405,  0.8321,  1.7665, -0.8298], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.8825, -1.4405,  0.8321,  1.7665, -0.8298], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 4.1555, 79.4275, -4.7473,  9.2149, -4.1025], grad_fn=<SliceBackward0>)
  [Layer 48] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 48] Output sample values after mixer: tensor([ 4.1555, 79.4275, -4.7473,  9.2149, -4.1025], grad_fn=<SliceBackward0>)
  [Layer 48] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 48] Residual connection sample values: tensor([ -4.4112, 150.3881,  10.9177, -18.3552, -90.2962],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([6770.2983], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0122], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0549,  2.7023,  0.1554, -0.2062, -1.1553], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Final backbone norm output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Final backbone norm output sample values: tensor([-0.0549,  2.7023,  0.1554, -0.2062, -1.1553], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Logits shape: torch.Size([1, 1, 50288])
[Mamba2LMHeadModel] Logits sample values: tensor([-37.7212, -47.0550, -37.9936, -39.9460, -40.2211],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Forward pass input_ids shape: torch.Size([1, 1])
[Mamba2LMHeadModel] input_ids sample values: tensor([512])
[Mamba2LMHeadModel] Embedding output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Embedding sample values: tensor([ 0.1748, -0.0461, -0.0037, -0.3882, -0.0222], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 1/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0320], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([5.5917], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2346, -0.0787, -0.0054, -0.4451, -0.0280], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3897,  0.3379,  0.1963,  0.0153, -0.1338], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3897,  0.3379,  0.1963,  0.0153, -0.1338], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.7267,  0.6820, -0.8612, -0.2129,  0.5517], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.1468,  0.1783,  0.1488,  0.2237, -0.1526], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2702,  0.5399,  0.0157,  0.7267, -0.5521], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-3.7521e-03, -2.2909e-05, -5.3315e-03,  7.5721e-02,  1.5554e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0388, -0.0076,  0.1074, -0.1338, -0.1816], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0198, -0.0038,  0.0566, -0.0624, -0.0826], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0198, -0.0038,  0.0566, -0.0624, -0.0826], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2657,  0.0699, -0.0087,  0.6454,  0.1167], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2600, -0.0336, -0.1219, -0.2515, -0.1603], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4384, -1.0011, -1.2129, -1.1530, -1.4844], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0643, 0.0404, 0.0282, 0.0325, 0.0193], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9722, 0.9604, 0.9664, 0.9632, 0.9718], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0198, -0.0038,  0.0566, -0.0624, -0.0826], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-3.3786e-04,  8.8917e-05, -1.1122e-05,  8.2057e-04,  1.4835e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0186, -0.0037, -0.0006,  0.0447, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.4842,  0.0364,  1.1182, -1.6993, -1.4402], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.5181,  0.0299,  1.2153, -1.8064, -1.5819], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.5181,  0.0299,  1.2153, -1.8064, -1.5819], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0815,  0.0059,  0.1310, -0.0139,  0.0988], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([37.3428], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1636], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0119,  0.0007,  0.0158, -0.0014,  0.0501], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0119,  0.0007,  0.0158, -0.0014,  0.0501], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0180,  0.5203, -0.0566,  0.3210, -0.0348], grad_fn=<SliceBackward0>)
  [Layer 1] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 1] Output sample values after mixer: tensor([ 0.0180,  0.5203, -0.0566,  0.3210, -0.0348], grad_fn=<SliceBackward0>)
  [Layer 1] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 1] Residual connection sample values: tensor([ 0.1928,  0.4742, -0.0603, -0.0672, -0.0570], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 2/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2188], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([2.1378], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2381,  0.4918, -0.0577, -0.0872, -0.0641], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.7302, -1.8447, -0.0866,  3.1007, -1.6571], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.7302, -1.8447, -0.0866,  3.1007, -1.6571], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.4321, -0.3597,  0.4921, -3.4813,  0.1977], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.4897, 3.3650, 0.5058, 0.9107, 0.5386], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.0932, -0.6335,  0.6623,  1.4321, -1.2538], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0358, -0.0771, -0.4002, -0.2441,  0.1689], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0451, -0.1070, -0.5120, -0.3881,  0.1723], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0220, -0.0506, -0.1919, -0.1569,  0.0936], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0220, -0.0506, -0.1919, -0.1569,  0.0936], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0524,  0.0384,  0.0404, -0.0763,  0.0778], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1319,  0.0752,  0.7442, -0.0557, -0.0617], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-12.6926, -19.4296,  -0.2289,  -2.1057,  -5.0389],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0810, 0.7078, 0.0405, 0.1491, 0.0953], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([3.5790e-01, 1.0659e-06, 9.9077e-01, 7.3054e-01, 6.1879e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0220, -0.0506, -0.1919, -0.1569,  0.0936], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-9.3526e-05, -6.8584e-05, -7.2135e-05,  1.3618e-04, -1.3885e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-9.8352e-05,  6.3618e-05, -1.8325e-04,  6.2098e-06, -8.1373e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0001,  0.0016,  0.0014,  0.0029, -0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0146, -0.0322, -0.1265, -0.1017,  0.0608], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0146, -0.0322, -0.1265, -0.1017,  0.0608], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0035,  0.0081,  0.0052, -0.3017, -0.0161], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([33.6960], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1723], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0011,  0.0037,  0.0022, -0.0829, -0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0011,  0.0037,  0.0022, -0.0829, -0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0462,  0.1202, -0.0039,  0.1334, -0.1036], grad_fn=<SliceBackward0>)
  [Layer 2] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 2] Output sample values after mixer: tensor([-0.0462,  0.1202, -0.0039,  0.1334, -0.1036], grad_fn=<SliceBackward0>)
  [Layer 2] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 2] Residual connection sample values: tensor([ 0.1466,  0.5944, -0.0642,  0.0663, -0.1606], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 3/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2606], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9588], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2493,  0.8483, -0.0816,  0.1207, -0.2607], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.1771, -0.8005, -1.8621, -0.8196, -1.8524], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.1771, -0.8005, -1.8621, -0.8196, -1.8524], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1130,  1.1922, -0.8316, -0.4133,  0.4280], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.3089, 1.4845, 0.7843, 1.2652, 1.1514], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1588, -2.0180,  2.5472, -0.1130,  2.0472], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.3104, -0.1422, -0.0969, -0.2761, -0.6124], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2655, -0.2200, -0.1481, -0.3227, -0.6793], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1503, -0.0979, -0.0686, -0.1356, -0.2285], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1503, -0.0979, -0.0686, -0.1356, -0.2285], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1716, -0.0545, -0.0692, -0.0157, -0.2520], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2686,  0.3264,  0.3900,  0.3648,  0.2113], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-20.9265,  -0.8803,  -0.6735,  -0.6461,  -0.2726],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([4.5723e-02, 2.1190e-02, 9.8686e-05, 1.8425e-02, 3.2222e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.3841, 0.9815, 0.9999, 0.9882, 0.9913], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1503, -0.0979, -0.0686, -0.1356, -0.2285], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0012, -0.0004, -0.0005, -0.0001, -0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0010, -0.0006, -0.0009, -0.0001, -0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 6.7111e-03,  9.2454e-06,  7.1172e-04, -1.3227e-02, -2.5817e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1134, -0.0695, -0.0480, -0.1095, -0.1880], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1134, -0.0695, -0.0480, -0.1095, -0.1880], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0314,  0.0172,  0.0120,  0.0274,  0.0472], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([98.9794], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1005], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0057,  0.0028,  0.0015,  0.0039,  0.0099], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0057,  0.0028,  0.0015,  0.0039,  0.0099], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0822,  0.0749,  0.0418, -0.0755,  0.0528], grad_fn=<SliceBackward0>)
  [Layer 3] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 3] Output sample values after mixer: tensor([-0.0822,  0.0749,  0.0418, -0.0755,  0.0528], grad_fn=<SliceBackward0>)
  [Layer 3] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 3] Residual connection sample values: tensor([ 0.0644,  0.6694, -0.0224, -0.0092, -0.1078], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 4/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2730], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9137], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0723,  0.6511, -0.0205, -0.0109, -0.1139], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.9771,  0.1764,  0.5922, -1.4735,  0.1153], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.9771,  0.1764,  0.5922, -1.4735,  0.1153], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.7260,  0.8919,  0.4667,  0.3300, -0.7496], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.3771, 1.0063, 1.1605, 1.2222, 0.8768], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.3341, -0.8082, -0.7386, -0.7260,  0.6433], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1566, -0.1074, -0.1100, -0.0976,  0.2806], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1787, -0.0948, -0.1504, -0.1623,  0.5396], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0973, -0.0452, -0.0696, -0.0746,  0.3409], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0973, -0.0452, -0.0696, -0.0746,  0.3409], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2780, -0.1223,  0.0863,  0.0504, -0.1045], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2742,  0.4251,  0.5128, -0.0700,  0.2083], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4907, -0.5048, -0.6491, -0.5552, -0.4657], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1673, 0.1488, 0.2451, 0.1283, 0.6623], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9212, 0.9276, 0.8529, 0.9313, 0.7346], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0973, -0.0452, -0.0696, -0.0746,  0.3409], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0045, -0.0020,  0.0014,  0.0008, -0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0329, -0.0050, -0.0001,  0.0024, -0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1134,  0.0474,  0.0129, -0.3356,  0.5034], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1779,  0.0175, -0.0332, -0.3851,  0.7296], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1779,  0.0175, -0.0332, -0.3851,  0.7296], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1263,  0.0017, -0.0127,  0.1058,  0.0445], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([60.0286], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1291], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0491,  0.0007, -0.0044,  0.0406,  0.0124], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0491,  0.0007, -0.0044,  0.0406,  0.0124], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2634,  0.4308,  0.1899, -0.1750,  0.2912], grad_fn=<SliceBackward0>)
  [Layer 4] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 4] Output sample values after mixer: tensor([-0.2634,  0.4308,  0.1899, -0.1750,  0.2912], grad_fn=<SliceBackward0>)
  [Layer 4] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 4] Residual connection sample values: tensor([-0.1991,  1.1001,  0.1675, -0.1842,  0.1834], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 5/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5144], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.3943], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2297,  1.0703,  0.1424, -0.2119,  0.2007], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.7708, -0.2242, -0.1094,  1.2828,  1.3822], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.7708, -0.2242, -0.1094,  1.2828,  1.3822], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.0947, -0.6500, -1.7781,  1.3355, -0.1624], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.4522, 2.3530, 1.1471, 1.7593, 1.7387], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6285, -2.4791,  0.2689,  1.0947, -6.2605], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1186, -2.4561, -0.9523, -0.2707,  0.0082], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0553, -2.6974, -0.9596, -0.2439,  0.0191], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0284, -0.1703, -0.2658, -0.1071,  0.0096], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0284, -0.1703, -0.2658, -0.1071,  0.0096], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1215,  0.2506, -0.2342, -0.1574, -0.0452], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0398,  0.1252, -0.2192, -0.1721, -0.1976], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0759, -0.5319, -0.0470, -1.4939, -3.6258], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.0923, 0.1383, 0.1116, 0.0790, 0.0890], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9204, 0.9291, 0.9948, 0.8887, 0.7243], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0284, -0.1703, -0.2658, -0.1071,  0.0096], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0038,  0.0078, -0.0073, -0.0049, -0.0014], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.1023e-02,  7.2955e-04,  5.1408e-01,  5.4188e-02, -1.5971e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-1.7465, -1.8052, -1.4124, -0.4899, -0.6980], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-1.7065, -2.0449, -1.7864, -0.6406, -0.6844], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-1.7065, -2.0449, -1.7864, -0.6406, -0.6844], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.4161,  0.2036,  0.0924, -0.6434, -0.7562], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([129.3996], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0879], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0121,  0.0063,  0.0058, -0.0445, -0.0568], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0121,  0.0063,  0.0058, -0.0445, -0.0568], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0801, -0.2324, -0.1178, -0.1323,  0.2620], grad_fn=<SliceBackward0>)
  [Layer 5] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 5] Output sample values after mixer: tensor([ 0.0801, -0.2324, -0.1178, -0.1323,  0.2620], grad_fn=<SliceBackward0>)
  [Layer 5] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 5] Residual connection sample values: tensor([-0.1190,  0.8678,  0.0497, -0.3165,  0.4453], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 6/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5668], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.3283], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1158,  0.6979,  0.0377, -0.2954,  0.3873], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.9183, -1.0087, -0.5102, -3.4161, -3.9733], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.9183, -1.0087, -0.5102, -3.4161, -3.9733], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.9054, -1.4639, -1.2689, -1.2566,  1.2457], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.8772, 2.5916, 1.8317, 2.0925, 1.9143], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.3852,  0.1846,  0.3888,  0.9054, -0.8712], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0808, -0.1061, -0.3586, -0.2366,  0.1219], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1280, -0.0921, -0.2774, -0.2482,  0.2600], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0599, -0.0439, -0.1196, -0.1088,  0.1468], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0599, -0.0439, -0.1196, -0.1088,  0.1468], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0021,  0.1483, -0.2312,  0.0225,  0.0900], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0526,  0.1274, -0.2504, -0.1355,  0.0754], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5110, -0.2862, -0.5421, -0.3954, -0.5986], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.7205, 0.9728, 0.4225, 0.7911, 0.5169], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6920, 0.7570, 0.7953, 0.7314, 0.7339], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0599, -0.0439, -0.1196, -0.1088,  0.1468], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-8.8881e-05, -6.4000e-03,  9.9799e-03, -9.6926e-04, -3.8832e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0039, -0.0098,  0.0006,  0.0057,  0.0050], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0639, -0.0274, -0.0725,  0.0253,  0.2272], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0048, -0.0778, -0.2096, -0.0995,  0.3956], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0048, -0.0778, -0.2096, -0.0995,  0.3956], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0007,  0.0210,  0.0401,  0.0108, -0.0290], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([220.1010], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0674], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0001,  0.0039,  0.0071,  0.0024, -0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0001,  0.0039,  0.0071,  0.0024, -0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0616, -0.0110,  0.0628,  0.0390,  0.0859], grad_fn=<SliceBackward0>)
  [Layer 6] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 6] Output sample values after mixer: tensor([ 0.0616, -0.0110,  0.0628,  0.0390,  0.0859], grad_fn=<SliceBackward0>)
  [Layer 6] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 6] Residual connection sample values: tensor([-0.0574,  0.8568,  0.1125, -0.2775,  0.5312], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 7/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6017], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2891], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0539,  0.6531,  0.0833, -0.2629,  0.4323], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.1481,  0.4472,  0.3347, -2.8472, -3.9607], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.1481,  0.4472,  0.3347, -2.8472, -3.9607], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-2.6796, -1.1523, -1.3614, -1.0838, -0.9564], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.3999, 2.3814, 0.7111, 1.3189, 1.4965], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.9645, -2.8754, -3.0653, -2.6796, -1.9667], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6751, -0.2436, -0.1483, -0.1640, -0.0241], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.7087, -0.3148, -0.2792, -0.1555, -0.0268], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2338, -0.1328, -0.1203, -0.0717, -0.0132], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2338, -0.1328, -0.1203, -0.0717, -0.0132], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0953,  0.1747,  0.0307,  0.0890,  0.0182], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0655, -0.0181,  0.1132, -0.0265, -0.0080], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-6.5957e-02, -4.5478e+00, -5.8281e+00, -4.2034e-01, -1.9005e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6743, 0.3108, 0.0726, 0.4441, 0.6692], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9565, 0.2433, 0.6549, 0.8297, 0.9987], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2338, -0.1328, -0.1203, -0.0717, -0.0132], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0150, -0.0275, -0.0048, -0.0140, -0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.1090,  0.0102, -0.0225,  0.0019,  0.0918], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2878, -0.1600, -0.3155,  0.2189,  0.0156], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.8299, -0.4680, -0.5943,  0.0525, -0.0150], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.8299, -0.4680, -0.5943,  0.0525, -0.0150], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.2295, -0.1277, -0.1160, -0.0082,  0.0011], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([29.0851], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1854], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0508, -0.0341, -0.0186, -0.0016,  0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0508, -0.0341, -0.0186, -0.0016,  0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1755,  0.1776,  0.4432, -0.0504,  0.1793], grad_fn=<SliceBackward0>)
  [Layer 7] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 7] Output sample values after mixer: tensor([ 0.1755,  0.1776,  0.4432, -0.0504,  0.1793], grad_fn=<SliceBackward0>)
  [Layer 7] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 7] Residual connection sample values: tensor([ 0.1181,  1.0344,  0.5557, -0.3279,  0.7105], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 8/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7670], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1418], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1289,  0.8449,  0.4241, -0.3484,  0.6497], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2579, -1.3635,  0.9807, -2.1745, -1.1546], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2579, -1.3635,  0.9807, -2.1745, -1.1546], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8658, -2.1259, -2.3590,  2.4241, -3.2601], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.8011, 4.1136, 2.9792, 2.4302, 3.1913], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.6702,  0.1199, -3.2333, -0.8658,  4.4188], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.4031,  0.4101,  0.3102,  0.2396, -0.2173], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4805,  0.4912,  0.3766,  0.1427, -0.2798], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1836,  0.3047,  0.2233,  0.0764, -0.1205], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1836,  0.3047,  0.2233,  0.0764, -0.1205], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0217,  0.1628, -0.0714,  1.2090, -0.1008], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0329, -0.0608, -0.1311, -0.0303, -0.1576], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6851, -0.1380, -0.4118, -0.2678, -0.1244], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2723, 5.4353, 2.1474, 1.8750, 4.3035], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8298, 0.4723, 0.4130, 0.6052, 0.5854], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1836,  0.3047,  0.2233,  0.0764, -0.1205], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0011, -0.0081,  0.0036, -0.0604,  0.0050], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0088,  0.0065,  0.0062, -0.0397,  0.0141], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2228, -0.1480,  0.0800, -0.1416,  0.0805], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.9144,  0.9996,  0.9212,  0.1463, -0.3733], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.9144,  0.9996,  0.9212,  0.1463, -0.3733], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1028, -0.2776,  0.6570, -0.0325,  0.1033], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([648.0150], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0393], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0094, -0.0133,  0.0972, -0.0041,  0.0089], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0094, -0.0133,  0.0972, -0.0041,  0.0089], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0516, -0.0334,  0.0707, -0.2009,  0.0013], grad_fn=<SliceBackward0>)
  [Layer 8] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 8] Output sample values after mixer: tensor([ 0.0516, -0.0334,  0.0707, -0.2009,  0.0013], grad_fn=<SliceBackward0>)
  [Layer 8] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 8] Residual connection sample values: tensor([ 0.1697,  1.0010,  0.6264, -0.5288,  0.7119], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 9/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.9181], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0436], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1630,  0.7427,  0.4449, -0.5090,  0.5953], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5333, -1.4178,  1.1245, -1.1664, -0.6155], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5333, -1.4178,  1.1245, -1.1664, -0.6155], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.1386,  2.1195, -2.5958,  0.4739,  0.2632], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([3.8820, 5.3251, 3.1418, 3.4910, 4.7424], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6423,  0.8244,  2.8223,  1.1386, -1.4182], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.8531,  0.5383,  0.4810,  0.0186,  0.0809], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-1.1065,  0.6288,  0.4768,  0.0253,  0.0622], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2750,  0.4101,  0.2942,  0.0128,  0.0321], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2750,  0.4101,  0.2942,  0.0128,  0.0321], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0253, -0.0281,  0.0990, -0.1469,  0.0099], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1367, -0.1819,  0.1368, -0.1418, -0.1553], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1701, -0.1135, -0.1054, -0.5864, -0.1497], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([4.3125, 6.1330, 4.9371, 2.1302, 4.9427], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4802, 0.4985, 0.5943, 0.2867, 0.4773], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2750,  0.4101,  0.2942,  0.0128,  0.0321], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0300,  0.0333, -0.1174,  0.1742, -0.0117], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0137, -0.0577, -0.1621,  0.3892,  0.1757], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.8207,  0.1837, -0.1236, -0.1048,  0.4453], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-1.5575,  1.2826,  0.6646, -0.0705,  0.5313], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-1.5575,  1.2826,  0.6646, -0.0705,  0.5313], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.5235, -0.3546,  0.5641,  0.0195, -0.1147], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([356.9330], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0529], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0241, -0.0304,  0.0323,  0.0013, -0.0076], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0241, -0.0304,  0.0323,  0.0013, -0.0076], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.6871e-02,  4.5748e-02, -1.6824e-01, -1.6312e-01,  8.8871e-05],
       grad_fn=<SliceBackward0>)
  [Layer 9] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 9] Output sample values after mixer: tensor([ 2.6871e-02,  4.5748e-02, -1.6824e-01, -1.6312e-01,  8.8871e-05],
       grad_fn=<SliceBackward0>)
  [Layer 9] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 9] Residual connection sample values: tensor([ 0.1966,  1.0467,  0.4581, -0.6919,  0.7120], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 10/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.0519], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9750], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1892,  0.7694,  0.3287, -0.6549,  0.5800], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.0386, -2.6867, -3.7640, -4.3333, -0.2401], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.0386, -2.6867, -3.7640, -4.3333, -0.2401], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-2.8205,  1.5775,  1.4093,  1.0604,  2.0356], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([4.4261, 2.5415, 2.0188, 5.6262, 2.4007], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.7704, -3.1215, -0.8985, -2.8205,  3.4394], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0191,  0.0622, -0.1223,  0.5462, -0.4638], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1894,  0.0382, -0.1602,  1.1502, -0.4149], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0858,  0.0195, -0.0737,  0.8736, -0.1650], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0858,  0.0195, -0.0737,  0.8736, -0.1650], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0384,  0.3762,  0.0281, -0.2049, -0.1385], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 1.4835, -0.1944,  0.0356,  0.1987,  0.4971], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0854, -0.0771, -0.0845, -0.0547, -0.0697], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([5.5093, 0.8012, 0.5389, 6.7270, 2.2388], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6249, 0.9401, 0.9555, 0.6922, 0.8556], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0858,  0.0195, -0.0737,  0.8736, -0.1650], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0182, -0.1777, -0.0133,  0.0968,  0.0654], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.1181, -0.9506, -0.0680,  0.4197, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-3.8814,  0.3678, -2.6213, 28.5076,  1.6052], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-4.2990,  0.4627, -2.9801, 32.7614,  0.8016], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-4.2990,  0.4627, -2.9801, 32.7614,  0.8016], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 1.0097, -0.0793,  0.2542, -1.8391, -0.0847], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2629.2207], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0195], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0120, -0.0020,  0.0071, -0.0394, -0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0120, -0.0020,  0.0071, -0.0394, -0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1250,  0.3594,  0.1565,  0.3557, -0.4135], grad_fn=<SliceBackward0>)
  [Layer 10] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 10] Output sample values after mixer: tensor([ 0.1250,  0.3594,  0.1565,  0.3557, -0.4135], grad_fn=<SliceBackward0>)
  [Layer 10] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 10] Residual connection sample values: tensor([ 0.3216,  1.4061,  0.6146, -0.3362,  0.2984], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 11/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.4145], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.8408], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1953,  0.6927,  0.2937, -0.2229,  0.1604], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.5948,  0.2493, -1.6225,  2.0984, -2.5400], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.5948,  0.2493, -1.6225,  2.0984, -2.5400], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.4402, -0.5750, -0.9585,  0.2143,  0.5952], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.3702, -0.0768,  0.2500,  2.0295,  3.4756], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 2.1559,  0.6833, -0.1301, -0.4402,  0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1559,  0.0938,  0.2410, -0.0384,  0.0554], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([0.3024, 0.2850, 0.2650, 0.0690, 0.1704], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([0.1739, 0.1626, 0.1499, 0.0357, 0.0924], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([0.1739, 0.1626, 0.1499, 0.0357, 0.0924], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2369,  0.0383,  0.1910, -0.1483,  0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1864,  0.3634,  0.0445,  0.0655, -0.1653], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2593, -0.1261, -0.1036, -0.2378, -0.4305], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0567, 0.0654, 0.1906, 1.9508, 3.5589], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9854, 0.9918, 0.9805, 0.6289, 0.2161], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([0.1739, 0.1626, 0.1499, 0.0357, 0.0924], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-2.3345e-03,  3.7737e-04,  1.8818e-03, -1.4614e-03,  2.6059e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1854,  0.0108,  0.0198, -0.0867,  0.1145], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([0.5631, 0.5671, 0.4962, 0.2932, 0.8301], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([0.0147, 0.0541, 0.0233, 0.1806, 0.5386], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([0.0147, 0.0541, 0.0233, 0.1806, 0.5386], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0195,  0.0076, -0.0062,  0.3375, -0.1000], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([93.3109], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1035], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0007,  0.0020, -0.0030,  0.0306, -0.0106], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0007,  0.0020, -0.0030,  0.0306, -0.0106], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0673, -0.0824, -0.1397,  0.1309,  0.3900], grad_fn=<SliceBackward0>)
  [Layer 11] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 11] Output sample values after mixer: tensor([ 0.0673, -0.0824, -0.1397,  0.1309,  0.3900], grad_fn=<SliceBackward0>)
  [Layer 11] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 11] Residual connection sample values: tensor([ 0.3889,  1.3238,  0.4749, -0.2053,  0.6884], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 12/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.7467], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7566], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1886,  0.5116,  0.1678, -0.1129,  0.2826], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 3.0246, -0.7573,  0.9502, -0.6029, -0.5343], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 3.0246, -0.7573,  0.9502, -0.6029, -0.5343], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5588,  0.3170, -1.3213, -0.3115, -0.5837], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.7791, 2.6529, 1.4245, 2.3183, 1.7769], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.6179, -2.6214, -0.6272,  0.5588,  2.6589], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1838, -0.9583,  0.0889, -0.1279,  0.6559], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2510, -1.7928,  0.0242, -0.1721,  0.4893], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1098, -0.2559,  0.0122, -0.0787,  0.3033], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1098, -0.2559,  0.0122, -0.0787,  0.3033], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1619, -0.0006, -0.0078,  0.5011,  0.0381], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1051, -0.2547, -0.2587, -0.2733,  0.6719], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1609, -0.1475, -0.2713, -0.1155, -0.0902], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.3974, 2.4859, 2.2790, 3.6808, 0.3559], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6800, 0.6931, 0.5389, 0.6536, 0.9684], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1098, -0.2559,  0.0122, -0.0787,  0.3033], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0426,  0.0002,  0.0021, -0.1319, -0.0100], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0639,  0.0254,  0.0874, -0.2871, -0.0284], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.6251, -1.4149, -0.4752, -0.1031,  5.5128], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.8033, -1.8302, -0.4554, -0.2307,  6.0051], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.8033, -1.8302, -0.4554, -0.2307,  6.0051], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-2.3172,  0.4425, -0.3120,  0.0492, -1.1855], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([165.9963], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0776], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2729,  0.0305, -0.0420,  0.0125, -0.1201], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2729,  0.0305, -0.0420,  0.0125, -0.1201], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2015,  0.1074, -0.5341,  0.5129,  0.1479], grad_fn=<SliceBackward0>)
  [Layer 12] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 12] Output sample values after mixer: tensor([-0.2015,  0.1074, -0.5341,  0.5129,  0.1479], grad_fn=<SliceBackward0>)
  [Layer 12] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 12] Residual connection sample values: tensor([ 0.1874,  1.4311, -0.0592,  0.3076,  0.8363], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 13/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.1174], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6872], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0696,  0.4341, -0.0171,  0.1229,  0.2787], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6656, -1.0005, -0.4063,  0.2734, -0.4105], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6656, -1.0005, -0.4063,  0.2734, -0.4105], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.1219,  0.4060, -0.3437,  0.6466, -0.6035], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.0963, -0.1565,  0.9472, -0.6032,  0.7021], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2791, -0.4165,  0.2538,  0.1219, -0.5398], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0879, -0.0192, -0.3814,  0.0400, -0.0256], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1500, -0.0378, -0.3735,  0.0283, -0.0561], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0694, -0.0186, -0.1523,  0.0144, -0.0272], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0694, -0.0186, -0.1523,  0.0144, -0.0272], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0767, -0.2175,  0.2000, -0.0457, -0.0846], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0034, -0.0089,  0.5377,  0.1293, -0.0700], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0234, -1.0903, -0.5085, -0.6785, -0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1497, 0.0086, 0.0218, 0.0029, 0.2869], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9965, 0.9907, 0.9890, 0.9980, 0.9928], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0694, -0.0186, -0.1523,  0.0144, -0.0272], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0008,  0.0023, -0.0021,  0.0005,  0.0009], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0929,  0.1018, -0.2830,  0.0235, -0.0586], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2038, -0.1919,  0.0020,  0.0043,  0.1770], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1958, -0.1898,  0.0196,  0.0026,  0.1801], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1958, -0.1898,  0.0196,  0.0026,  0.1801], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0442,  0.0511, -0.0032,  0.0004, -0.0295], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.8623], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5911], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0131,  0.0100, -0.0021,  0.0006, -0.0100], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0131,  0.0100, -0.0021,  0.0006, -0.0100], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1437, -0.2203, -0.1791,  0.6194,  0.1686], grad_fn=<SliceBackward0>)
  [Layer 13] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 13] Output sample values after mixer: tensor([-0.1437, -0.2203, -0.1791,  0.6194,  0.1686], grad_fn=<SliceBackward0>)
  [Layer 13] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 13] Residual connection sample values: tensor([ 0.0437,  1.2109, -0.2383,  0.9270,  1.0049], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 14/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.6838], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6104], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0127,  0.3032, -0.0584,  0.3042,  0.2730], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1925, -0.9414, -0.3839,  1.1748, -0.7967], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1925, -0.9414, -0.3839,  1.1748, -0.7967], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0043,  0.2673, -0.8197,  0.4601, -0.5005], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.2095, -0.4494,  1.9887,  0.8630,  1.7749], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.9049,  1.7297, -0.3864,  0.0043, -1.2733], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0027,  0.0410, -0.4620, -0.1448,  0.1351], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0731, -0.0084, -0.6538, -0.1924,  0.1213], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0379, -0.0042, -0.2237, -0.0870,  0.0643], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0379, -0.0042, -0.2237, -0.0870,  0.0643], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0307,  0.1284, -0.0597,  0.2323, -0.1194], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1249,  0.2340, -0.0875,  0.3402, -0.2154], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-7.2745, -0.0385, -2.2024, -0.0138, -5.3378], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0672, 0.0385, 0.0829, 0.1145, 0.0925], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6131, 0.9985, 0.8332, 0.9984, 0.6105], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0379, -0.0042, -0.2237, -0.0870,  0.0643], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-7.8288e-05,  3.2741e-04, -1.5219e-04,  5.9205e-04, -3.0432e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0004, -0.0002,  0.0006,  0.0005, -0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0022, -0.0036, -0.0280, -0.0071,  0.0073], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0321, -0.0069, -0.2041, -0.0755,  0.0579], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0321, -0.0069, -0.2041, -0.0755,  0.0579], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0028,  0.0018,  0.0317, -0.0678, -0.0143], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.2151], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9072], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0060,  0.0027,  0.0325, -0.1004, -0.0270], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0060,  0.0027,  0.0325, -0.1004, -0.0270], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5709,  0.3852, -0.2967, -0.7621,  0.3085], grad_fn=<SliceBackward0>)
  [Layer 14] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 14] Output sample values after mixer: tensor([-0.5709,  0.3852, -0.2967, -0.7621,  0.3085], grad_fn=<SliceBackward0>)
  [Layer 14] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 14] Residual connection sample values: tensor([-0.5272,  1.5961, -0.5350,  0.1649,  1.3134], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 15/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3.3417], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5470], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1755,  0.4370, -0.1470,  0.0650,  0.4080], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 2.1412,  0.0129,  0.5189, -2.1870, -6.0243], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 2.1412,  0.0129,  0.5189, -2.1870, -6.0243], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-3.2269, -0.2154,  1.4374,  1.7837, -1.3098], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.8480,  1.4327, -0.2559,  7.0583,  1.6969], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4331, -1.1423,  0.1975, -3.2269,  1.3801], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([0.3331, 0.0917, 0.0576, 0.3611, 0.2403], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0031,  0.0675,  1.3828,  0.8037,  0.2268], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0016,  0.0349,  1.1055,  0.5552,  0.1262], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0016,  0.0349,  1.1055,  0.5552,  0.1262], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0420, -0.1629,  0.1480, -0.0691, -0.1001], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0388, -0.0497,  0.0227, -0.0499, -0.1268], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.4414, -0.0592, -0.7390, -0.0051, -0.0087], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3411, 1.2252, 0.0170, 4.0716, 0.5970], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4348, 0.9300, 0.9875, 0.9795, 0.9948], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0016,  0.0349,  1.1055,  0.5552,  0.1262], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.2271e-05,  8.6429e-05, -7.8530e-05,  3.6662e-05,  5.3095e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0006,  0.0034,  0.0020,  0.0007,  0.0040], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0060,  0.0014,  0.0708,  0.0268,  0.0038], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0088,  0.0637,  2.0450,  1.0183,  0.2292], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0088,  0.0637,  2.0450,  1.0183,  0.2292], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-1.6801e-02,  4.1283e-04,  6.6518e-01, -2.2475e-01, -3.3320e-03],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([6.6072], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3890], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0144,  0.0003,  0.1226, -0.1089, -0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0144,  0.0003,  0.1226, -0.1089, -0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5160,  0.0640, -0.1621, -0.1767, -0.0349], grad_fn=<SliceBackward0>)
  [Layer 15] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 15] Output sample values after mixer: tensor([-0.5160,  0.0640, -0.1621, -0.1767, -0.0349], grad_fn=<SliceBackward0>)
  [Layer 15] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 15] Residual connection sample values: tensor([-1.0433,  1.6601, -0.6971, -0.0119,  1.2785], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 16/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.2502], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4851], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2284,  0.3004, -0.1176, -0.0033,  0.2646], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.6408e-02, -1.8509e-04, -6.3899e+00, -6.7820e-01, -1.0860e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.6408e-02, -1.8509e-04, -6.3899e+00, -6.7820e-01, -1.0860e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.8545,  0.3433, -2.5231,  0.8572, -1.1348], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([3.4974, 0.8159, 1.9321, 0.5898, 0.8829], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2483,  1.2534, -0.1357,  0.8545, -0.9999], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0122, -0.0630, -0.1301, -0.0491,  0.0753], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0140, -0.0542,  0.0066, -0.0873,  0.0829], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0070, -0.0264,  0.0033, -0.0418,  0.0431], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0070, -0.0264,  0.0033, -0.0418,  0.0431], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0210, -0.0354, -0.1052, -0.0300, -0.0023], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1302, -0.0627, -0.0182, -0.1900, -0.2426], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.1349e-03, -3.0370e-03, -2.7156e+00, -4.1511e-03, -4.2926e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.3228, 0.1439, 0.1527, 0.0482, 0.0027], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9985, 0.9996, 0.6606, 0.9998, 0.9988], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0070, -0.0264,  0.0033, -0.0418,  0.0431], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.9370e-04,  3.2565e-04,  9.6929e-04,  2.7663e-04,  2.1236e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0042, 0.1099, 0.0394, 0.0022, 0.0039], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0127,  0.0403,  0.0165,  0.1130,  0.0152], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0111,  0.0464,  0.0158,  0.1228,  0.0051], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0111,  0.0464,  0.0158,  0.1228,  0.0051], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 9.0307e-05, -4.2981e-06, -1.6880e-04, -2.8028e-02, -1.4077e-03],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2831], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.8795], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 7.4423e-05, -2.0166e-06, -3.1880e-04, -9.2148e-03, -1.3733e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 7.4423e-05, -2.0166e-06, -3.1880e-04, -9.2148e-03, -1.3733e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.3112,  0.2069, -0.4248, -0.3585,  0.0694], grad_fn=<SliceBackward0>)
  [Layer 16] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 16] Output sample values after mixer: tensor([ 0.3112,  0.2069, -0.4248, -0.3585,  0.0694], grad_fn=<SliceBackward0>)
  [Layer 16] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 16] Residual connection sample values: tensor([-0.7321,  1.8670, -1.1220, -0.3704,  1.3479], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 17/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.4671], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4731], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2339,  0.5133, -0.3082, -0.1356,  0.3967], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-7.3771, -5.3008,  0.5402, -1.4830, -2.5806], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-7.3771, -5.3008,  0.5402, -1.4830, -2.5806], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 2.4675, -1.3283, -0.5923, -0.5277,  0.3527], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.7110, 2.1182, 1.3380, 1.9322, 2.7166], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4500,  0.2817, -1.7254,  2.4675,  0.4414], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4208,  0.1822, -0.2438, -0.1072,  0.0842], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.3258,  0.2043, -0.3582, -0.0727,  0.1794], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1892,  0.1126, -0.1474, -0.0350,  0.0977], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1892,  0.1126, -0.1474, -0.0350,  0.0977], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0298,  0.0717, -0.2650,  0.0413, -0.2356], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1330, -0.0983, -0.2759, -0.1410, -0.0370], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3863, -0.8773, -1.4027, -0.6828, -0.3905], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.1784, 0.5421, 0.4250, 1.0881, 1.8997], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.1952, 0.6215, 0.5509, 0.4757, 0.4763], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1892,  0.1126, -0.1474, -0.0350,  0.0977], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0066,  0.0160, -0.0591,  0.0092, -0.0525], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0033,  0.0149, -0.0512,  0.0097, -0.0476], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1330,  0.0901, -0.1306, -0.0219,  0.0833], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.6313,  0.3866, -0.5188, -0.1142,  0.3407], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.6313,  0.3866, -0.5188, -0.1142,  0.3407], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0029, -0.0102, -0.1771,  0.0313, -0.0619], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([25.6082], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1976], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0011, -0.0040, -0.0733,  0.0160, -0.0291], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0011, -0.0040, -0.0733,  0.0160, -0.0291], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.5955,  0.3388, -0.3967,  0.3984, -0.0955], grad_fn=<SliceBackward0>)
  [Layer 17] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 17] Output sample values after mixer: tensor([ 0.5955,  0.3388, -0.3967,  0.3984, -0.0955], grad_fn=<SliceBackward0>)
  [Layer 17] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 17] Residual connection sample values: tensor([-0.1366,  2.2058, -1.5187,  0.0281,  1.2524], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 18/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([5.0916], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4432], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0290,  0.4055, -0.2751,  0.0073,  0.2356], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3555, -0.4255, -0.6451, -0.7421,  1.1245], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3555, -0.4255, -0.6451, -0.7421,  1.1245], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6895, -0.8774,  0.0260, -0.8825, -2.3567], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([5.7896e-01, 5.9092e+00, 4.9432e+00, 6.3998e+00, 4.3017e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0273,  0.2538, -0.1540, -0.6895, -1.0216], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1251,  1.1442,  0.0049, -0.2111,  0.1303], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1344,  0.7462,  0.0161, -0.1805,  0.0781], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0717,  0.5062,  0.0081, -0.0821,  0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0717,  0.5062,  0.0081, -0.0821,  0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1539,  0.0145,  0.0519, -0.0317, -0.0038], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0546, -0.0092, -0.0038, -0.0558,  0.0427], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.3195e-03, -6.5336e+00, -1.4897e+01, -1.3796e-03, -2.0873e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2240, 7.0214, 6.3912, 4.2597, 0.1376], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9948e-01, 1.1933e-20, 4.4743e-42, 9.9414e-01, 9.9971e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0717,  0.5062,  0.0081, -0.0821,  0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.4726e-03,  2.3218e-04,  8.3358e-04, -5.0856e-04, -6.1529e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0056, -0.0084,  0.0931, -0.0391,  0.0122], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2815, -1.7789,  0.0681, -0.2031, -0.3007], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2872, -1.8190,  0.0675, -0.1966, -0.3039], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2872, -1.8190,  0.0675, -0.1966, -0.3039], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0421,  0.3059, -0.0150,  0.0471, -0.2580], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([17.3926], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2398], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0498,  0.0886, -0.0039,  0.0286, -0.0736], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0498,  0.0886, -0.0039,  0.0286, -0.0736], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1432,  0.3559, -0.0834,  0.1664, -0.3939], grad_fn=<SliceBackward0>)
  [Layer 18] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 18] Output sample values after mixer: tensor([-0.1432,  0.3559, -0.0834,  0.1664, -0.3939], grad_fn=<SliceBackward0>)
  [Layer 18] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 18] Residual connection sample values: tensor([-0.2798,  2.5617, -1.6021,  0.1945,  0.8584], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 19/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([5.9684], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4093], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0683,  0.5192, -0.3282,  0.0587,  0.1860], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.7230, -0.8671, -0.5936,  0.3108,  0.2283], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.7230, -0.8671, -0.5936,  0.3108,  0.2283], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.5319,  1.2369,  0.7249, -1.2866,  1.4174], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.0619, 2.2248, 2.9096, 2.9427, 3.6310], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.3610, -1.4364, -1.2169,  1.5319, -1.1119], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3130,  0.0757,  0.1680,  0.2747,  0.2471], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3645,  0.0762,  0.1542,  0.0670,  0.2459], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1494,  0.0396,  0.0830,  0.0346,  0.1380], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1494,  0.0396,  0.0830,  0.0346,  0.1380], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0231, -0.1478, -0.2764, -0.0533,  0.1133], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2061,  0.0440, -0.1006, -0.0736,  0.1008], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1739, -1.5063, -1.5725, -0.1983, -0.0768], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.0667, 1.3923, 2.0596, 4.1106, 2.8701], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5866, 0.1228, 0.0392, 0.4426, 0.8022], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1494,  0.0396,  0.0830,  0.0346,  0.1380], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0106,  0.0677,  0.1266,  0.0244, -0.0519], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0048,  0.0720,  0.0793,  0.0619, -0.1037], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.5275, -0.2234,  0.0263, -0.3114,  0.3874], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.7550, -0.1631,  0.1528, -0.2587,  0.5975], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.7550, -0.1631,  0.1528, -0.2587,  0.5975], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.3675,  0.0419, -0.0323, -0.0464,  0.0760], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([24.8795], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2005], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0860,  0.0169, -0.0155, -0.0092,  0.0557], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0860,  0.0169, -0.0155, -0.0092,  0.0557], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.3816,  3.1619, -0.4068,  0.0589,  0.6262], grad_fn=<SliceBackward0>)
  [Layer 19] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 19] Output sample values after mixer: tensor([-1.3816,  3.1619, -0.4068,  0.0589,  0.6262], grad_fn=<SliceBackward0>)
  [Layer 19] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 19] Residual connection sample values: tensor([-1.6614,  5.7236, -2.0089,  0.2535,  1.4846], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 20/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([12.1229], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2872], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1760,  0.5550, -0.1950,  0.0329,  0.1537], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3123, -0.4242,  0.8578, -0.6725,  0.5506], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3123, -0.4242,  0.8578, -0.6725,  0.5506], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0231, -1.0546, -0.8556,  0.6825, -0.3648], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.1816, 2.2853, 0.2062, 1.9236, 1.3580], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8696,  0.8534,  1.2464,  0.0231, -0.6242], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0451,  0.2611, -0.3444,  0.1225, -0.0657], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0306,  0.2229, -0.5239,  0.1015, -0.1123], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0156,  0.1238, -0.1949,  0.0533, -0.0530], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0156,  0.1238, -0.1949,  0.0533, -0.0530], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0274,  0.0024, -0.0401,  0.0492, -0.0086], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2266, -0.1756, -0.2253, -0.2474, -0.2106], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.0858e-01, -2.9306e+00, -5.2962e+00, -1.2326e+01, -8.1593e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0229, 0.2322, 0.0726, 0.4334, 0.1549], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9929, 0.5063, 0.6809, 0.0048, 0.9987], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0156,  0.1238, -0.1949,  0.0533, -0.0530], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-9.7691e-06,  8.5639e-07, -1.4289e-05,  1.7566e-05, -3.0605e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.2647e-04, -2.4238e-04, -2.0246e-04,  8.9303e-05, -4.8548e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 2.0368e-04,  1.8994e-04, -1.6355e-05, -1.7764e-03,  8.3066e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0130,  0.1020, -0.1603,  0.0421, -0.0427], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0130,  0.1020, -0.1603,  0.0421, -0.0427], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0017, -0.0171, -0.0965, -0.0096, -0.0149], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0581], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([4.1490], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0178, -0.1531, -0.5946, -0.0967, -0.0987], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0178, -0.1531, -0.5946, -0.0967, -0.0987], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1343,  0.1300,  0.3197, -0.0314,  0.3048], grad_fn=<SliceBackward0>)
  [Layer 20] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 20] Output sample values after mixer: tensor([-0.1343,  0.1300,  0.3197, -0.0314,  0.3048], grad_fn=<SliceBackward0>)
  [Layer 20] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 20] Residual connection sample values: tensor([-1.7956,  5.8536, -1.6892,  0.2221,  1.7894], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 21/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([14.2655], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2648], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2403,  0.7087, -0.2095,  0.0351,  0.2302], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2105, -1.0034,  0.7077, -0.8147, -0.4501], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2105, -1.0034,  0.7077, -0.8147, -0.4501], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.0821, -0.4590,  0.6218,  1.1556,  1.5226], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.3691,  1.0040,  0.9247, -0.0388,  1.1968], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.6583, -0.2675,  0.5755, -0.0821, -2.1235], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0208, -0.1084, -0.0656, -0.2971,  0.3799], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3366, -0.2059, -0.0913, -0.3951,  0.3259], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1402, -0.0924, -0.0436, -0.1590,  0.1893], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1402, -0.0924, -0.0436, -0.1590,  0.1893], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0050, -0.2691, -0.0706, -0.1260, -0.0290], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1340, -0.1324,  0.1287, -0.0376,  0.1073], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3228, -0.3764, -0.1595, -0.1054, -0.3757], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.6587, 1.1435, 1.4188, 0.4276, 1.2406], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5855, 0.6502, 0.7975, 0.9559, 0.6275], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1402, -0.0924, -0.0436, -0.1590,  0.1893], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0012,  0.0626,  0.0164,  0.0293,  0.0068], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0618, 0.1308, 0.0293, 0.0856, 0.0122], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2696, -0.1722, -0.0870, -0.0551,  0.3767], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.5660, -0.3674, -0.1791, -0.3912,  0.7767], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.5660, -0.3674, -0.1791, -0.3912,  0.7767], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0658,  0.0989, -0.0849,  0.0978, -0.1361], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([4.1506], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4908], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0673,  0.1277, -0.1240,  0.1002, -0.1202], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0673,  0.1277, -0.1240,  0.1002, -0.1202], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.7985, -0.1722, -0.8396,  0.3379,  0.5036], grad_fn=<SliceBackward0>)
  [Layer 21] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 21] Output sample values after mixer: tensor([ 0.7985, -0.1722, -0.8396,  0.3379,  0.5036], grad_fn=<SliceBackward0>)
  [Layer 21] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 21] Residual connection sample values: tensor([-0.9971,  5.6814, -2.5288,  0.5600,  2.2929], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 22/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([16.5367], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2459], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1268,  0.6682, -0.2977,  0.0841,  0.2825], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5940,  1.6218,  0.9450, -3.0870,  0.7548], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5940,  1.6218,  0.9450, -3.0870,  0.7548], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.0115,  0.8055, -0.3535,  0.3072,  0.8268], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([4.0034, 1.1962, 2.2674, 1.7297, 0.9971], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6772, -1.7266, -0.3219, -0.0115,  0.2002], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0297, -0.2505, -0.0091,  0.0252,  0.0947], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0215, -0.1859,  0.0036,  0.0068,  0.0953], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0106, -0.0844,  0.0018,  0.0034,  0.0499], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0106, -0.0844,  0.0018,  0.0034,  0.0499], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1911,  0.2101,  0.2362, -0.1741, -0.0384], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2573, -0.1156, -0.1266, -0.2172, -0.2321], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0709, -0.0702, -0.0699, -0.0895, -0.3897], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.6043, 1.5698, 0.7806, 1.1621, 1.3459], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7745, 0.8956, 0.9469, 0.9013, 0.5918], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0106, -0.0844,  0.0018,  0.0034,  0.0499], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0073, -0.0080, -0.0090,  0.0067,  0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0052, 0.0244, 0.0052, 0.0133, 0.0453], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0507,  0.1539, -0.1277, -0.0411,  0.0109], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0324,  0.2993, -0.1308, -0.0470, -0.0751], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0324,  0.2993, -0.1308, -0.0470, -0.0751], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0124,  0.4054, -0.0890,  0.0063, -0.0386], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([6.6278], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3884], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0127,  0.1802, -0.0913,  0.0097, -0.0378], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0127,  0.1802, -0.0913,  0.0097, -0.0378], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.4111,  2.2288, -0.6958, -1.5260,  1.0109], grad_fn=<SliceBackward0>)
  [Layer 22] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 22] Output sample values after mixer: tensor([ 0.4111,  2.2288, -0.6958, -1.5260,  1.0109], grad_fn=<SliceBackward0>)
  [Layer 22] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 22] Residual connection sample values: tensor([-0.5861,  7.9102, -3.2246, -0.9660,  3.3038], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 23/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([19.8217], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2246], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0579,  0.7057, -0.3027, -0.1173,  0.3036], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5284,  0.9680, -1.4260, -0.6147, -0.5924], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5284,  0.9680, -1.4260, -0.6147, -0.5924], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.5488, -0.2129,  0.1273,  0.6203,  0.4576], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.8764, 1.7276, 1.6022, 2.0439, 1.5197], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.9223, -0.9369,  0.7956, -1.5488, -0.0992], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4628, -0.0744,  0.4883, -0.1146, -0.0435], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.4291, -0.0820,  0.4463, -0.0983, -0.0479], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.2599, -0.0393,  0.2722, -0.0467, -0.0234], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.2599, -0.0393,  0.2722, -0.0467, -0.0234], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0814,  0.1576, -0.0095,  0.3030,  0.0611], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0884, -0.1559, -0.0084,  0.2701,  0.0704], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1232, -0.2255, -0.2420, -0.0956, -0.2396], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3968, 0.8537, 0.7657, 0.4678, 0.6281], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9523, 0.8249, 0.8309, 0.9563, 0.8603], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.2599, -0.0393,  0.2722, -0.0467, -0.0234], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0084,  0.0163, -0.0010,  0.0313,  0.0063], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0271,  0.0132, -0.0012,  0.0842, -0.0114], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0421,  0.0149,  0.1583, -0.0236,  0.0232], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0300,  0.0168,  0.1456, -0.0214,  0.0243], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0300,  0.0168,  0.1456, -0.0214,  0.0243], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0100,  0.0118, -0.0402,  0.0046, -0.0051], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3540], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.6806], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0165,  0.0590, -0.3314,  0.0382, -0.0235], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0165,  0.0590, -0.3314,  0.0382, -0.0235], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5912, -2.2911,  0.8136,  0.5969, -0.9126], grad_fn=<SliceBackward0>)
  [Layer 23] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 23] Output sample values after mixer: tensor([-0.5912, -2.2911,  0.8136,  0.5969, -0.9126], grad_fn=<SliceBackward0>)
  [Layer 23] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 23] Residual connection sample values: tensor([-1.1773,  5.6191, -2.4110, -0.3691,  2.3913], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 24/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([21.9313], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2135], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1388,  0.5882, -0.2743, -0.0500,  0.2598], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5186, -0.0659,  0.3658, -1.6651, -1.2364], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5186, -0.0659,  0.3658, -1.6651, -1.2364], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2398, -1.8114, -1.3452, -3.5035, -0.9611], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.7762, 1.5771, 1.8685, 0.6712, 1.7995], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1848, -0.1602, -0.2574,  0.2398, -2.1053], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0711, -0.2079, -0.1673, -0.8420,  0.1267], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0559, -0.1105, -0.1695, -0.9211,  0.1335], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0287, -0.0522, -0.0776, -0.2623,  0.0712], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0287, -0.0522, -0.0776, -0.2623,  0.0712], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0208,  0.0386, -0.1229,  0.1187, -0.0680], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0110, -0.1519, -0.2372,  0.0090, -0.2273], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6296, -0.1967, -0.1434, -0.1402, -0.2238], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.2643, 1.8685, 1.8153, 1.6560, 1.5215], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4511, 0.6924, 0.7709, 0.7928, 0.7114], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0287, -0.0522, -0.0776, -0.2623,  0.0712], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0008,  0.0014, -0.0045,  0.0043, -0.0025], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0196,  0.0057, -0.0032,  0.0163, -0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0708, -0.0404, -0.0636, -0.1315, -0.0677], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2114, -0.2961, -0.4436, -1.4161,  0.2811], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2114, -0.2961, -0.4436, -1.4161,  0.2811], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0687,  0.0094, -0.0958,  0.3751, -0.0782], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([5.4003], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4303], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0326,  0.0140, -0.1249,  0.3632, -0.0702], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0326,  0.0140, -0.1249,  0.3632, -0.0702], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.1431, -0.0092,  0.0295,  0.4031,  0.4931], grad_fn=<SliceBackward0>)
  [Layer 24] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 24] Output sample values after mixer: tensor([-1.1431, -0.0092,  0.0295,  0.4031,  0.4931], grad_fn=<SliceBackward0>)
  [Layer 24] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 24] Residual connection sample values: tensor([-2.3203,  5.6099, -2.3815,  0.0340,  2.8844], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 25/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([24.3834], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2025], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1805,  0.4050, -0.1726,  0.0030,  0.2102], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.1686, -0.0483, -1.7436,  0.1678, -0.0156], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.1686, -0.0483, -1.7436,  0.1678, -0.0156], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1364, -0.4162,  1.5744, -1.3104, -0.3957], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.0506, 1.2739, 1.1333, 2.0374, 1.8999], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1695,  0.0134,  0.0313, -0.1364,  0.5003], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0387,  0.0423, -0.3427, -0.6394, -0.2628], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0193,  0.0457, -0.2400, -0.7445, -0.3014], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0098,  0.0234, -0.1057, -0.2397, -0.1282], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0098,  0.0234, -0.1057, -0.2397, -0.1282], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0445, -0.0174, -0.0395, -0.0101, -0.0144], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1989, -0.2370, -0.0939, -0.0668, -0.2387], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1626, -0.3327, -0.3294, -0.2016, -0.1541], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.9663, 0.9226, 0.8202, 1.6513, 1.7297], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7263, 0.7357, 0.7632, 0.7169, 0.7660], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0098,  0.0234, -0.1057, -0.2397, -0.1282], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0009, -0.0003, -0.0008, -0.0002, -0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0017,  0.0007, -0.0012,  0.0013, -0.0061], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0085,  0.0116, -0.0404, -0.2128, -0.0753], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0004,  0.0331, -0.1375, -0.4331, -0.1931], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0004,  0.0331, -0.1375, -0.4331, -0.1931], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0001, -0.0008,  0.0357, -0.0394,  0.0015], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2380], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.0496], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0009, -0.0044,  0.1664, -0.1030,  0.0060], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0009, -0.0044,  0.1664, -0.1030,  0.0060], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.1494,  0.2057, -1.0944,  0.9439, -0.1562], grad_fn=<SliceBackward0>)
  [Layer 25] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 25] Output sample values after mixer: tensor([ 1.1494,  0.2057, -1.0944,  0.9439, -0.1562], grad_fn=<SliceBackward0>)
  [Layer 25] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 25] Residual connection sample values: tensor([-1.1709,  5.8156, -3.4758,  0.9779,  2.7282], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 26/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([28.0696], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1887], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1057,  0.4888, -0.3072,  0.1060,  0.2355], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.8393,  0.5851, -0.0465, -0.3253,  0.3574], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.8393,  0.5851, -0.0465, -0.3253,  0.3574], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.1091, -0.2470,  0.9967,  1.6720, -0.3708], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.3801, 1.8349, 1.2554, 3.2995, 1.9308], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.4920, -1.0918,  0.0586, -1.1091, -1.8933], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2682, -0.0920, -0.2404,  0.4596, -0.2666], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3592, -0.1459, -0.2657,  0.3963, -0.5344], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1477, -0.0676, -0.1153,  0.2369, -0.1975], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1477, -0.0676, -0.1153,  0.2369, -0.1975], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1665, -0.1312, -0.0317,  0.0862, -0.0908], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1316, -0.2784, -0.1591,  0.1823, -0.1120], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3298, -0.0634, -0.2289, -0.1264, -0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.3793, 0.8386, 2.6790, 4.3892, 1.7675], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6345, 0.9482, 0.5416, 0.5742, 0.9019], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1477, -0.0676, -0.1153,  0.2369, -0.1975], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0339,  0.0267,  0.0065, -0.0176,  0.0185], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0408,  0.0377,  0.0011, -0.0348,  0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2870, -0.2873, -0.1680,  0.2110, -0.5508], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.8827, -0.5601, -0.6330,  1.1665, -1.3472], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.8827, -0.5601, -0.6330,  1.1665, -1.3472], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.2235, -0.2105,  0.0144, -0.1592, -0.2833], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([4.3063], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4819], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2550, -0.1675,  0.0151, -0.1838, -0.2409], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.2550, -0.1675,  0.0151, -0.1838, -0.2409], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3534, -1.3135,  1.2027, -0.1112,  1.3001], grad_fn=<SliceBackward0>)
  [Layer 26] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 26] Output sample values after mixer: tensor([-0.3534, -1.3135,  1.2027, -0.1112,  1.3001], grad_fn=<SliceBackward0>)
  [Layer 26] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 26] Residual connection sample values: tensor([-1.5244,  4.5020, -2.2732,  0.8667,  4.0284], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 27/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([33.8035], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1720], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1093,  0.3072, -0.1572,  0.0718,  0.2908], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0304, -0.6532,  0.5289,  0.2300,  0.8083], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0304, -0.6532,  0.5289,  0.2300,  0.8083], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.3812, -0.5171,  0.9733,  0.3115, -0.2204], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.8227, 0.5790, 1.1096, 1.5589, 0.3869], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4002,  0.9614,  0.7114, -0.3812,  1.3907], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0597, -0.1857,  0.2297, -0.1985, -0.0080], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0430, -0.2375,  0.1746, -0.3987, -0.0062], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0220, -0.1047,  0.0949, -0.1601, -0.0031], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0220, -0.1047,  0.0949, -0.1601, -0.0031], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1476, -0.0432,  0.2662,  0.0725,  0.0522], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2600, -0.0791, -0.1130, -0.1573, -0.1570], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5626, -0.0303, -0.7559, -1.1613, -0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1671, 0.0782, 0.0280, 0.3224, 0.0463], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9103, 0.9976, 0.9791, 0.6877, 0.9981], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0220, -0.1047,  0.0949, -0.1601, -0.0031], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0005, -0.0002,  0.0010,  0.0003,  0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0023, -0.0111, -0.0036, -0.0068, -0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0463, -0.0180,  0.0256, -0.0711,  0.0305], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0026, -0.2262,  0.2144, -0.3895,  0.0244], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0026, -0.2262,  0.2144, -0.3895,  0.0244], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 3.8785e-05,  5.0581e-02,  7.1346e-02, -4.9916e-02,  1.3631e-02],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7133], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1840], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 1.0548e-04,  1.0826e-01,  2.2026e-01, -3.9651e-02,  5.3744e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 1.0548e-04,  1.0826e-01,  2.2026e-01, -3.9651e-02,  5.3744e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4340,  2.1022,  0.6546,  0.4776, -1.8028], grad_fn=<SliceBackward0>)
  [Layer 27] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 27] Output sample values after mixer: tensor([-0.4340,  2.1022,  0.6546,  0.4776, -1.8028], grad_fn=<SliceBackward0>)
  [Layer 27] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 27] Residual connection sample values: tensor([-1.9584,  6.6042, -1.6186,  1.3443,  2.2256], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 28/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([37.2456], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1639], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1145,  0.3715, -0.0930,  0.0919,  0.1260], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3039, -0.7305, -0.1097, -0.1897,  0.3644], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3039, -0.7305, -0.1097, -0.1897,  0.3644], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.2641,  0.9191,  0.0229,  0.1796,  0.0960], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.4087, 0.6787, 0.8584, 0.9900, 0.4836], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8534,  0.5593,  0.0029, -1.2641, -1.7144], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.3533,  0.2192, -0.0402, -0.0335, -0.0307], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2253,  0.1298, -0.1693, -0.1236, -0.0963], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1253,  0.0691, -0.0775, -0.0580, -0.0458], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1253,  0.0691, -0.0775, -0.0580, -0.0458], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0647, -0.0272,  0.0448,  0.0522, -0.2587], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0743,  0.1110,  0.0435, -0.2593, -0.0102], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5442, -0.1843, -0.1064, -0.1124, -0.2523], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2595, 0.8353, 1.5082, 1.5208, 0.6933], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8683, 0.8573, 0.8517, 0.8429, 0.8395], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1253,  0.0691, -0.0775, -0.0580, -0.0458], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0021, -0.0009,  0.0015,  0.0017, -0.0084], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0145, -0.0047,  0.0051,  0.0004,  0.0059], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0114, -0.0306, -0.0178,  0.0071, -0.0113], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2224,  0.0983, -0.1624, -0.1011, -0.0968], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2224,  0.0983, -0.1624, -0.1011, -0.0968], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0287, -0.0233,  0.0084,  0.0087, -0.0208], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1553], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.5377], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1485, -0.1135,  0.0391,  0.0465, -0.1299], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1485, -0.1135,  0.0391,  0.0465, -0.1299], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.9801,  2.8171, -1.7684,  4.9894, -0.1424], grad_fn=<SliceBackward0>)
  [Layer 28] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 28] Output sample values after mixer: tensor([-1.9801,  2.8171, -1.7684,  4.9894, -0.1424], grad_fn=<SliceBackward0>)
  [Layer 28] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 28] Residual connection sample values: tensor([-3.9385,  9.4213, -3.3869,  6.3337,  2.0832], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 29/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([51.9893], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1387], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2404,  0.5678, -0.2084,  0.4778,  0.1277], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1562, -0.9253,  0.2596, -1.3032, -0.3875], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1562, -0.9253,  0.2596, -1.3032, -0.3875], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([0.1798, 0.2175, 0.1983, 0.2160, 0.2771], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.0245, 1.4389, 2.1591, 0.9993, 1.8800], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4068,  0.7908,  0.2165,  0.1798,  0.3650], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0411, -0.0901, -0.1507, -0.0284,  0.0491], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0551, -0.1657, -0.2890,  0.3383,  1.5491], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0283, -0.0760, -0.1238,  0.1975,  1.2776], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0283, -0.0760, -0.1238,  0.1975,  1.2776], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0328, -0.0306, -0.1105, -0.0640,  0.0122], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1507, -0.0481, -0.0378, -0.0230, -0.1406], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6542, -0.1369, -1.4589, -0.3682, -0.1218], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2163, 0.2145, 0.6203, 0.2588, 1.1684], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8680, 0.9711, 0.4046, 0.9091, 0.8674], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0283, -0.0760, -0.1238,  0.1975,  1.2776], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-2.0103e-04, -1.8767e-04, -6.7679e-04, -3.9215e-04,  7.4781e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0080, -0.0007, -0.0002, -0.0028,  0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0031, -0.0259, -0.0339,  0.0477,  0.3500], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0507, -0.1537, -0.2419,  0.3797,  2.4977], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0507, -0.1537, -0.2419,  0.3797,  2.4977], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0043,  0.0404, -0.0355, -0.1057, -0.3913], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2065], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.2006], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0307,  0.2268, -0.1488, -0.5447, -0.3124], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0307,  0.2268, -0.1488, -0.5447, -0.3124], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.2573, -0.8976,  0.1715, -1.5317, -0.0371], grad_fn=<SliceBackward0>)
  [Layer 29] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 29] Output sample values after mixer: tensor([ 1.2573, -0.8976,  0.1715, -1.5317, -0.0371], grad_fn=<SliceBackward0>)
  [Layer 29] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 29] Residual connection sample values: tensor([-2.6811,  8.5238, -3.2155,  4.8021,  2.0461], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 30/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([60.1404], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1289], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1410,  0.4280, -0.1646,  0.2884,  0.1046], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.6257,  0.1375,  0.1970, -1.0593,  1.3844], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.6257,  0.1375,  0.1970, -1.0593,  1.3844], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.0343,  1.0553, -1.5596, -0.7383,  0.3600], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.5214, 1.7803, 1.3020, 1.7604, 2.0097], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.4507, -1.0557, -0.9705,  1.0343, -0.7599], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1836, -0.0308,  0.4661,  0.2669,  0.3498], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2264, -0.0726,  1.0413,  0.3163,  0.2573], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1005, -0.0350,  0.7696,  0.1830,  0.1451], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1005, -0.0350,  0.7696,  0.1830,  0.1451], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0529,  0.1392,  0.0166,  0.0510, -0.2134], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1476, -0.1543, -0.2341, -0.1622, -0.2563], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2038, -0.3668, -0.2078, -0.0952, -0.4265], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.4259, 0.9517, 1.1149, 0.4743, 1.1542], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7479, 0.7053, 0.7932, 0.9558, 0.6112], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1005, -0.0350,  0.7696,  0.1830,  0.1451], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0076, -0.0199, -0.0024, -0.0073,  0.0306], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0026, -0.0372, -0.0037, -0.0244,  0.0847], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1149, -0.0410,  1.1133,  0.2314, -0.1229], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1315, -0.0467,  1.2404,  0.2616, -0.0989], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1315, -0.0467,  1.2404,  0.2616, -0.0989], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1787, -0.0034,  0.1342, -0.0714, -0.1095], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3805], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.6212], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.7252, -0.0154,  0.3637, -0.3210, -0.1807], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.7252, -0.0154,  0.3637, -0.3210, -0.1807], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.8189, -1.7357, -0.5284, -3.2770, -2.5828], grad_fn=<SliceBackward0>)
  [Layer 30] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 30] Output sample values after mixer: tensor([-1.8189, -1.7357, -0.5284, -3.2770, -2.5828], grad_fn=<SliceBackward0>)
  [Layer 30] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 30] Residual connection sample values: tensor([-4.5000,  6.7880, -3.7439,  1.5250, -0.5367], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 31/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([70.0362], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1195], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1485,  0.2271, -0.1241,  0.0570, -0.0177], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2136,  0.0146,  0.1332, -0.0951, -0.1178], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2136,  0.0146,  0.1332, -0.0951, -0.1178], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.1196,  0.2736,  0.0642,  0.0642, -1.1741], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-2.2139, -0.6939,  2.0481,  1.7485, -0.6310], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.7817, -0.2069, -0.2253, -1.1196,  0.8216], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2098, -0.0630, -0.0115, -0.0430, -0.9505], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2068, -0.0281, -0.0220, -0.0611, -1.0108], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1141, -0.0138, -0.0109, -0.0296, -0.2697], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1141, -0.0138, -0.0109, -0.0296, -0.2697], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0831,  0.0268, -0.0929, -0.0448,  0.0807], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1145, -0.0284, -0.0449, -0.1468, -0.0370], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-9.5766e-03, -1.0642e-02, -2.6350e+01, -6.4468e+02, -1.6547e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0051, 0.0296, 2.6702, 2.8427, 0.0339], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9995e-01, 9.9969e-01, 2.7734e-31, 0.0000e+00, 9.9944e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1141, -0.0138, -0.0109, -0.0296, -0.2697], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-4.8588e-05,  1.5679e-05, -5.4341e-05, -2.6235e-05,  4.7217e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0160, -0.0105,  0.0078,  0.0154,  0.0059], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0068, -0.0167, -0.0039, -0.0293, -0.0476], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0212, -0.0150, -0.0026, -0.0255, -0.0137], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0212, -0.0150, -0.0026, -0.0255, -0.0137], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0025, -0.0001, -0.0002,  0.0012,  0.0008], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0310], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([5.6783], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0565, -0.0023, -0.0038,  0.1060,  0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0565, -0.0023, -0.0038,  0.1060,  0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1207,  2.1123, -0.1095, -1.7686, -0.8229], grad_fn=<SliceBackward0>)
  [Layer 31] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 31] Output sample values after mixer: tensor([ 0.1207,  2.1123, -0.1095, -1.7686, -0.8229], grad_fn=<SliceBackward0>)
  [Layer 31] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 31] Residual connection sample values: tensor([-4.3793,  8.9004, -3.8534, -0.2436, -1.3596], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 32/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([89.1528], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1059], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2168,  0.4313, -0.1854, -0.0141, -0.0683], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5968, -2.2294,  1.6843,  0.7113,  1.0423], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5968, -2.2294,  1.6843,  0.7113,  1.0423], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.0596,  0.3462,  0.0548, -0.9357,  0.6010], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.7264, 2.3983, 2.1529, 2.6913, 0.8951], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1900, -1.0760, -0.3789, -0.0596,  0.5137], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1694,  0.0657,  0.2008,  0.4376, -0.0645], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1557, -0.3023,  0.1987,  0.4141, -0.0768], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0839, -0.1285,  0.1092,  0.2493, -0.0369], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0839, -0.1285,  0.1092,  0.2493, -0.0369], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0868,  0.1267,  0.0062, -0.0233, -0.0443], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2716, -0.2225, -0.2774, -0.2644, -0.0383], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0662, -0.0811, -0.5879, -0.0956, -0.5448], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.3015, 3.0764, 1.7054, 3.0729, 1.1014], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8036, 0.7791, 0.3669, 0.7455, 0.5488], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0839, -0.1285,  0.1092,  0.2493, -0.0369], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0241,  0.0351,  0.0017, -0.0064, -0.0123], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0232, 0.1145, 0.1425, 0.2923, 0.1653], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.7983, -1.5325,  0.3395,  1.2180, -0.5301], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.7964, -1.5295,  0.3370,  1.2124, -0.5293], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.7964, -1.5295,  0.3370,  1.2124, -0.5293], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.3065,  0.3313,  0.4788,  0.5784, -0.4079], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([3.4983], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5347], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1845,  0.4331,  0.6239,  0.4723, -0.3752], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1845,  0.4331,  0.6239,  0.4723, -0.3752], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.6644,  2.1368, -1.3016, -0.9259,  2.9497], grad_fn=<SliceBackward0>)
  [Layer 32] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 32] Output sample values after mixer: tensor([ 0.6644,  2.1368, -1.3016, -0.9259,  2.9497], grad_fn=<SliceBackward0>)
  [Layer 32] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 32] Residual connection sample values: tensor([-3.7149, 11.0372, -5.1550, -1.1696,  1.5902], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 33/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([104.3631], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0979], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1748,  0.5072, -0.2412, -0.0578,  0.0757], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5499,  0.4906,  0.8381, -0.9454,  0.7787], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5499,  0.4906,  0.8381, -0.9454,  0.7787], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.9687,  1.3173,  0.5579, -0.6039, -0.6919], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.2038, 1.3759, 1.1008, 0.5922, 1.1710], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1889,  0.2802, -0.7093,  1.9687, -0.0816], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4839,  0.3026,  0.0881, -0.1103, -0.1471], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2137,  0.2660,  0.0747, -0.2333, -0.1815], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1182,  0.1506,  0.0388, -0.1031, -0.0825], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1182,  0.1506,  0.0388, -0.1031, -0.0825], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.2988, -0.1202, -0.1254, -0.0247, -0.0929], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0315,  0.3069,  0.1622, -0.2031, -0.0208], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-13.0444,  -1.3850,  -0.1668,  -0.2359,  -5.2550],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0463, 0.0190, 0.1581, 0.0929, 0.0266], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5469, 0.9741, 0.9740, 0.9783, 0.8696], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1182,  0.1506,  0.0388, -0.1031, -0.0825], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0016, -0.0007, -0.0007, -0.0001, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 2.2825e-03, -1.5275e-03, -3.2943e-04, -1.1093e-05,  1.4603e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0006,  0.0010,  0.0005, -0.0011, -0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1272,  0.1623,  0.0420, -0.1116, -0.0886], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1272,  0.1623,  0.0420, -0.1116, -0.0886], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0256,  0.0494,  0.0246,  0.0295, -0.0473], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0926], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.2851], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2317,  0.4336,  0.2945,  0.2971, -0.5380], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2317,  0.4336,  0.2945,  0.2971, -0.5380], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.5576,  0.9050, -1.5127, -0.9323, -2.1757], grad_fn=<SliceBackward0>)
  [Layer 33] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 33] Output sample values after mixer: tensor([ 0.5576,  0.9050, -1.5127, -0.9323, -2.1757], grad_fn=<SliceBackward0>)
  [Layer 33] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 33] Residual connection sample values: tensor([-3.1574, 11.9422, -6.6678, -2.1018, -0.5855], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 34/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([116.0138], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0928], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1245,  0.4637, -0.2733, -0.0840, -0.0236], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.0128, -1.5695, -0.2750,  0.7563, -0.4964], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.0128, -1.5695, -0.2750,  0.7563, -0.4964], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3785, -0.6896, -0.6731,  0.4341, -0.8283], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.0351, -1.6178,  0.6950, -0.6737,  1.1425], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.3540,  0.2165, -0.6319,  0.3785, -1.3992], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0612,  0.4766,  0.1716, -0.0827, -0.3195], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0178,  0.3793,  0.1376, -0.1638, -0.3935], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0090,  0.2252,  0.0735, -0.0752, -0.1585], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0090,  0.2252,  0.0735, -0.0752, -0.1585], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0137, -0.0325, -0.0373, -0.0022, -0.0776], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2781, -0.1526,  0.0630, -0.1153, -0.1747], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2225, -0.1537, -0.8169, -0.8591, -2.0730], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0127, 0.0014, 0.3547, 0.0520, 0.4711], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9972, 0.9998, 0.7484, 0.9563, 0.3766], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0090,  0.2252,  0.0735, -0.0752, -0.1585], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.5621e-06, -3.7001e-06, -4.2432e-06, -2.5093e-07, -8.8356e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0030,  0.0074,  0.0034, -0.0067,  0.0106], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0220,  0.0774,  0.0430, -0.0206, -0.0315], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0043,  0.5205,  0.1877, -0.1686, -0.3434], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0043,  0.5205,  0.1877, -0.1686, -0.3434], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0012, -0.1407, -0.0223, -0.0868,  0.0645], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2018], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.2259], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0069, -0.4681, -0.1108, -0.5101,  0.4040], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0069, -0.4681, -0.1108, -0.5101,  0.4040], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0942, -3.1903,  4.6333, -1.4540,  3.3417], grad_fn=<SliceBackward0>)
  [Layer 34] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 34] Output sample values after mixer: tensor([ 0.0942, -3.1903,  4.6333, -1.4540,  3.3417], grad_fn=<SliceBackward0>)
  [Layer 34] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 34] Residual connection sample values: tensor([-3.0631,  8.7519, -2.0344, -3.5558,  2.7562], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 35/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([146.2451], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0827], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1422,  0.4032, -0.0931, -0.1760,  0.1272], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2506, -0.7282,  0.0372,  0.3887,  4.0201], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2506, -0.7282,  0.0372,  0.3887,  4.0201], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.4899,  0.0389, -1.6558, -1.7378,  1.6300], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([3.1912, 2.7962, 0.4511, 2.5533, 2.0500], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.6062, -0.9954,  0.3614, -0.4899,  1.1062], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0929,  0.0296, -0.5174, -0.3340,  0.3821], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0414,  0.0078, -0.5448, -0.3589,  0.2699], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0211,  0.0039, -0.2000, -0.1476,  0.1530], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0211,  0.0039, -0.2000, -0.1476,  0.1530], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2652, -0.0551,  0.0607,  0.1944,  0.0381], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2212,  0.1439, -0.2731, -0.0648,  0.2489], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2054, -0.1417, -0.1071, -0.1460, -0.2581], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([4.7555, 4.9750, 1.1568, 4.8968, 2.4849], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.3766, 0.4941, 0.8835, 0.4891, 0.5266], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0211,  0.0039, -0.2000, -0.1476,  0.1530], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0267, -0.0055,  0.0061,  0.0196,  0.0038], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0117, -0.0054, -0.0089,  0.0006, -0.0206], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0592,  0.0972, -0.8440, -0.7206,  0.4914], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1145,  0.1075, -1.3677, -1.1071,  0.8921], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1145,  0.1075, -1.3677, -1.1071,  0.8921], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0126, -0.0255, -0.0259, -0.2565,  3.5231], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([7.1439], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3741], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0179, -0.0352, -0.0124, -0.5274,  4.1989], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0179, -0.0352, -0.0124, -0.5274,  4.1989], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.2710, -1.1208, -0.1489, -2.1983,  1.7681], grad_fn=<SliceBackward0>)
  [Layer 35] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 35] Output sample values after mixer: tensor([-1.2710, -1.1208, -0.1489, -2.1983,  1.7681], grad_fn=<SliceBackward0>)
  [Layer 35] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 35] Residual connection sample values: tensor([-4.3341,  7.6311, -2.1833, -5.7541,  4.5243], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 36/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([182.0103], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0741], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1606,  0.2892, -0.0814, -0.2276,  0.1718], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-3.2684,  0.0335, -1.6800, -0.4566, -0.4761], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-3.2684,  0.0335, -1.6800, -0.4566, -0.4761], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 2.9650,  2.6883,  0.0916, -0.6075, -0.9227], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.9763, 2.1148, 1.5437, 1.0192, 2.1596], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.7234, 1.8071, 0.9456, 2.9650, 1.1233], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.7942,  0.6274,  0.0250, -0.1602, -0.1405], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.7539,  0.5098, -0.0371, -0.3049, -0.1526], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2412,  0.3185, -0.0182, -0.1294, -0.0705], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2412,  0.3185, -0.0182, -0.1294, -0.0705], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1936, -0.0081,  0.0120,  0.0678, -0.2025], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1049,  0.0091, -0.2468, -0.0871, -0.0998], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.8655, -5.6378, -3.8976, -2.4260, -3.6937], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1759, 0.1338, 0.0823, 0.1061, 0.1971], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6041, 0.4703, 0.7257, 0.7730, 0.4829], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2412,  0.3185, -0.0182, -0.1294, -0.0705], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0082,  0.0003, -0.0005, -0.0029,  0.0086], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0129,  0.0019, -0.0038,  0.0041,  0.0047], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0217,  0.0535, -0.0201, -0.0395, -0.0242], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.7615,  1.0303, -0.0758, -0.4363, -0.2404], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.7615,  1.0303, -0.0758, -0.4363, -0.2404], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0913, 0.0175, 0.0200, 0.0773, 0.0439], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6459], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2443], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.2177, 0.0893, 0.0704, 0.2899, 0.1872], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.2177, 0.0893, 0.0704, 0.2899, 0.1872], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([5.6547, 2.3569, 6.9134, 2.6996, 2.2120], grad_fn=<SliceBackward0>)
  [Layer 36] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 36] Output sample values after mixer: tensor([5.6547, 2.3569, 6.9134, 2.6996, 2.2120], grad_fn=<SliceBackward0>)
  [Layer 36] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 36] Residual connection sample values: tensor([ 1.3206,  9.9880,  4.7300, -3.0545,  6.7364], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 37/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([236.3013], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0651], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0414,  0.3217,  0.1557, -0.0981,  0.2168], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.6296, -0.7034,  0.3579, -0.6403, -0.3863], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.6296, -0.7034,  0.3579, -0.6403, -0.3863], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6329,  0.6879,  0.6382, -0.8114,  1.6344], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.8702, -0.2163,  4.1248,  0.3330, -0.2188], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6262, -0.6172, -0.6494, -0.6329,  2.0893], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1898, -0.3374, -0.2846,  0.2919,  0.1043], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1121, -0.4015, -0.3692,  0.3268,  0.0206], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0592, -0.1610, -0.1509,  0.1899,  0.0104], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0592, -0.1610, -0.1509,  0.1899,  0.0104], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1946, -0.0969, -0.1837, -0.0245, -0.0907], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2696, -0.2492, -0.1287, -0.1973, -0.2755], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.8179, -31.1699, -39.0195,  -0.4619,  -0.6477],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0003, 0.0058, 0.1882, 0.0010, 0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9952e-01, 8.3387e-01, 6.4559e-04, 9.9952e-01, 9.9914e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0592, -0.1610, -0.1509,  0.1899,  0.0104], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-3.0464e-06, -1.5170e-06, -2.8756e-06, -3.8291e-07, -1.4200e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0004,  0.0003, -0.0006,  0.0009, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0003,  0.0029, -0.0093,  0.0062, -0.0043], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1087, -0.2920, -0.2857,  0.3540,  0.0148], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1087, -0.2920, -0.2857,  0.3540,  0.0148], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0447,  0.0680, -0.0602, -0.0782, -0.0023], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1980], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.2471], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.3738,  0.4115, -0.3426, -0.7046, -0.0111], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.3738,  0.4115, -0.3426, -0.7046, -0.0111], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-7.0233, -1.1835, -4.6073, -0.3430, -1.3384], grad_fn=<SliceBackward0>)
  [Layer 37] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 37] Output sample values after mixer: tensor([-7.0233, -1.1835, -4.6073, -0.3430, -1.3384], grad_fn=<SliceBackward0>)
  [Layer 37] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 37] Residual connection sample values: tensor([-5.7027,  8.8045,  0.1228, -3.3975,  5.3979], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 38/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([295.7635], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0581], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1700,  0.2625,  0.0036, -0.0982,  0.1620], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.5467, -1.7288, -0.2970, -1.5266, -0.9585], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.5467, -1.7288, -0.2970, -1.5266, -0.9585], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.8303, -0.9633,  0.9439,  0.2975,  0.4696], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.4627, 2.2750, 0.9582, 1.7892, 2.0378], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.5038,  1.7691,  2.6654,  0.8303, -0.5605], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6988,  0.0352, -0.3947, -0.2596,  0.8545], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.7012, -0.2541, -0.4848, -0.3028,  0.9475], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2325, -0.1110, -0.1848, -0.1286,  0.6828], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2325, -0.1110, -0.1848, -0.1286,  0.6828], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0300, -0.0554, -0.0063,  0.0244, -0.0226], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0939, -0.0682, -0.1839, -0.2584, -0.0467], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1704, -2.0832, -0.1351, -0.4124, -3.5315], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.8370, 0.7997, 1.2482, 1.1237, 0.5840], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7312, 0.1890, 0.8449, 0.6291, 0.1272], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2325, -0.1110, -0.1848, -0.1286,  0.6828], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0128,  0.0237,  0.0027, -0.0104,  0.0096], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0135,  0.1634,  0.0016, -0.0012, -0.0177], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3962, -0.3555, -0.2489, -0.2361,  1.0595], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.4303, -0.3718, -0.2760, -0.2550,  1.1596], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.4303, -0.3718, -0.2760, -0.2550,  1.1596], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1169,  0.0969,  0.0349,  0.0695, -0.3081], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6603], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2306], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.4530,  0.2529,  0.1009,  0.4004, -1.2277], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.4530,  0.2529,  0.1009,  0.4004, -1.2277], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.0314e+01,  1.7695e+01,  5.2426e+00, -6.5736e+00, -1.2795e-02],
       grad_fn=<SliceBackward0>)
  [Layer 38] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 38] Output sample values after mixer: tensor([-1.0314e+01,  1.7695e+01,  5.2426e+00, -6.5736e+00, -1.2795e-02],
       grad_fn=<SliceBackward0>)
  [Layer 38] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 38] Residual connection sample values: tensor([-16.0171,  26.4999,   5.3653,  -9.9711,   5.3851],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 39/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([431.9096], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0481], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2924,  0.5261,  0.1033, -0.2014,  0.1032], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0739,  0.2018,  0.3117, -1.9589, -0.8965], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0739,  0.2018,  0.3117, -1.9589, -0.8965], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6229,  1.6666,  1.9218, -0.8420, -0.1485], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.1532,  1.2240, -1.9160,  1.2085, -0.1242], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1630,  2.4910, -0.6531, -0.6229,  0.3986], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1160, -0.2912,  0.3990, -0.2029, -0.0476], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0515, -0.3519,  0.4143,  0.3347, -0.0510], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0251, -0.1453,  0.2495,  0.1951, -0.0248], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0251, -0.1453,  0.2495,  0.1951, -0.0248], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0011, -0.0305, -0.2771,  0.0254,  0.0827], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2769, -0.2166,  0.0029,  0.0482, -0.2691], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.7351e+02, -2.3790e+00, -2.6079e-03, -1.4979e+00, -6.3307e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2353, 0.7191, 0.0435, 0.3719, 0.0079], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([1.8636e-18, 1.8074e-01, 9.9989e-01, 5.7288e-01, 9.9950e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0251, -0.1453,  0.2495,  0.1951, -0.0248], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-6.6926e-06,  1.7996e-04,  1.6370e-03, -1.5017e-04, -4.8864e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-6.6926e-06,  1.7996e-04,  1.6370e-03, -1.5017e-04, -4.8864e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0019, -0.0108,  0.0185,  0.0145, -0.0018], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1155, -0.6683,  1.1473,  0.8973, -0.1142], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1155, -0.6683,  1.1473,  0.8973, -0.1142], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0044, -0.0742,  0.2064, -0.2172,  0.0297], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7609], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1464], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0237, -0.3769,  0.9919, -1.0185,  0.1678], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0237, -0.3769,  0.9919, -1.0185,  0.1678], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.5674,  0.2936, -8.4647, -5.1518,  0.9067], grad_fn=<SliceBackward0>)
  [Layer 39] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 39] Output sample values after mixer: tensor([-1.5674,  0.2936, -8.4647, -5.1518,  0.9067], grad_fn=<SliceBackward0>)
  [Layer 39] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 39] Residual connection sample values: tensor([-17.5844,  26.7935,  -3.0994, -15.1229,   6.2918],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 40/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([590.4924], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0412], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3556,  0.5782, -0.0655, -0.2928,  0.1317], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.9566,  0.8132,  0.8186, -0.7709,  1.0074], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.9566,  0.8132,  0.8186, -0.7709,  1.0074], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0038,  1.1060, -0.8782, -0.4632,  1.0621], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.9174, -0.3710, -0.5461, -2.9313, -0.2080], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.8997, -0.4070, -0.3095,  0.0038, -0.2458], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0005, -0.1977, -0.1604,  0.0380,  0.1890], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.3318, -0.2462, -0.2321,  0.0264,  0.1905], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1931, -0.1080, -0.1026,  0.0134,  0.1043], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1931, -0.1080, -0.1026,  0.0134,  0.1043], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0002,  0.1003, -0.0075, -0.0265,  0.0165], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1777, -0.2658, -0.2778, -0.1376,  0.0375], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5267, -0.6301, -0.3878, -2.7909, -0.4284], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0441, 0.0090, 0.0161, 0.0003, 0.0131], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9770, 0.9944, 0.9938, 0.9991, 0.9944], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1931, -0.1080, -0.1026,  0.0134,  0.1043], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.7406e-06,  8.5544e-04, -6.4050e-05, -2.2612e-04,  1.4042e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0027, -0.0434, -0.0068,  0.0001, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0876, -0.0506, -0.0555, -0.0167,  0.0515], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.5658, -0.3180, -0.3096,  0.0164,  0.3097], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.5658, -0.3180, -0.3096,  0.0164,  0.3097], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1502, -0.1792, -0.1759, -0.0040,  0.2285], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2882], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.8628], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.8974, -1.2671, -1.2664, -0.0228,  2.1418], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.8974, -1.2671, -1.2664, -0.0228,  2.1418], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.9277,  0.6713, -7.9600,  0.1760, -3.6209], grad_fn=<SliceBackward0>)
  [Layer 40] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 40] Output sample values after mixer: tensor([ 1.9277,  0.6713, -7.9600,  0.1760, -3.6209], grad_fn=<SliceBackward0>)
  [Layer 40] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 40] Residual connection sample values: tensor([-15.6567,  27.4648, -11.0594, -14.9469,   2.6709],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 41/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([801.3866], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0353], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1932,  0.3624, -0.1408, -0.1823,  0.0330], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.4562, -1.5655, -0.5802,  1.1806,  0.2242], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.4562, -1.5655, -0.5802,  1.1806,  0.2242], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.0690,  1.2318, -0.1682,  1.2909,  0.6061], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.2523,  0.7676,  0.5654,  0.3162, -0.4362], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2174, -0.6705, -1.1127, -1.0690,  0.0093], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2737,  0.0114, -0.0385, -0.2239, -0.1344], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3054,  0.1337, -0.0385, -0.3166, -0.1440], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1296,  0.0713, -0.0189, -0.1335, -0.0668], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1296,  0.0713, -0.0189, -0.1335, -0.0668], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0789,  0.0829,  0.1619,  0.0095,  0.1786], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2387, -0.0331,  0.0866, -0.1970, -0.2352], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.0531, -1.1356, -0.8719, -1.5713, -1.7431], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5305, 0.4070, 0.1739, 0.1694, 0.0537], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5720, 0.6299, 0.8593, 0.7663, 0.9106], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1296,  0.0713, -0.0189, -0.1335, -0.0668], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0054, -0.0057, -0.0111, -0.0007, -0.0123], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0094, -0.0053, -0.0133, -0.0021, -0.0122], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0301,  0.0209,  0.0010, -0.0334, -0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1958,  0.1122, -0.0231, -0.2041, -0.0947], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1958,  0.1122, -0.0231, -0.2041, -0.0947], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.2313, -0.0304,  0.0048, -0.1843, -0.0118], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0236], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.5098], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-4.8194, -0.8444,  0.1156, -5.3812, -0.3198], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-4.8194, -0.8444,  0.1156, -5.3812, -0.3198], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 3.6564,  2.7527, -4.0508,  0.9771, -5.8286], grad_fn=<SliceBackward0>)
  [Layer 41] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 41] Output sample values after mixer: tensor([ 3.6564,  2.7527, -4.0508,  0.9771, -5.8286], grad_fn=<SliceBackward0>)
  [Layer 41] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 41] Residual connection sample values: tensor([-12.0003,  30.2174, -15.1102, -13.9699,  -3.1577],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 42/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([950.6903], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0324], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1402,  0.3792, -0.1887, -0.1629, -0.0388], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1700,  1.0208, -0.8364, -0.5424,  0.8144], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1700,  1.0208, -0.8364, -0.5424,  0.8144], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2633,  0.5278, -0.4274, -0.2680,  0.1329], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.3078, -0.7445,  2.8772,  0.1724,  1.3305], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1302,  0.8538,  0.7887,  0.2633,  0.1824], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0615,  0.1099,  0.0953,  0.0541,  0.0417], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0824,  0.0741,  0.0999,  0.0504, -0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0395,  0.0384,  0.0525,  0.0258, -0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0395,  0.0384,  0.0525,  0.0258, -0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0065, -0.0796,  0.0439, -0.0020,  0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0961, -0.2259, -0.0326, -0.1190, -0.2458], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.2458, -1.7474, -3.3797, -1.2264, -1.3705], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3391, 0.0640, 1.2423, 0.0246, 0.2658], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4669, 0.8941, 0.0150, 0.9702, 0.6947], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0395,  0.0384,  0.0525,  0.0258, -0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-8.7630e-05,  1.0662e-03, -5.8817e-04,  2.7019e-05, -3.3564e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 1.1675e-03,  1.5377e-03,  9.8140e-04,  2.8121e-04, -5.1319e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0070,  0.0061,  0.0094,  0.0040,  0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0611,  0.0586,  0.0811,  0.0393, -0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0611,  0.0586,  0.0811,  0.0393, -0.0026], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0056,  0.0440, -0.0205, -0.0078, -0.0015], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0283], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([5.9388], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1310,  0.9847, -0.4725, -0.1830, -0.0232], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1310,  0.9847, -0.4725, -0.1830, -0.0232], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-4.7756, -5.1136, -0.2899,  1.3144,  5.8683], grad_fn=<SliceBackward0>)
  [Layer 42] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 42] Output sample values after mixer: tensor([-4.7756, -5.1136, -0.2899,  1.3144,  5.8683], grad_fn=<SliceBackward0>)
  [Layer 42] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 42] Residual connection sample values: tensor([-16.7760,  25.1038, -15.4001, -12.6555,   2.7106],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 43/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1103.6746], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0301], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1784,  0.2922, -0.1716, -0.1345,  0.0293], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.7887,  2.7902, -0.1281, -0.6503,  0.6793], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.7887,  2.7902, -0.1281, -0.6503,  0.6793], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1455, -0.0715,  0.1365,  0.1394, -0.1990], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.3462,  0.8887, -2.2711,  0.7009, -0.2721], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2408, -0.4484, -0.0125, -0.1455,  0.0175], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0288,  0.0106, -0.0291,  0.0260, -0.0374], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0434, -0.0436, -0.0571, -0.0218, -0.0458], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0212, -0.0213, -0.0277, -0.0108, -0.0224], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0212, -0.0213, -0.0277, -0.0108, -0.0224], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0308, -0.0767,  0.1663, -0.2770,  0.1405], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2121,  0.0885,  0.2496, -0.2768,  0.0249], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.7046, -2.6553, -8.2110, -2.2382, -4.0926], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0860, 0.1830, 0.0066, 0.6191, 0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7271, 0.6152, 0.9469, 0.2502, 0.9960], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0212, -0.0213, -0.0277, -0.0108, -0.0224], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.6301e-05,  1.3996e-04, -3.0355e-04,  5.0573e-04, -2.5652e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.3281e-04, -7.0955e-05, -4.6765e-04,  1.2544e-03, -1.0365e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-6.6242e-04, -3.4661e-03, -1.9014e-03,  4.9675e-04, -4.7997e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0357, -0.0387, -0.0477, -0.0173, -0.0369], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0357, -0.0387, -0.0477, -0.0173, -0.0369], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0088, -0.1016,  0.0029,  0.0039, -0.0166], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0145], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([8.3104], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1889, -2.9258,  0.0658,  0.0894, -0.3993], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1889, -2.9258,  0.0658,  0.0894, -0.3993], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.5342,  5.0509,  2.5248, -2.9001, -6.0930], grad_fn=<SliceBackward0>)
  [Layer 43] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 43] Output sample values after mixer: tensor([-1.5342,  5.0509,  2.5248, -2.9001, -6.0930], grad_fn=<SliceBackward0>)
  [Layer 43] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 43] Residual connection sample values: tensor([-18.3102,  30.1548, -12.8753, -15.5556,  -3.3824],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 44/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1274.0085], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0280], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1836,  0.3127, -0.1339, -0.1525, -0.0343], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.5071, -0.3907, -0.3734,  0.2024,  0.2600], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.5071, -0.3907, -0.3734,  0.2024,  0.2600], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5637, -0.0423, -0.3960, -0.1316,  1.0312], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.4642, -0.4762,  0.4619,  0.2079,  0.6196], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4715,  0.2910, -0.7956, -0.5637,  0.0659], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1151,  0.0109, -0.0649,  0.0250,  0.1912], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0936, -0.0462, -0.0937,  0.0118,  0.1978], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0446, -0.0226, -0.0446,  0.0059,  0.1087], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0446, -0.0226, -0.0446,  0.0059,  0.1087], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0745, -0.2670, -0.2668,  0.1125,  0.0982], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0383, -0.2519, -0.1545, -0.0278, -0.0144], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-4.6876, -0.9753, -0.8255, -1.2938, -0.4953], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0636, 0.0278, 0.0387, 0.0556, 0.0144], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7424, 0.9732, 0.9686, 0.9306, 0.9929], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0446, -0.0226, -0.0446,  0.0059,  0.1087], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0002,  0.0008,  0.0008, -0.0003, -0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-8.1125e-04,  1.6749e-03,  1.7559e-03,  4.9722e-05, -1.2301e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0020,  0.0009, -0.0013,  0.0008,  0.0018], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0796, -0.0383, -0.0789,  0.0111,  0.1906], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0796, -0.0383, -0.0789,  0.0111,  0.1906], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0982,  0.0060,  0.0120,  0.0012,  0.0280], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0183], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([7.3911], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-2.3384,  0.1318,  0.3320,  0.0294,  0.6520], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-2.3384,  0.1318,  0.3320,  0.0294,  0.6520], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-5.4312, 12.4573,  3.8184, -1.9926,  4.6390], grad_fn=<SliceBackward0>)
  [Layer 44] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 44] Output sample values after mixer: tensor([-5.4312, 12.4573,  3.8184, -1.9926,  4.6390], grad_fn=<SliceBackward0>)
  [Layer 44] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 44] Residual connection sample values: tensor([-23.7413,  42.6121,  -9.0569, -17.5482,   1.2566],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 45/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1378.2649], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0269], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2745,  0.5319, -0.1100, -0.2036,  0.0147], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0066, -2.1430, -0.8470, -0.5235, -1.7690], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0066, -2.1430, -0.8470, -0.5235, -1.7690], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2402,  1.3189, -0.6050, -0.0995,  0.0739], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.1579, -0.7230,  0.3497, -0.2735,  0.9497], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.3554, -0.1891,  0.3072,  0.2402,  0.2691], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0414,  0.1490, -0.1166,  0.0177,  0.0073], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0357,  0.4070, -0.1389, -0.0383, -0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0182,  0.2444, -0.0646, -0.0188, -0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0182,  0.2444, -0.0646, -0.0188, -0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1570,  0.0995, -0.0771, -0.1627, -0.1081], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1959, -0.2599, -0.2020, -0.0907, -0.2668], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3039e+00, -3.9385e-02, -6.8874e+00, -8.0559e-01, -1.9935e+03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0026, 0.0090, 0.0109, 0.0005, 0.0487], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9662e-01, 9.9964e-01, 9.2741e-01, 9.9961e-01, 6.8243e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0182,  0.2444, -0.0646, -0.0188, -0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-7.4175e-06,  4.7028e-06, -3.6437e-06, -7.6876e-06, -5.1097e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0017, 0.0010, 0.0012, 0.0002, 0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0015,  0.0297, -0.0067, -0.0096,  0.0040], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 4.5654e-02,  6.6389e-01, -1.7440e-01, -5.8372e-02, -4.5304e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 4.5654e-02,  6.6389e-01, -1.7440e-01, -5.8372e-02, -4.5304e-04],
       grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-1.5083e-04, -1.4936e-01,  4.4325e-02,  1.1369e-02,  1.1674e-04],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0981], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.1918], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0019, -1.3874,  0.4916,  0.1194,  0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0019, -1.3874,  0.4916,  0.1194,  0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ -1.8778,  -3.5888,  -3.8944,  -0.3059, -11.1609],
       grad_fn=<SliceBackward0>)
  [Layer 45] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 45] Output sample values after mixer: tensor([ -1.8778,  -3.5888,  -3.8944,  -0.3059, -11.1609],
       grad_fn=<SliceBackward0>)
  [Layer 45] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 45] Residual connection sample values: tensor([-25.6191,  39.0233, -12.9513, -17.8541,  -9.9044],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 46/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1561.5247], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0253], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2642,  0.4328, -0.1407, -0.1874, -0.1011], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.0162, -0.9957, -0.9856, -0.5567, -0.6091], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.0162, -0.9957, -0.9856, -0.5567, -0.6091], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.2188, -1.1098,  1.0939,  0.2707,  0.3200], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.2068, -0.4349, -1.3684, -0.4146,  0.3678], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.3296, 1.3961, 0.3865, 1.2188, 1.4446], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0297,  0.2049,  0.2132, -0.0470, -0.0514], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0852,  0.1676,  0.4161, -0.0425, -0.0566], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0444,  0.0908,  0.2507, -0.0208, -0.0275], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0444,  0.0908,  0.2507, -0.0208, -0.0275], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2112, -0.0139, -0.0230,  0.0631, -0.0828], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0806, -0.0642, -0.1520, -0.0492,  0.0417], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.4426,  -0.9830, -10.1590,  -1.3638,  -1.7559],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0071, 0.0090, 0.0003, 0.0086, 0.0157], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9897, 0.9911, 0.9972, 0.9883, 0.9729], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0444,  0.0908,  0.2507, -0.0208, -0.0275], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-6.7043e-05, -4.4000e-06, -7.2901e-06,  2.0014e-05, -2.6289e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.5310e-03,  3.0699e-04, -5.0220e-05,  4.2138e-04, -8.2466e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0002, -0.0008,  0.0011,  0.0005, -0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0542,  0.1104,  0.3082, -0.0250, -0.0339], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0542,  0.1104,  0.3082, -0.0250, -0.0339], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0146, -0.0297, -0.0826,  0.0051,  0.0073], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0159], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([7.9251], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.5155, -0.9716, -2.3065,  0.1403,  0.2010], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.5155, -0.9716, -2.3065,  0.1403,  0.2010], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.2294,  7.0371, -0.4779, -6.6382, -9.9278], grad_fn=<SliceBackward0>)
  [Layer 46] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 46] Output sample values after mixer: tensor([ 2.2294,  7.0371, -0.4779, -6.6382, -9.9278], grad_fn=<SliceBackward0>)
  [Layer 46] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 46] Residual connection sample values: tensor([-23.3897,  46.0604, -13.4292, -24.4923, -19.8322],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 47/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1737.4417], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0240], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2056,  0.4222, -0.1206, -0.2033, -0.1745], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4942,  0.3263, -0.7181, -1.1286, -0.4262], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4942,  0.3263, -0.7181, -1.1286, -0.4262], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2363,  0.2168,  1.4038, -0.7600, -0.4658], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.3174, -0.3675,  0.2160, -1.3760, -0.1303], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1793, -0.7106,  0.2697, -0.2363,  0.4096], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0477,  0.0401,  0.2712,  0.1374, -0.0802], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0348,  0.0552,  0.2701,  0.1442, -0.0821], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0177,  0.0284,  0.1532,  0.0773, -0.0394], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0177,  0.0284,  0.1532,  0.0773, -0.0394], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0316,  0.0005,  0.0468, -0.0940, -0.2733], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2775,  0.0768,  0.1722, -0.2651, -0.2276], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-5.7667e+01, -2.2024e+00, -3.8371e+00, -4.6046e-02, -2.0700e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0631, 0.0031, 0.0161, 0.0045, 0.0036], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.0263, 0.9932, 0.9403, 0.9998, 0.9926], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0177,  0.0284,  0.1532,  0.0773, -0.0394], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 3.5238e-05,  5.7463e-07,  5.2173e-05, -1.0490e-04, -3.0495e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 4.5145e-05,  2.8243e-07,  5.1458e-05, -1.0616e-04, -3.1427e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0005,  0.0008,  0.0042,  0.0021, -0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0284,  0.0455,  0.2456,  0.1239, -0.0632], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0284,  0.0455,  0.2456,  0.1239, -0.0632], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0053,  0.0086, -0.0578, -0.0342,  0.0106], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0132], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([8.6978], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1576,  0.2833, -1.7405, -1.4738,  0.3700], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1576,  0.2833, -1.7405, -1.4738,  0.3700], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-10.6463,  31.9897,  -1.0777,   2.1116,   2.0298],
       grad_fn=<SliceBackward0>)
  [Layer 47] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 47] Output sample values after mixer: tensor([-10.6463,  31.9897,  -1.0777,   2.1116,   2.0298],
       grad_fn=<SliceBackward0>)
  [Layer 47] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 47] Residual connection sample values: tensor([-34.0361,  78.0500, -14.5069, -22.3807, -17.8023],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 48/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2183.0996], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0214], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2659,  0.6578, -0.1208, -0.1705, -0.1439], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.9292, -1.7141, -0.6680, -0.6820,  0.9034], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.9292, -1.7141, -0.6680, -0.6820,  0.9034], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2116,  0.9581, -0.2415, -0.8020, -0.1960], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.2675, -3.6752, -0.9548,  0.5067,  0.4671], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.5801,  0.2603,  0.5810, -0.2116,  1.1265], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0287,  0.1508, -0.0304, -0.0939, -0.0323], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0326,  0.1203, -0.0425, -0.1740, -0.1146], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0166,  0.0638, -0.0208, -0.0795, -0.0540], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0166,  0.0638, -0.0208, -0.0795, -0.0540], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0332,  0.2225, -0.2665, -0.1090, -0.0064], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0569, -0.0749, -0.2768, -0.0140, -0.0108], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.7304,  -7.3891,  -3.3797,  -1.8028, -17.7601],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.2469e-03, 5.4465e-06, 2.4715e-03, 3.1849e-02, 1.4746e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9944, 1.0000, 0.9917, 0.9442, 0.0729], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0166,  0.0638, -0.0208, -0.0795, -0.0540], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.7850e-06,  1.1975e-05, -1.4344e-05, -5.8680e-06, -3.4368e-07],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.7659e-04,  5.0833e-04,  8.4273e-04, -2.2637e-04, -2.2092e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0006,  0.0010, -0.0011, -0.0049, -0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0230,  0.0917, -0.0306, -0.1179, -0.0802], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0230,  0.0917, -0.0306, -0.1179, -0.0802], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0061, -0.0240,  0.0069,  0.0270, -0.0515], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0056], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([13.3619], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2870, -1.2739,  0.3486,  1.1941, -3.1047], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2870, -1.2739,  0.3486,  1.1941, -3.1047], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-18.5490,  47.0027,   0.3391,  14.3131,  -1.8224],
       grad_fn=<SliceBackward0>)
  [Layer 48] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 48] Output sample values after mixer: tensor([-18.5490,  47.0027,   0.3391,  14.3131,  -1.8224],
       grad_fn=<SliceBackward0>)
  [Layer 48] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 48] Residual connection sample values: tensor([-52.5851, 125.0527, -14.1678,  -8.0676, -19.6247],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3783.2163], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0163], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.8750,  3.0060, -0.2697, -0.1212, -0.3359], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Final backbone norm output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Final backbone norm output sample values: tensor([-0.8750,  3.0060, -0.2697, -0.1212, -0.3359], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Logits shape: torch.Size([1, 1, 50288])
[Mamba2LMHeadModel] Logits sample values: tensor([-51.9066, -58.1313, -51.4364, -54.7587, -54.2394],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Forward pass input_ids shape: torch.Size([1, 1])
[Mamba2LMHeadModel] input_ids sample values: tensor([253])
[Mamba2LMHeadModel] Embedding output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Embedding sample values: tensor([-0.1349, -0.0366, -0.2664, -0.0213,  0.2356], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 1/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0317], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([5.6186], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1819, -0.0628, -0.3939, -0.0246,  0.2975], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2101,  0.8613,  0.3215,  0.2665, -0.1894], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2101,  0.8613,  0.3215,  0.2665, -0.1894], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.6464,  3.4875,  0.7014, -0.7221,  1.2974], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.4149,  0.0916,  0.1986,  0.2136, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5399,  0.0157,  0.7267,  0.6464, -0.4055], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0820, -0.0040, -0.1121, -0.0154,  0.0508], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1245, -0.0116,  0.0006, -0.2249, -0.1464], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0661, -0.0058,  0.0003, -0.0999, -0.0678], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0661, -0.0058,  0.0003, -0.0999, -0.0678], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2474, -0.0296,  0.0080,  0.6471,  0.0023], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2499, -0.0646,  0.0859, -0.1404, -0.0462], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4384, -1.0011, -1.2129, -1.1530, -1.4844], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0832, 0.0371, 0.0296, 0.0322, 0.0210], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9642, 0.9635, 0.9647, 0.9635, 0.9692], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0661, -0.0058,  0.0003, -0.0999, -0.0678], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.3617e-03, -1.6320e-04,  4.4240e-05,  3.5619e-03,  1.2909e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0193, -0.0038, -0.0006,  0.0467, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1688,  0.0407,  0.4644, -0.7657, -0.5741], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2823,  0.0308,  0.4649, -0.9370, -0.6904], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2823,  0.0308,  0.4649, -0.9370, -0.6904], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0328,  0.0186,  0.0867, -0.1414,  0.0592], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([84.7896], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1086], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0032,  0.0015,  0.0069, -0.0093,  0.0199], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0032,  0.0015,  0.0069, -0.0093,  0.0199], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0762, -0.0927, -0.0264, -0.0139, -0.0358], grad_fn=<SliceBackward0>)
  [Layer 1] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 1] Output sample values after mixer: tensor([ 0.0762, -0.0927, -0.0264, -0.0139, -0.0358], grad_fn=<SliceBackward0>)
  [Layer 1] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 1] Residual connection sample values: tensor([-0.0587, -0.1293, -0.2928, -0.0352,  0.1998], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 2/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0519], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([4.3901], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1489, -0.2753, -0.5755, -0.0939,  0.4612], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.3264, -0.6269,  0.2598,  2.6846, -0.9460], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.3264, -0.6269,  0.2598,  2.6846, -0.9460], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.1390,  0.0078, -0.1789,  0.4840, -0.2684], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.1473,  1.4661, -0.1680,  0.9014,  1.0118], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6335,  0.6623,  1.4321,  0.1390, -0.6793], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2724,  0.0594, -0.0971,  0.6330,  0.0359], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2817,  0.0295, -0.2090,  0.4889,  0.0393], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1211,  0.0150, -0.0936,  0.3031,  0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1211,  0.0150, -0.0936,  0.3031,  0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0648,  0.0102,  0.1029, -0.0513, -0.0425], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0122, -0.1009, -0.2167, -0.1538,  0.0405], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-12.6926, -19.4296,  -0.2289,  -2.1057,  -5.0389],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0581, 0.1434, 0.0209, 0.1478, 0.1488], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4781, 0.0617, 0.9952, 0.7325, 0.4725], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1211,  0.0150, -0.0936,  0.3031,  0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 4.5627e-04, -7.2045e-05, -7.2494e-04,  3.6142e-04,  2.9939e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 4.0926e-04, -4.1633e-05, -8.1255e-04,  3.6439e-04,  2.6049e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-1.8317e-03,  4.0934e-05, -4.2941e-03,  5.9746e-04,  1.5199e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0826,  0.0100, -0.0667,  0.2026,  0.0149], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0826,  0.0100, -0.0667,  0.2026,  0.0149], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0157, -0.0022, -0.0098,  0.5092, -0.0039], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([46.5297], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1466], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0044, -0.0009, -0.0035,  0.1191, -0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0044, -0.0009, -0.0035,  0.1191, -0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0554,  0.0987,  0.0616, -0.0289, -0.1325], grad_fn=<SliceBackward0>)
  [Layer 2] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 2] Output sample values after mixer: tensor([ 0.0554,  0.0987,  0.0616, -0.0289, -0.1325], grad_fn=<SliceBackward0>)
  [Layer 2] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 2] Residual connection sample values: tensor([-0.0033, -0.0306, -0.2312, -0.0641,  0.0673], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 3/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0886], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([3.3592], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0097, -0.0750, -0.5040, -0.2001,  0.1874], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3623, -0.3169, -1.3713, -0.5629, -0.6155], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3623, -0.3169, -1.3713, -0.5629, -0.6155], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2154, -0.0261,  2.2766, -0.3525,  0.9946], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.1814, 0.4280, 0.5881, 0.2775, 0.3992], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.0180,  2.5472, -0.1130,  0.2154, -0.8149], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0372,  0.2699, -0.2168, -0.0882,  0.0537], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0077,  0.1921, -0.2679, -0.1348, -0.0131], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0038,  0.1053, -0.1161, -0.0629, -0.0065], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0038,  0.1053, -0.1161, -0.0629, -0.0065], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2641,  0.1304, -0.0938,  0.1029, -0.2732], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2664,  0.3524,  0.1251,  0.5474,  0.4345], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-20.9265,  -0.8803,  -0.6735,  -0.6461,  -0.2726],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([4.0360e-02, 7.4178e-03, 8.1102e-05, 6.9020e-03, 1.5318e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4297, 0.9935, 0.9999, 0.9956, 0.9958], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0038,  0.1053, -0.1161, -0.0629, -0.0065], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 4.0902e-05, -2.0189e-05,  1.4523e-05, -1.5934e-05,  4.2315e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-3.6803e-04, -2.7655e-04, -3.6223e-04, -7.6279e-05, -6.0178e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0014,  0.0087, -0.0095, -0.0085, -0.0081], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0013,  0.0834, -0.0919, -0.0531, -0.0127], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0013,  0.0834, -0.0919, -0.0531, -0.0127], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0002, -0.0111,  0.0255,  0.0108,  0.0027], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([57.4754], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1319], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 4.5176e-05, -2.3505e-03,  4.2517e-03,  2.0115e-03,  7.5584e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 4.5176e-05, -2.3505e-03,  4.2517e-03,  2.0115e-03,  7.5584e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1093, -0.2132, -0.1504,  0.0780,  0.0101], grad_fn=<SliceBackward0>)
  [Layer 3] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 3] Output sample values after mixer: tensor([-0.1093, -0.2132, -0.1504,  0.0780,  0.0101], grad_fn=<SliceBackward0>)
  [Layer 3] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 3] Residual connection sample values: tensor([-0.1126, -0.2439, -0.3816,  0.0139,  0.0774], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 4/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1241], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([2.8383], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1876, -0.3518, -0.5183,  0.0246,  0.1213], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.3982,  0.4982, -0.3860, -0.1082,  0.0732], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.3982,  0.4982, -0.3860, -0.1082,  0.0732], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0591, -0.3051,  0.3719, -1.4473,  0.5009], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.6632, 0.6734, 0.5376, 0.1409, 0.5133], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8082, -0.7386, -0.7260,  0.0591, -0.3944], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0948, -0.0468, -0.1134, -0.2119, -0.0327], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1168, -0.0343, -0.1538, -0.2766,  0.2263], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0618, -0.0168, -0.0710, -0.1193,  0.1259], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0618, -0.0168, -0.0710, -0.1193,  0.1259], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2763,  0.1428,  0.0797,  0.0253,  0.0790], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2762, -0.1293,  0.4484,  0.0916, -0.1303], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4907, -0.5048, -0.6491, -0.5552, -0.4657], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0854, 0.1089, 0.1389, 0.0454, 0.5026], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9589, 0.9465, 0.9138, 0.9751, 0.7913], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0618, -0.0168, -0.0710, -0.1193,  0.1259], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0015,  0.0008,  0.0004,  0.0001,  0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0331, -0.0040,  0.0003,  0.0024, -0.0009], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0195,  0.0034,  0.0022, -0.0406,  0.0656], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0605, -0.0078, -0.0449, -0.1197,  0.1491], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0605, -0.0078, -0.0449, -0.1197,  0.1491], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0678, -0.0024,  0.0070,  0.0061,  0.0057], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([21.5754], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2153], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0440, -0.0017,  0.0041,  0.0039,  0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0440, -0.0017,  0.0041,  0.0039,  0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0242,  0.0041,  0.0821,  0.1929, -0.0483], grad_fn=<SliceBackward0>)
  [Layer 4] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 4] Output sample values after mixer: tensor([-0.0242,  0.0041,  0.0821,  0.1929, -0.0483], grad_fn=<SliceBackward0>)
  [Layer 4] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 4] Residual connection sample values: tensor([-0.1369, -0.2398, -0.2995,  0.2068,  0.0291], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 5/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1608], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([2.4936], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2825, -0.4172, -0.4555,  0.4255,  0.0570], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1481,  0.2817, -0.1915,  0.2339,  0.4408], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1481,  0.2817, -0.1915,  0.2339,  0.4408], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8512,  0.0495, -0.7885,  1.2419, -0.2239], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.3121, 0.3573, 0.6981, 0.8762, 1.6023], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.4791,  0.2689,  1.0947, -0.8512,  1.2426], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0971, -0.8048, -0.4729, -0.2188,  0.0379], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0337, -1.0462, -0.4803, -0.1920,  0.0488], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0172, -0.2720, -0.1836, -0.0868,  0.0250], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0172, -0.2720, -0.1836, -0.0868,  0.0250], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1028,  0.0248, -0.2222, -0.0641,  0.0438], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0297,  0.1196, -0.2607, -0.2107, -0.2196], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0759, -0.5319, -0.0470, -1.4939, -3.6258], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4907, 0.0200, 0.0727, 0.0334, 0.0781], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9634, 0.9894, 0.9966, 0.9513, 0.7535], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0172, -0.2720, -0.1836, -0.0868,  0.0250], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0009,  0.0002, -0.0019, -0.0005,  0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.1120e-02,  9.1163e-04,  4.9341e-01,  5.1667e-02,  2.1504e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.5878, -0.7850, -0.6277, -0.2711, -0.1931], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.5637, -1.1677, -0.8861, -0.3932, -0.1579], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.5637, -1.1677, -0.8861, -0.3932, -0.1579], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0448, -0.1875,  0.0767, -0.0513, -0.0423], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([89.6152], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1056], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0016, -0.0069,  0.0058, -0.0043, -0.0038], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0016, -0.0069,  0.0058, -0.0043, -0.0038], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5252, -0.1103,  0.5046,  0.3677,  0.7082], grad_fn=<SliceBackward0>)
  [Layer 5] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 5] Output sample values after mixer: tensor([-0.5252, -0.1103,  0.5046,  0.3677,  0.7082], grad_fn=<SliceBackward0>)
  [Layer 5] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 5] Residual connection sample values: tensor([-0.6620, -0.3501,  0.2051,  0.5745,  0.7373], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 6/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6101], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2803], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.6212, -0.2714,  0.1500,  0.5168,  0.6181], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5210, -0.3836, -0.3541, -1.1480,  0.6428], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5210, -0.3836, -0.3541, -1.1480,  0.6428], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.1231, -0.9853,  0.0608, -0.4552,  0.6308], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.4830, 1.0576, 1.4980, 1.1269, 0.5329], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.1846, 0.3888, 0.9054, 1.1231, 0.1207], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1804, -0.2812, -0.1977,  0.1983,  0.2524], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2276, -0.2672, -0.1165,  0.1866,  0.3906], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1009, -0.1158, -0.0549,  0.1020,  0.2329], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1009, -0.1158, -0.0549,  0.1020,  0.2329], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0844, -0.0325, -0.2777, -0.0452, -0.0749], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2780,  0.0579, -0.2648, -0.1526, -0.0152], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5110, -0.2862, -0.5421, -0.3954, -0.5986], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5374, 0.3037, 0.3196, 0.3779, 0.1570], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7598, 0.9167, 0.8409, 0.8612, 0.9103], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1009, -0.1158, -0.0549,  0.1020,  0.2329], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0046,  0.0018,  0.0151,  0.0025,  0.0041], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0076, -0.0057,  0.0156,  0.0068,  0.0079], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0353, -0.0081, -0.0367, -0.0291,  0.0534], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1510, -0.1410, -0.0996,  0.0879,  0.3206], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1510, -0.1410, -0.0996,  0.0879,  0.3206], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0293,  0.0219,  0.0145, -0.0243,  0.1350], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([62.3356], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1267], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0108,  0.0077,  0.0049, -0.0100,  0.0405], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0108,  0.0077,  0.0049, -0.0100,  0.0405], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0443, -0.0326,  0.1623, -0.1801,  0.0315], grad_fn=<SliceBackward0>)
  [Layer 6] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 6] Output sample values after mixer: tensor([-0.0443, -0.0326,  0.1623, -0.1801,  0.0315], grad_fn=<SliceBackward0>)
  [Layer 6] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 6] Residual connection sample values: tensor([-0.7063, -0.3827,  0.3674,  0.3944,  0.7688], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 7/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7003], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1950], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.6145, -0.2704,  0.2521,  0.3463,  0.5800], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2509, -3.8247, -0.5660, -0.2223,  1.5128], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2509, -3.8247, -0.5660, -0.2223,  1.5128], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.3474, -2.3347, -1.6331,  0.1266,  0.0116], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.2109, -0.3147,  0.1010,  0.3515,  0.8003], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.8754, -3.0653, -2.6796, -1.3474, -1.2104], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.4135, -0.4547, -0.3880, -0.1283,  0.0876], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4471, -0.5260, -0.5189, -0.1198,  0.0849], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1744, -0.1954, -0.1936, -0.0563,  0.0442], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1744, -0.1954, -0.1936, -0.0563,  0.0442], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0392, -0.0059,  0.1218, -0.0224, -0.0063], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0072, -0.0387,  0.1294,  0.0150, -0.1409], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-6.5957e-02, -4.5478e+00, -5.8281e+00, -4.2034e-01, -1.9005e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5861, 0.0243, 0.0401, 0.1927, 0.3886], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9621, 0.8954, 0.7915, 0.9222, 0.9993], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1744, -0.1954, -0.1936, -0.0563,  0.0442], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0040,  0.0006, -0.0124,  0.0023,  0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.1008,  0.0104, -0.0341,  0.0041,  0.0890], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2184, -0.1544, -0.2187,  0.0712,  0.0148], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.6227, -0.6074, -0.6677, -0.0594,  0.1173], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.6227, -0.6074, -0.6677, -0.0594,  0.1173], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0684, 0.0496, 0.1369, 0.0059, 0.1455], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([15.0734], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2576], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0210, 0.0184, 0.0305, 0.0016, 0.0858], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0210, 0.0184, 0.0305, 0.0016, 0.0858], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.5011,  0.0828, -0.3441, -0.1702,  0.0905], grad_fn=<SliceBackward0>)
  [Layer 7] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 7] Output sample values after mixer: tensor([ 0.5011,  0.0828, -0.3441, -0.1702,  0.0905], grad_fn=<SliceBackward0>)
  [Layer 7] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 7] Residual connection sample values: tensor([-0.2052, -0.2999,  0.0233,  0.2242,  0.8593], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 8/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.8832], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0641], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2086, -0.2283,  0.0166,  0.2220,  0.7322], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.6055, -0.3417, -1.4975,  0.1416, -0.7580], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.6055, -0.3417, -1.4975,  0.1416, -0.7580], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-2.0933, -0.4146, -2.9492,  0.8123, -0.1179], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.5993, 3.9549, 2.1667, 1.5453, 3.2071], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1199, -3.2333, -0.8658, -2.0933, -0.5757], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.5182,  0.3183,  0.1721,  0.1116, -0.3985], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.5956,  0.3993,  0.2384,  0.0147, -0.4611], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2116,  0.2390,  0.1333,  0.0074, -0.1783], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2116,  0.2390,  0.1333,  0.0074, -0.1783], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0581,  0.6591,  0.0957, -0.0702,  0.0707], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0904, -0.0761, -0.0483, -0.0004, -0.1317], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6851, -0.1380, -0.4118, -0.2678, -0.1244], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2277, 5.2774, 1.4715, 1.1875, 4.3191], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8555, 0.4827, 0.5455, 0.7276, 0.5842], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2116,  0.2390,  0.1333,  0.0074, -0.1783], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0028, -0.0318, -0.0046,  0.0034, -0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0047, -0.0262,  0.0007, -0.0306,  0.0087], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1663, -0.0345,  0.0887, -0.0777,  0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.9635,  0.8657,  0.5910, -0.0498, -0.6624], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.9635,  0.8657,  0.5910, -0.0498, -0.6624], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.2587, -0.1229, -0.1618, -0.0038,  0.1602], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([354.2602], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0531], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0318, -0.0080, -0.0324, -0.0006,  0.0187], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0318, -0.0080, -0.0324, -0.0006,  0.0187], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1447,  0.1289, -0.1685, -0.2576, -0.0891], grad_fn=<SliceBackward0>)
  [Layer 8] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 8] Output sample values after mixer: tensor([-0.1447,  0.1289, -0.1685, -0.2576, -0.0891], grad_fn=<SliceBackward0>)
  [Layer 8] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 8] Residual connection sample values: tensor([-0.3498, -0.1711, -0.1453, -0.0334,  0.7703], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 9/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.1136], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9476], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3050, -0.1153, -0.0937, -0.0292,  0.5849], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.8886, -2.4630, -1.6535, -1.2717, -0.3447], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.8886, -2.4630, -1.6535, -1.2717, -0.3447], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 2.1009,  0.8116, -1.9520,  0.4732,  0.3479], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.8111, 3.7602, 2.8445, 3.0634, 2.9368], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.8244, 2.8223, 1.1386, 2.1009, 4.4495], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.8678, -0.1666, -0.7629, -0.0951,  0.0954], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-1.1212, -0.0760, -0.7671, -0.0884,  0.0768], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2756, -0.0366, -0.2433, -0.0423,  0.0398], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2756, -0.0366, -0.2433, -0.0423,  0.0398], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0493, -0.0273,  0.2411, -0.1282,  0.0710], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0068, -0.1030,  0.0259, -0.1432, -0.0918], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1701, -0.1135, -0.1054, -0.5864, -0.1497], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.2670, 4.5762, 4.6423, 1.7641, 3.1727], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5737, 0.5948, 0.6131, 0.3554, 0.6220], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2756, -0.0366, -0.2433, -0.0423,  0.0398], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0444,  0.0246, -0.2171,  0.1155, -0.0639], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0365, -0.0085, -0.3101,  0.3387,  0.0369], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2986,  0.1881,  0.0853, -0.0130,  0.1051], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-1.0370,  0.0901, -0.5665, -0.1263,  0.2119], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-1.0370,  0.0901, -0.5665, -0.1263,  0.2119], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.6529, -0.0174,  0.1505,  0.0352, -0.0303], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([84.5375], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1088], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0616, -0.0031,  0.0177,  0.0047, -0.0041], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0616, -0.0031,  0.0177,  0.0047, -0.0041], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0250,  0.0347, -0.0415, -0.0821,  0.4001], grad_fn=<SliceBackward0>)
  [Layer 9] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 9] Output sample values after mixer: tensor([ 0.0250,  0.0347, -0.0415, -0.0821,  0.4001], grad_fn=<SliceBackward0>)
  [Layer 9] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 9] Residual connection sample values: tensor([-0.3249, -0.1364, -0.1867, -0.1156,  1.1703], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 10/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.2940], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.8791], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2818, -0.0904, -0.1208, -0.0986,  0.8595], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-3.3466, -0.3177,  0.3420, -3.3739, -1.2056], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-3.3466, -0.3177,  0.3420, -3.3739, -1.2056], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-2.0003,  1.3544,  0.3646,  1.0312,  1.1573], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.2641, 0.4346, 0.8329, 0.8295, 0.2772], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-3.1215, -0.8985, -2.8205, -2.0003, -2.3998], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6447, -0.4645, -0.2159,  0.3309, -0.3576], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.8150, -0.4885, -0.2539,  0.9349, -0.3087], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2501, -0.1857, -0.1109,  0.6713, -0.1307], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2501, -0.1857, -0.1109,  0.6713, -0.1307], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0166,  0.4293, -0.0476, -0.2568,  0.1026], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 1.7567, -0.2219,  0.9489,  0.1727,  0.2982], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0854, -0.0771, -0.0845, -0.0547, -0.0697], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.4349, 0.1392, 0.1973, 2.0647, 0.6944], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8123, 0.9893, 0.9835, 0.8932, 0.9528], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2501, -0.1857, -0.1109,  0.6713, -0.1307], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0101, -0.2614,  0.0290,  0.1564, -0.0624], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0858, -1.0336, -0.0263,  0.4973, -0.1155], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-3.1779, -0.4250, -1.8447, 18.3295, -0.1779], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-4.3955, -1.3294, -2.3847, 21.5982, -0.8144], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-4.3955, -1.3294, -2.3847, 21.5982, -0.8144], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.5002,  0.1779, -0.4768, -2.4135,  0.2263], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1020.5576], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0313], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0095,  0.0073, -0.0213, -0.0831,  0.0094], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0095,  0.0073, -0.0213, -0.0831,  0.0094], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0311,  0.0551, -0.0644, -0.0346, -0.3296], grad_fn=<SliceBackward0>)
  [Layer 10] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 10] Output sample values after mixer: tensor([ 0.0311,  0.0551, -0.0644, -0.0346, -0.3296], grad_fn=<SliceBackward0>)
  [Layer 10] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 10] Residual connection sample values: tensor([-0.2938, -0.0813, -0.2511, -0.1501,  0.8407], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 11/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.5857], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7941], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1685, -0.0378, -0.1133, -0.0940,  0.4267], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.0576, -2.5742, -2.8956,  2.1000, -3.6548], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.0576, -2.5742, -2.8956,  2.1000, -3.6548], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.1526, -0.2364, -2.2356,  0.3202, -0.3369], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-2.2488, -0.6326, -0.2795,  0.8275,  1.9954], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.6833, -0.1301, -0.4402, -1.1526, -0.5953], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.3583,  0.0380,  0.6064, -0.0482,  0.0762], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([0.5048, 0.2292, 0.6303, 0.0593, 0.1912], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([0.3148, 0.1277, 0.4113, 0.0305, 0.1047], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([0.3148, 0.1277, 0.4113, 0.0305, 0.1047], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2590, -0.0037, -0.0858,  0.0047, -0.0884], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1795,  0.4273,  0.0506,  0.0804, -0.1250], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2593, -0.1261, -0.1036, -0.2378, -0.4305], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0239, 0.0380, 0.1166, 1.0346, 2.1709], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9938, 0.9952, 0.9880, 0.7819, 0.3927], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([0.3148, 0.1277, 0.4113, 0.0305, 0.1047], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.9515e-03, -2.7872e-05, -6.4605e-04,  3.5330e-05, -6.6624e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1862,  0.0107,  0.0190, -0.0862,  0.1131], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([0.5309, 0.5184, 0.5166, 0.2811, 0.8040], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.4619,  0.1158, -0.7807,  0.1849,  0.4738], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.4619,  0.1158, -0.7807,  0.1849,  0.4738], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.3626, -0.0211,  0.1184,  0.3459, -0.0437], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([55.7044], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1340], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0170, -0.0073,  0.0739,  0.0406, -0.0060], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0170, -0.0073,  0.0739,  0.0406, -0.0060], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5002, -0.1653,  0.1305,  0.3932,  0.2771], grad_fn=<SliceBackward0>)
  [Layer 11] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 11] Output sample values after mixer: tensor([-0.5002, -0.1653,  0.1305,  0.3932,  0.2771], grad_fn=<SliceBackward0>)
  [Layer 11] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 11] Residual connection sample values: tensor([-0.7940, -0.2466, -0.1207,  0.2431,  1.1177], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 12/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.9762], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7113], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3621, -0.0896, -0.0401,  0.1257,  0.4313], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5487, -0.1418,  0.2584, -0.9225,  0.5521], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5487, -0.1418,  0.2584, -0.9225,  0.5521], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.7531,  1.3497, -2.3031,  0.7171, -1.4171], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.4466,  0.0302,  0.0319, -0.3460,  0.0458], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.6214, -0.6272,  0.5588, -0.7531,  1.3270], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2843, -0.2513,  0.4176,  0.1726,  0.4471], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2171, -1.0858,  0.3528,  0.1284,  0.2804], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1203, -0.2741,  0.2072,  0.0683,  0.1597], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1203, -0.2741,  0.2072,  0.0683,  0.1597], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1338, -0.1227, -0.0403,  0.6537, -0.0882], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0586, -0.2776, -0.2426, -0.2766, -0.1251], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1609, -0.1475, -0.2713, -0.1155, -0.0902], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.2911, 0.5875, 1.1563, 1.3067, 0.0730], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8124, 0.9170, 0.7308, 0.8599, 0.9934], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1203, -0.2741,  0.2072,  0.0683,  0.1597], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0208, -0.0191, -0.0063,  0.1015, -0.0137], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0311,  0.0016,  0.0647, -0.1317, -0.0368], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3087, -1.3032,  0.0237,  0.0098,  3.1424], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1134, -1.7480,  0.3600,  0.1206,  3.4016], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1134, -1.7480,  0.3600,  0.1206,  3.4016], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0395,  0.1151,  0.0525, -0.0316,  1.1918], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([80.3480], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1116], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0067,  0.0114,  0.0102, -0.0116,  0.1736], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0067,  0.0114,  0.0102, -0.0116,  0.1736], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1319, -0.2449, -0.7045,  0.3683,  0.0512], grad_fn=<SliceBackward0>)
  [Layer 12] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 12] Output sample values after mixer: tensor([-0.1319, -0.2449, -0.7045,  0.3683,  0.0512], grad_fn=<SliceBackward0>)
  [Layer 12] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 12] Residual connection sample values: tensor([-0.9259, -0.4915, -0.8251,  0.6114,  1.1689], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 13/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.3750], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6489], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3248, -0.1408, -0.2250,  0.2307,  0.3678], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.8667, -0.1490, -0.6197,  1.1237, -0.8396], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.8667, -0.1490, -0.6197,  1.1237, -0.8396], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5625, -0.7664,  0.8671, -0.7219, -0.2113], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.1041, -1.0828,  0.2035, -0.3260,  0.3315], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4165,  0.2538,  0.1219,  0.5625, -1.0352], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0238,  0.1220,  0.1214, -0.0288, -0.1494], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0859,  0.1034,  0.1293, -0.0405, -0.1798], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0411,  0.0543,  0.0688, -0.0198, -0.0818], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0411,  0.0543,  0.0688, -0.0198, -0.0818], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0535, -0.1656,  0.1744,  0.0968,  0.0157], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1665, -0.0941,  0.2226,  0.0017, -0.1910], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0234, -1.0903, -0.5085, -0.6785, -0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0581, 0.0034, 0.0104, 0.0038, 0.2065], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9986, 0.9963, 0.9947, 0.9974, 0.9948], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0411,  0.0543,  0.0688, -0.0198, -0.0818], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.2781e-04,  3.9565e-04, -4.1680e-04, -2.3140e-04, -3.7471e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0926,  0.1021, -0.2830,  0.0232, -0.0586], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2052, -0.0947, -0.0693,  0.0099,  0.1545], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2005, -0.1010, -0.0772,  0.0122,  0.1639], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2005, -0.1010, -0.0772,  0.0122,  0.1639], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0514,  0.0070,  0.0167,  0.0104, -0.0415], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.1212], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6866], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0177,  0.0016,  0.0129,  0.0189, -0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0177,  0.0016,  0.0129,  0.0189, -0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1735,  0.2429, -0.1513,  0.2604,  0.4168], grad_fn=<SliceBackward0>)
  [Layer 13] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 13] Output sample values after mixer: tensor([ 0.1735,  0.2429, -0.1513,  0.2604,  0.4168], grad_fn=<SliceBackward0>)
  [Layer 13] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 13] Residual connection sample values: tensor([-0.7525, -0.2486, -0.9764,  0.8718,  1.5857], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 14/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.8662], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5907], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2112, -0.0602, -0.2313,  0.2768,  0.4169], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5250, -1.2309, -0.1546, -0.6426, -2.0844], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5250, -1.2309, -0.1546, -0.6426, -2.0844], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.3358, -0.9601, -1.1126, -0.6914, -0.4017], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.4266, -0.6674,  1.5276,  1.5555,  1.8688], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.7297, -0.3864,  0.0043, -0.3358, -1.4277], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0738, -0.1932, -0.5669,  0.1726,  0.1115], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1442, -0.2426, -0.7586,  0.1250,  0.0977], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0773, -0.1067, -0.2420,  0.0664,  0.0512], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0773, -0.1067, -0.2420,  0.0664,  0.0512], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0081,  0.0267, -0.0898,  0.0486, -0.0870], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0966, -0.0874, -0.0976, -0.0604, -0.1775], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-7.2745, -0.0385, -2.2024, -0.0138, -5.3378], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0829, 0.0311, 0.0531, 0.2170, 0.1011], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5472, 0.9988, 0.8897, 0.9970, 0.5829], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0773, -0.1067, -0.2420,  0.0664,  0.0512], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.1799e-05,  1.7121e-04, -5.7523e-04,  3.1171e-04, -5.5744e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.6570e-04,  7.8084e-05, -2.5690e-04,  5.9288e-04, -6.8310e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0053, -0.0089, -0.0242,  0.0033,  0.0052], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0661, -0.0929, -0.2147,  0.0555,  0.0455], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0661, -0.0929, -0.2147,  0.0555,  0.0455], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0129,  0.0258,  0.0153, -0.0123, -0.0105], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6582], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2326], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0375,  0.0523,  0.0213, -0.0247, -0.0268], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0375,  0.0523,  0.0213, -0.0247, -0.0268], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1335,  0.2342, -0.0977,  0.1349, -0.0541], grad_fn=<SliceBackward0>)
  [Layer 14] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 14] Output sample values after mixer: tensor([ 0.1335,  0.2342, -0.0977,  0.1349, -0.0541], grad_fn=<SliceBackward0>)
  [Layer 14] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 14] Residual connection sample values: tensor([-0.6189, -0.0145, -1.0741,  1.0067,  1.5316], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 15/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3.5469], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5310], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1999, -0.0038, -0.2866,  0.3855,  0.4618], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.2311,  1.3858,  0.4474, -0.4326, -4.6152], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.2311,  1.3858,  0.4474, -0.4326, -4.6152], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.9594, -1.1692,  0.5689,  1.1674,  0.3583], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.9228, -0.3477, -0.3421, -0.1020,  0.3494], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.1423,  0.1975, -3.2269,  0.9594,  0.6829], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0985,  0.1493,  0.2932,  0.2425,  0.1574], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4346,  0.1251,  1.6184,  0.6851,  0.1439], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1708,  0.0665,  1.3507,  0.4555,  0.0771], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1708,  0.0665,  1.3507,  0.4555,  0.0771], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0388, -0.0940,  0.0483, -0.0558, -0.1058], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0655, -0.0464, -0.0288, -0.0629, -0.0935], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.4414, -0.0592, -0.7390, -0.0051, -0.0087], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3633, 0.3403, 0.0156, 0.0438, 0.1925], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4119, 0.9800, 0.9885, 0.9998, 0.9983], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1708,  0.0665,  1.3507,  0.4555,  0.0771], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0024,  0.0058, -0.0030,  0.0035,  0.0066], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0022,  0.0072, -0.0022,  0.0037,  0.0082], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0130,  0.0054,  0.1240,  0.0453,  0.0080], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3181,  0.1241,  2.5360,  0.8587,  0.1457], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3181,  0.1241,  2.5360,  0.8587,  0.1457], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0885,  0.1375,  0.6922, -0.1462, -0.0066], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([5.5934], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4228], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0827,  0.0938,  0.1387, -0.0770, -0.0063], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0827,  0.0938,  0.1387, -0.0770, -0.0063], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1658,  0.3067, -0.0197,  0.4331,  0.3976], grad_fn=<SliceBackward0>)
  [Layer 15] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 15] Output sample values after mixer: tensor([ 0.1658,  0.3067, -0.0197,  0.4331,  0.3976], grad_fn=<SliceBackward0>)
  [Layer 15] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 15] Residual connection sample values: tensor([-0.4532,  0.2922, -1.0938,  1.4397,  1.9293], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 16/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.4274], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4753], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0972,  0.0518, -0.1807,  0.3919,  0.3913], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.1988, -0.7838, -6.4214,  0.1479, -1.4630], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.1988, -0.7838, -6.4214,  0.1479, -1.4630], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.4791,  0.0553, -1.0904, -0.6048, -0.8221], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([6.0490, 0.6562, 2.4080, 0.3440, 1.7585], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.2534, -0.1357,  0.8545,  1.4791,  0.5847], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0878, -0.0083, -0.6177, -0.2281,  0.1239], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0860,  0.0005, -0.4809, -0.2663,  0.1314], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0448,  0.0003, -0.1837, -0.1155,  0.0700], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0448,  0.0003, -0.1837, -0.1155,  0.0700], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1718, -0.0662, -0.0135,  0.0009, -0.0306], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0038, -0.0964, -0.1019, -0.2455, -0.2465], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.1349e-03, -3.0370e-03, -2.7156e+00, -4.1511e-03, -4.2926e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.5925, 0.1239, 0.2354, 0.0379, 0.0065], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9959, 0.9996, 0.5277, 0.9998, 0.9972], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0448,  0.0003, -0.1837, -0.1155,  0.0700], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0277, -0.0107, -0.0022,  0.0002, -0.0049], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0319,  0.0988,  0.0371,  0.0023, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0325,  0.0026, -0.0995, -0.0410,  0.0190], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0220,  0.0025, -0.0568, -0.0142,  0.0027], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0220,  0.0025, -0.0568, -0.0142,  0.0027], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0061, -0.0006,  0.0006, -0.0011, -0.0007], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2274], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.0969], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0056, -0.0003,  0.0012, -0.0004, -0.0008], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0056, -0.0003,  0.0012, -0.0004, -0.0008], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.6021, -0.0830,  0.0335,  0.4193,  0.1653], grad_fn=<SliceBackward0>)
  [Layer 16] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 16] Output sample values after mixer: tensor([-0.6021, -0.0830,  0.0335,  0.4193,  0.1653], grad_fn=<SliceBackward0>)
  [Layer 16] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 16] Residual connection sample values: tensor([-1.0553,  0.2092, -1.0604,  1.8590,  2.0946], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 17/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([5.0718], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4440], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3164,  0.0540, -0.2734,  0.6388,  0.5786], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-4.8233, -2.7186, -1.0607, -1.2779, -0.7723], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-4.8233, -2.7186, -1.0607, -1.2779, -0.7723], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.2513, -1.7858,  0.2550,  1.3118, -0.4245], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.3015, 1.8075, 0.6353, 2.1783, 1.3948], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2817, -1.7254,  2.4675,  1.2513,  0.2341], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4038,  0.1613, -0.0553,  0.2757, -0.1035], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.3088,  0.1834, -0.1697,  0.3101, -0.0083], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1780,  0.1001, -0.0777,  0.1789, -0.0041], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1780,  0.1001, -0.0777,  0.1789, -0.0041], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0889,  0.0860, -0.2732,  0.0120, -0.1914], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2018, -0.1618, -0.2778, -0.1052, -0.0609], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3863, -0.8773, -1.4027, -0.6828, -0.3905], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4379, 0.4236, 0.2329, 1.2578, 0.9225], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5450, 0.6896, 0.7213, 0.4237, 0.6975], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1780,  0.1001, -0.0777,  0.1789, -0.0041], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0069,  0.0067, -0.0213,  0.0009, -0.0149], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0087,  0.0148, -0.0492,  0.0062, -0.0409], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0949,  0.0596, -0.0656,  0.0596,  0.0210], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.5638,  0.3232, -0.2702,  0.5308,  0.0101], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.5638,  0.3232, -0.2702,  0.5308,  0.0101], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0217, -0.0544,  0.0737, -0.1478, -0.0025], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([14.6099], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2616], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0111, -0.0283,  0.0404, -0.0998, -0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0111, -0.0283,  0.0404, -0.0998, -0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0139,  0.2058, -0.1111, -0.2193,  1.7149], grad_fn=<SliceBackward0>)
  [Layer 17] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 17] Output sample values after mixer: tensor([-0.0139,  0.2058, -0.1111, -0.2193,  1.7149], grad_fn=<SliceBackward0>)
  [Layer 17] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 17] Residual connection sample values: tensor([-1.0692,  0.4150, -1.1715,  1.6397,  3.8094], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 18/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([6.0288], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4073], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2089,  0.0701, -0.1950,  0.3893,  0.6587], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3144, -1.0386, -1.4342, -0.2446, -0.9964], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3144, -1.0386, -1.4342, -0.2446, -0.9964], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5580, -1.9548,  0.6067, -0.0795,  0.7669], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.8106, 5.3150, 4.1016, 1.9088, 0.2690], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2538, -0.1540, -0.6895, -0.5580,  0.2653], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1183,  1.7914, -0.1553, -0.1280,  0.7151], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1277,  1.3935, -0.1440, -0.0974,  0.6629], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0679,  1.1164, -0.0668, -0.0463,  0.4374], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0679,  1.1164, -0.0668, -0.0463,  0.4374], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0188,  0.0365,  0.0039, -0.0331,  0.0155], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0778, -0.0190, -0.0465, -0.0566,  0.0410], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.3195e-03, -6.5336e+00, -1.4897e+01, -1.3796e-03, -2.0873e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2750, 6.4280, 5.5518, 0.5779, 0.1758], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9936e-01, 5.7636e-19, 1.2051e-36, 9.9920e-01, 9.9963e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0679,  1.1164, -0.0668, -0.0463,  0.4374], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 3.5172e-04,  6.8191e-04,  7.2284e-05, -6.1837e-04,  2.8975e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0060, -0.0077,  0.0931, -0.0397,  0.0124], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2407, -1.2820,  0.0606, -0.1641, -0.1991], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2461, -1.3703,  0.0659, -0.1604, -0.2337], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2461, -1.3703,  0.0659, -0.1604, -0.2337], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0327,  0.3721, -0.0182,  0.0172,  0.0628], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([26.6922], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1936], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0312,  0.0870, -0.0038,  0.0084,  0.0145], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0312,  0.0870, -0.0038,  0.0084,  0.0145], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1829, -0.6171, -0.4132,  0.0679,  0.5769], grad_fn=<SliceBackward0>)
  [Layer 18] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 18] Output sample values after mixer: tensor([ 0.1829, -0.6171, -0.4132,  0.0679,  0.5769], grad_fn=<SliceBackward0>)
  [Layer 18] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 18] Residual connection sample values: tensor([-0.8862, -0.2021, -1.5847,  1.7076,  4.3863], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 19/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([7.7809], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3585], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1894, -0.0359, -0.2843,  0.4514,  0.8323], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0331, -2.1376, -1.0263,  0.0050, -0.0694], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0331, -2.1376, -1.0263,  0.0050, -0.0694], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.0119,  0.7380,  0.3183, -0.5254, -0.6333], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.2933,  0.0738,  1.2252,  0.9531, -0.4972], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.4364, -1.2169,  1.5319, -1.0119,  0.6032], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.5011,  0.3179,  0.0516,  0.5326, -0.1551], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.4496,  0.3184,  0.0378,  0.3249, -0.1563], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.2745,  0.1843,  0.0192,  0.1886, -0.0721], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.2745,  0.1843,  0.0192,  0.1886, -0.0721], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0506, -0.0373, -0.2387, -0.0524,  0.3246], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2736, -0.0292, -0.0988, -0.0719, -0.0828], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1739, -1.5063, -1.5725, -0.1983, -0.0768], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.5022, 0.3015, 0.8197, 2.2195, 0.2375], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7701, 0.6350, 0.2756, 0.6440, 0.9819], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.2745,  0.1843,  0.0192,  0.1886, -0.0721], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0209, -0.0154, -0.0984, -0.0216,  0.1338], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0172,  0.0401, -0.0374,  0.0260,  0.0540], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([0.0252, 0.2123, 0.1415, 0.1953, 0.2245], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([0.4432, 0.4930, 0.1708, 0.4826, 0.1147], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([0.4432, 0.4930, 0.1708, 0.4826, 0.1147], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0075, -0.1112, -0.0462,  0.0012, -0.0038], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([16.9281], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2431], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0021, -0.0545, -0.0270,  0.0003, -0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0021, -0.0545, -0.0270,  0.0003, -0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.0114, -0.0666, -1.9743,  0.0588, -0.7578], grad_fn=<SliceBackward0>)
  [Layer 19] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 19] Output sample values after mixer: tensor([-1.0114, -0.0666, -1.9743,  0.0588, -0.7578], grad_fn=<SliceBackward0>)
  [Layer 19] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 19] Residual connection sample values: tensor([-1.8977, -0.2687, -3.5590,  1.7664,  3.6285], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 20/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([10.1146], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3144], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2201, -0.0285, -0.3781,  0.2507,  0.4111], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6181, -0.5111,  0.9990, -0.0334,  0.1961], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6181, -0.5111,  0.9990, -0.0334,  0.1961], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1964, -1.7616,  0.0972,  0.5933, -0.1354], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.5477,  0.9786,  0.6132,  1.5865,  0.0946], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.8534,  1.2464,  0.0231, -0.1964,  0.3280], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0223,  0.4549, -0.0040,  0.1391, -0.0567], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0368,  0.4167, -0.1835,  0.1180, -0.1032], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0181,  0.2512, -0.0834,  0.0625, -0.0490], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0181,  0.2512, -0.0834,  0.0625, -0.0490], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0878, -0.0053, -0.0863, -0.0838, -0.0302], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1530, -0.2037, -0.0890, -0.1870, -0.2078], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.0858e-01, -2.9306e+00, -5.2962e+00, -1.2326e+01, -8.1593e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0041, 0.0684, 0.1071, 0.3273, 0.0463], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9987, 0.8184, 0.5670, 0.0177, 0.9996], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0181,  0.2512, -0.0834,  0.0625, -0.0490], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([6.5158e-06, 3.9021e-07, 6.4037e-06, 6.2216e-06, 2.2393e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.1966e-04, -2.4169e-04, -1.9580e-04,  9.5411e-05, -4.6247e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0002,  0.0006, -0.0015,  0.0002,  0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0151,  0.2071, -0.0701,  0.0515, -0.0402], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0151,  0.2071, -0.0701,  0.0515, -0.0402], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0033, -0.0397, -0.0512, -0.0008, -0.0043], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0708], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.7579], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0307, -0.3216, -0.2854, -0.0077, -0.0259], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0307, -0.3216, -0.2854, -0.0077, -0.0259], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.9457, -0.1070,  0.6816, -0.1358,  0.2611], grad_fn=<SliceBackward0>)
  [Layer 20] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 20] Output sample values after mixer: tensor([-0.9457, -0.1070,  0.6816, -0.1358,  0.2611], grad_fn=<SliceBackward0>)
  [Layer 20] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 20] Residual connection sample values: tensor([-2.8433, -0.3757, -2.8774,  1.6306,  3.8896], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 21/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([11.8924], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2900], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4167, -0.0498, -0.3909,  0.2826,  0.5480], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.6383, -0.4026,  0.0028, -0.5648,  0.0463], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.6383, -0.4026,  0.0028, -0.5648,  0.0463], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.4285,  0.8622, -1.6014, -0.6783, -0.1557], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.6655,  0.7184, -0.4699, -0.8344,  0.3418], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2675,  0.5755, -0.0821, -0.4285, -0.1388], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1356,  0.2243, -0.0750,  0.1283,  0.0574], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4931,  0.1269, -0.1006,  0.0302,  0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1870,  0.0675, -0.0478,  0.0153,  0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1870,  0.0675, -0.0478,  0.0153,  0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.4331, -0.2084, -0.0524,  0.1073, -0.0508], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0301, -0.1010, -0.0011, -0.0549,  0.1907], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3228, -0.3764, -0.1595, -0.1054, -0.3757], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4421, 0.9581, 0.5747, 0.2158, 0.7155], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8670, 0.6972, 0.9124, 0.9775, 0.7643], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1870,  0.0675, -0.0478,  0.0153,  0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0358,  0.0172,  0.0043, -0.0089,  0.0042], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0178, 0.1306, 0.0297, 0.0654, 0.0147], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2468, -0.0946, -0.0716, -0.0427,  0.2688], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.6419,  0.0480, -0.1726, -0.0102,  0.2724], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.6419,  0.0480, -0.1726, -0.0102,  0.2724], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-2.6811e-01, -7.7428e-03, -2.4074e-04,  2.0947e-03,  6.4555e-03],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([3.2538], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5544], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.3095, -0.0113, -0.0004,  0.0024,  0.0064], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.3095, -0.0113, -0.0004,  0.0024,  0.0064], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2499, -0.7401, -0.5387,  0.1942, -0.0770], grad_fn=<SliceBackward0>)
  [Layer 21] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 21] Output sample values after mixer: tensor([-0.2499, -0.7401, -0.5387,  0.1942, -0.0770], grad_fn=<SliceBackward0>)
  [Layer 21] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 21] Residual connection sample values: tensor([-3.0932, -1.1158, -3.4161,  1.8248,  3.8127], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 22/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([13.5835], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2713], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4340, -0.1448, -0.4438,  0.3024,  0.5182], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1807,  0.3017,  0.4967, -3.0440,  0.4210], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1807,  0.3017,  0.4967, -3.0440,  0.4210], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.3442, -0.9945, -1.1524,  0.2815, -0.4975], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.8300, -2.7042, -1.2841,  0.4627, -0.2841], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.7266, -0.3219, -0.0115, -0.3442, -0.8233], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0023, -0.1122, -0.0309,  0.0380,  0.0752], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0059, -0.0476, -0.0183,  0.0196,  0.0759], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0029, -0.0233, -0.0090,  0.0099,  0.0394], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0029, -0.0233, -0.0090,  0.0099,  0.0394], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2557,  0.1969,  0.1172, -0.0862, -0.0127], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2459, -0.0716, -0.0668, -0.2384, -0.1814], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0709, -0.0702, -0.0699, -0.0895, -0.3897], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2504, 0.0742, 0.0334, 0.4816, 0.5817], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9824, 0.9948, 0.9977, 0.9578, 0.7972], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0029, -0.0233, -0.0090,  0.0099,  0.0394], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.8788e-04,  1.4471e-04,  8.6139e-05, -6.3350e-05, -9.3537e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0049, 0.0241, 0.0052, 0.0130, 0.0445], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0141,  0.0461, -0.1532,  0.0249,  0.0108], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0192,  0.0862, -0.1376,  0.0079, -0.0571], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0192,  0.0862, -0.1376,  0.0079, -0.0571], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0019,  0.0149, -0.0425, -0.0011, -0.0145], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([6.7060], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3862], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0019,  0.0066, -0.0434, -0.0017, -0.0141], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0019,  0.0066, -0.0434, -0.0017, -0.0141], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2987,  0.4520, -1.2222,  0.8081,  0.5505], grad_fn=<SliceBackward0>)
  [Layer 22] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 22] Output sample values after mixer: tensor([ 0.2987,  0.4520, -1.2222,  0.8081,  0.5505], grad_fn=<SliceBackward0>)
  [Layer 22] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 22] Residual connection sample values: tensor([-2.7945, -0.6638, -4.6384,  2.6328,  4.3631], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 23/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([15.4152], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2547], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3130, -0.0672, -0.4938,  0.3625,  0.4547], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4407,  1.0019, -1.7801, -0.6015, -0.2125], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4407,  1.0019, -1.7801, -0.6015, -0.2125], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0025, -1.3988,  0.3247,  0.8270,  0.1119], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.3344, -0.4314, -0.2101, -1.7538, -0.5013], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.9369,  0.7956, -1.5488,  0.0025,  0.3281], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.7781, -0.0080, -0.0646, -0.0795, -0.0987], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.8118, -0.0156, -0.1065, -0.0632, -0.1031], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2496, -0.0077, -0.0504, -0.0306, -0.0489], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2496, -0.0077, -0.0504, -0.0306, -0.0489], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([0.0715, 0.1347, 0.0275, 1.2247, 0.0302], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0240, -0.0982,  0.2990,  0.2345,  0.2181], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1232, -0.2255, -0.2420, -0.0956, -0.2396], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0195, 0.1447, 0.1722, 0.0133, 0.1096], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9976, 0.9679, 0.9592, 0.9987, 0.9741], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2496, -0.0077, -0.0504, -0.0306, -0.0489], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0003, -0.0007, -0.0001, -0.0059, -0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0267,  0.0125, -0.0013,  0.0781, -0.0115], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0489,  0.0254,  0.1379, -0.0262,  0.0105], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0605,  0.0258,  0.1403, -0.0248,  0.0127], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0605,  0.0258,  0.1403, -0.0248,  0.0127], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0162,  0.0189, -0.0360,  0.0053, -0.0012], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2997], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.8266], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0292,  0.1030, -0.3227,  0.0474, -0.0061], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0292,  0.1030, -0.3227,  0.0474, -0.0061], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.6116, -0.7035,  0.3007,  0.2278, -0.3306], grad_fn=<SliceBackward0>)
  [Layer 23] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 23] Output sample values after mixer: tensor([-0.6116, -0.7035,  0.3007,  0.2278, -0.3306], grad_fn=<SliceBackward0>)
  [Layer 23] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 23] Residual connection sample values: tensor([-3.4061, -1.3673, -4.3377,  2.8606,  4.0325], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 24/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([16.7549], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2443], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4595, -0.1638, -0.5645,  0.4429,  0.5012], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5587, -0.1411, -1.0283, -3.0288, -1.1728], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5587, -0.1411, -1.0283, -3.0288, -1.1728], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.4168, -2.0091, -0.7588, -0.4050,  0.0137], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.8979, -1.0325, -0.4862, -0.6197, -0.7461], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1602, -0.2574,  0.2398, -0.4168, -0.8777], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1632, -0.2327, -0.1080, -0.1142, -0.0253], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2901, -0.1354, -0.1101, -0.1933, -0.0184], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1659, -0.0631, -0.0520, -0.0873, -0.0091], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1659, -0.0631, -0.0520, -0.0873, -0.0091], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2781, -0.0501, -0.1313,  0.0060, -0.0191], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0239, -0.0729, -0.2586, -0.0210, -0.1947], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6296, -0.1967, -0.1434, -0.1402, -0.2238], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3896, 0.3386, 0.3975, 0.7727, 0.2474], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7825, 0.9356, 0.9446, 0.8973, 0.9461], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1659, -0.0631, -0.0520, -0.0873, -0.0091], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0180, -0.0032, -0.0085,  0.0004, -0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0026,  0.0012, -0.0110,  0.0131, -0.0035], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0949, -0.0574, -0.0781, -0.1767, -0.0416], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.9076, -0.3665, -0.3329, -0.6045, -0.0863], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.9076, -0.3665, -0.3329, -0.6045, -0.0863], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.3226, 0.0240, 0.0902, 0.0845, 0.0239], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([6.2216], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4009], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.1427, 0.0332, 0.1095, 0.0762, 0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.1427, 0.0332, 0.1095, 0.0762, 0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.8256, -0.0136,  0.7803, -0.6176,  0.6663], grad_fn=<SliceBackward0>)
  [Layer 24] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 24] Output sample values after mixer: tensor([-0.8256, -0.0136,  0.7803, -0.6176,  0.6663], grad_fn=<SliceBackward0>)
  [Layer 24] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 24] Residual connection sample values: tensor([-4.2317, -1.3809, -3.5575,  2.2430,  4.6989], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 25/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([19.2210], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2281], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3707, -0.1123, -0.2904,  0.2250,  0.3857], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6746,  0.1120, -1.9709,  0.4753, -0.9130], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6746,  0.1120, -1.9709,  0.4753, -0.9130], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.7093,  0.1249, -0.6746, -0.9570,  0.0773], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.2260, -0.2652,  0.0208,  0.2751, -0.1947], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0134,  0.0313, -0.1364,  0.7093, -0.3305], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2065, -0.0542,  0.0879, -0.6067, -0.0679], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2259, -0.0508,  0.1906, -0.7118, -0.1066], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1002, -0.0248,  0.1043, -0.2343, -0.0505], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1002, -0.0248,  0.1043, -0.2343, -0.0505], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0013, -0.0992, -0.0832, -0.0228,  0.2286], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2776, -0.1689,  0.0088, -0.2310, -0.2781], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1626, -0.3327, -0.3294, -0.2016, -0.1541], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4889, 0.2816, 0.3491, 0.5442, 0.4518], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9236, 0.9106, 0.8914, 0.8961, 0.9327], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1002, -0.0248,  0.1043, -0.2343, -0.0505], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-6.1369e-05,  4.8600e-03,  4.0781e-03,  1.1192e-03, -1.1205e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0015,  0.0055,  0.0030,  0.0023, -0.0168], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0082,  0.0170, -0.0626, -0.2376, -0.1003], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1003, -0.0058,  0.0332, -0.4529, -0.1467], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1003, -0.0058,  0.0332, -0.4529, -0.1467], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0228, -0.0003, -0.0080, -0.1328,  0.0384], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2744], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9090], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1516, -0.0018, -0.0348, -0.3235,  0.1439], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1516, -0.0018, -0.0348, -0.3235,  0.1439], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 3.3378e-01, -3.6033e-01,  5.8675e-04,  6.2536e-01, -4.4814e-01],
       grad_fn=<SliceBackward0>)
  [Layer 25] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 25] Output sample values after mixer: tensor([ 3.3378e-01, -3.6033e-01,  5.8675e-04,  6.2536e-01, -4.4814e-01],
       grad_fn=<SliceBackward0>)
  [Layer 25] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 25] Residual connection sample values: tensor([-3.8979, -1.7412, -3.5569,  2.8684,  4.2507], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 26/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([21.4619], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2159], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4022, -0.1674, -0.3595,  0.3555,  0.4196], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6544, -1.0407, -0.4020,  0.3433, -0.9461], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6544, -1.0407, -0.4020,  0.3433, -0.9461], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8268, -0.3152,  1.5901,  1.0136,  0.4352], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.4491, -2.0130,  0.0881,  0.2945, -1.2154], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.0918,  0.0586, -1.1091, -0.8268, -1.5826], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2541, -0.0989, -0.4007,  0.2606,  0.0917], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3451, -0.1529, -0.4259,  0.1973, -0.1762], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1431, -0.0706, -0.1683,  0.1084, -0.0803], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1431, -0.0706, -0.1683,  0.1084, -0.0803], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1606, -0.0387,  0.1577,  0.1731,  0.1315], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1368, -0.2580, -0.0590,  0.1045, -0.2058], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3298, -0.0634, -0.2289, -0.1264, -0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3901, 0.0276, 1.6531, 1.5977, 0.1897], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8793, 0.9982, 0.6850, 0.8171, 0.9890], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1431, -0.0706, -0.1683,  0.1084, -0.0803], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0090,  0.0022, -0.0088, -0.0097, -0.0073], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0448,  0.0353, -0.0078, -0.0403, -0.0033], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3381, -0.2782, -0.2334,  0.2722, -0.5348], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.9151, -0.5629, -0.9121,  0.7093, -0.8589], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.9151, -0.5629, -0.9121,  0.7093, -0.8589], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.2048, 0.1529, 0.1470, 0.1424, 0.2272], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([5.0775], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4438], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.2152, 0.1121, 0.1423, 0.1515, 0.1780], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.2152, 0.1121, 0.1423, 0.1515, 0.1780], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.8164, -0.4655,  0.4952,  0.7570,  1.6633], grad_fn=<SliceBackward0>)
  [Layer 26] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 26] Output sample values after mixer: tensor([-1.8164, -0.4655,  0.4952,  0.7570,  1.6633], grad_fn=<SliceBackward0>)
  [Layer 26] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 26] Residual connection sample values: tensor([-5.7143, -2.2067, -3.0616,  3.6254,  5.9140], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 27/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([28.1094], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1886], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4492, -0.1651, -0.2322,  0.3294,  0.4681], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0519, -0.7411,  0.6461,  0.2982,  0.0623], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0519, -0.7411,  0.6461,  0.2982,  0.0623], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0210, -1.2730,  0.4145, -0.5754, -0.4692], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.3419, -0.9181, -0.2793,  0.2815,  0.5397], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.9614,  0.7114, -0.3812,  0.0210, -0.4188], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0079, -0.4316,  0.1256,  0.3740, -0.0477], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0246, -0.4834,  0.0705,  0.1738, -0.0459], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0121, -0.1844,  0.0365,  0.0944, -0.0224], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0121, -0.1844,  0.0365,  0.0944, -0.0224], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1306, -0.0964,  0.1092,  0.0427, -0.0086], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2548, -0.0084, -0.1169, -0.1369, -0.2217], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5626, -0.0303, -0.7559, -1.1613, -0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1065, 0.0180, 0.0071, 0.1008, 0.0538], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9418, 0.9995, 0.9947, 0.8895, 0.9978], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0121, -0.1844,  0.0365,  0.0944, -0.0224], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.6879e-04,  1.2455e-04, -1.4107e-04, -5.5191e-05,  1.1143e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0023, -0.0103, -0.0036, -0.0065, -0.0042], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0270, -0.0258,  0.0278, -0.0730,  0.0206], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0511, -0.3925,  0.1003,  0.1148, -0.0240], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0511, -0.3925,  0.1003,  0.1148, -0.0240], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0014,  0.0939,  0.0425,  0.0197, -0.0008], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6788], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2138], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0038,  0.2060,  0.1346,  0.0160, -0.0031], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0038,  0.2060,  0.1346,  0.0160, -0.0031], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4807,  1.6123, -2.4870, -2.8765,  1.0283], grad_fn=<SliceBackward0>)
  [Layer 27] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 27] Output sample values after mixer: tensor([-0.4807,  1.6123, -2.4870, -2.8765,  1.0283], grad_fn=<SliceBackward0>)
  [Layer 27] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 27] Residual connection sample values: tensor([-6.1951, -0.5944, -5.5486,  0.7490,  6.9422], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 28/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([34.9898], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1691], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3736, -0.0345, -0.3291,  0.0528,  0.4054], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2306, -0.7690,  0.5217, -0.3254, -0.3358], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2306, -0.7690,  0.5217, -0.3254, -0.3358], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6237,  0.8165,  0.4236, -0.3803, -1.8518], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.8848,  0.2209, -0.1683,  0.2970,  0.5626], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5593,  0.0029, -1.2641, -0.6237, -1.4499], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2409,  0.2830,  0.0856,  0.0886, -0.3921], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1130,  0.1936, -0.0435, -0.0015, -0.4577], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0597,  0.1061, -0.0213, -0.0007, -0.1774], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0597,  0.1061, -0.0213, -0.0007, -0.1774], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1626,  0.0285,  0.0640, -0.0127, -0.2710], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0395,  0.1518,  0.3008, -0.1300, -0.0545], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5442, -0.1843, -0.1064, -0.1124, -0.2523], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3900, 0.6021, 0.8155, 1.0254, 0.7336], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8087, 0.8950, 0.9169, 0.8911, 0.8310], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0597,  0.1061, -0.0213, -0.0007, -0.1774], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0038,  0.0007,  0.0015, -0.0003, -0.0063], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 7.9681e-03, -3.1582e-03,  5.6204e-03,  3.6919e-05, -1.5480e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0011, -0.0231, -0.0128,  0.0044, -0.0082], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1103,  0.1749, -0.0526,  0.0030, -0.3391], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1103,  0.1749, -0.0526,  0.0030, -0.3391], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0142, -0.0426, -0.0172, -0.0004,  0.0475], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1208], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.8773], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0832, -0.2348, -0.0905, -0.0025,  0.3359], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0832, -0.2348, -0.0905, -0.0025,  0.3359], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4627,  0.7605, -0.4238,  1.2398,  0.5115], grad_fn=<SliceBackward0>)
  [Layer 28] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 28] Output sample values after mixer: tensor([-0.4627,  0.7605, -0.4238,  1.2398,  0.5115], grad_fn=<SliceBackward0>)
  [Layer 28] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 28] Residual connection sample values: tensor([-6.6578,  0.1660, -5.9724,  1.9888,  7.4537], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 29/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([44.8378], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1493], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4377,  0.0108, -0.3957,  0.1616,  0.4922], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.9048,  0.0024,  0.4163, -0.2402, -0.4922], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.9048,  0.0024,  0.4163, -0.2402, -0.4922], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.7339,  0.2297,  0.4304,  1.7138, -0.0416], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.2282, -1.1114,  0.5526, -0.0389, -0.6526], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.7908, 0.2165, 0.1798, 0.7339, 0.6935], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1336, -0.0790, -0.1610, -0.3121,  0.0992], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1476, -0.1547, -0.2993,  0.0546,  1.5992], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0792, -0.0714, -0.1274,  0.0281,  1.3304], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0792, -0.0714, -0.1274,  0.0281,  1.3304], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1334, -0.0059, -0.0157, -0.0452,  0.0239], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0970,  0.0103,  0.0948, -0.0995, -0.0520], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6542, -0.1369, -1.4589, -0.3682, -0.1218], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1034, 0.0185, 0.1591, 0.0995, 0.1622], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9346, 0.9975, 0.7929, 0.9640, 0.9804], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0792, -0.0714, -0.1274,  0.0281,  1.3304], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.0930e-03, -4.8089e-05, -1.2844e-04, -3.7005e-04,  1.9622e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0063, -0.0007, -0.0003, -0.0030,  0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0006, -0.0126, -0.0228,  0.0415,  0.2483], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1338, -0.1326, -0.2369,  0.0886,  2.4846], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1338, -0.1326, -0.2369,  0.0886,  2.4846], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-3.4881e-02, -1.6160e-04, -5.9436e-02, -9.3757e-03, -4.6394e-01],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1981], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.2466], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2562, -0.0009, -0.2547, -0.0493, -0.3781], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2562, -0.0009, -0.2547, -0.0493, -0.3781], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.2697,  0.2352,  0.5486,  0.2209, -0.9841], grad_fn=<SliceBackward0>)
  [Layer 29] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 29] Output sample values after mixer: tensor([ 1.2697,  0.2352,  0.5486,  0.2209, -0.9841], grad_fn=<SliceBackward0>)
  [Layer 29] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 29] Residual connection sample values: tensor([-5.3881,  0.4013, -5.4238,  2.2097,  6.4696], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 30/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([49.1776], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1426], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3134,  0.0223, -0.3070,  0.1468,  0.3658], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5963,  1.5850,  0.8554, -0.7543,  1.5385], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5963,  1.5850,  0.8554, -0.7543,  1.5385], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6531,  1.5907, -0.8943, -0.4752,  0.7480], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.0248,  0.4175,  0.1880, -1.6096,  0.6992], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.0557, -0.9705,  1.0343, -0.6531, -0.2448], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.3048, -0.5283,  0.3584,  0.2065, -0.1726], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2620, -0.5701,  0.9336,  0.2560, -0.2652], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1481, -0.2059,  0.6701,  0.1443, -0.1151], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1481, -0.2059,  0.6701,  0.1443, -0.1151], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0683, -0.0162, -0.0779,  0.1217, -0.2374], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1706, -0.0799, -0.1702, -0.1271, -0.2542], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2038, -0.3668, -0.2078, -0.0952, -0.4265], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5352, 0.3415, 0.5144, 0.0207, 0.4609], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8967, 0.8823, 0.8986, 0.9980, 0.8215], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1481, -0.2059,  0.6701,  0.1443, -0.1151], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0054, -0.0013, -0.0062,  0.0096, -0.0188], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0031, -0.0346, -0.0095, -0.0122,  0.0572], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0841, -0.1016,  1.2967,  0.2586, -0.1110], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0597, -0.1356,  1.4074,  0.2824, -0.1300], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0597, -0.1356,  1.4074,  0.2824, -0.1300], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0229, -0.1783,  0.8447, -0.0682, -0.1647], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4415], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.5049], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0864, -0.7423,  2.1253, -0.2846, -0.2522], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0864, -0.7423,  2.1253, -0.2846, -0.2522], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0833, -1.6084, -1.5067, -3.5655, -1.2114], grad_fn=<SliceBackward0>)
  [Layer 30] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 30] Output sample values after mixer: tensor([ 0.0833, -1.6084, -1.5067, -3.5655, -1.2114], grad_fn=<SliceBackward0>)
  [Layer 30] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 30] Residual connection sample values: tensor([-5.3047, -1.2071, -6.9305, -1.3558,  5.2582], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 31/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([62.4399], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1266], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1854, -0.0428, -0.2432, -0.0537,  0.1841], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.8731, -0.8019,  0.5665, -0.1079, -0.0941], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.8731, -0.8019,  0.5665, -0.1079, -0.0941], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.4060,  0.4710,  0.0123,  0.0259, -0.5407], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.2449,  0.5913,  1.0250,  0.7889,  0.3120], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2069, -0.2253, -1.1196, -0.4060,  0.3407], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0726, -0.1051, -0.0017, -0.0151, -0.4132], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0697, -0.0702, -0.0122, -0.0333, -0.4735], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0361, -0.0339, -0.0061, -0.0164, -0.1817], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0361, -0.0339, -0.0061, -0.0164, -0.1817], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0708,  0.0434,  0.0162, -0.0400,  0.0611], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1216,  0.0005, -0.0827, -0.1311, -0.1135], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-9.5766e-03, -1.0642e-02, -2.6350e+01, -6.4468e+02, -1.6547e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0362, 0.1030, 1.7634, 1.9728, 0.0848], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9965e-01, 9.9890e-01, 6.6079e-21, 0.0000e+00, 9.9860e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0361, -0.0339, -0.0061, -0.0164, -0.1817], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-9.2323e-05,  5.6612e-05,  2.1170e-05, -5.2150e-05,  7.9686e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0159, -0.0105,  0.0078,  0.0154,  0.0059], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0203, -0.0337,  0.0075, -0.0097, -0.0542], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0248, -0.0295,  0.0083, -0.0077, -0.0314], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0248, -0.0295,  0.0083, -0.0077, -0.0314], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0153,  0.0073,  0.0030,  0.0004,  0.0014], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0226], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.6571], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.4046,  0.1755,  0.0724,  0.0420,  0.0099], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.4046,  0.1755,  0.0724,  0.0420,  0.0099], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-6.2376,  1.6631, -3.6151, -1.9906,  0.2732], grad_fn=<SliceBackward0>)
  [Layer 31] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 31] Output sample values after mixer: tensor([-6.2376,  1.6631, -3.6151, -1.9906,  0.2732], grad_fn=<SliceBackward0>)
  [Layer 31] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 31] Residual connection sample values: tensor([-11.5423,   0.4560, -10.5455,  -3.3465,   5.5314],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 32/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([77.5821], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1135], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.6127,  0.0237, -0.5440, -0.2070,  0.2979], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([1.1474, 0.1848, 0.9365, 1.5763, 0.3800], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([1.1474, 0.1848, 0.9365, 1.5763, 0.3800], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.3214, -0.2636,  0.8414, -1.8361,  0.3846], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.2560,  0.1849,  0.3138,  0.2438, -0.4727], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.0760, -0.3789, -0.0596, -0.3214, -0.8074], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0041,  0.0628, -0.0469,  0.0857, -0.1062], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0096, -0.3051, -0.0490,  0.0623, -0.1185], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0048, -0.1295, -0.0239,  0.0321, -0.0558], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0048, -0.1295, -0.0239,  0.0321, -0.0558], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.2650,  0.0078,  0.0394, -0.0610,  0.0268], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2479, -0.2069, -0.2516, -0.0571, -0.1667], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0662, -0.0811, -0.5879, -0.0956, -0.5448], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.8438, 1.1820, 0.5399, 1.0233, 0.4131], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9457, 0.9086, 0.7280, 0.9068, 0.7985], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0048, -0.1295, -0.0239,  0.0321, -0.0558], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.0721e-03, -3.1524e-05, -1.5937e-04,  2.4686e-04, -1.0855e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0209, 0.1082, 0.1346, 0.2766, 0.1562], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.4939, -1.2671,  0.2031,  1.1541, -0.4662], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.4940, -1.2642,  0.2037,  1.1534, -0.4649], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.4940, -1.2642,  0.2037,  1.1534, -0.4649], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.4302, -0.1276,  0.1370,  1.5066, -0.1049], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.7867], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7481], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.3624, -0.2334,  0.2498,  1.7215, -0.1351], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.3624, -0.2334,  0.2498,  1.7215, -0.1351], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-3.9245,  1.9111,  0.6436,  0.1759,  2.6672], grad_fn=<SliceBackward0>)
  [Layer 32] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 32] Output sample values after mixer: tensor([-3.9245,  1.9111,  0.6436,  0.1759,  2.6672], grad_fn=<SliceBackward0>)
  [Layer 32] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 32] Residual connection sample values: tensor([-15.4668,   2.3670,  -9.9020,  -3.1706,   8.1986],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 33/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([99.4772], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1003], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.7455,  0.1114, -0.4746, -0.1605,  0.3996], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1975,  0.2722,  0.2100, -1.0568, -0.6989], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1975,  0.2722,  0.2100, -1.0568, -0.6989], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.9715,  1.4759,  0.2100, -0.7826,  0.7039], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.6256,  0.6271, -1.4719, -1.5226,  0.2806], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2802, -0.7093,  1.9687,  0.9715, -0.5150], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2560,  0.3994,  0.0307, -0.2287,  0.1400], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0142,  0.3628,  0.0173, -0.3516,  0.1057], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0071,  0.2139,  0.0087, -0.1452,  0.0556], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0071,  0.2139,  0.0087, -0.1452,  0.0556], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0165,  0.0439,  0.0055, -0.0137,  0.0517], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0296, -0.1603,  0.4562,  0.2168,  0.0257], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-13.0444,  -1.3850,  -0.1668,  -0.2359,  -5.2550],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0697, 0.0090, 0.0130, 0.0117, 0.0110], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4028, 0.9876, 0.9978, 0.9972, 0.9438], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0071,  0.2139,  0.0087, -0.1452,  0.0556], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-8.1444e-06, -2.1631e-05, -2.7299e-06,  6.7732e-06, -2.5486e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 9.1125e-04, -6.3689e-04, -1.3542e-04,  2.3050e-06,  3.3332e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 1.3248e-03, -5.3854e-04,  1.4292e-05,  4.3962e-04, -1.1374e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0062,  0.2286,  0.0094, -0.1551,  0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0062,  0.2286,  0.0094, -0.1551,  0.0584], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0007,  0.0353,  0.0011,  0.0423, -0.0136], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0680], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.8344], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0072,  0.3619,  0.0152,  0.4967, -0.1802], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0072,  0.3619,  0.0152,  0.4967, -0.1802], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.6866,  0.9052, -2.4981, -0.9695,  1.8548], grad_fn=<SliceBackward0>)
  [Layer 33] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 33] Output sample values after mixer: tensor([-1.6866,  0.9052, -2.4981, -0.9695,  1.8548], grad_fn=<SliceBackward0>)
  [Layer 33] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 33] Residual connection sample values: tensor([-17.1534,   3.2722, -12.4001,  -4.1401,  10.0533],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 34/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([133.2499], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0866], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.6309,  0.1186, -0.4742, -0.1545,  0.3776], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2125, -0.5997, -0.4936,  0.4855, -0.4828], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2125, -0.5997, -0.4936,  0.4855, -0.4828], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1197, -1.0826,  0.0781,  1.7314, -0.9512], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.8231, -1.3253,  0.6953,  0.1767,  0.7894], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2165, -0.6319,  0.3785, -0.1197, -1.6985], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0220,  0.5821, -0.0047, -0.3236, -0.3188], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0654,  0.4849, -0.0387, -0.4047, -0.3929], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0316,  0.3001, -0.0190, -0.1620, -0.1583], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0316,  0.3001, -0.0190, -0.1620, -0.1583], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0022, -0.0243, -0.0030,  0.0134, -0.0153], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2783,  0.0652,  0.0166,  0.0015, -0.1564], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2225, -0.1537, -0.8169, -0.8591, -2.0730], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0058, 0.0019, 0.3548, 0.1178, 0.3526], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9987, 0.9997, 0.7484, 0.9037, 0.4815], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0316,  0.3001, -0.0190, -0.1620, -0.1583], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-4.0354e-07,  4.4416e-06,  5.5343e-07, -2.4548e-06,  2.7979e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0030,  0.0074,  0.0034, -0.0067,  0.0106], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0304,  0.1110,  0.0655, -0.0261, -0.0504], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0926,  0.7014,  0.0283, -0.3447, -0.3619], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0926,  0.7014,  0.0283, -0.3447, -0.3619], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0088, -0.1491, -0.0053, -0.1036,  0.0667], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1402], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.6708], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0628, -0.5949, -0.0315, -0.7305,  0.5012], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0628, -0.5949, -0.0315, -0.7305,  0.5012], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2672,  1.4495, -2.4935,  0.0407,  0.5252], grad_fn=<SliceBackward0>)
  [Layer 34] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 34] Output sample values after mixer: tensor([ 0.2672,  1.4495, -2.4935,  0.0407,  0.5252], grad_fn=<SliceBackward0>)
  [Layer 34] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 34] Residual connection sample values: tensor([-16.8862,   4.7217, -14.8936,  -4.0993,  10.5785],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 35/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([145.5146], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0829], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.7860,  0.2181, -0.6830, -0.2034,  0.4894], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.7258, -0.2897,  0.0449, -0.2564,  1.0170], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.7258, -0.2897,  0.0449, -0.2564,  1.0170], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1723,  0.8958, -0.5074, -2.2417,  1.5655], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.8594,  1.1858, -0.9002,  1.3216,  0.8687], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.9954,  0.3614, -0.4899, -0.1723, -0.1254], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0276,  0.2023, -0.4108, -0.4380,  0.3767], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0239,  0.1806, -0.4383, -0.4629,  0.2645], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0118,  0.0984, -0.1719, -0.1788,  0.1496], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0118,  0.0984, -0.1719, -0.1788,  0.1496], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0406, -0.0675,  0.1277, -0.1133, -0.0790], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0639,  0.1275, -0.2784,  0.0185,  0.1616], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2054, -0.1417, -0.1071, -0.1460, -0.2581], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.5006, 3.3919, 0.4475, 3.6830, 1.4760], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5984, 0.6184, 0.9532, 0.5840, 0.6832], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0118,  0.0984, -0.1719, -0.1788,  0.1496], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0012,  0.0020, -0.0038,  0.0033,  0.0023], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0058, -0.0012, -0.0091,  0.0037, -0.0100], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0088,  0.2629, -0.6933, -0.6654,  0.5072], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0221,  0.5206, -1.1434, -1.1336,  0.8990], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0221,  0.5206, -1.1434, -1.1336,  0.8990], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0052, -0.0646, -0.0263,  0.1268,  0.6715], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([3.8619], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5089], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0101, -0.1212, -0.0170,  0.3546,  1.0884], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0101, -0.1212, -0.0170,  0.3546,  1.0884], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-2.7149, -0.6738, -2.0109,  2.0689,  0.5846], grad_fn=<SliceBackward0>)
  [Layer 35] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 35] Output sample values after mixer: tensor([-2.7149, -0.6738, -2.0109,  2.0689,  0.5846], grad_fn=<SliceBackward0>)
  [Layer 35] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 35] Residual connection sample values: tensor([-19.6011,   4.0479, -16.9045,  -2.0305,  11.1631],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 36/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([200.8606], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0706], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.6915,  0.1460, -0.5999, -0.0765,  0.4034], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.4003, -0.6595, -1.1091, -0.1505, -0.8566], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.4003, -0.6595, -1.1091, -0.1505, -0.8566], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.4971,  1.6251, -0.2212,  0.3396, -1.2132], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.5635, 1.1719, 0.6582, 1.1792, 0.5836], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.8071,  0.9456,  2.9650, -0.4971,  1.0246], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1316,  0.3759, -0.0653,  0.0574, -0.1958], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0913,  0.2583, -0.1274, -0.0873, -0.2080], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0436,  0.1458, -0.0596, -0.0417, -0.0932], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0436,  0.1458, -0.0596, -0.0417, -0.0932], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0725, -0.0403, -0.0787,  0.2302, -0.0220], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1001,  0.0865, -0.2035, -0.0614,  0.0700], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.8655, -5.6378, -3.8976, -2.4260, -3.6937], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1198, 0.0543, 0.0348, 0.1234, 0.0441], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7095, 0.7364, 0.8733, 0.7412, 0.8498], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0436,  0.1458, -0.0596, -0.0417, -0.0932], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0004,  0.0002,  0.0004, -0.0012,  0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0095,  0.0016, -0.0022,  0.0017,  0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0201,  0.0312, -0.0080, -0.0138, -0.0133], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1538,  0.4782, -0.1910, -0.1418, -0.2992], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1538,  0.4782, -0.1910, -0.1418, -0.2992], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0307, -0.1075,  0.0525,  0.0099,  0.0764], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4244], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.5350], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0903, -0.6755,  0.2281,  0.0457,  0.4024], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0903, -0.6755,  0.2281,  0.0457,  0.4024], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.9601, -2.6919,  4.4102, -5.5730,  1.8387], grad_fn=<SliceBackward0>)
  [Layer 36] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 36] Output sample values after mixer: tensor([ 2.9601, -2.6919,  4.4102, -5.5730,  1.8387], grad_fn=<SliceBackward0>)
  [Layer 36] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 36] Residual connection sample values: tensor([-16.6410,   1.3560, -12.4943,  -7.6034,  13.0018],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 37/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([239.8592], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0646], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.5181,  0.0434, -0.4081, -0.2425,  0.4152], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6609, -0.6317, -0.2104, -1.3822,  2.2891], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6609, -0.6317, -0.2104, -1.3822,  2.2891], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1335,  1.0873,  0.8125, -1.4223,  1.0415], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.6175,  1.6584,  3.8679,  0.6063, -0.3493], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6172, -0.6494, -0.6329, -0.1335,  2.2240], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0642, -0.3872, -0.2998,  0.3813, -0.2831], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0136, -0.4513, -0.3844,  0.4162, -0.3667], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0067, -0.1756, -0.1557,  0.2508, -0.1501], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0067, -0.1756, -0.1557,  0.2508, -0.1501], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2146, -0.2471, -0.0483, -0.0770, -0.1202], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2395, -0.1559, -0.0368, -0.1699, -0.2278], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.8179, -31.1699, -39.0195,  -0.4619,  -0.6477],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0032, 0.0374, 0.1486, 0.0014, 0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9942, 0.3117, 0.0030, 0.9994, 0.9992], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0067, -0.1756, -0.1557,  0.2508, -0.1501], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([4.6020e-06, 5.2971e-06, 1.0355e-06, 1.6509e-06, 2.5772e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0004,  0.0004, -0.0006,  0.0009, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0017,  0.0062, -0.0090,  0.0128, -0.0054], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0107, -0.3154, -0.2942,  0.4722, -0.2804], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0107, -0.3154, -0.2942,  0.4722, -0.2804], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0024,  0.0692,  0.0277, -0.1310, -0.5827], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1635], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.4733], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0222,  0.4608,  0.1736, -1.2982, -3.0825], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0222,  0.4608,  0.1736, -1.2982, -3.0825], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.6356, -4.6292,  2.8309,  0.1380, -1.1897], grad_fn=<SliceBackward0>)
  [Layer 37] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 37] Output sample values after mixer: tensor([ 2.6356, -4.6292,  2.8309,  0.1380, -1.1897], grad_fn=<SliceBackward0>)
  [Layer 37] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 37] Residual connection sample values: tensor([-14.0054,  -3.2732,  -9.6635,  -7.4655,  11.8121],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 38/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([294.4614], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0583], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4184, -0.0978, -0.2873, -0.2161,  0.3553], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.5580, -1.0693,  0.8707, -0.7233,  0.5672], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.5580, -1.0693,  0.8707, -0.7233,  0.5672], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5341, -1.0287,  0.1494, -0.8804,  0.7891], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.3291,  0.3166, -0.5950,  0.5970,  1.5507], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([1.7691, 2.6654, 0.8303, 0.5341, 0.2553], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3293, -0.1369,  0.2690,  0.1054,  0.1325], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3317, -0.4262,  0.1789,  0.0622,  0.2255], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1386, -0.1684,  0.0975,  0.0321,  0.1254], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1386, -0.1684,  0.0975,  0.0321,  0.1254], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0413, -0.1459,  0.1396, -0.0346, -0.0604], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1394, -0.0886, -0.2749, -0.0167, -0.1560], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1704, -2.0832, -0.1351, -0.4124, -3.5315], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6310, 0.1594, 0.4224, 0.4888, 0.3970], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8980, 0.7175, 0.9445, 0.8175, 0.2461], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1386, -0.1684,  0.0975,  0.0321,  0.1254], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0036,  0.0128, -0.0122,  0.0030,  0.0053], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0085,  0.1595, -0.0108,  0.0020, -0.0106], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2732, -0.2445, -0.1132, -0.1300,  0.5555], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2935, -0.2692, -0.0989, -0.1253,  0.5739], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2935, -0.2692, -0.0989, -0.1253,  0.5739], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0795,  0.0735, -0.0607,  0.0296,  0.2077], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7736], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1370], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2849,  0.1774, -0.1619,  0.1576,  0.7648], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.2849,  0.1774, -0.1619,  0.1576,  0.7648], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-7.8947, 19.1768, -4.2501, -1.0794,  6.0778], grad_fn=<SliceBackward0>)
  [Layer 38] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 38] Output sample values after mixer: tensor([-7.8947, 19.1768, -4.2501, -1.0794,  6.0778], grad_fn=<SliceBackward0>)
  [Layer 38] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 38] Residual connection sample values: tensor([-21.9001,  15.9037, -13.9135,  -8.5449,  17.8899],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 39/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([421.5384], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0487], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4047,  0.3196, -0.2712, -0.1747,  0.3470], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2267,  0.1259, -0.8453, -0.2148, -1.4220], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2267,  0.1259, -0.8453, -0.2148, -1.4220], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.8240,  0.7514, -0.2491,  0.2423,  0.3363], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.5342,  1.8382, -1.9129,  2.1744,  0.8107], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 2.4910, -0.6531, -0.6229,  1.8240,  0.4256], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.3398, -0.1617, -0.0207,  0.0540,  0.0928], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.4043, -0.2224, -0.0054,  0.5916,  0.0894], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.2425, -0.0989, -0.0027,  0.3808,  0.0467], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.2425, -0.0989, -0.0027,  0.3808,  0.0467], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0222,  0.0190, -0.1644,  0.1786, -0.0891], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2635, -0.2299, -0.0090, -0.0884, -0.2780], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.7351e+02, -2.3790e+00, -2.6079e-03, -1.4979e+00, -6.3307e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4236, 1.0802, 0.0436, 0.7810, 0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([1.1920e-32, 7.6551e-02, 9.9989e-01, 3.1042e-01, 9.9874e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.2425, -0.0989, -0.0027,  0.3808,  0.0467], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0023,  0.0020, -0.0169,  0.0183, -0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0023,  0.0020, -0.0169,  0.0183, -0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0466, -0.0190, -0.0005,  0.0731,  0.0090], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 1.1437, -0.4664, -0.0127,  1.7962,  0.2203], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 1.1437, -0.4664, -0.0127,  1.7962,  0.2203], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1150, -0.0312,  0.0032, -0.1722, -0.0609], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5521], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.3458], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.7235, -0.1860,  0.0182, -0.9480, -0.4043], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.7235, -0.1860,  0.0182, -0.9480, -0.4043], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-4.5584, -5.0074, -2.2404,  7.9695, -4.3186], grad_fn=<SliceBackward0>)
  [Layer 39] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 39] Output sample values after mixer: tensor([-4.5584, -5.0074, -2.2404,  7.9695, -4.3186], grad_fn=<SliceBackward0>)
  [Layer 39] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 39] Residual connection sample values: tensor([-26.4585,  10.8963, -16.1539,  -0.5754,  13.5713],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 40/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([593.5380], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0410], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.5337,  0.2345, -0.3406, -0.0111,  0.2834], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1643, -0.3456,  0.7950, -0.8612,  0.0072], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1643, -0.3456,  0.7950, -0.8612,  0.0072], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8216,  0.6326, -0.7039, -0.5723, -0.1140], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.7388,  0.4511, -0.0051, -3.2479,  0.5157], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4070, -0.3095,  0.0038, -0.8216,  0.1099], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1242, -0.1047, -0.1245,  0.1336, -0.0159], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2071, -0.1532, -0.1962,  0.1220, -0.0144], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1143, -0.0708, -0.0885,  0.0647, -0.0071], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1143, -0.0708, -0.0885,  0.0647, -0.0071], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0351, -0.2165, -0.0270,  0.0450,  0.0619], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2293, -0.2695, -0.1924,  0.2331,  1.0904], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5267, -0.6301, -0.3878, -2.7909, -0.4284], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0371, 0.0203, 0.0276, 0.0002, 0.0268], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9807, 0.9873, 0.9894, 0.9993, 0.9886], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1143, -0.0708, -0.0885,  0.0647, -0.0071], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0001, -0.0009, -0.0001,  0.0002,  0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0028, -0.0435, -0.0068,  0.0003, -0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0824, -0.0531, -0.0589, -0.0049,  0.0261], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.3652, -0.2283, -0.2780,  0.1554,  0.0084], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.3652, -0.2283, -0.2780,  0.1554,  0.0084], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-2.7541e-02,  3.2694e-02, -1.5225e-01, -3.9747e-02,  3.0567e-05],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3293], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.7427], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-1.5392e-01,  2.1632e-01, -1.0255e+00, -2.1159e-01,  2.6801e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-1.5392e-01,  2.1632e-01, -1.0255e+00, -2.1159e-01,  2.6801e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-3.9092, -3.2098, -8.6998, -1.5898,  0.1218], grad_fn=<SliceBackward0>)
  [Layer 40] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 40] Output sample values after mixer: tensor([-3.9092, -3.2098, -8.6998, -1.5898,  0.1218], grad_fn=<SliceBackward0>)
  [Layer 40] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 40] Residual connection sample values: tensor([-30.3677,   7.6865, -24.8537,  -2.1652,  13.6931],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 41/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([851.5137], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0343], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3636,  0.0984, -0.3069, -0.0256,  0.1643], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.8921, -1.2107, -0.1967, -0.1928,  0.0430], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.8921, -1.2107, -0.1967, -0.1928,  0.0430], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8642,  0.7782, -0.1816,  1.0633, -0.1439], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.4663,  0.4960,  0.8829, -0.8212, -0.3973], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6705, -1.1127, -1.0690, -0.8642, -0.6583], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2287, -0.1840, -0.0409, -0.1854,  0.0352], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2603, -0.0616, -0.0408, -0.2781,  0.0256], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1133, -0.0299, -0.0200, -0.1198,  0.0130], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1133, -0.0299, -0.0200, -0.1198,  0.0130], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0344,  0.0223,  0.1601, -0.0378, -0.0312], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0506,  0.1235,  0.0006, -0.0881, -0.2021], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.0531, -1.1356, -0.8719, -1.5713, -1.7431], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2767, 0.3242, 0.2318, 0.0575, 0.0558], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7472, 0.6920, 0.8170, 0.9136, 0.9073], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1133, -0.0299, -0.0200, -0.1198,  0.0130], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0011, -0.0007, -0.0050,  0.0012,  0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0081, -0.0047, -0.0150, -0.0004, -0.0081], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0189,  0.0077, -0.0008, -0.0213, -0.0038], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1639, -0.0304, -0.0264, -0.1746,  0.0128], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1639, -0.0304, -0.0264, -0.1746,  0.0128], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1037,  0.0085,  0.0023,  0.0152,  0.0003], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0231], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.5749], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-2.1828,  0.2378,  0.0569,  0.4484,  0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-2.1828,  0.2378,  0.0569,  0.4484,  0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-7.4425, -3.0588,  1.7868,  4.8953,  1.1712], grad_fn=<SliceBackward0>)
  [Layer 41] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 41] Output sample values after mixer: tensor([-7.4425, -3.0588,  1.7868,  4.8953,  1.1712], grad_fn=<SliceBackward0>)
  [Layer 41] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 41] Residual connection sample values: tensor([-37.8102,   4.6276, -23.0669,   2.7301,  14.8643],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 42/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([999.6002], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0316], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4307,  0.0566, -0.2809,  0.0311,  0.1781], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1501,  0.4969, -0.8359, -0.6540, -0.0635], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1501,  0.4969, -0.8359, -0.6540, -0.0635], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.0213,  0.7890, -0.5623,  0.2938, -0.2196], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.9090, -0.9921,  1.3703,  0.6317,  0.8139], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.8538,  0.7887,  0.2633, -0.0213,  1.0389], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0020,  0.1624,  0.1213, -0.0555, -0.0491], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0189,  0.1266,  0.1259, -0.0592, -0.0953], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0093,  0.0673,  0.0669, -0.0287, -0.0454], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0093,  0.0673,  0.0669, -0.0287, -0.0454], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1452, -0.0088, -0.1592, -0.0005,  0.0119], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0677, -0.2338, -0.1896, -0.2647, -0.2778], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.2458, -1.7474, -3.3797, -1.2264, -1.3705], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2398, 0.0503, 0.4356, 0.0387, 0.1669], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5836, 0.9158, 0.2294, 0.9536, 0.7955], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0093,  0.0673,  0.0669, -0.0287, -0.0454], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-3.2534e-04,  1.9655e-05,  3.5666e-04,  1.1451e-06, -2.6755e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 3.5608e-04,  9.1711e-04,  9.2943e-04,  1.6527e-04, -5.6706e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0055,  0.0130,  0.0132, -0.0006, -0.0050], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0182,  0.1050,  0.1046, -0.0399, -0.0670], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0182,  0.1050,  0.1046, -0.0399, -0.0670], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0013,  0.0324, -0.0264,  0.0089,  0.0021], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0303], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([5.7433], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0285,  0.7022, -0.5895,  0.2013,  0.0317], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0285,  0.7022, -0.5895,  0.2013,  0.0317], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-4.1989, -2.4674,  1.6752, -0.3436, -2.4897], grad_fn=<SliceBackward0>)
  [Layer 42] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 42] Output sample values after mixer: tensor([-4.1989, -2.4674,  1.6752, -0.3436, -2.4897], grad_fn=<SliceBackward0>)
  [Layer 42] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 42] Residual connection sample values: tensor([-42.0092,   2.1602, -21.3917,   2.3865,  12.3746],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 43/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1074.4866], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0305], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4527,  0.0255, -0.2415,  0.0257,  0.1356], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2729,  0.6161, -0.6971,  0.3900, -1.3113], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2729,  0.6161, -0.6971,  0.3900, -1.3113], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2589, -0.2500, -0.5794, -0.4303, -0.3427], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.2135,  0.4270, -0.7707,  1.0934, -0.7706], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4484, -0.0125, -0.1455, -0.2589,  0.6541], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0538,  0.0364,  0.1200, -0.0756, -0.0630], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0684, -0.0178,  0.0920, -0.1234, -0.0713], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0330, -0.0088,  0.0481, -0.0579, -0.0344], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0330, -0.0088,  0.0481, -0.0579, -0.0344], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0112,  0.0024, -0.0088, -0.2545,  0.1028], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1909,  0.0969, -0.0686, -0.2375,  0.1106], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.7046, -2.6553, -8.2110, -2.2382, -4.0926], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.9381e-01, 1.1915e-01, 2.9430e-02, 8.1944e-01, 5.9256e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4877, 0.7288, 0.7853, 0.1598, 0.9976], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0330, -0.0088,  0.0481, -0.0579, -0.0344], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-7.1411e-05, -1.5063e-05,  5.6054e-05,  1.6284e-03, -6.5791e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.3618e-04, -4.9670e-05, -1.7203e-04,  2.2402e-03, -1.1634e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0034, -0.0022,  0.0035, -0.0064, -0.0040], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0579, -0.0167,  0.0828, -0.1019, -0.0607], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0579, -0.0167,  0.0828, -0.1019, -0.0607], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0068, -0.0067, -0.0192, -0.0237,  0.0169], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0162], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([7.8478], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1385, -0.1822, -0.4178, -0.5195,  0.3826], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1385, -0.1822, -0.4178, -0.5195,  0.3826], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.5184, -4.2713, -1.0717,  7.9264, -2.4681], grad_fn=<SliceBackward0>)
  [Layer 43] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 43] Output sample values after mixer: tensor([ 1.5184, -4.2713, -1.0717,  7.9264, -2.4681], grad_fn=<SliceBackward0>)
  [Layer 43] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 43] Residual connection sample values: tensor([-40.4907,  -2.1111, -22.4634,  10.3130,   9.9065],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 44/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1185.3337], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0290], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4209, -0.0227, -0.2421,  0.1048,  0.1042], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.6191,  0.0276, -0.3467,  0.3249,  0.1733], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.6191,  0.0276, -0.3467,  0.3249,  0.1733], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.6244,  0.0391, -0.5336, -0.4695, -0.5113], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.1146, -1.3464, -0.0847,  0.2761, -0.7105], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2910, -0.7956, -0.5637,  0.6244, -0.8588], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1268, -0.0080, -0.0895,  0.0818, -0.0897], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1483, -0.0650, -0.1182,  0.0687, -0.0830], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0796, -0.0315, -0.0556,  0.0355, -0.0398], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0796, -0.0315, -0.0556,  0.0355, -0.0398], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0115, -0.2183, -0.2785,  0.0738, -0.0209], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1411, -0.2772, -0.1662, -0.1422, -0.1129], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-4.6876, -0.9753, -0.8255, -1.2938, -0.4953], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0890, 0.0117, 0.0226, 0.0594, 0.0038], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6589, 0.9886, 0.9815, 0.9261, 0.9981], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0796, -0.0315, -0.0556,  0.0355, -0.0398], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-8.1351e-05, -1.5467e-03, -1.9730e-03,  5.2314e-04, -1.4811e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0006, -0.0004, -0.0008,  0.0006, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-4.0568e-05, -2.9977e-04, -9.5136e-04,  6.1017e-04,  1.3162e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1383, -0.0550, -0.0976,  0.0623, -0.0690], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1383, -0.0550, -0.0976,  0.0623, -0.0690], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0557, -0.0008,  0.0140,  0.0118, -0.0065], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0195], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([7.1534], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 1.2831, -0.0162,  0.3750,  0.2704, -0.1465], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 1.2831, -0.0162,  0.3750,  0.2704, -0.1465], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.7151,  1.8543,  1.4422,  1.3868, -0.6791], grad_fn=<SliceBackward0>)
  [Layer 44] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 44] Output sample values after mixer: tensor([-0.7151,  1.8543,  1.4422,  1.3868, -0.6791], grad_fn=<SliceBackward0>)
  [Layer 44] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 44] Residual connection sample values: tensor([-41.2058,  -0.2568, -21.0212,  11.6998,   9.2274],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 45/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1228.7800], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0285], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.5045, -0.0034, -0.2704,  0.1437,  0.1145], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6315, -1.6148,  0.1662, -0.4374, -1.4204], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6315, -1.6148,  0.1662, -0.4374, -1.4204], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.3617,  0.9198, -0.6642, -0.4967,  0.7462], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.6298, -0.5277,  0.9528,  1.9191,  0.9498], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1891,  0.3072,  0.2402, -0.3617,  0.3864], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0595,  0.1079, -0.1246,  0.1024,  0.1231], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0652,  0.3660, -0.1468,  0.0464,  0.1124], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0315,  0.2161, -0.0680,  0.0237,  0.0593], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0315,  0.2161, -0.0680,  0.0237,  0.0593], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1623, -0.1621, -0.1149, -0.2742, -0.0664], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2467, -0.1677, -0.0729, -0.0703, -0.2550], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3039e+00, -3.9385e-02, -6.8874e+00, -8.0559e-01, -1.9935e+03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0042, 0.0110, 0.0199, 0.0043, 0.0487], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9459e-01, 9.9957e-01, 8.7186e-01, 9.9656e-01, 6.7823e-43],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0315,  0.2161, -0.0680,  0.0237,  0.0593], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([2.1301e-05, 2.1285e-05, 1.5090e-05, 3.5992e-05, 8.7165e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0017, 0.0010, 0.0012, 0.0002, 0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0009,  0.0314, -0.0081, -0.0115,  0.0059], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0827,  0.5923, -0.1847,  0.0501,  0.1599], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0827,  0.5923, -0.1847,  0.0501,  0.1599], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0181, -0.1587, -0.0166, -0.0086, -0.0442], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1069], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.0578], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2151, -1.4121, -0.1766, -0.0865, -0.5336], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.2151, -1.4121, -0.1766, -0.0865, -0.5336], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-3.9894,  4.0028,  0.5563,  2.7097, -6.3496], grad_fn=<SliceBackward0>)
  [Layer 45] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 45] Output sample values after mixer: tensor([-3.9894,  4.0028,  0.5563,  2.7097, -6.3496], grad_fn=<SliceBackward0>)
  [Layer 45] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 45] Residual connection sample values: tensor([-45.1952,   3.7460, -20.4648,  14.4095,   2.8777],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 46/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1323.4851], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0275], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.5062,  0.0451, -0.2416,  0.1643,  0.0319], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1273, -0.1983,  0.1520, -1.7908,  1.5218], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1273, -0.1983,  0.1520, -1.7908,  1.5218], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.8542, -0.6489,  0.0774,  0.0634,  1.3555], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.0221, -0.0064, -1.2870, -0.2723,  0.5005], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.3961,  0.3865,  1.2188,  0.8542, -0.6814], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0365,  0.1178,  0.0152, -0.0122, -0.2213], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0189,  0.0804,  0.2181, -0.0077, -0.2265], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0096,  0.0418,  0.1209, -0.0038, -0.1005], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0096,  0.0418,  0.1209, -0.0038, -0.1005], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1906, -0.0403, -0.1092, -0.0616, -0.0497], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0478,  0.0366, -0.1155, -0.1064,  0.0529], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.4426,  -0.9830, -10.1590,  -1.3638,  -1.7559],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0090, 0.0139, 0.0003, 0.0100, 0.0179], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9871, 0.9865, 0.9969, 0.9865, 0.9691], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0096,  0.0418,  0.1209, -0.0038, -0.1005], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.6359e-05, -3.4608e-06, -9.3727e-06, -5.2920e-06, -4.2661e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.5148e-03,  2.9957e-04, -5.8946e-05,  4.1067e-04, -8.1832e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0004, -0.0010,  0.0048, -0.0003, -0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0121,  0.0503,  0.1529, -0.0050, -0.1257], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0121,  0.0503,  0.1529, -0.0050, -0.1257], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0008, -0.0045,  0.0125,  0.0013, -0.1570], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0229], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.6107], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0240, -0.1228,  0.2915,  0.0296, -3.6208], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0240, -0.1228,  0.2915,  0.0296, -3.6208], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.3991, -1.7249,  4.8537,  0.9695, -4.1448], grad_fn=<SliceBackward0>)
  [Layer 46] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 46] Output sample values after mixer: tensor([ 1.3991, -1.7249,  4.8537,  0.9695, -4.1448], grad_fn=<SliceBackward0>)
  [Layer 46] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 46] Residual connection sample values: tensor([-43.7961,   2.0211, -15.6112,  15.3790,  -1.2670],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 47/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1466.2673], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0261], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4191,  0.0202, -0.1526,  0.1389, -0.0121], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5594, -0.4050, -0.0665, -0.3174, -0.6133], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5594, -0.4050, -0.0665, -0.3174, -0.6133], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.7600,  0.4322,  1.1128, -1.9382,  0.0553], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.0850, 0.0663, 0.7064, 1.0904, 1.2035], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.7106,  0.2697, -0.2363, -0.7600,  0.9004], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([0.1681, 0.0734, 0.2160, 0.3443, 0.0051], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([0.1552, 0.0884, 0.2149, 0.3511, 0.0032], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([0.0836, 0.0462, 0.1190, 0.2060, 0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([0.0836, 0.0462, 0.1190, 0.2060, 0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0206, -0.0258,  0.0072,  0.0119, -0.2190], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2577, -0.1370,  0.1298, -0.2200, -0.2533], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-5.7667e+01, -2.2024e+00, -3.8371e+00, -4.6046e-02, -2.0700e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0503, 0.0047, 0.0261, 0.0519, 0.0135], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.0549, 0.9896, 0.9048, 0.9976, 0.9724], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([0.0836, 0.0462, 0.1190, 0.2060, 0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-8.6869e-05, -1.0854e-04,  3.0155e-05,  5.0188e-05, -9.2118e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-8.4391e-05, -1.0852e-04,  3.2979e-05,  4.4362e-05, -9.3843e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 1.4525e-03,  8.2553e-04,  2.2204e-03,  3.6213e-03, -1.9753e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([0.1332, 0.0736, 0.1897, 0.3283, 0.0025], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([0.1332, 0.0736, 0.1897, 0.3283, 0.0025], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0271, -0.0119, -0.0061, -0.0439, -0.0005], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0144], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([8.3288], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.7699, -0.3749, -0.1758, -1.8126, -0.0179], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.7699, -0.3749, -0.1758, -1.8126, -0.0179], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.1767, 24.2438, -3.8478,  4.3806,  1.4930], grad_fn=<SliceBackward0>)
  [Layer 47] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 47] Output sample values after mixer: tensor([-1.1767, 24.2438, -3.8478,  4.3806,  1.4930], grad_fn=<SliceBackward0>)
  [Layer 47] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 47] Residual connection sample values: tensor([-44.9728,  26.2649, -19.4590,  19.7596,   0.2260],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 48/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1653.0554], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0246], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4037,  0.2544, -0.1863,  0.1730,  0.0021], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.6706, -1.0581, -0.5411, -0.2348,  0.1616], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.6706, -1.0581, -0.5411, -0.2348,  0.1616], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5649,  0.6336, -0.1194, -1.0255, -0.5217], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.2987, -3.7511, -0.3239,  1.0484,  0.2731], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2603,  0.5810, -0.2116,  0.5649,  1.2447], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0865,  0.1010, -0.0148, -0.1204, -0.0824], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0825,  0.0705, -0.0268, -0.2005, -0.1646], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0396,  0.0365, -0.0132, -0.0902, -0.0756], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0396,  0.0365, -0.0132, -0.0902, -0.0756], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0875, -0.0721, -0.2773, -0.0556,  0.0823], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0220, -0.0269, -0.2665, -0.0561,  0.0170], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.7304,  -7.3891,  -3.3797,  -1.8028, -17.7601],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.1472e-03, 5.0484e-06, 4.6397e-03, 5.4133e-02, 1.2299e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9946, 1.0000, 0.9844, 0.9070, 0.1126], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0396,  0.0365, -0.0132, -0.0902, -0.0756], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.0898e-05,  8.9753e-06,  3.4523e-05,  6.9276e-06, -1.0252e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.6473e-04,  5.1455e-04,  8.7268e-04, -2.1822e-04, -3.2224e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0005,  0.0011, -0.0010, -0.0039, -0.0028], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0567,  0.0530, -0.0199, -0.1322, -0.1102], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0567,  0.0530, -0.0199, -0.1322, -0.1102], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0150, -0.0144,  0.0040,  0.0137, -0.0096], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0075], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([11.5035], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.6122, -0.6600,  0.1711,  0.5221, -0.4991], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.6122, -0.6600,  0.1711,  0.5221, -0.4991], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-2.8036,  0.3554,  6.9393, 10.2602, 14.0709], grad_fn=<SliceBackward0>)
  [Layer 48] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 48] Output sample values after mixer: tensor([-2.8036,  0.3554,  6.9393, 10.2602, 14.0709], grad_fn=<SliceBackward0>)
  [Layer 48] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 48] Residual connection sample values: tensor([-47.7764,  26.6203, -12.5197,  30.0198,  14.2968],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2896.2629], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0186], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.9086,  0.7313, -0.2724,  0.5156,  0.2797], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Final backbone norm output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Final backbone norm output sample values: tensor([-0.9086,  0.7313, -0.2724,  0.5156,  0.2797], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Logits shape: torch.Size([1, 1, 50288])
[Mamba2LMHeadModel] Logits sample values: tensor([-31.1719, -38.5644, -35.2405, -36.2968, -34.2005],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Forward pass input_ids shape: torch.Size([1, 1])
[Mamba2LMHeadModel] input_ids sample values: tensor([1039])
[Mamba2LMHeadModel] Embedding output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Embedding sample values: tensor([-0.4272,  0.0318, -0.2668, -0.1763,  0.0533], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 1/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0395], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([5.0326], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.5160,  0.0489, -0.3534, -0.1819,  0.0602], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.8925, -0.3399,  0.0230,  0.4144, -0.1532], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.8925, -0.3399,  0.0230,  0.4144, -0.1532], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0886, -0.3855,  0.5471, -0.2064,  0.4020], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.2770,  0.0424,  0.1560,  0.1102, -0.0097], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.0157, 0.7267, 0.6464, 0.0886, 0.1471], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0784,  0.5562,  0.0715, -0.0931, -0.0830], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1209,  0.5486,  0.1842, -0.3026, -0.2802], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0641,  0.3477,  0.1006, -0.1286, -0.1206], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0641,  0.3477,  0.1006, -0.1286, -0.1206], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2527, -0.0753, -0.0855,  0.6459, -0.0548], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2734, -0.0565, -0.0598, -0.2042,  0.2382], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4384, -1.0011, -1.2129, -1.1530, -1.4844], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0729, 0.0353, 0.0284, 0.0291, 0.0222], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9686, 0.9652, 0.9661, 0.9670, 0.9675], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0641,  0.3477,  0.1006, -0.1286, -0.1206], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0012, -0.0004, -0.0004,  0.0030, -0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0198, -0.0040, -0.0009,  0.0482, -0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1125,  0.0252,  0.2277, -0.3635, -0.3002], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2224,  0.6215,  0.4002, -0.5840, -0.5070], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2224,  0.6215,  0.4002, -0.5840, -0.5070], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0577, -0.0879,  0.0047, -0.1457,  0.0359], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.9005], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0538], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0544, -0.0684,  0.0036, -0.0929,  0.1171], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0544, -0.0684,  0.0036, -0.0929,  0.1171], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3608,  0.1956,  1.0732, -0.1328, -0.2585], grad_fn=<SliceBackward0>)
  [Layer 1] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 1] Output sample values after mixer: tensor([-0.3608,  0.1956,  1.0732, -0.1328, -0.2585], grad_fn=<SliceBackward0>)
  [Layer 1] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 1] Residual connection sample values: tensor([-0.7880,  0.2274,  0.8063, -0.3090, -0.2053], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 2/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4023], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.5765], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.7176,  0.1739,  0.5692, -0.2959, -0.1702], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.5213, -2.0700, -0.8391,  3.0658, -1.0953], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.5213, -2.0700, -0.8391,  3.0658, -1.0953], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.8233,  0.4484,  1.3937, -5.0439,  0.3850], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.1275,  0.8113, -1.1106,  0.5228,  0.8871], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.6623, 1.4321, 0.1390, 1.8233, 0.4700], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0623, -0.0023, -0.1718, -0.2178, -0.0449], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0529, -0.0322, -0.2836, -0.3618, -0.0415], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0272, -0.0158, -0.1218, -0.1485, -0.0203], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0272, -0.0158, -0.1218, -0.1485, -0.0203], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0253, -0.0111,  0.0830, -0.0395,  0.0122], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0297, -0.0809, -0.2384,  0.2487,  0.0401], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-12.6926, -19.4296,  -0.2289,  -2.1057,  -5.0389],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0445, 0.0770, 0.0082, 0.1035, 0.1324], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5686, 0.2238, 0.9981, 0.8041, 0.5131], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0272, -0.0158, -0.1218, -0.1485, -0.0203], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-3.0631e-05, -1.3454e-05,  1.0026e-04, -4.7696e-05,  1.4703e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 2.0207e-04, -3.7126e-05, -3.6175e-04,  1.5949e-04,  1.6282e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0017,  0.0005, -0.0003,  0.0049,  0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0164, -0.0101, -0.0815, -0.0941, -0.0132], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0164, -0.0101, -0.0815, -0.0941, -0.0132], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0031,  0.0023,  0.0206, -0.2757,  0.0036], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([8.9524], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3342], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0020,  0.0021,  0.0167, -0.1469,  0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0020,  0.0021,  0.0167, -0.1469,  0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1101,  0.0171, -0.2298,  0.0415, -0.0820], grad_fn=<SliceBackward0>)
  [Layer 2] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 2] Output sample values after mixer: tensor([ 0.1101,  0.0171, -0.2298,  0.0415, -0.0820], grad_fn=<SliceBackward0>)
  [Layer 2] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 2] Residual connection sample values: tensor([-0.6780,  0.2445,  0.5765, -0.2676, -0.2873], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 3/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4807], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.4423], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.8489,  0.2570,  0.5396, -0.3586, -0.3433], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 2.9303, -1.1393, -0.8943,  0.1319, -1.9326], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 2.9303, -1.1393, -0.8943,  0.1319, -1.9326], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5941, -0.7755,  0.7784,  2.2696, -0.5298], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.7368, -0.0963, -1.3536,  0.5253,  0.5818], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 2.5472, -0.1130,  0.2154, -0.5941, -0.5313], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0708,  0.0153,  0.4011, -0.1159,  0.1772], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1156, -0.0625,  0.3500, -0.1625,  0.1103], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0545, -0.0303,  0.2053, -0.0747,  0.0582], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0545, -0.0303,  0.2053, -0.0747,  0.0582], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1602,  0.3453, -0.0392, -0.0193, -0.2528], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1454,  0.2174, -0.0880,  0.2046,  0.1365], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-20.9265,  -0.8803,  -0.6735,  -0.6461,  -0.2726],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.6060e-02, 4.3978e-03, 1.1636e-05, 8.8341e-03, 1.8357e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5796, 0.9961, 1.0000, 0.9943, 0.9950], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0545, -0.0303,  0.2053, -0.0747,  0.0582], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.2741e-04, -4.9019e-04,  5.5613e-05,  2.7365e-05,  3.5888e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 1.4085e-05, -6.5049e-04, -1.5435e-04, -1.6850e-05,  1.0061e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0004,  0.0027, -0.0026, -0.0033, -0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0382, -0.0188,  0.1431, -0.0563,  0.0393], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0382, -0.0188,  0.1431, -0.0563,  0.0393], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1063,  0.0052, -0.0371, -0.0040, -0.0096], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([6.8289], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3827], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0730,  0.0032, -0.0180, -0.0021, -0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0730,  0.0032, -0.0180, -0.0021, -0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2477,  0.5479, -0.2706, -0.1016, -0.3020], grad_fn=<SliceBackward0>)
  [Layer 3] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 3] Output sample values after mixer: tensor([-0.2477,  0.5479, -0.2706, -0.1016, -0.3020], grad_fn=<SliceBackward0>)
  [Layer 3] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 3] Residual connection sample values: tensor([-0.9257,  0.7924,  0.3059, -0.3691, -0.5893], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 4/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7294], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1709], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.6361,  0.4716,  0.1714, -0.2697, -0.3810], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4405, -2.4329, -0.5899, -1.0694, -1.6784], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4405, -2.4329, -0.5899, -1.0694, -1.6784], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1960,  1.8550, -1.5264, -1.2792, -0.8869], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.4135,  0.6859,  0.4246,  0.0684, -0.4241], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.7386, -0.7260,  0.0591, -0.1960,  0.5750], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0282, -0.1457,  0.0967, -0.5011,  0.0794], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0502, -0.1332,  0.0563, -0.5658,  0.3384], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0257, -0.0622,  0.0289, -0.2049,  0.1976], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0257, -0.0622,  0.0289, -0.2049,  0.1976], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2575, -0.0756,  0.0713, -0.0215,  0.0228], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2780,  0.5264,  0.4898, -0.0473, -0.0954], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4907, -0.5048, -0.6491, -0.5552, -0.4657], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0672, 0.1102, 0.1249, 0.0423, 0.2277], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9676, 0.9459, 0.9221, 0.9768, 0.8994], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0257, -0.0622,  0.0289, -0.2049,  0.1976], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-4.4525e-04, -1.3072e-04,  1.2328e-04, -3.7108e-05,  3.9516e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0324, -0.0040,  0.0004,  0.0023, -0.0008], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0203,  0.0064, -0.0048, -0.0310,  0.0241], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0374, -0.0349,  0.0144, -0.1670,  0.1551], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0374, -0.0349,  0.0144, -0.1670,  0.1551], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0064,  0.0068, -0.0030,  0.0456, -0.0410], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([5.0227], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4462], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0087,  0.0099, -0.0036,  0.0606, -0.0396], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0087,  0.0099, -0.0036,  0.0606, -0.0396], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1359, -0.1283, -0.2547, -0.0129, -0.2225], grad_fn=<SliceBackward0>)
  [Layer 4] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 4] Output sample values after mixer: tensor([-0.1359, -0.1283, -0.2547, -0.0129, -0.2225], grad_fn=<SliceBackward0>)
  [Layer 4] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 4] Residual connection sample values: tensor([-1.0616,  0.6641,  0.0512, -0.3820, -0.8117], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 5/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.8504], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0844], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.9528,  0.5025,  0.0339, -0.3418, -0.6911], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-4.8556, -0.7839, -0.2321, -1.4057, -0.2891], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-4.8556, -0.7839, -0.2321, -1.4057, -0.2891], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-2.9134, -2.2761,  1.7679,  1.0080, -0.7282], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.2056, -1.8749,  0.8366, -0.9461,  0.9557], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2689,  1.0947, -0.8512, -2.9134, -3.9254], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.9208, -0.8833,  0.1494, -0.1925,  0.1009], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.9841, -1.1246,  0.1420, -0.1656,  0.1118], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2678, -0.2757,  0.0760, -0.0760,  0.0590], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2678, -0.2757,  0.0760, -0.0760,  0.0590], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0356,  0.0507, -0.1933, -0.0818,  0.0204], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0114, -0.1932, -0.2765, -0.1553,  0.0474], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0759, -0.5319, -0.0470, -1.4939, -3.6258], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1300, 0.0022, 0.0830, 0.0055, 0.0416], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9902, 0.9989, 0.9961, 0.9918, 0.8598], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2678, -0.2757,  0.0760, -0.0760,  0.0590], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0012, -0.0018,  0.0067,  0.0028, -0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0222, -0.0009,  0.4953,  0.0540, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3834, -0.4726, -0.3257, -0.1654, -0.0989], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.7602, -0.8606, -0.2187, -0.2723, -0.0158], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.7602, -0.8606, -0.2187, -0.2723, -0.0158], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0285, 0.2115, 0.0224, 0.0754, 0.0020], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([20.8719], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2189], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0021, 0.0162, 0.0035, 0.0130, 0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0021, 0.0162, 0.0035, 0.0130, 0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3829, -0.4988,  0.0303,  0.7028,  0.6256], grad_fn=<SliceBackward0>)
  [Layer 5] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 5] Output sample values after mixer: tensor([-0.3829, -0.4988,  0.0303,  0.7028,  0.6256], grad_fn=<SliceBackward0>)
  [Layer 5] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 5] Residual connection sample values: tensor([-1.4445,  0.1653,  0.0815,  0.3208, -0.1861], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 6/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.4953], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.8178], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.8657,  0.0819,  0.0381,  0.1843, -0.0997], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0176, -0.8117, -0.7900,  0.0353, -2.7396], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0176, -0.8117, -0.7900,  0.0353, -2.7396], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([0.0604, 2.1113, 0.9274, 0.6947, 2.3171], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.5057, -1.8012, -0.4486,  0.2568,  0.0723], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3888,  0.9054,  1.1231,  0.0604, -0.5116], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2513, -0.1688,  0.1028,  0.1154,  0.2936], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2985, -0.1548,  0.1841,  0.1037,  0.4318], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1271, -0.0714,  0.1005,  0.0546,  0.2618], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1271, -0.0714,  0.1005,  0.0546,  0.2618], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0651,  0.1684, -0.2621, -0.0218, -0.1262], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2482,  0.0391, -0.2753,  0.0106, -0.1214], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5110, -0.2862, -0.5421, -0.3954, -0.5986], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0929, 0.0201, 0.0524, 0.1759, 0.1019], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9536, 0.9943, 0.9720, 0.9328, 0.9408], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1271, -0.0714,  0.1005,  0.0546,  0.2618], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0008, -0.0020,  0.0031,  0.0003,  0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0080, -0.0074,  0.0179,  0.0067,  0.0090], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0383, -0.0397, -0.0502,  0.0008,  0.1429], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1841, -0.1216,  0.0650,  0.0634,  0.4432], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1841, -0.1216,  0.0650,  0.0634,  0.4432], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0016,  0.0304, -0.0160,  0.0011, -0.0737], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([21.3592], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2164], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0010,  0.0183, -0.0092,  0.0008, -0.0377], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0010,  0.0183, -0.0092,  0.0008, -0.0377], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5717, -0.5403,  0.2897, -0.5085, -0.7031], grad_fn=<SliceBackward0>)
  [Layer 6] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 6] Output sample values after mixer: tensor([-0.5717, -0.5403,  0.2897, -0.5085, -0.7031], grad_fn=<SliceBackward0>)
  [Layer 6] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 6] Residual connection sample values: tensor([-2.0162, -0.3750,  0.3712, -0.1878, -0.8892], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 7/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.8905], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7273], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-1.0676, -0.1613,  0.1550, -0.1004, -0.4083], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5686, -0.5106, -1.6984,  1.8248, -0.2890], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5686, -0.5106, -1.6984,  1.8248, -0.2890], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3541, -1.3051,  1.0447,  0.8244, -2.0430], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.0489,  1.5259, -0.4046, -0.1675, -0.5542], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-3.0653, -2.6796, -1.3474,  0.3541, -2.1564], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0349, -0.2750,  0.0073,  0.0982, -0.0447], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0685, -0.3462, -0.1237,  0.1066, -0.0474], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0331, -0.1434, -0.0580,  0.0562, -0.0231], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0331, -0.1434, -0.0580,  0.0562, -0.0231], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0282, -0.0817,  0.1605,  0.0234, -0.1551], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0114,  0.0146, -0.1361, -0.0779,  0.2945], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-6.5957e-02, -4.5478e+00, -5.8281e+00, -4.2034e-01, -1.9005e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2038, 0.1440, 0.0244, 0.1191, 0.1156], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9866, 0.5194, 0.8675, 0.9512, 0.9998], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0331, -0.1434, -0.0580,  0.0562, -0.0231], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0002,  0.0006, -0.0011, -0.0002,  0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0997,  0.0108, -0.0348,  0.0039,  0.0888], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2083, -0.1135, -0.1748,  0.0356,  0.0233], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2850, -0.4461, -0.3094,  0.1658, -0.0303], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2850, -0.4461, -0.3094,  0.1658, -0.0303], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0586, 0.0854, 0.0813, 0.2606, 0.0038], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([4.5922], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4666], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0327, 0.0575, 0.0328, 0.1273, 0.0040], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0327, 0.0575, 0.0328, 0.1273, 0.0040], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.8416, -0.9282, -0.2515, -0.2996,  0.3468], grad_fn=<SliceBackward0>)
  [Layer 7] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 7] Output sample values after mixer: tensor([-0.8416, -0.9282, -0.2515, -0.2996,  0.3468], grad_fn=<SliceBackward0>)
  [Layer 7] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 7] Residual connection sample values: tensor([-2.8578, -1.3032,  0.1197, -0.4874, -0.5424], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 8/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.4759], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6355], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-1.7355, -0.5925,  0.0508, -0.2883, -0.2760], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.7291, -2.7487, -1.5139, -2.0388, -3.6229], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.7291, -2.7487, -1.5139, -2.0388, -3.6229], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.9844,  1.8163, -1.4132, -0.2506,  0.3656], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.0516, -2.0670, -0.8539, -0.0502, -1.2031], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-3.2333, -0.8658, -2.0933,  1.9844,  0.5374], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1561, -0.3340,  0.3175, -0.0202, -0.0094], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0787, -0.2529,  0.3839, -0.1172, -0.0720], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0409, -0.1106,  0.2283, -0.0551, -0.0347], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0409, -0.1106,  0.2283, -0.0551, -0.0347], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0443,  0.4339, -0.0260, -0.1668, -0.0116], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0630,  0.0540, -0.1948, -0.0366,  0.2005], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6851, -0.1380, -0.4118, -0.2678, -0.1244], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0530, 0.3870, 0.1516, 0.3799, 0.6423], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9644, 0.9480, 0.9395, 0.9033, 0.9232], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0409, -0.1106,  0.2283, -0.0551, -0.0347], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 9.5963e-05,  9.4039e-04, -5.6408e-05, -3.6147e-04, -2.5149e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0045, -0.0243,  0.0006, -0.0298,  0.0083], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0883, -0.0093,  0.0458, -0.0388, -0.0209], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0658, -0.4257,  0.9057, -0.2466, -0.1515], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0658, -0.4257,  0.9057, -0.2466, -0.1515], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0966,  0.0704, -0.2473,  0.0579,  0.0143], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([61.9211], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1271], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0284,  0.0109, -0.1183,  0.0236,  0.0040], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0284,  0.0109, -0.1183,  0.0236,  0.0040], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3315, -0.7763, -0.4053, -0.4161,  0.9254], grad_fn=<SliceBackward0>)
  [Layer 8] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 8] Output sample values after mixer: tensor([-0.3315, -0.7763, -0.4053, -0.4161,  0.9254], grad_fn=<SliceBackward0>)
  [Layer 8] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 8] Residual connection sample values: tensor([-3.1893, -2.0795, -0.2856, -0.9035,  0.3830], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 9/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.9832], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5790], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-1.6986, -0.8560, -0.1126, -0.4825,  0.1777], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4035, -3.5910, -3.5295, -1.2367, -2.2713], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4035, -3.5910, -3.5295, -1.2367, -2.2713], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 3.7295, -0.9914, -1.4892,  0.5001, -0.7201], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.9250, -0.6423,  0.4148,  0.9968, -0.4581], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 2.8223,  1.1386,  2.1009,  3.7295, -3.0782], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-1.2697, -0.2630, -0.7049, -0.0949, -0.0622], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-1.5231, -0.1725, -0.7091, -0.0882, -0.0808], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2726, -0.0788, -0.2339, -0.0421, -0.0388], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2726, -0.0788, -0.2339, -0.0421, -0.0388], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0661, -0.0349,  0.2212, -0.0883,  0.2570], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.2354, -0.2756,  0.0302, -0.2048, -0.0266], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1701, -0.1135, -0.1054, -0.5864, -0.1497], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4711, 0.7781, 2.3077, 0.4777, 0.5694], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9230, 0.9155, 0.7841, 0.7557, 0.9183], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2726, -0.0788, -0.2339, -0.0421, -0.0388], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0085,  0.0045, -0.0284,  0.0113, -0.0330], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0252, -0.0034, -0.3146,  0.3240,  0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.7179,  0.0154, -0.4032, -0.0760,  0.1585], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-1.4485, -0.1958, -1.0298, -0.1889,  0.0545], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-1.4485, -0.1958, -1.0298, -0.1889,  0.0545], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.2341,  0.0189,  0.1035,  0.0526, -0.0116], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([20.2988], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2220], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0451,  0.0068,  0.0249,  0.0145, -0.0032], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0451,  0.0068,  0.0249,  0.0145, -0.0032], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 3.0546, -0.4087,  2.4187,  1.6659,  1.6866], grad_fn=<SliceBackward0>)
  [Layer 9] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 9] Output sample values after mixer: tensor([ 3.0546, -0.4087,  2.4187,  1.6659,  1.6866], grad_fn=<SliceBackward0>)
  [Layer 9] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 9] Residual connection sample values: tensor([-0.1347, -2.4882,  2.1331,  0.7624,  2.0696], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 10/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([6.4357], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3942], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0524, -0.7394,  0.6187,  0.2917,  0.6816], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-3.1731, -1.9992, -1.1166, -1.9804, -0.0367], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-3.1731, -1.9992, -1.1166, -1.9804, -0.0367], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.1614, -1.8032, -1.8599,  1.0350,  5.3950], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.9985, -0.6844, -0.6800, -3.0031, -0.9942], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8985, -2.8205, -2.0003,  0.1614, -0.8320], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6838, -0.1113,  0.3260,  0.2848, -1.1133], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.8541, -0.1352,  0.2880,  0.8888, -1.0644], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2550, -0.0631,  0.1646,  0.6298, -0.2730], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2550, -0.0631,  0.1646,  0.6298, -0.2730], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0525,  0.2067,  0.0527, -0.1036, -0.0338], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.5997, -0.1751, -0.1801, -0.2697,  0.1532], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0854, -0.0771, -0.0845, -0.0547, -0.0697], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3356, 0.0476, 0.0469, 0.1389, 0.2478], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9718, 0.9963, 0.9960, 0.9924, 0.9829], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2550, -0.0631,  0.1646,  0.6298, -0.2730], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0045, -0.0177, -0.0045,  0.0089,  0.0029], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0879, -1.0221, -0.0300,  0.4922, -0.1094], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-2.7959, -0.8047, -1.4141, 14.2900, -0.3982], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-4.0376, -1.1117, -0.6127, 17.3567, -1.7274], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-4.0376, -1.1117, -0.6127, 17.3567, -1.7274], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.5149,  0.2651,  0.1687, -4.1687,  0.0311], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([191.8880], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0722], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0227,  0.0250,  0.0174, -0.3309,  0.0030], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0227,  0.0250,  0.0174, -0.3309,  0.0030], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.4547, -0.2645,  0.0484, -0.9494,  0.4590], grad_fn=<SliceBackward0>)
  [Layer 10] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 10] Output sample values after mixer: tensor([ 0.4547, -0.2645,  0.0484, -0.9494,  0.4590], grad_fn=<SliceBackward0>)
  [Layer 10] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 10] Residual connection sample values: tensor([ 0.3200, -2.7528,  2.1815, -0.1870,  2.5286], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 11/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([7.5446], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3641], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0841, -0.5872,  0.4514, -0.0537,  0.5884], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.2858, -0.4421, -2.6172,  0.9365, -1.9161], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.2858, -0.4421, -2.6172,  0.9365, -1.9161], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.5225,  0.9414,  0.2617,  0.6699, -1.5001], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.8407, -1.2499, -1.7453, -0.8273, -0.7383], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1301, -0.4402, -1.1526, -1.5225, -0.9644], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4516, -0.1476, -0.1074, -0.1000, -0.3400], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.5981,  0.0436, -0.0835,  0.0074, -0.2251], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.3859,  0.0223, -0.0400,  0.0037, -0.0999], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.3859,  0.0223, -0.0400,  0.0037, -0.0999], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2487,  0.1111, -0.0155,  0.2499, -0.1174], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2735,  0.0100, -0.0888,  0.0364, -0.2784], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2593, -0.1261, -0.1036, -0.2378, -0.4305], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0358, 0.0207, 0.0282, 0.2976, 0.4086], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9908, 0.9974, 0.9971, 0.9317, 0.8387], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.3859,  0.0223, -0.0400,  0.0037, -0.0999], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0034,  0.0015, -0.0002,  0.0035, -0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1879,  0.0122,  0.0186, -0.0819,  0.1104], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([0.4443, 0.4307, 0.4631, 0.2392, 0.6794], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.7730,  0.3606,  0.5893,  0.2274,  0.9945], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.7730,  0.3606,  0.5893,  0.2274,  0.9945], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.7787, -0.0624, -0.1049,  0.1530, -0.2445], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([18.3722], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2333], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0637, -0.0378, -0.1141,  0.0313, -0.0583], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0637, -0.0378, -0.1141,  0.0313, -0.0583], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.9391,  0.8008, -1.3874, -0.4389, -0.0103], grad_fn=<SliceBackward0>)
  [Layer 11] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 11] Output sample values after mixer: tensor([-0.9391,  0.8008, -1.3874, -0.4389, -0.0103], grad_fn=<SliceBackward0>)
  [Layer 11] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 11] Residual connection sample values: tensor([-0.6191, -1.9520,  0.7942, -0.6258,  2.5183], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 12/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([8.6958], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3391], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1346, -0.3381,  0.1258, -0.1543,  0.4633], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.2512, -1.4871,  0.6211, -0.5367, -1.4057], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.2512, -1.4871,  0.6211, -0.5367, -1.4057], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-2.4550,  3.5918, -0.5253,  2.3211,  1.4816], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-2.2731, -2.2532, -2.9210, -3.8101, -1.3038], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6272,  0.5588, -0.7531, -2.4550,  0.5299], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0919,  0.6172,  0.2340,  0.5149,  0.1672], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1591, -0.2173,  0.1693,  0.4707,  0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-7.3239e-02, -9.6900e-02,  9.1775e-02,  2.8974e-01,  2.7469e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-7.3239e-02, -9.6900e-02,  9.1775e-02,  2.8974e-01,  2.7469e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1244, -0.2774,  0.0575,  0.6464, -0.1142], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.3592, -0.1636,  0.2838, -0.2577,  0.4443], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1609, -0.1475, -0.2713, -0.1155, -0.0902], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1602, 0.0784, 0.1077, 0.0810, 0.0194], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9746, 0.9885, 0.9712, 0.9907, 0.9982], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-7.3239e-02, -9.6900e-02,  9.1775e-02,  2.8974e-01,  2.7469e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0015,  0.0033, -0.0007, -0.0076,  0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0318,  0.0048,  0.0624, -0.1360, -0.0345], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2777, -1.6950,  0.1188,  0.0291,  3.8780], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3966, -1.8523,  0.2677,  0.4993,  3.8785], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3966, -1.8523,  0.2677,  0.4993,  3.8785], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.3858,  0.5078,  0.1081, -0.0989, -1.0736], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([47.3522], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1453], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0851,  0.0654,  0.0273, -0.0471, -0.2037], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0851,  0.0654,  0.0273, -0.0471, -0.2037], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.8250, -0.0097, -0.2737,  0.7486,  0.6901], grad_fn=<SliceBackward0>)
  [Layer 12] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 12] Output sample values after mixer: tensor([ 0.8250, -0.0097, -0.2737,  0.7486,  0.6901], grad_fn=<SliceBackward0>)
  [Layer 12] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 12] Residual connection sample values: tensor([ 0.2060, -1.9617,  0.5205,  0.1228,  3.2084], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 13/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([9.7726], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3199], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0356, -0.2770,  0.0700,  0.0228,  0.4976], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1973, -1.7762, -0.7375,  0.1745, -0.9049], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1973, -1.7762, -0.7375,  0.1745, -0.9049], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.9691,  0.7766, -0.2069,  0.3977, -2.0527], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.9641, -1.7811, -0.3393, -1.4592, -0.4617], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2538,  0.1219,  0.5625, -0.9691, -0.0330], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2297, -0.2348, -0.1650,  0.0029, -0.4524], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2917, -0.2535, -0.1571, -0.0089, -0.4829], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1247, -0.1108, -0.0724, -0.0044, -0.1843], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1247, -0.1108, -0.0724, -0.0044, -0.1843], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.2042, -0.1645,  0.0320,  0.1314, -0.0489], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.4781, -0.1407,  0.2359,  0.0469, -0.2677], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0234, -1.0903, -0.5085, -0.6785, -0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0204, 0.0017, 0.0061, 0.0012, 0.0987], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9995, 0.9982, 0.9969, 0.9992, 0.9975], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1247, -0.1108, -0.0724, -0.0044, -0.1843], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.1869e-04,  4.1782e-04, -8.1284e-05, -3.3376e-04,  1.2419e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0931,  0.1024, -0.2829,  0.0229, -0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1479, -0.0389, -0.0034, -0.0017,  0.3091], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1335, -0.0261,  0.0050, -0.0012,  0.3304], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1335, -0.0261,  0.0050, -0.0012,  0.3304], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0145,  0.0067, -0.0012, -0.0001, -0.0861], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7636], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1444], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0083,  0.0025, -0.0015, -0.0004, -0.0568], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0083,  0.0025, -0.0015, -0.0004, -0.0568], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1318,  0.0426,  0.0675,  0.9830,  0.1811], grad_fn=<SliceBackward0>)
  [Layer 13] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 13] Output sample values after mixer: tensor([-0.1318,  0.0426,  0.0675,  0.9830,  0.1811], grad_fn=<SliceBackward0>)
  [Layer 13] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 13] Residual connection sample values: tensor([ 0.0742, -1.9191,  0.5880,  1.1057,  3.3895], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 14/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([11.3819], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2964], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0104, -0.2333,  0.0699,  0.1762,  0.4472], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.8807, -2.0753, -0.9601, -0.3568, -0.3810], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.8807, -2.0753, -0.9601, -0.3568, -0.3810], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.9533, -0.7754, -1.9212,  0.5932, -0.9464], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.2190, -0.9910, -0.1440,  1.9238,  0.7879], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.3864,  0.0043, -0.3358, -0.9533,  0.4325], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2032, -0.2756, -0.8353, -0.1345,  0.2594], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2736, -0.3250, -1.0271, -0.1821,  0.2456], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1554, -0.1363, -0.2708, -0.0828,  0.1378], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1554, -0.1363, -0.2708, -0.0828,  0.1378], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0376, -0.0225, -0.1590,  0.0278, -0.1072], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0659,  0.0194, -0.1437,  0.0510, -0.1637], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-7.2745, -0.0385, -2.2024, -0.0138, -5.3378], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0165, 0.0226, 0.0102, 0.3004, 0.0355], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8867, 0.9991, 0.9778, 0.9959, 0.8275], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1554, -0.1363, -0.2708, -0.0828,  0.1378], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-9.6593e-05, -5.7738e-05, -4.0857e-04,  7.1496e-05, -2.7551e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-3.3218e-04,  1.1498e-05, -6.3636e-04,  5.9719e-04, -8.8120e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0074, -0.0095, -0.0241,  0.0001,  0.0075], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1297, -0.1168, -0.2372, -0.0650,  0.1159], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1297, -0.1168, -0.2372, -0.0650,  0.1159], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0335,  0.0270,  0.0630,  0.0096, -0.0179], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2805], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.8880], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1490,  0.0839,  0.1342,  0.0294, -0.0702], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1490,  0.0839,  0.1342,  0.0294, -0.0702], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1258, -0.1351,  0.0449,  0.1030,  0.7703], grad_fn=<SliceBackward0>)
  [Layer 14] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 14] Output sample values after mixer: tensor([-0.1258, -0.1351,  0.0449,  0.1030,  0.7703], grad_fn=<SliceBackward0>)
  [Layer 14] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 14] Residual connection sample values: tensor([-0.0516, -2.0542,  0.6329,  1.2087,  4.1598], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 15/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([12.8865], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2786], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0087, -0.2864,  0.0886,  0.2428,  0.6581], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-3.9481,  4.5811, -0.0699, -0.8164, -4.2304], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-3.9481,  4.5811, -0.0699, -0.8164, -4.2304], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.5488, -0.1879,  0.9661,  1.6963,  1.9254], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.8633, -2.3716, -0.0516, -4.2298,  0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1975, -3.2269,  0.9594,  1.5488,  0.0405], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1636, -0.0504,  0.2574,  0.3495, -0.0777], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4998, -0.0746,  1.5826,  0.7921, -0.0912], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1887, -0.0359,  1.3129,  0.5452, -0.0435], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1887, -0.0359,  1.3129,  0.5452, -0.0435], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0900, -0.0600, -0.0270, -0.0815, -0.0910], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0535, -0.0541, -0.1043, -0.0387, -0.1120], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.4414, -0.0592, -0.7390, -0.0051, -0.0087], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1414, 0.0522, 0.0208, 0.0007, 0.1416], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7081, 0.9969, 0.9847, 1.0000, 0.9988], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1887, -0.0359,  1.3129,  0.5452, -0.0435], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([0.0024, 0.0016, 0.0007, 0.0022, 0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0039,  0.0067, -0.0008,  0.0048,  0.0082], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0111,  0.0026,  0.0735,  0.0215,  0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3481, -0.0615,  2.4181,  0.9952, -0.0757], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3481, -0.0615,  2.4181,  0.9952, -0.0757], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0260, -0.2787, -0.0816, -0.2490,  0.0046], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.4034], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6450], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0371, -0.2899, -0.0249, -0.2000,  0.0067], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0371, -0.2899, -0.0249, -0.2000,  0.0067], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1961, -0.1699,  0.4872, -0.3710,  0.7006], grad_fn=<SliceBackward0>)
  [Layer 15] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 15] Output sample values after mixer: tensor([ 0.1961, -0.1699,  0.4872, -0.3710,  0.7006], grad_fn=<SliceBackward0>)
  [Layer 15] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 15] Residual connection sample values: tensor([ 0.1445, -2.2241,  1.1201,  0.8378,  4.8604], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 16/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([13.8067], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2691], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0176, -0.2233,  0.1048,  0.1291,  0.5582], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4911, -0.1843, -5.4154,  1.4797,  0.4055], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4911, -0.1843, -5.4154,  1.4797,  0.4055], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 2.1004,  0.0799, -0.7569, -2.2378,  0.2883], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.4037, 0.7706, 1.2988, 1.0708, 0.4846], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1357,  0.8545,  1.4791,  2.1004,  0.2263], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1495, -0.0156, -0.2936,  0.1516,  0.0871], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1477, -0.0068, -0.1569,  0.1135,  0.0946], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0793, -0.0034, -0.0723,  0.0599,  0.0495], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0793, -0.0034, -0.0723,  0.0599,  0.0495], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0296, -0.0815, -0.1043, -0.0134, -0.0269], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0958, -0.0872,  0.0294, -0.2688, -0.2097], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.1349e-03, -3.0370e-03, -2.7156e+00, -4.1511e-03, -4.2926e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6536, 0.1380, 0.0839, 0.0769, 0.0018], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9993, 0.9996, 0.7962, 0.9997, 0.9992], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0793, -0.0034, -0.0723,  0.0599,  0.0495], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0015, -0.0042, -0.0054, -0.0007, -0.0014], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0334,  0.0945,  0.0316,  0.0017, -0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0392,  0.0565, -0.1973,  0.1024,  0.0762], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0208,  0.0573, -0.1805,  0.0885,  0.0647], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0208,  0.0573, -0.1805,  0.0885,  0.0647], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0039, -0.0048,  0.0043,  0.1066,  0.0157], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1125], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.9816], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0051, -0.0036,  0.0130,  0.0556,  0.0244], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0051, -0.0036,  0.0130,  0.0556,  0.0244], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.9261,  0.1053,  0.1509, -0.3371, -0.3517], grad_fn=<SliceBackward0>)
  [Layer 16] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 16] Output sample values after mixer: tensor([-0.9261,  0.1053,  0.1509, -0.3371, -0.3517], grad_fn=<SliceBackward0>)
  [Layer 16] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 16] Residual connection sample values: tensor([-0.7816, -2.1189,  1.2710,  0.5007,  4.5087], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 17/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([14.2121], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2653], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1400, -0.3266,  0.1957,  0.1028,  0.7440], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-4.9148, -0.9500, -0.0538, -0.7534, -1.8358], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-4.9148, -0.9500, -0.0538, -0.7534, -1.8358], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3392,  0.2056,  0.3105, -0.1566,  0.5875], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.3603,  0.6252, -0.9854,  0.4119, -0.9528], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.7254,  2.4675,  1.2513,  0.3392, -1.4417], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2373,  0.2130,  0.0345,  0.0073,  0.1440], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3323,  0.2351, -0.0799,  0.0418,  0.2392], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1388,  0.1313, -0.0384,  0.0213,  0.1339], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1388,  0.1313, -0.0384,  0.0213,  0.1339], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0392,  0.1019, -0.2735,  0.0154, -0.0441], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1928, -0.1483, -0.2706, -0.1461, -0.0306], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3863, -0.8773, -1.4027, -0.6828, -0.3905], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0992, 0.1499, 0.0506, 0.3580, 0.1353], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8715, 0.8768, 0.9315, 0.7832, 0.9485], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1388,  0.1313, -0.0384,  0.0213,  0.1339], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0005, -0.0014,  0.0038, -0.0002,  0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0071,  0.0115, -0.0391,  0.0052, -0.0350], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1197,  0.0949, -0.0896,  0.0812,  0.0420], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2459,  0.4408, -0.1906,  0.1373,  0.3945], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2459,  0.4408, -0.1906,  0.1373,  0.3945], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0088, -0.1168,  0.0050, -0.0331, -0.0996], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([8.2563], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3480], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0060, -0.0810,  0.0036, -0.0297, -0.0825], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0060, -0.0810,  0.0036, -0.0297, -0.0825], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0328,  0.6964,  1.2554,  0.1306, -1.0067], grad_fn=<SliceBackward0>)
  [Layer 17] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 17] Output sample values after mixer: tensor([-0.0328,  0.6964,  1.2554,  0.1306, -1.0067], grad_fn=<SliceBackward0>)
  [Layer 17] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 17] Residual connection sample values: tensor([-0.8144, -1.4225,  2.5264,  0.6312,  3.5020], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 18/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([16.2007], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2484], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0971, -0.1466,  0.2565,  0.0914,  0.3694], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1692, -0.1500, -1.4208, -0.8217, -1.0347], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1692, -0.1500, -1.4208, -0.8217, -1.0347], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2216,  1.0389, -0.4086,  0.5723,  0.3319], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.3173,  4.8835,  4.1349, -0.0186,  2.7635], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1540, -0.6895, -0.5580, -0.2216, -1.2625], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0668,  0.4907,  0.1007,  0.0183, -0.2932], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0761,  0.0927,  0.1120,  0.0489, -0.3455], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0395,  0.0485,  0.0591,  0.0250, -0.1432], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0395,  0.0485,  0.0591,  0.0250, -0.1432], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0640,  0.0519, -0.0199, -0.0460,  0.0471], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0072, -0.0284,  0.0782, -0.1407,  0.0151], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.3195e-03, -6.5336e+00, -1.4897e+01, -1.3796e-03, -2.0873e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.8871, 5.9973, 5.5849, 0.1078, 1.2028], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9794e-01, 9.6097e-18, 7.3601e-37, 9.9985e-01, 9.9749e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0395,  0.0485,  0.0591,  0.0250, -0.1432], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0022,  0.0018, -0.0007, -0.0016,  0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0037, -0.0059,  0.0922, -0.0412,  0.0141], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2565, -1.4010,  0.1328, -0.1766, -0.3237], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2596, -1.4049,  0.1281, -0.1786, -0.3123], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2596, -1.4049,  0.1281, -0.1786, -0.3123], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0201,  0.0975, -0.0354,  0.0448,  0.0847], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([11.0176], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3013], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0299,  0.0355, -0.0116,  0.0342,  0.0304], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0299,  0.0355, -0.0116,  0.0342,  0.0304], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1636,  0.4726,  0.5227, -0.4430,  0.1058], grad_fn=<SliceBackward0>)
  [Layer 18] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 18] Output sample values after mixer: tensor([ 0.1636,  0.4726,  0.5227, -0.4430,  0.1058], grad_fn=<SliceBackward0>)
  [Layer 18] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 18] Residual connection sample values: tensor([-0.6508, -0.9499,  3.0491,  0.1882,  3.6078], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 19/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([16.5592], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2457], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0954, -0.1156,  0.3750,  0.0341,  0.4693], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6758, -1.5816, -1.5125, -0.8465, -1.3843], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6758, -1.5816, -1.5125, -0.8465, -1.3843], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5868,  0.8876, -1.4626,  1.9380,  0.4223], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.1211, -0.2919,  0.0439, -1.7282, -1.5418], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.2169,  1.5319, -1.0119, -0.5868, -0.1216], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2049,  0.2436, -0.3610, -0.7673,  0.0800], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2563,  0.2441, -0.3748, -0.9749,  0.0788], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1118,  0.1369, -0.1527, -0.2670,  0.0410], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1118,  0.1369, -0.1527, -0.2670,  0.0410], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0184,  0.1403,  1.2259, -0.1754,  0.4237], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0810, -0.0082, -0.0576, -0.1470,  0.1106], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1739, -1.5063, -1.5725, -0.1983, -0.0768], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6145, 0.2184, 0.3291, 0.4458, 0.0901], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8986, 0.7196, 0.5960, 0.9154, 0.9931], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1118,  0.1369, -0.1527, -0.2670,  0.0410], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0013, -0.0096, -0.0842,  0.0121, -0.0291], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0142,  0.0264, -0.1178,  0.0355,  0.0194], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3908,  0.1030,  0.0007, -0.2030,  0.3831], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.5610,  0.3115, -0.2318, -0.6096,  0.4454], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.5610,  0.3115, -0.2318, -0.6096,  0.4454], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1278, -0.0840,  0.0633,  0.1549, -0.1235], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([9.1454], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3307], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0493, -0.0561,  0.0503,  0.0507, -0.1495], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0493, -0.0561,  0.0503,  0.0507, -0.1495], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3256, -0.3656,  1.6029, -0.2539,  0.6464], grad_fn=<SliceBackward0>)
  [Layer 19] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 19] Output sample values after mixer: tensor([-0.3256, -0.3656,  1.6029, -0.2539,  0.6464], grad_fn=<SliceBackward0>)
  [Layer 19] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 19] Residual connection sample values: tensor([-0.9765, -1.3155,  4.6520, -0.0657,  4.2541], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 20/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([19.0911], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2289], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0824, -0.1017,  0.3597, -0.0068,  0.3509], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3661, -0.9036,  1.0133, -0.9515, -0.2316], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3661, -0.9036,  1.0133, -0.9515, -0.2316], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3091, -1.4873, -1.2089, -0.1189, -0.6225], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.1482,  0.4390,  0.9060,  1.1214,  0.1198], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.2464,  0.0231, -0.1964,  0.3091, -0.3891], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0656,  0.4363, -0.4272,  0.0166, -0.0946], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0511,  0.3981, -0.6068, -0.0044, -0.1411], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0262,  0.2382, -0.2141, -0.0022, -0.0656], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0262,  0.2382, -0.2141, -0.0022, -0.0656], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0172, -0.0555,  0.0582, -0.0253, -0.0426], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1020, -0.0419, -0.1224, -0.2742, -0.1819], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.0858e-01, -2.9306e+00, -5.2962e+00, -1.2326e+01, -8.1593e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0023, 0.0404, 0.1411, 0.2177, 0.0474], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9993, 0.8883, 0.4737, 0.0683, 0.9996], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0262,  0.2382, -0.2141, -0.0022, -0.0656], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.0162e-06, -3.2808e-06,  3.4401e-06, -1.4964e-06, -2.5187e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.2053e-04, -2.4480e-04, -1.9222e-04,  9.3849e-05, -4.8734e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0004,  0.0006, -0.0020,  0.0019, -0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 2.1970e-02,  1.9646e-01, -1.7806e-01,  1.2555e-04, -5.5138e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 2.1970e-02,  1.9646e-01, -1.7806e-01,  1.2555e-04, -5.5138e-02],
       grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-3.2938e-03, -5.1182e-02, -1.3237e-01, -3.3280e-05,  5.6479e-03],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0404], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([4.9730], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-4.1013e-02, -5.4882e-01, -9.7713e-01, -4.0340e-04,  4.4736e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-4.1013e-02, -5.4882e-01, -9.7713e-01, -4.0340e-04,  4.4736e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.3967,  0.7691, -0.1083, -1.3215, -0.5824], grad_fn=<SliceBackward0>)
  [Layer 20] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 20] Output sample values after mixer: tensor([ 1.3967,  0.7691, -0.1083, -1.3215, -0.5824], grad_fn=<SliceBackward0>)
  [Layer 20] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 20] Residual connection sample values: tensor([ 0.4202, -0.5464,  4.5436, -1.3872,  3.6718], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 21/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([19.8657], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2244], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0476, -0.0561,  0.4776, -0.1860,  0.4002], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0132, -1.0807,  0.4365, -0.5838, -0.4900], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0132, -1.0807,  0.4365, -0.5838, -0.4900], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-2.0421,  0.1544,  0.1789,  1.2067, -0.2672], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-2.0973, -0.7712, -1.9047, -1.8196, -1.2612], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5755, -0.0821, -0.4285, -2.0421,  0.1980], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6324,  0.0677,  0.1802, -0.3041, -0.0791], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.9899, -0.0298,  0.1546, -0.4022, -0.1331], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2682, -0.0147,  0.0832, -0.1612, -0.0621], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2682, -0.0147,  0.0832, -0.1612, -0.0621], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.4085, -0.1035, -0.0965, -0.0947, -0.0410], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1017, -0.1476, -0.0295, -0.0329, -0.1678], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3228, -0.3764, -0.1595, -0.1054, -0.3757], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1247, 0.3091, 0.1697, 0.0861, 0.1909], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9606, 0.8902, 0.9733, 0.9910, 0.9308], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2682, -0.0147,  0.0832, -0.1612, -0.0621], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0137,  0.0035,  0.0032,  0.0032,  0.0014], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0034, 0.1289, 0.0318, 0.0659, 0.0155], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.4328, -0.1513, -0.1006, -0.1178,  0.3997], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.9997, -0.1823,  0.0753, -0.4585,  0.2684], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.9997, -0.1823,  0.0753, -0.4585,  0.2684], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0065,  0.0499,  0.0200,  0.0958, -0.0500], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([3.3421], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5470], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0075,  0.0718,  0.0325,  0.1094, -0.0492], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0075,  0.0718,  0.0325,  0.1094, -0.0492], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2611, -1.1774, -1.6048,  2.0877,  1.2000], grad_fn=<SliceBackward0>)
  [Layer 21] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 21] Output sample values after mixer: tensor([ 0.2611, -1.1774, -1.6048,  2.0877,  1.2000], grad_fn=<SliceBackward0>)
  [Layer 21] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 21] Residual connection sample values: tensor([ 0.6813, -1.7238,  2.9389,  0.7005,  4.8718], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 22/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([21.7259], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2145], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0756, -0.1769,  0.3019,  0.0918,  0.5236], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.9020,  0.4501,  0.6051, -4.9487,  0.7992], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.9020,  0.4501,  0.6051, -4.9487,  0.7992], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2561,  1.3061, -1.3555, -1.8725, -1.4498], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.8408, -3.8005, -1.5670, -1.3165, -1.0127], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.3219, -0.0115, -0.3442,  0.2561,  1.2203], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0333,  0.1321, -0.1289, -0.4112, -0.0568], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0251,  0.1966, -0.1162, -0.4295, -0.0562], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0124,  0.1079, -0.0547, -0.1693, -0.0273], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0124,  0.1079, -0.0547, -0.1693, -0.0273], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2726,  0.1546,  0.1963, -0.0983,  0.0857], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2781,  0.5873,  0.7944, -0.2768, -0.1215], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0709, -0.0702, -0.0699, -0.0895, -0.3897], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0985, 0.0254, 0.0252, 0.0993, 0.3227], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9930, 0.9982, 0.9982, 0.9912, 0.8818], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0124,  0.1079, -0.0547, -0.1693, -0.0273], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0003, -0.0002, -0.0002,  0.0001, -0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0052, 0.0237, 0.0050, 0.0131, 0.0441], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0079,  0.2402, -0.2616, -0.0575,  0.0129], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0135,  0.0542, -0.1672,  0.2345,  0.0599], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0135,  0.0542, -0.1672,  0.2345,  0.0599], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0087,  0.0149, -0.0654, -0.0082,  0.0330], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([6.5501], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3907], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0090,  0.0067, -0.0676, -0.0125,  0.0325], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0090,  0.0067, -0.0676, -0.0125,  0.0325], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.0991,  0.5769, -0.8378, -2.9062,  4.0343], grad_fn=<SliceBackward0>)
  [Layer 22] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 22] Output sample values after mixer: tensor([-1.0991,  0.5769, -0.8378, -2.9062,  4.0343], grad_fn=<SliceBackward0>)
  [Layer 22] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 22] Residual connection sample values: tensor([-0.4178, -1.1469,  2.1011, -2.2057,  8.9061], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 23/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([29.7689], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1833], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0337, -0.0835,  0.1610, -0.2185,  0.6679], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.2124,  0.2871, -1.5917,  0.4878, -1.7670], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.2124,  0.2871, -1.5917,  0.4878, -1.7670], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2032, -0.0412,  0.9685,  0.3187, -1.4771], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.3000, -0.8501, -0.8745, -1.3148, -1.0587], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.7956, -1.5488,  0.0025,  0.2032,  0.3186], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1063,  0.2809, -0.0192, -0.1058,  0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1400,  0.2733, -0.0612, -0.0894, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0651,  0.1552, -0.0296, -0.0427, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0651,  0.1552, -0.0296, -0.0427, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([0.7062, 0.1630, 0.0570, 0.8328, 0.0364], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0864, -0.1232,  0.5096,  0.1799, -0.0779], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1232, -0.2255, -0.2420, -0.0956, -0.2396], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0201, 0.0975, 0.0923, 0.0205, 0.0642], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9975, 0.9783, 0.9779, 0.9980, 0.9847], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0651,  0.1552, -0.0296, -0.0427, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-9.2536e-04, -2.1359e-04, -7.4748e-05, -1.0913e-03, -4.7721e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0257,  0.0123, -0.0014,  0.0768, -0.0115], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0278,  0.0222,  0.1836, -0.0256,  0.0351], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0309,  0.0150,  0.1850, -0.0236,  0.0351], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0309,  0.0150,  0.1850, -0.0236,  0.0351], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0086,  0.0025, -0.0498, -0.0071, -0.0090], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1918], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.2832], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0193,  0.0167, -0.5576, -0.0801, -0.0566], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0193,  0.0167, -0.5576, -0.0801, -0.0566], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.1751, -2.3110,  2.2873,  2.0696, -2.9925], grad_fn=<SliceBackward0>)
  [Layer 23] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 23] Output sample values after mixer: tensor([ 1.1751, -2.3110,  2.2873,  2.0696, -2.9925], grad_fn=<SliceBackward0>)
  [Layer 23] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 23] Residual connection sample values: tensor([ 0.7573, -3.4579,  4.3884, -0.1361,  5.9136], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 24/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([33.5101], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1727], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0722, -0.2928,  0.4038, -0.0149,  0.5198], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3597, -0.9660, -0.7386, -1.4428, -1.2720], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3597, -0.9660, -0.7386, -1.4428, -1.2720], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.1667, -1.8085, -0.6329, -0.9614,  0.6206], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.2009, -1.7054, -0.2276, -1.1580, -0.5833], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2574,  0.2398, -0.4168,  0.1667, -2.2652], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0328, -0.2081, -0.0855, -0.2517, -0.1676], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0941, -0.1107, -0.0877, -0.3308, -0.1607], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0493, -0.0523, -0.0419, -0.1383, -0.0739], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0493, -0.0523, -0.0419, -0.1383, -0.0739], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 9.6781e-01,  1.0506e-01, -3.9086e-04,  2.1996e-02, -5.6347e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0676, -0.0869, -0.2394, -0.1407, -0.2034], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6296, -0.1967, -0.1434, -0.1402, -0.2238], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3014, 0.1870, 0.4899, 0.5191, 0.2854], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8271, 0.9639, 0.9322, 0.9298, 0.9381], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0493, -0.0523, -0.0419, -0.1383, -0.0739], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.4379e-02,  1.5609e-03, -5.8073e-06,  3.2681e-04, -8.3718e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0122,  0.0025, -0.0091,  0.0112, -0.0038], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1076, -0.0761, -0.0991, -0.2434, -0.0335], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.3490, -0.3322, -0.3044, -0.9208, -0.3955], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.3490, -0.3322, -0.3044, -0.9208, -0.3955], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0516,  0.0885,  0.0727,  0.2539,  0.1101], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([5.2263], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4374], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0249,  0.1333,  0.0963,  0.2499,  0.1005], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0249,  0.1333,  0.0963,  0.2499,  0.1005], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0240, -0.7258, -0.0587,  3.5646,  0.5417], grad_fn=<SliceBackward0>)
  [Layer 24] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 24] Output sample values after mixer: tensor([-0.0240, -0.7258, -0.0587,  3.5646,  0.5417], grad_fn=<SliceBackward0>)
  [Layer 24] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 24] Residual connection sample values: tensor([ 0.7333, -4.1837,  4.3297,  3.4285,  6.4553], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 25/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([38.4468], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1613], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0454, -0.2405,  0.2499,  0.2431,  0.3746], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.7669,  1.2795, -1.8223,  0.0087, -0.7073], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.7669,  1.2795, -1.8223,  0.0087, -0.7073], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5925,  0.1079,  1.4646, -0.9297, -0.7573], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.8513, -0.2977, -0.7111, -0.1360, -0.6063], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0313, -0.1364,  0.7093, -0.5925,  0.2518], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2350,  0.0062, -0.2789, -0.5077, -0.0809], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2156,  0.0095, -0.1762, -0.6128, -0.1196], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1194,  0.0048, -0.0804, -0.2154, -0.0562], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1194,  0.0048, -0.0804, -0.2154, -0.0562], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0189, -0.0478, -0.0170,  0.0500, -0.1453], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2178, -0.2381,  0.7700, -0.0405,  0.0659], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1626, -0.3327, -0.3294, -0.2016, -0.1541], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2908, 0.2737, 0.1831, 0.3917, 0.3209], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9538, 0.9130, 0.9415, 0.9241, 0.9517], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1194,  0.0048, -0.0804, -0.2154, -0.0562], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0007, -0.0017, -0.0006,  0.0017, -0.0050], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0007,  0.0036,  0.0022,  0.0039, -0.0211], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0079,  0.0231, -0.1083, -0.4317, -0.1880], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1018,  0.0275, -0.1822, -0.6296, -0.2397], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1018,  0.0275, -0.1822, -0.6296, -0.2397], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0263,  0.0276,  0.0462, -0.0028,  0.0560], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2601], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9609], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1790,  0.1472,  0.2061, -0.0069,  0.2158], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1790,  0.1472,  0.2061, -0.0069,  0.2158], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.4565, -0.7368, -1.9923, -0.7518,  0.7762], grad_fn=<SliceBackward0>)
  [Layer 25] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 25] Output sample values after mixer: tensor([-1.4565, -0.7368, -1.9923, -0.7518,  0.7762], grad_fn=<SliceBackward0>)
  [Layer 25] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 25] Residual connection sample values: tensor([-0.7232, -4.9205,  2.3374,  2.6767,  7.2315], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 26/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([45.8503], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1477], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0511, -0.3236,  0.1616,  0.2270,  0.4884], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4273,  0.4866, -0.1094, -1.2446, -0.2045], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4273,  0.4866, -0.1094, -1.2446, -0.2045], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.5061, -1.6325,  2.0376, -0.3962, -1.1156], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.1170, -1.3225, -2.0732, -1.6947, -1.4469], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0586, -1.1091, -0.8268, -1.5061, -1.1958], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.4061, -0.5197, -0.5367, -0.1347, -0.3280], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4971, -0.5737, -0.5620, -0.1980, -0.5958], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1880, -0.2067, -0.2040, -0.0892, -0.2117], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1880, -0.2067, -0.2040, -0.0892, -0.2117], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0802, -0.0310, -0.1032,  0.1429, -0.0424], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0504, -0.2783, -0.2713, -0.0183,  0.0502], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3298, -0.0634, -0.2289, -0.1264, -0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5099, 0.0543, 0.3964, 0.4313, 0.1533], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8452, 0.9966, 0.9133, 0.9469, 0.9911], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1880, -0.2067, -0.2040, -0.0892, -0.2117], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0077,  0.0030,  0.0099, -0.0137,  0.0041], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0456,  0.0329,  0.0033, -0.0477,  0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3025, -0.2768, -0.2320,  0.1587, -0.5160], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-1.0608, -1.1106, -1.0550, -0.2011, -1.3698], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-1.0608, -1.1106, -1.0550, -0.2011, -1.3698], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.2744, -0.3347,  0.0546,  0.0560,  0.1258], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.9590], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5813], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.3775, -0.3213,  0.0692,  0.0780,  0.1290], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.3775, -0.3213,  0.0692,  0.0780,  0.1290], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.4683, -0.9907,  1.2111,  1.4048,  0.2921], grad_fn=<SliceBackward0>)
  [Layer 26] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 26] Output sample values after mixer: tensor([ 1.4683, -0.9907,  1.2111,  1.4048,  0.2921], grad_fn=<SliceBackward0>)
  [Layer 26] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 26] Residual connection sample values: tensor([ 0.7451, -5.9113,  3.5486,  4.0815,  7.5236], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 27/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([52.6886], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1378], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0428, -0.3231,  0.1966,  0.2709,  0.4350], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5813, -1.0831, -0.2816,  0.0014,  0.9015], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5813, -1.0831, -0.2816,  0.0014,  0.9015], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5378,  1.1548, -0.5335,  0.0480, -0.1911], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.0301, -1.7875, -0.1970,  1.3642, -0.2992], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.7114, -0.3812,  0.0210, -0.5378, -0.7652], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1398,  0.2729, -0.0871, -0.0308, -0.0271], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1231,  0.2211, -0.1421, -0.2310, -0.0252], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0653,  0.1227, -0.0660, -0.1022, -0.0125], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0653,  0.1227, -0.0660, -0.1022, -0.0125], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0932, -0.0578,  0.0458,  0.0202, -0.0946], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2605,  0.0909, -0.0640, -0.1257, -0.2452], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5626, -0.0303, -0.7559, -1.1613, -0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0791, 0.0076, 0.0077, 0.2724, 0.0236], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9565, 0.9998, 0.9942, 0.7288, 0.9990], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0653,  0.1227, -0.0660, -0.1022, -0.0125], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0005, -0.0003,  0.0002,  0.0001, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0017, -0.0102, -0.0032, -0.0061, -0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0322, -0.0472,  0.0089, -0.0034,  0.0102], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0977,  0.1969, -0.1224, -0.2067, -0.0146], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0977,  0.1969, -0.1224, -0.2067, -0.0146], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0204, -0.0539,  0.0148, -0.0001, -0.0093], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5070], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.4044], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0657, -0.1369,  0.0543, -0.0001, -0.0437], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0657, -0.1369,  0.0543, -0.0001, -0.0437], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.7761, -0.0961,  0.5645,  0.5989, -1.0549], grad_fn=<SliceBackward0>)
  [Layer 27] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 27] Output sample values after mixer: tensor([-0.7761, -0.0961,  0.5645,  0.5989, -1.0549], grad_fn=<SliceBackward0>)
  [Layer 27] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 27] Residual connection sample values: tensor([-0.0310, -6.0074,  4.1130,  4.6804,  6.4687], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 28/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([58.2737], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1310], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0014, -0.2701,  0.1890,  0.2557,  0.2927], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.9679, -1.3040,  0.0437,  0.9793,  1.1651], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.9679, -1.3040,  0.0437,  0.9793,  1.1651], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.4452,  1.6297, -0.8635, -0.7736,  0.5704], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.2950, -0.9222, -0.5478, -0.4230, -0.6717], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0029, -1.2641, -0.6237, -1.4452,  0.0051], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4681,  0.5328, -0.1955,  0.1920,  0.0564], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.3402,  0.4434, -0.3246,  0.1019, -0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1988,  0.2701, -0.1362,  0.0535, -0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1988,  0.2701, -0.1362,  0.0535, -0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 1.0471, -0.0536, -0.0122,  0.0099,  1.6653], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0594,  0.0746,  0.2955, -0.1319, -0.1143], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5442, -0.1843, -0.1064, -0.1124, -0.2523], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1368, 0.2338, 0.6218, 0.6261, 0.2739], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9283, 0.9578, 0.9360, 0.9320, 0.9332], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1988,  0.2701, -0.1362,  0.0535, -0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0285, -0.0015, -0.0003,  0.0003,  0.0453], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0359, -0.0044,  0.0049,  0.0003,  0.0438], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0049, -0.0057, -0.0032,  0.0007, -0.0139], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.3659,  0.4982, -0.2573,  0.1006, -0.0224], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.3659,  0.4982, -0.2573,  0.1006, -0.0224], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0975, -0.1387, -0.0057,  0.0716, -0.0199], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1053], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.0815], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.6127, -0.8189, -0.0324,  0.4662, -0.1509], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.6127, -0.8189, -0.0324,  0.4662, -0.1509], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.8124, -2.4067,  1.3032, -0.6787,  2.5556], grad_fn=<SliceBackward0>)
  [Layer 28] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 28] Output sample values after mixer: tensor([ 1.8124, -2.4067,  1.3032, -0.6787,  2.5556], grad_fn=<SliceBackward0>)
  [Layer 28] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 28] Residual connection sample values: tensor([ 1.7814, -8.4141,  5.4162,  4.0017,  9.0243], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 29/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([63.8010], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1252], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0982, -0.4578,  0.3008,  0.2725,  0.4995], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.7887, -1.1882, -0.6046,  1.9296,  1.5968], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.7887, -1.1882, -0.6046,  1.9296,  1.5968], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([0.0419, 0.3009, 0.1170, 1.7092, 0.9373], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.7069, -1.2535,  0.1178, -0.5619, -1.1375], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.2165, 0.1798, 0.7339, 0.0419, 0.6881], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0258, -0.0877, -0.0778, -0.3034,  0.0014], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0398, -0.1634, -0.2161,  0.0633,  1.5014], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0203, -0.0750, -0.0964,  0.0326,  1.2278], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0203, -0.0750, -0.0964,  0.0326,  1.2278], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0875,  0.0064,  0.0065,  0.0557,  0.0802], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1984, -0.0287, -0.1912,  0.1228, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6542, -0.1369, -1.4589, -0.3682, -0.1218], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1620, 0.0161, 0.1058, 0.0602, 0.1030], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8995, 0.9978, 0.8570, 0.9781, 0.9875], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0203, -0.0750, -0.0964,  0.0326,  1.2278], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-2.8773e-04,  2.0946e-05,  2.1443e-05,  1.8296e-04,  2.6375e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0054, -0.0006, -0.0002, -0.0025,  0.0025], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0037, -0.0343, -0.0380,  0.0574,  0.4143], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0379, -0.1604, -0.2001,  0.1122,  2.4781], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0379, -0.1604, -0.2001,  0.1122,  2.4781], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0093,  0.0445,  0.0427,  0.1891,  3.2905], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2506], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9975], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0609,  0.2270,  0.1628,  0.8846,  2.3846], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0609,  0.2270,  0.1628,  0.8846,  2.3846], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-2.8920, -0.6586,  3.8275,  3.7606, -0.8388], grad_fn=<SliceBackward0>)
  [Layer 29] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 29] Output sample values after mixer: tensor([-2.8920, -0.6586,  3.8275,  3.7606, -0.8388], grad_fn=<SliceBackward0>)
  [Layer 29] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 29] Residual connection sample values: tensor([-1.1106, -9.0727,  9.2437,  7.7623,  8.1855], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 30/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([82.3498], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1102], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0499, -0.3893,  0.4044,  0.3985,  0.3576], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.3876, -0.1545, -0.1513, -1.0362,  2.5929], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.3876, -0.1545, -0.1513, -1.0362,  2.5929], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.6209,  0.4424,  0.3134, -0.5084,  0.1305], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.0745,  0.2334, -0.9242, -0.9735,  0.3673], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.9705,  1.0343, -0.6531,  1.6209, -0.9353], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0881, -0.3827,  0.0493,  0.1770, -0.4249], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1309, -0.4245,  0.6245,  0.2265, -0.5175], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0612, -0.1679,  0.4067,  0.1260, -0.1932], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0612, -0.1679,  0.4067,  0.1260, -0.1932], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0816, -0.0562, -0.0449,  0.1384, -0.2660], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2548, -0.1649, -0.2724, -0.2754, -0.2685], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2038, -0.3668, -0.2078, -0.0952, -0.4265], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2117, 0.2916, 0.1998, 0.0387, 0.3508], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9578, 0.8986, 0.9593, 0.9963, 0.8610], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0612, -0.1679,  0.4067,  0.1260, -0.1932], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0011,  0.0007,  0.0006, -0.0018,  0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0019, -0.0324, -0.0085, -0.0135,  0.0582], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0936, -0.1010,  1.4037,  0.3307, -0.1252], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1037, -0.1288,  1.4708,  0.3516, -0.1571], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1037, -0.1288,  1.4708,  0.3516, -0.1571], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0239,  0.0092, -0.1029, -0.0954, -0.3791], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3911], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.5990], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0959,  0.0406, -0.2750, -0.4234, -0.6169], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0959,  0.0406, -0.2750, -0.4234, -0.6169], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 4.7153, -1.9588, -5.4438, -5.2345,  0.5159], grad_fn=<SliceBackward0>)
  [Layer 30] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 30] Output sample values after mixer: tensor([ 4.7153, -1.9588, -5.4438, -5.2345,  0.5159], grad_fn=<SliceBackward0>)
  [Layer 30] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 30] Residual connection sample values: tensor([  3.6048, -11.0315,   3.7999,   2.5277,   8.7014],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 31/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([99.6934], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1002], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0997, -0.3094,  0.1056,  0.0792,  0.2411], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5213, -1.0506,  0.2986, -0.2071, -0.2707], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5213, -1.0506,  0.2986, -0.2071, -0.2707], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.7385,  0.5896,  0.6755,  0.5685, -0.1052], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.8559, 1.8480, 1.6824, 1.1463, 0.9874], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2253, -1.1196, -0.4060,  0.7385,  0.0287], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1469, -0.1322, -0.1430, -0.2438, -0.0521], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1498, -0.0972, -0.1536, -0.2619, -0.1124], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0693, -0.0462, -0.0709, -0.1139, -0.0531], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0693, -0.0462, -0.0709, -0.1139, -0.0531], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0792,  0.0372, -0.0016, -0.0365, -0.0149], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0989, -0.0289, -0.0965, -0.0246, -0.0564], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-9.5766e-03, -1.0642e-02, -2.6350e+01, -6.4468e+02, -1.6547e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1050, 0.3229, 2.3345, 2.2875, 0.1604], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9899e-01, 9.9657e-01, 1.9221e-27, 0.0000e+00, 9.9735e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0693, -0.0462, -0.0709, -0.1139, -0.0531], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 5.7664e-04, -2.7103e-04,  1.1452e-05,  2.6548e-04,  1.0818e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0165, -0.0107,  0.0078,  0.0156,  0.0060], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0067, -0.0277, -0.0175, -0.0450, -0.0708], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0020, -0.0219, -0.0086, -0.0307, -0.0642], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0020, -0.0219, -0.0086, -0.0307, -0.0642], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0006,  0.0060, -0.0015,  0.0029,  0.0075], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0246], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.3732], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0163,  0.1370, -0.0341,  0.2937,  0.0504], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0163,  0.1370, -0.0341,  0.2937,  0.0504], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([0.5947, 3.3060, 0.2791, 4.6359, 1.3690], grad_fn=<SliceBackward0>)
  [Layer 31] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 31] Output sample values after mixer: tensor([0.5947, 3.3060, 0.2791, 4.6359, 1.3690], grad_fn=<SliceBackward0>)
  [Layer 31] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 31] Residual connection sample values: tensor([ 4.1994, -7.7255,  4.0790,  7.1637, 10.0705], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 32/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([113.2504], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0940], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1845, -0.3321,  0.1741,  0.3668,  0.4489], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0933, -2.3002,  1.3847,  0.5562,  0.3229], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0933, -2.3002,  1.3847,  0.5562,  0.3229], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.7309,  0.6075, -0.1347, -0.6009,  0.2436], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.8088, -1.5991, -0.7625, -1.1953, -1.0201], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.3789, -0.0596, -0.3214, -0.7309,  0.2174], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0950, -0.0313,  0.1045,  0.3266, -0.0579], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0813, -0.3992,  0.1025,  0.3031, -0.0702], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0423, -0.1603,  0.0538,  0.1743, -0.0339], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0423, -0.1603,  0.0538,  0.1743, -0.0339], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0723,  0.2290,  0.1527, -0.0644,  0.1087], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2638, -0.0673, -0.2780, -0.2709, -0.1366], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0662, -0.0811, -0.5879, -0.0956, -0.5448], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2472, 0.3219, 0.2184, 0.3526, 0.2592], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9838, 0.9742, 0.8795, 0.9669, 0.8683], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0423, -0.1603,  0.0538,  0.1743, -0.0339], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0008,  0.0024,  0.0016, -0.0007,  0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0213, 0.1089, 0.1340, 0.2715, 0.1548], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.6140, -1.3836,  0.3493,  1.3049, -0.4948], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.6130, -1.3800,  0.3480,  1.3010, -0.4940], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.6130, -1.3800,  0.3480,  1.3010, -0.4940], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0273,  0.2892,  0.3854,  0.4599, -0.0925], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.7997], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5976], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0183,  0.4226,  0.5615,  0.4198, -0.0951], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0183,  0.4226,  0.5615,  0.4198, -0.0951], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([1.2517, 2.9385, 1.5007, 2.5613, 5.0428], grad_fn=<SliceBackward0>)
  [Layer 32] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 32] Output sample values after mixer: tensor([1.2517, 2.9385, 1.5007, 2.5613, 5.0428], grad_fn=<SliceBackward0>)
  [Layer 32] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 32] Residual connection sample values: tensor([ 5.4511, -4.7871,  5.5797,  9.7250, 15.1133], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 33/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([136.8389], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0855], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2240, -0.1921,  0.2280,  0.4197,  0.6280], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.8132, -0.4532,  2.3535, -0.7204,  1.3998], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.8132, -0.4532,  2.3535, -0.7204,  1.3998], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.6152, -0.1215,  1.1568,  0.0261, -1.1831], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.2416, -0.3313, -1.2943, -1.2633, -0.9931], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.7093,  1.9687,  0.9715,  1.6152, -0.1080], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4237,  0.0565,  0.1747, -0.0383, -0.2412], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1534,  0.0199,  0.1614, -0.1612, -0.2755], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0826,  0.0100,  0.0872, -0.0741, -0.1189], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0826,  0.0100,  0.0872, -0.0741, -0.1189], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0008,  0.0966,  0.0254, -0.0301,  0.0410], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0621,  1.1334,  0.0931, -0.2775, -0.0245], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-13.0444,  -1.3850,  -0.1668,  -0.2359,  -5.2550],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0179, 0.0035, 0.0155, 0.0151, 0.0031], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7914, 0.9952, 0.9974, 0.9964, 0.9839], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0826,  0.0100,  0.0872, -0.0741, -0.1189], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.1527e-06,  1.4297e-04,  3.7552e-05, -4.4517e-05,  6.0724e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 7.2005e-04, -3.6109e-04, -6.9629e-05, -4.2693e-05,  8.7105e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 1.0105e-04,  1.8774e-03,  3.9173e-04, -1.8714e-03,  8.2886e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0886,  0.0126,  0.0938, -0.0813, -0.1273], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0886,  0.0126,  0.0938, -0.0813, -0.1273], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0221, -0.0022,  0.2015,  0.0192, -0.1429], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0852], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.4257], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2089, -0.0203,  2.5172,  0.2012, -1.6964], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2089, -0.0203,  2.5172,  0.2012, -1.6964], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.4328,  0.4369, -1.6584, -2.6246,  3.0585], grad_fn=<SliceBackward0>)
  [Layer 33] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 33] Output sample values after mixer: tensor([ 2.4328,  0.4369, -1.6584, -2.6246,  3.0585], grad_fn=<SliceBackward0>)
  [Layer 33] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 33] Residual connection sample values: tensor([ 7.8839, -4.3502,  3.9213,  7.1004, 18.1718], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 34/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([170.7672], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0765], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2561, -0.1392,  0.1325,  0.2340,  0.6029], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.7788, -0.8031, -0.5868,  0.5646, -1.9134], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.7788, -0.8031, -0.5868,  0.5646, -1.9134], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.4561, -1.2736, -1.0543,  1.3134, -1.4763], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.0599, -0.3491,  1.8140, -1.0987,  0.4818], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6319,  0.3785, -0.1197, -0.4561, -1.0597], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0936,  0.6516,  0.2499, -0.2323, -0.4367], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1370,  0.5544,  0.2159, -0.3134, -0.5107], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0638,  0.3521,  0.1196, -0.1323, -0.1915], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0638,  0.3521,  0.1196, -0.1323, -0.1915], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0372, -0.0590, -0.0659, -0.1215,  0.0490], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2557, -0.0374, -0.1793, -0.0164, -0.1070], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2225, -0.1537, -0.8169, -0.8591, -2.0730], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0123, 0.0050, 0.8345, 0.0343, 0.2706], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9973, 0.9992, 0.5058, 0.9709, 0.5706], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0638,  0.3521,  0.1196, -0.1323, -0.1915], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.9338e-05,  4.6524e-05,  5.1971e-05,  9.5757e-05, -3.8598e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0030,  0.0075,  0.0034, -0.0066,  0.0106], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0203,  0.0698,  0.0320, -0.0142, -0.0296], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1459,  0.7625,  0.2673, -0.2746, -0.4065], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1459,  0.7625,  0.2673, -0.2746, -0.4065], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0375, -0.1894, -0.0560, -0.0988,  0.1000], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1472], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.6067], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2611, -0.7379, -0.3264, -0.6804,  0.7338], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.2611, -0.7379, -0.3264, -0.6804,  0.7338], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.5469, -4.2582,  1.0830,  3.6780, -2.9165], grad_fn=<SliceBackward0>)
  [Layer 34] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 34] Output sample values after mixer: tensor([ 0.5469, -4.2582,  1.0830,  3.6780, -2.9165], grad_fn=<SliceBackward0>)
  [Layer 34] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 34] Residual connection sample values: tensor([ 8.4308, -8.6084,  5.0043, 10.7784, 15.2552], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 35/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([196.5083], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0713], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.3377, -0.3421,  0.1975,  0.4603,  0.6074], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0531, -0.7111, -0.1416, -1.9769,  2.9165], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0531, -0.7111, -0.1416, -1.9769,  2.9165], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.0363,  0.7590, -1.4870, -1.3114, -0.2596], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.1386, -1.2376, -1.6042, -2.0774,  0.6724], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3614, -0.4899, -0.1723,  1.0363,  1.2329], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2030,  0.1870, -0.1768, -0.2682, -0.0552], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2544,  0.1653, -0.2042, -0.2930, -0.1674], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1111,  0.0895, -0.0917, -0.1252, -0.0767], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1111,  0.0895, -0.0917, -0.1252, -0.0767], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2781,  0.0822,  0.3148,  0.4784,  0.2219], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2422, -0.1782, -0.2773, -0.0747,  0.0463], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2054, -0.1417, -0.1071, -0.1460, -0.2581], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.6341, 1.2656, 0.2462, 0.8307, 1.3281], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7149, 0.8358, 0.9740, 0.8857, 0.7098], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1111,  0.0895, -0.0917, -0.1252, -0.0767], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0505, -0.0149, -0.0572, -0.0869, -0.0403], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0463, -0.0158, -0.0637, -0.0842, -0.0474], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1908,  0.2851, -0.6097, -0.6574,  0.1158], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.4818,  0.5194, -0.8499, -0.9852, -0.0851], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.4818,  0.5194, -0.8499, -0.9852, -0.0851], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0131, -0.1216,  0.0559,  0.2369, -0.2355], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([6.0253], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4074], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0203, -0.1827,  0.0291,  0.5305, -0.3056], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0203, -0.1827,  0.0291,  0.5305, -0.3056], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.2000,  0.4817, -3.2546, -1.3301,  2.9781], grad_fn=<SliceBackward0>)
  [Layer 35] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 35] Output sample values after mixer: tensor([-1.2000,  0.4817, -3.2546, -1.3301,  2.9781], grad_fn=<SliceBackward0>)
  [Layer 35] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 35] Residual connection sample values: tensor([ 7.2308, -8.1266,  1.7497,  9.4483, 18.2334], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 36/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([262.0959], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0618], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2233, -0.2566,  0.0544,  0.3115,  0.5769], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.8862, -0.3085, -2.1423,  0.5451, -0.6545], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.8862, -0.3085, -2.1423,  0.5451, -0.6545], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.1749,  2.3699,  1.3898, -0.9520, -1.8787], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.2927, 2.4204, 1.7227, 0.4231, 1.4582], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.9456,  2.9650, -0.4971,  1.1749,  1.5891], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2817,  0.5415,  0.4019, -0.2146, -0.2996], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2414,  0.4240,  0.3398, -0.3592, -0.3118], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1062,  0.2563,  0.1985, -0.1477, -0.1318], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1062,  0.2563,  0.1985, -0.1477, -0.1318], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0220, -0.0201, -0.0600,  0.1793, -0.0713], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1437, -0.1220, -0.1776, -0.0803, -0.1522], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.8655, -5.6378, -3.8976, -2.4260, -3.6937], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0926, 0.1776, 0.0976, 0.0598, 0.1026], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7668, 0.3675, 0.6835, 0.8649, 0.6846], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1062,  0.2563,  0.1985, -0.1477, -0.1318], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0002,  0.0002,  0.0006, -0.0018,  0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0075,  0.0014, -0.0011, -0.0005,  0.0033], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0309,  0.0688,  0.0013, -0.0411, -0.0340], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3566,  0.8548,  0.6101, -0.4941, -0.4381], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3566,  0.8548,  0.6101, -0.4941, -0.4381], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0886, -0.1117, -0.1373, -0.1705,  0.0981], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7119], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1852], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2012, -0.5418, -0.4603, -0.6092,  0.3988], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.2012, -0.5418, -0.4603, -0.6092,  0.3988], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.5067, -2.7820,  2.0093, -8.4141,  0.6601], grad_fn=<SliceBackward0>)
  [Layer 36] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 36] Output sample values after mixer: tensor([-1.5067, -2.7820,  2.0093, -8.4141,  0.6601], grad_fn=<SliceBackward0>)
  [Layer 36] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 36] Residual connection sample values: tensor([  5.7241, -10.9087,   3.7590,   1.0341,  18.8934],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 37/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([284.9197], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0592], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1635, -0.3200,  0.1127,  0.0303,  0.5536], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.3637, -0.7811,  0.0341,  1.0824,  0.1589], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.3637, -0.7811,  0.0341,  1.0824,  0.1589], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5111,  0.2203,  2.7498, -1.4539, -3.5785], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.6063, -0.2306,  2.6287, -1.1815,  0.0781], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6494, -0.6329, -0.1335, -0.5111,  2.0781], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1398, -0.1416, -0.8187,  0.4083, -0.9221], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0621, -0.2057, -0.9033,  0.4432, -1.0058], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0320, -0.0923, -0.2605,  0.2699, -0.2694], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0320, -0.0923, -0.2605,  0.2699, -0.2694], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2234, -0.0220, -0.0261, -0.1130,  0.0123], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2737, -0.2412, -0.1539, -0.2229, -0.2785], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.8179, -31.1699, -39.0195,  -0.4619,  -0.6477],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0001, 0.0057, 0.0454, 0.0002, 0.0018], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9998, 0.8360, 0.1704, 0.9999, 0.9988], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0320, -0.0923, -0.2605,  0.2699, -0.2694], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-9.0593e-07, -8.9099e-08, -1.0584e-07, -4.5827e-07,  4.9749e-08],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0004,  0.0004, -0.0006,  0.0009, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0007,  0.0015, -0.0086,  0.0065, -0.0033], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0593, -0.1676, -0.4858,  0.5009, -0.4966], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0593, -0.1676, -0.4858,  0.5009, -0.4966], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0127,  0.0411, -0.0084,  0.4049, -0.0426], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2502], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9991], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0948,  0.2214, -0.0426,  3.2443, -0.1821], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0948,  0.2214, -0.0426,  3.2443, -0.1821], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-13.0965,  -3.4844,   5.9033,  -1.3143,   2.2652],
       grad_fn=<SliceBackward0>)
  [Layer 37] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 37] Output sample values after mixer: tensor([-13.0965,  -3.4844,   5.9033,  -1.3143,   2.2652],
       grad_fn=<SliceBackward0>)
  [Layer 37] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 37] Residual connection sample values: tensor([ -7.3724, -14.3931,   9.6623,  -0.2801,  21.1586],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 38/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([343.3684], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0540], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2040, -0.3982,  0.2661, -0.0075,  0.5893], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2553, -0.6815, -0.3413, -1.8646,  1.6707], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2553, -0.6815, -0.3413, -1.8646,  1.6707], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.8919, -0.3671, -1.6558,  1.0658,  1.3784], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.3746, -0.0194, -1.3026, -1.2402,  1.1725], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 2.6654,  0.8303,  0.5341,  0.8919, -0.7357], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2806, -0.5377,  0.0017, -0.0848,  0.2468], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2830, -0.8270, -0.0884, -0.1280,  0.3398], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1216, -0.2516, -0.0423, -0.0599,  0.1985], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1216, -0.2516, -0.0423, -0.0599,  0.1985], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1843,  0.7191, -0.0856, -0.0540,  0.0062], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1889, -0.1262, -0.2783, -0.2579,  0.0339], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1704, -2.0832, -0.1351, -0.4124, -3.5315], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2694, 0.1164, 0.2303, 0.0957, 0.2881], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9551, 0.7846, 0.9694, 0.9613, 0.3616], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1216, -0.2516, -0.0423, -0.0599,  0.1985], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0060, -0.0236,  0.0028,  0.0018, -0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0142,  0.1288, -0.0075,  0.0037, -0.0104], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.4391, -0.3593, -0.2689, -0.2328,  1.1259], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.4569, -0.3962, -0.2751, -0.2415,  1.1550], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.4569, -0.3962, -0.2751, -0.2415,  1.1550], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0509, 0.0907, 0.0390, 0.0604, 1.6241], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7892], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1256], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.1806, 0.2165, 0.1030, 0.3186, 5.9199], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.1806, 0.2165, 0.1030, 0.3186, 5.9199], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 6.7038,  1.0549,  9.1984,  8.2111, -1.1612], grad_fn=<SliceBackward0>)
  [Layer 38] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 38] Output sample values after mixer: tensor([ 6.7038,  1.0549,  9.1984,  8.2111, -1.1612], grad_fn=<SliceBackward0>)
  [Layer 38] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 38] Residual connection sample values: tensor([ -0.6686, -13.3382,  18.8606,   7.9310,  19.9974],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 39/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([418.5966], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0489], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0124, -0.2690,  0.3689,  0.1627,  0.3892], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.6539,  0.4887, -0.5016, -2.2429, -0.1789], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.6539,  0.4887, -0.5016, -2.2429, -0.1789], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.2065e+00,  5.3262e-02,  2.2886e+00, -2.7723e-01,  6.2197e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.4837,  2.7235, -0.4140,  2.0113,  0.3508], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-6.5311e-01, -6.2294e-01,  1.8240e+00, -1.2065e+00, -1.7278e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2218, -0.0338,  0.4735, -0.0686, -0.0063], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1573, -0.0945,  0.4887,  0.4690, -0.0097], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0725, -0.0450,  0.3029,  0.2885, -0.0048], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0725, -0.0450,  0.3029,  0.2885, -0.0048], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0068,  0.0407, -0.1955, -0.0362, -0.0399], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2715, -0.1618, -0.0023, -0.0400, -0.2779], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.7351e+02, -2.3790e+00, -2.6079e-03, -1.4979e+00, -6.3307e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.8600, 1.7430, 0.1819, 0.6959, 0.0126], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.0000, 0.0158, 0.9995, 0.3526, 0.9992], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0725, -0.0450,  0.3029,  0.2885, -0.0048], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0004, -0.0025,  0.0122,  0.0023,  0.0025], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0004, -0.0025,  0.0122,  0.0023,  0.0025], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0192, -0.0119,  0.0802,  0.0764, -0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3472, -0.2156,  1.4509,  1.3818, -0.0232], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3472, -0.2156,  1.4509,  1.3818, -0.0232], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1494, -0.0653, -0.2745, -0.2974,  0.0019], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.0841], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9604], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.6707, -0.2778, -1.1050, -1.1683,  0.0089], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.6707, -0.2778, -1.1050, -1.1683,  0.0089], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.9964,  0.6717, -6.5221, -2.5634, -5.4507], grad_fn=<SliceBackward0>)
  [Layer 39] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 39] Output sample values after mixer: tensor([-1.9964,  0.6717, -6.5221, -2.5634, -5.4507], grad_fn=<SliceBackward0>)
  [Layer 39] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 39] Residual connection sample values: tensor([ -2.6650, -12.6665,  12.3385,   5.3675,  14.5468],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 40/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([521.0220], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0438], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0574, -0.2910,  0.2777,  0.1106,  0.3242], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4360,  0.5607,  0.7244,  0.9518, -1.1654], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4360,  0.5607,  0.7244,  0.9518, -1.1654], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1680,  0.9552, -0.1030,  0.5688,  0.9020], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.0959,  0.4686,  0.3785, -0.6490,  0.2856], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.3095,  0.0038, -0.8216, -0.1680,  1.3096], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0257, -0.1648, -0.0091, -0.0709,  0.1549], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.3056, -0.2133, -0.0807, -0.0824,  0.1564], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1760, -0.0953, -0.0387, -0.0395,  0.0843], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1760, -0.0953, -0.0387, -0.0395,  0.0843], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0017, -0.0501, -0.0607,  0.0547, -0.0187], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1670, -0.2342, -0.2435, -0.2780, -0.0198], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5267, -0.6301, -0.3878, -2.7909, -0.4284], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0525, 0.0206, 0.0402, 0.0032, 0.0214], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9727, 0.9871, 0.9845, 0.9912, 0.9909], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1760, -0.0953, -0.0387, -0.0395,  0.0843], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.5511e-05, -4.6334e-04, -5.6158e-04,  5.0561e-04, -1.7293e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0028, -0.0428, -0.0072,  0.0008, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0729, -0.0384, -0.0416, -0.0135,  0.0288], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.5085, -0.2743, -0.1374, -0.1113,  0.2375], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.5085, -0.2743, -0.1374, -0.1113,  0.2375], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1346, -0.0979, -0.0671, -0.0764, -0.0658], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3664], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.6520], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.7133, -0.6143, -0.4282, -0.3857, -0.5468], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.7133, -0.6143, -0.4282, -0.3857, -0.5468], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([  3.5263,   3.4776, -10.4514,  -8.3763,   0.8323],
       grad_fn=<SliceBackward0>)
  [Layer 40] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 40] Output sample values after mixer: tensor([  3.5263,   3.4776, -10.4514,  -8.3763,   0.8323],
       grad_fn=<SliceBackward0>)
  [Layer 40] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 40] Residual connection sample values: tensor([ 0.8613, -9.1889,  1.8871, -3.0088, 15.3791], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 41/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([718.3991], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0373], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0112, -0.1281,  0.0254, -0.0388,  0.2009], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.8953, -3.0290, -0.0720,  1.1698,  0.3463], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.8953, -3.0290, -0.0720,  1.1698,  0.3463], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8012,  0.6232,  0.2126,  0.3140,  0.0489], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.3630,  0.3331, -0.7373,  0.3076,  0.7930], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.1127, -1.0690, -0.8642, -0.8012,  0.0712], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2109, -0.1352,  0.0452, -0.0627, -0.0095], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2425, -0.0128,  0.0453, -0.1554, -0.0191], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1066, -0.0064,  0.0231, -0.0717, -0.0094], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1066, -0.0064,  0.0231, -0.0717, -0.0094], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0737, -0.0028,  0.0201,  0.0079, -0.0395], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1530,  0.1187,  0.0106, -0.1303, -0.2772], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.0531, -1.1356, -0.8719, -1.5713, -1.7431], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1006, 0.2816, 0.0503, 0.1681, 0.1728], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8995, 0.7263, 0.9571, 0.7679, 0.7399], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1066, -0.0064,  0.0231, -0.0717, -0.0094], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 7.9011e-04,  2.9978e-05, -2.1525e-04, -8.4221e-05,  4.2387e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0081, -0.0042, -0.0137, -0.0005, -0.0069], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0105,  0.0063,  0.0011, -0.0116, -0.0019], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1469, -0.0018,  0.0307, -0.1032, -0.0140], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1469, -0.0018,  0.0307, -0.1032, -0.0140], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0934,  0.0003, -0.0011, -0.0922, -0.0028], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0257], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.2424], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-1.8665,  0.0067, -0.0245, -2.5797, -0.0736], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-1.8665,  0.0067, -0.0245, -2.5797, -0.0736], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-4.0439,  2.9561, -0.0537,  1.6567,  3.0793], grad_fn=<SliceBackward0>)
  [Layer 41] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 41] Output sample values after mixer: tensor([-4.0439,  2.9561, -0.0537,  1.6567,  3.0793], grad_fn=<SliceBackward0>)
  [Layer 41] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 41] Residual connection sample values: tensor([-3.1826, -6.2328,  1.8334, -1.3521, 18.4584], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 42/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([838.0129], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0345], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0396, -0.0833,  0.0244, -0.0168,  0.2416], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3058,  1.0041, -0.2344, -1.4607,  0.1799], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3058,  1.0041, -0.2344, -1.4607,  0.1799], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8487,  0.8345, -0.9202,  0.6916, -1.1116], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.6632, -0.8771,  2.1251, -0.1932,  1.2226], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.7887,  0.2633, -0.0213, -0.8487,  0.0239], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1764,  0.1751,  0.1985, -0.1366, -0.2862], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1555,  0.1393,  0.2031, -0.1404, -0.3323], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0838,  0.0745,  0.1118, -0.0653, -0.1388], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0838,  0.0745,  0.1118, -0.0653, -0.1388], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0077, -0.1086,  0.0552, -0.0338, -0.0744], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0532, -0.1987, -0.0363, -0.2780, -0.1827], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.2458, -1.7474, -3.3797, -1.2264, -1.3705], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1922, 0.0563, 0.7707, 0.0172, 0.2417], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6495, 0.9063, 0.0739, 0.9792, 0.7180], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0838,  0.0745,  0.1118, -0.0653, -0.1388], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0001, -0.0017,  0.0009, -0.0005, -0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0001, -0.0012,  0.0015, -0.0004, -0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0038,  0.0109,  0.0157, -0.0046, -0.0131], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1183,  0.1128,  0.1686, -0.0938, -0.2029], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1183,  0.1128,  0.1686, -0.0938, -0.2029], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0153,  0.0829, -0.0174,  0.0258, -0.0199], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0334], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([5.4695], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.3290,  1.7084, -0.3704,  0.5552, -0.2913], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.3290,  1.7084, -0.3704,  0.5552, -0.2913], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-4.3076, -2.4639,  1.2506, -3.7374, -1.8479], grad_fn=<SliceBackward0>)
  [Layer 42] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 42] Output sample values after mixer: tensor([-4.3076, -2.4639,  1.2506, -3.7374, -1.8479], grad_fn=<SliceBackward0>)
  [Layer 42] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 42] Residual connection sample values: tensor([-7.4902, -8.6967,  3.0840, -5.0896, 16.6104], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 43/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([943.8098], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0326], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0861, -0.1095,  0.0372, -0.0585,  0.1942], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.9962,  0.9076, -0.4787, -0.9532, -0.5646], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.9962,  0.9076, -0.4787, -0.9532, -0.5646], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.9998,  0.2731,  0.1345, -0.3608, -0.1791], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.2075,  0.4325,  0.0135,  0.8127, -0.4153], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.0125, -0.1455, -0.2589, -0.9998,  1.0407], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1994, -0.0385, -0.0248, -0.0705, -0.0357], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2140, -0.0927, -0.0528, -0.1183, -0.0440], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0956, -0.0442, -0.0257, -0.0556, -0.0215], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0956, -0.0442, -0.0257, -0.0556, -0.0215], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1277,  0.0085,  0.0821, -0.2424,  0.1960], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1680,  0.0580,  0.2483, -0.2662, -0.1421], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.7046, -2.6553, -8.2110, -2.2382, -4.0926], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4561, 0.1198, 0.0634, 0.6722, 0.0008], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.1846, 0.7276, 0.5943, 0.2221, 0.9965], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0956, -0.0442, -0.0257, -0.0556, -0.0215], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0056, -0.0004, -0.0036,  0.0106, -0.0085], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0055, -0.0004, -0.0036,  0.0110, -0.0088], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0031, -0.0015, -0.0007, -0.0018, -0.0008], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1608, -0.0744, -0.0432, -0.0935, -0.0362], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1608, -0.0744, -0.0432, -0.0935, -0.0362], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0432, -0.0481,  0.0079,  0.0248,  0.0074], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0184], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([7.3766], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.8240, -1.2301,  0.1617,  0.5112,  0.1580], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.8240, -1.2301,  0.1617,  0.5112,  0.1580], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-2.4238, -7.9623, -1.5528, -8.1112,  4.9087], grad_fn=<SliceBackward0>)
  [Layer 43] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 43] Output sample values after mixer: tensor([-2.4238, -7.9623, -1.5528, -8.1112,  4.9087], grad_fn=<SliceBackward0>)
  [Layer 43] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 43] Residual connection sample values: tensor([ -9.9140, -16.6590,   1.5312, -13.2008,  21.5192],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 44/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1110.9636], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0300], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1065, -0.1850,  0.0170, -0.1386,  0.2339], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.6893,  1.2435, -0.0525, -0.4458,  0.0737], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.6893,  1.2435, -0.0525, -0.4458,  0.0737], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.0672, -0.9473, -0.4742, -0.4047,  0.4678], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.2013, -0.2174,  0.9320,  0.6635, -0.1061], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.7956, -0.5637,  0.6244, -1.0672, -0.8419], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2188,  0.2013, -0.0792,  0.0717,  0.0885], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1973,  0.1443, -0.1080,  0.0586,  0.0951], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0890,  0.0773, -0.0511,  0.0301,  0.0498], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0890,  0.0773, -0.0511,  0.0301,  0.0498], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0180, -0.2375, -0.2734,  0.0441, -0.0058], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0084, -0.2746, -0.1695, -0.0214, -0.0610], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-4.6876, -0.9753, -0.8255, -1.2938, -0.4953], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2979, 0.0359, 0.0612, 0.0863, 0.0070], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.2475, 0.9656, 0.9508, 0.8944, 0.9966], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0890,  0.0773, -0.0511,  0.0301,  0.0498], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0005,  0.0063,  0.0072, -0.0012,  0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 3.2394e-04,  6.1842e-03,  7.0421e-03, -1.0310e-03, -8.3204e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0096,  0.0083, -0.0056,  0.0033,  0.0054], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1642,  0.1427, -0.0944,  0.0557,  0.0920], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1642,  0.1427, -0.0944,  0.0557,  0.0920], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.2342,  0.1377,  0.0024, -0.0097,  0.0035], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0245], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.3865], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-4.8199,  2.5952,  0.0576, -0.1989,  0.0707], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-4.8199,  2.5952,  0.0576, -0.1989,  0.0707], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-2.8536,  4.5520,  1.4011,  1.1347, -0.7733], grad_fn=<SliceBackward0>)
  [Layer 44] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 44] Output sample values after mixer: tensor([-2.8536,  4.5520,  1.4011,  1.1347, -0.7733], grad_fn=<SliceBackward0>)
  [Layer 44] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 44] Residual connection sample values: tensor([-12.7676, -12.1070,   2.9323, -12.0661,  20.7459],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 45/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1245.8555], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0283], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1553, -0.1589,  0.0375, -0.1472,  0.2556], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4438, -2.9666,  0.1463, -0.1985, -0.4494], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4438, -2.9666,  0.1463, -0.1985, -0.4494], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.1007,  0.5763, -0.7032,  0.8936, -0.2355], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.6456, -0.6653, -0.6645, -0.0741,  1.3030], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3072,  0.2402, -0.3617,  0.1007,  1.3222], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0132,  0.0717, -0.1317, -0.1815, -0.0246], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0076,  0.3298, -0.1540, -0.2375, -0.0353], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0038,  0.1918, -0.0711, -0.1047, -0.0173], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0038,  0.1918, -0.0711, -0.1047, -0.0173], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2077, -0.0599, -0.0116,  0.1363,  0.0280], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2698, -0.0066, -0.2317,  0.0165, -0.0909], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3039e+00, -3.9385e-02, -6.8874e+00, -8.0559e-01, -1.9935e+03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0042, 0.0096, 0.0040, 0.0006, 0.0686], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9945, 0.9996, 0.9729, 0.9995, 0.0000], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0038,  0.1918, -0.0711, -0.1047, -0.0173], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-3.3281e-06, -9.6019e-07, -1.8584e-07,  2.1847e-06,  4.4806e-07],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0017, 0.0010, 0.0012, 0.0002, 0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0011,  0.0285, -0.0039, -0.0075,  0.0067], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0087,  0.5263, -0.1884, -0.2792, -0.0383], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0087,  0.5263, -0.1884, -0.2792, -0.0383], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0024, -0.0764, -0.0148,  0.0250,  0.0067], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1188], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.9010], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0265, -0.6453, -0.1491,  0.2384,  0.0768], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0265, -0.6453, -0.1491,  0.2384,  0.0768], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 5.0530, -6.0506,  0.4212, -4.8125, -1.6146], grad_fn=<SliceBackward0>)
  [Layer 45] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 45] Output sample values after mixer: tensor([ 5.0530, -6.0506,  0.4212, -4.8125, -1.6146], grad_fn=<SliceBackward0>)
  [Layer 45] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 45] Residual connection sample values: tensor([ -7.7145, -18.1575,   3.3534, -16.8785,  19.1313],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 46/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1362.5154], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0271], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0852, -0.2156,  0.0390, -0.1897,  0.2090], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.0923, -0.9902, -0.6197, -0.1656,  0.7443], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.0923, -0.9902, -0.6197, -0.1656,  0.7443], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2080, -0.1183,  1.0012, -0.2784,  0.4977], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.0427, -0.1037, -0.9254, -0.2991,  1.1861], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3865,  1.2188,  0.8542,  0.2080, -0.0123], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0514,  0.0212,  0.1979,  0.0465, -0.0812], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0041, -0.0161,  0.4007,  0.0510, -0.0864], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0020, -0.0080,  0.2400,  0.0261, -0.0413], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0020, -0.0080,  0.2400,  0.0261, -0.0413], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1310, -0.0053, -0.0326, -0.0653, -0.1340], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0470,  0.0629, -0.0700, -0.0834,  0.0612], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.4426,  -0.9830, -10.1590,  -1.3638,  -1.7559],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0084, 0.0126, 0.0004, 0.0097, 0.0352], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9879, 0.9877, 0.9956, 0.9869, 0.9401], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0020, -0.0080,  0.2400,  0.0261, -0.0413], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-2.2427e-06, -9.0761e-08, -5.5856e-07, -1.1177e-06, -2.2946e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.4867e-03,  2.9587e-04, -5.8793e-05,  4.0459e-04, -8.1073e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 1.3280e-03, -3.9898e-05,  3.5121e-03, -4.8802e-04, -1.2347e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0038, -0.0098,  0.2975,  0.0315, -0.0519], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0038, -0.0098,  0.2975,  0.0315, -0.0519], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0010,  0.0026, -0.0645, -0.0024, -0.0262], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0231], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.5814], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0307,  0.0716, -1.4967, -0.0550, -0.6010], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0307,  0.0716, -1.4967, -0.0550, -0.6010], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.9601,  4.0029, -5.8943, -2.3698, -7.2245], grad_fn=<SliceBackward0>)
  [Layer 46] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 46] Output sample values after mixer: tensor([ 2.9601,  4.0029, -5.8943, -2.3698, -7.2245], grad_fn=<SliceBackward0>)
  [Layer 46] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 46] Residual connection sample values: tensor([ -4.7544, -14.1546,  -2.5409, -19.2483,  11.9068],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 47/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1416.8149], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0266], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0463, -0.1437, -0.0253, -0.1769,  0.1160], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2239, -0.0798, -0.7762, -0.6525,  0.4466], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2239, -0.0798, -0.7762, -0.6525,  0.4466], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5188, -0.5438,  0.4110, -0.5591, -0.0955], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.4464,  0.6886,  0.1148,  1.3447, -0.6019], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2697, -0.2363, -0.7600, -0.5188,  0.4965], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1266, -0.0855,  0.0811,  0.1041, -0.0166], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1137, -0.0704,  0.0800,  0.1109, -0.0185], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0601, -0.0340,  0.0416,  0.0585, -0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0601, -0.0340,  0.0416,  0.0585, -0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 1.5782e-02, -5.6083e-03,  1.5680e-04, -3.6006e-02, -2.5705e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 1.3914, -0.0374,  0.4859, -0.2731, -0.2574], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-5.7667e+01, -2.2024e+00, -3.8371e+00, -4.6046e-02, -2.0700e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0299, 0.0088, 0.0145, 0.0664, 0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.1784, 0.9807, 0.9458, 0.9969, 0.9954], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0601, -0.0340,  0.0416,  0.0585, -0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.8337e-05, -1.0070e-05,  2.8154e-07, -6.4650e-05, -4.6155e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 1.3280e-05, -2.9432e-05,  6.1653e-06, -5.6736e-05, -6.2898e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0009, -0.0003,  0.0008,  0.0012, -0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0956, -0.0539,  0.0664,  0.0934, -0.0146], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0956, -0.0539,  0.0664,  0.0934, -0.0146], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0095,  0.0021, -0.0162, -0.0209, -0.0040], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0201], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([7.0435], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2285,  0.0549, -0.3958, -0.7287, -0.1120], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2285,  0.0549, -0.3958, -0.7287, -0.1120], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ -3.0382,   3.4507, -18.1443, -10.3497, -14.4179],
       grad_fn=<SliceBackward0>)
  [Layer 47] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 47] Output sample values after mixer: tensor([ -3.0382,   3.4507, -18.1443, -10.3497, -14.4179],
       grad_fn=<SliceBackward0>)
  [Layer 47] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 47] Residual connection sample values: tensor([ -7.7926, -10.7040, -20.6852, -29.5981,  -2.5111],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 48/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1908.0238], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0229], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0651, -0.0965, -0.1843, -0.2412, -0.0217], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.0017, -1.3870, -1.0242, -0.8628, -0.6961], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.0017, -1.3870, -1.0242, -0.8628, -0.6961], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0768,  0.1977, -0.3210, -1.0823, -0.3663], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.3942, -0.9194, -0.5536,  0.6384,  0.2548], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5810, -0.2116,  0.5649,  0.0768,  0.8314], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0153,  0.0340, -0.0352, -0.1271, -0.0582], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0114,  0.0035, -0.0472, -0.2071, -0.1405], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0057,  0.0017, -0.0231, -0.0929, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0057,  0.0017, -0.0231, -0.0929, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0875,  0.0111, -0.2656, -0.0717,  0.0271], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0804, -0.0882, -0.2759, -0.0350, -0.0463], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.7304,  -7.3891,  -3.3797,  -1.8028, -17.7601],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.8612e-03, 8.5695e-05, 3.6894e-03, 3.6250e-02, 1.2089e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9951, 0.9994, 0.9876, 0.9367, 0.1168], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0057,  0.0017, -0.0231, -0.0929, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.4155e-06, -1.8026e-07,  4.2957e-06,  1.1599e-06, -4.3769e-07],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.6250e-04,  5.1183e-04,  8.7266e-04, -2.1598e-04, -3.2503e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0005,  0.0009, -0.0010, -0.0050, -0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0086,  0.0034, -0.0338, -0.1371, -0.0963], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0086,  0.0034, -0.0338, -0.1371, -0.0963], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0023, -0.0009,  0.0091,  0.0351,  0.0223], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0077], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([11.3969], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0933, -0.0422,  0.3922,  1.3249,  1.1458], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0933, -0.0422,  0.3922,  1.3249,  1.1458], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([  3.1324, -20.7950, -17.7617,   3.5367,  10.7316],
       grad_fn=<SliceBackward0>)
  [Layer 48] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 48] Output sample values after mixer: tensor([  3.1324, -20.7950, -17.7617,   3.5367,  10.7316],
       grad_fn=<SliceBackward0>)
  [Layer 48] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 48] Residual connection sample values: tensor([ -4.6603, -31.4990, -38.4469, -26.0614,   8.2205],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3705.5393], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0164], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0784, -0.7651, -0.7395, -0.3957,  0.1422], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Final backbone norm output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Final backbone norm output sample values: tensor([-0.0784, -0.7651, -0.7395, -0.3957,  0.1422], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Logits shape: torch.Size([1, 1, 50288])
[Mamba2LMHeadModel] Logits sample values: tensor([90.4355, 82.0429, 93.1449, 87.1018, 87.0856], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Forward pass input_ids shape: torch.Size([1, 1])
[Mamba2LMHeadModel] input_ids sample values: tensor([432])
[Mamba2LMHeadModel] Embedding output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Embedding sample values: tensor([-0.0597, -0.2578, -0.1704, -0.2057, -0.0127], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 1/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0322], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([5.5727], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0799, -0.4388, -0.2499, -0.2351, -0.0159], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3511,  0.1389, -0.6294, -0.5779, -0.5792], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3511,  0.1389, -0.6294, -0.5779, -0.5792], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0774, -0.6667,  0.2552, -1.1729,  1.4598], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.3213, 0.1852, 0.1699, 0.1092, 0.0146], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.7267, 0.6464, 0.0886, 0.0774, 0.6820], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0111, -0.0285,  0.0618, -0.0079,  0.0710], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0537, -0.0361,  0.1745, -0.2174, -0.1261], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0276, -0.0177,  0.0949, -0.0969, -0.0591], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0276, -0.0177,  0.0949, -0.0969, -0.0591], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2254, -0.0391,  0.0581,  0.6480, -0.0117], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2434, -0.1164, -0.1233, -0.2552,  0.0711], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4384, -1.0011, -1.2129, -1.1530, -1.4844], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0761, 0.0407, 0.0288, 0.0291, 0.0228], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9672, 0.9601, 0.9657, 0.9670, 0.9668], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0276, -0.0177,  0.0949, -0.0969, -0.0591], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-4.7241e-04, -8.1920e-05,  1.2183e-04,  1.3581e-03, -2.4527e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0197, -0.0039, -0.0008,  0.0480, -0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1535,  0.0390,  0.4024, -0.6532, -0.4862], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2008,  0.0086,  0.5651, -0.8194, -0.5876], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2008,  0.0086,  0.5651, -0.8194, -0.5876], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0291,  0.0006, -0.1237,  0.1702,  0.1222], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([40.3331], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1575], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-4.1022e-03,  7.4635e-05, -1.4365e-02,  1.6213e-02,  5.9610e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-4.1022e-03,  7.4635e-05, -1.4365e-02,  1.6213e-02,  5.9610e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0366, -0.0439, -0.1056,  0.0321,  0.0495], grad_fn=<SliceBackward0>)
  [Layer 1] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 1] Output sample values after mixer: tensor([-0.0366, -0.0439, -0.1056,  0.0321,  0.0495], grad_fn=<SliceBackward0>)
  [Layer 1] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 1] Residual connection sample values: tensor([-0.0963, -0.3018, -0.2760, -0.1736,  0.0369], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 2/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0905], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([3.3234], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1850, -0.4865, -0.4107, -0.3505,  0.0645], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2456, -0.8037, -1.3043,  3.5856, -0.3635], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2456, -0.8037, -1.3043,  3.5856, -0.3635], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5496,  0.0887,  0.4687, -1.1392, -0.7259], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.7335,  0.5243, -0.0751,  0.3348,  0.0310], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.4321,  0.1390,  1.8233, -0.5496, -0.3597], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3827, -0.0765, -0.3323,  0.8501,  0.0628], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3920, -0.1064, -0.4442,  0.7060,  0.0662], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1581, -0.0504, -0.1736,  0.4727,  0.0342], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1581, -0.0504, -0.1736,  0.4727,  0.0342], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0071, -0.0636, -0.0301,  0.0807,  0.0156], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0250,  0.2257,  0.4273,  0.0997,  0.0806], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-12.6926, -19.4296,  -0.2289,  -2.1057,  -5.0389],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1022, 0.0584, 0.0229, 0.0865, 0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.2733, 0.3217, 0.9948, 0.8334, 0.7450], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1581, -0.0504, -0.1736,  0.4727,  0.0342], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0001,  0.0010,  0.0005, -0.0013, -0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0002,  0.0010,  0.0004, -0.0013, -0.0002], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0031,  0.0009,  0.0019, -0.0109, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1022, -0.0327, -0.1138,  0.3042,  0.0223], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1022, -0.0327, -0.1138,  0.3042,  0.0223], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0141,  0.0081,  0.0317,  1.0612, -0.0033], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([47.4407], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1452], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0039,  0.0032,  0.0111,  0.2457, -0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0039,  0.0032,  0.0111,  0.2457, -0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0360,  0.0239,  0.0364, -0.0018, -0.0869], grad_fn=<SliceBackward0>)
  [Layer 2] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 2] Output sample values after mixer: tensor([ 0.0360,  0.0239,  0.0364, -0.0018, -0.0869], grad_fn=<SliceBackward0>)
  [Layer 2] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 2] Residual connection sample values: tensor([-0.0604, -0.2779, -0.2396, -0.1754, -0.0500], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 3/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1153], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([2.9442], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1543, -0.5960, -0.4578, -0.4800, -0.1219], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.5929, -0.9816, -1.1079, -0.8428, -1.4759], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.5929, -0.9816, -1.1079, -0.8428, -1.4759], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3079, -1.0469, -1.1915,  0.3597,  1.1678], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.8175,  0.1741,  1.6466,  0.0407,  0.2355], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1130,  0.2154, -0.5941,  0.3079,  1.1922], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0292, -0.1686,  0.2006,  0.4512, -0.1053], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0740, -0.2464,  0.1495,  0.4046, -0.1721], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0356, -0.1081,  0.0803,  0.2427, -0.0787], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0356, -0.1081,  0.0803,  0.2427, -0.0787], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2442,  0.2670,  0.1252, -0.2146, -0.1354], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2779,  0.0661, -0.0367,  0.4334,  0.2647], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-20.9265,  -0.8803,  -0.6735,  -0.6461,  -0.2726],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0056, 0.0058, 0.0002, 0.0055, 0.0130], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8901, 0.9949, 0.9998, 0.9965, 0.9965], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0356, -0.1081,  0.0803,  0.2427, -0.0787], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 4.8442e-05, -5.2953e-05, -2.4835e-05,  4.2574e-05,  2.6851e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 6.0979e-05, -6.3194e-04, -1.6222e-04,  2.7576e-05,  3.5806e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0015,  0.0059, -0.0092, -0.0034, -0.0069], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0238, -0.0708,  0.0479,  0.1689, -0.0628], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0238, -0.0708,  0.0479,  0.1689, -0.0628], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0064,  0.0189, -0.0132, -0.0428,  0.0172], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([60.7797], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1283], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0015,  0.0039, -0.0021, -0.0077,  0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0015,  0.0039, -0.0021, -0.0077,  0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1815, -0.3348,  0.1716, -0.0787,  0.2216], grad_fn=<SliceBackward0>)
  [Layer 3] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 3] Output sample values after mixer: tensor([-0.1815, -0.3348,  0.1716, -0.0787,  0.2216], grad_fn=<SliceBackward0>)
  [Layer 3] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 3] Residual connection sample values: tensor([-0.2419, -0.6127, -0.0680, -0.2541,  0.1717], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 4/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1813], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([2.3485], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3334, -0.7314, -0.0765, -0.3724,  0.2227], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.2471,  0.1459, -1.2313, -0.3237,  0.1088], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.2471,  0.1459, -1.2313, -0.3237,  0.1088], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5310, -0.4639, -1.2498, -0.8179,  0.5204], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.0174,  0.0516,  1.0330, -0.1414,  0.4172], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.7260,  0.0591, -0.1960, -0.5310,  0.8919], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0559, -0.0917,  0.3524, -0.4900, -0.1155], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0779, -0.0792,  0.3120, -0.5547,  0.1436], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0405, -0.0380,  0.1801, -0.2023,  0.0769], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0405, -0.0380,  0.1801, -0.2023,  0.0769], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2575,  0.0648,  0.0505,  0.0045,  0.0158], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2750,  0.0107,  0.2229, -0.1063,  0.0765], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4907, -0.5048, -0.6491, -0.5552, -0.4657], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0457, 0.0599, 0.2188, 0.0344, 0.4657], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9778, 0.9702, 0.8676, 0.9811, 0.8050], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0405, -0.0380,  0.1801, -0.2023,  0.0769], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-4.7657e-04,  1.1988e-04,  9.3439e-05,  8.3457e-06,  2.9179e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0322, -0.0038,  0.0005,  0.0023, -0.0008], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0893,  0.0117,  0.0161, -0.1799,  0.2984], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1161, -0.0135,  0.1356, -0.3141,  0.3495], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1161, -0.0135,  0.1356, -0.3141,  0.3495], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1125, -0.0011, -0.0377,  0.0427,  0.0200], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([46.3198], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1469], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0498, -0.0005, -0.0150,  0.0187,  0.0064], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0498, -0.0005, -0.0150,  0.0187,  0.0064], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0327, -0.2305, -0.0212,  0.1278, -0.1978], grad_fn=<SliceBackward0>)
  [Layer 4] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 4] Output sample values after mixer: tensor([ 0.0327, -0.2305, -0.0212,  0.1278, -0.1978], grad_fn=<SliceBackward0>)
  [Layer 4] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 4] Residual connection sample values: tensor([-0.2091, -0.8432, -0.0892, -0.1263, -0.0262], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 5/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2310], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([2.0806], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3601, -1.2241, -0.1132, -0.2168, -0.0427], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.1602, -0.6606, -0.8922, -0.9192, -0.6813], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.1602, -0.6606, -0.8922, -0.9192, -0.6813], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.0104, -1.2028, -0.7541,  1.0490,  1.5645], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.2942,  0.4725, -0.7920,  0.7797,  0.9948], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.0947, -0.8512, -2.9134, -0.0104, -0.6500], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-1.0470, -1.5564,  0.2376, -0.1826, -0.0630], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-1.1104, -1.7978,  0.2302, -0.1557, -0.0521], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2752, -0.2555,  0.1283, -0.0718, -0.0254], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2752, -0.2555,  0.1283, -0.0718, -0.0254], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0291, -0.0357, -0.2141,  0.0598, -0.0564], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0600, -0.0281, -0.2544, -0.2747,  0.2502], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0759, -0.5319, -0.0470, -1.4939, -3.6258], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4838, 0.0224, 0.0168, 0.0304, 0.0433], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9639, 0.9882, 0.9992, 0.9556, 0.8548], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2752, -0.2555,  0.1283, -0.0718, -0.0254], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0039,  0.0048,  0.0285, -0.0080,  0.0075], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0175,  0.0039,  0.5059,  0.0441,  0.0070], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.5912, -0.8500, -0.5883, -0.2613, -0.2157], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.9784, -1.2095, -0.4077, -0.3623, -0.2514], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.9784, -1.2095, -0.4077, -0.3623, -0.2514], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.2709, 0.2721, 0.1057, 0.0950, 0.0575], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([111.1090], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0949], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0085, 0.0090, 0.0072, 0.0071, 0.0047], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0085, 0.0090, 0.0072, 0.0071, 0.0047], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0017, -0.0280,  0.0699, -0.0026,  0.0310], grad_fn=<SliceBackward0>)
  [Layer 5] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 5] Output sample values after mixer: tensor([ 0.0017, -0.0280,  0.0699, -0.0026,  0.0310], grad_fn=<SliceBackward0>)
  [Layer 5] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 5] Residual connection sample values: tensor([-0.2074, -0.8712, -0.0194, -0.1288,  0.0048], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 6/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3150], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.7818], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2709, -0.9398, -0.0197, -0.1613,  0.0056], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0794, -0.3025, -0.9335, -0.9005, -1.9608], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0794, -0.3025, -0.9335, -0.9005, -1.9608], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.7968,  0.1228, -0.9523, -0.0570, -0.6439], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.0768, 2.0664, 1.9499, 1.4783, 1.5130], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.9054,  1.1231,  0.0604, -0.7968, -1.4639], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0420,  0.3673, -0.0285, -0.1258,  0.3174], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0892,  0.3813,  0.0527, -0.1375,  0.4556], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0426,  0.2266,  0.0271, -0.0640,  0.2788], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0426,  0.2266,  0.0271, -0.0640,  0.2788], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0331, -0.0054, -0.2698,  0.0376, -0.0536], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.5299,  0.0987, -0.2635,  0.0366, -0.0162], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5110, -0.2862, -0.5421, -0.3954, -0.5986], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3880, 0.6796, 0.4648, 0.5023, 0.3737], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8201, 0.8232, 0.7773, 0.8199, 0.7996], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0426,  0.2266,  0.0271, -0.0640,  0.2788], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.4774e-04,  8.8500e-05,  4.4617e-03, -6.2172e-04,  8.8570e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0071, -0.0060,  0.0192,  0.0049,  0.0083], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0269, -0.0220, -0.0579,  0.0132,  0.1948], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0219,  0.2378, -0.0268, -0.0603,  0.5146], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0219,  0.2378, -0.0268, -0.0603,  0.5146], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0009, -0.0306,  0.0071,  0.0157, -0.1245], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([84.3039], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1089], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0003, -0.0093,  0.0020,  0.0056, -0.0321], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0003, -0.0093,  0.0020,  0.0056, -0.0321], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.3315, -0.4471,  0.1520,  0.0865,  0.0345], grad_fn=<SliceBackward0>)
  [Layer 6] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 6] Output sample values after mixer: tensor([ 0.3315, -0.4471,  0.1520,  0.0865,  0.0345], grad_fn=<SliceBackward0>)
  [Layer 6] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 6] Residual connection sample values: tensor([ 0.1240, -1.3183,  0.1327, -0.0424,  0.0393], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 7/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3865], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.6086], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1453, -1.2539,  0.1225, -0.0501,  0.0399], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 2.2958, -1.1805, -0.4337, -1.8747, -0.8128], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 2.2958, -1.1805, -0.4337, -1.8747, -0.8128], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.0369, -1.6285,  0.0450,  0.6856, -0.4780], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.0937, 2.5049, 1.6038, 0.7401, 0.8523], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.6796, -1.3474,  0.3541, -1.0369, -1.1523], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2172, -0.3218,  0.0274,  0.1867,  0.1753], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2508, -0.3931, -0.1036,  0.1952,  0.1726], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1098, -0.1584, -0.0491,  0.1071,  0.0937], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1098, -0.1584, -0.0491,  0.1071,  0.0937], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0005, -0.0330, -0.1547, -0.0885,  0.2248], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0256,  0.0663, -0.0469, -0.0374,  0.0312], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-6.5957e-02, -4.5478e+00, -5.8281e+00, -4.2034e-01, -1.9005e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5357, 0.3453, 0.1689, 0.2726, 0.4057], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9653, 0.2080, 0.3738, 0.8917, 0.9992], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1098, -0.1584, -0.0491,  0.1071,  0.0937], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.6665e-05,  1.9416e-03,  9.0943e-03,  5.2027e-03, -1.3216e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0962,  0.0124, -0.0245,  0.0090,  0.0725], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0777, -0.0540, -0.0464, -0.0121,  0.0320], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3321, -0.4213, -0.1603,  0.2363,  0.2493], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3321, -0.4213, -0.1603,  0.2363,  0.2493], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.6928,  0.1169,  0.0273, -0.0589, -0.0623], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([17.7974], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2370], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1961,  0.0399,  0.0056, -0.0146, -0.0338], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1961,  0.0399,  0.0056, -0.0146, -0.0338], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1139, -0.3848,  0.4007, -0.1904,  0.2864], grad_fn=<SliceBackward0>)
  [Layer 7] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 7] Output sample values after mixer: tensor([-0.1139, -0.3848,  0.4007, -0.1904,  0.2864], grad_fn=<SliceBackward0>)
  [Layer 7] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 7] Residual connection sample values: tensor([ 0.0101, -1.7031,  0.5334, -0.2328,  0.3257], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 8/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5439], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.3559], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0131, -1.6519,  0.4835, -0.2938,  0.3536], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.9615, -2.7683, -2.1961,  0.2869, -2.3779], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.9615, -2.7683, -2.1961,  0.2869, -2.3779], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5381,  0.3010, -3.0725, -0.7551, -1.1900], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.8376,  3.0908,  1.2101, -0.4415,  1.8323], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8658, -2.0933,  1.9844,  0.5381, -2.1259], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1775, -0.2180,  0.0346, -0.0886, -0.1574], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1001, -0.1369,  0.1010, -0.1855, -0.2200], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0526, -0.0638,  0.0530, -0.0842, -0.0980], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0526, -0.0638,  0.0530, -0.0842, -0.0980], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1235,  0.1243, -0.2423, -0.1290,  0.1187], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0299,  0.0380, -0.0752, -0.0795, -0.0814], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6851, -0.1380, -0.4118, -0.2678, -0.1244], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0430, 4.4203, 0.8282, 0.2719, 2.9829], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9710, 0.5433, 0.7110, 0.9298, 0.6899], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0526, -0.0638,  0.0530, -0.0842, -0.0980], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0003,  0.0003, -0.0005, -0.0003,  0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-4.6139e-03, -2.3340e-02,  6.2943e-05, -2.9268e-02,  8.3459e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1162, -0.0505,  0.0526, -0.0703,  0.0371], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0818, -0.2907,  0.2523, -0.3873, -0.3318], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0818, -0.2907,  0.2523, -0.3873, -0.3318], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0198,  0.0475, -0.0555, -0.0635,  0.0670], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([255.8338], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0625], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0029,  0.0036, -0.0131, -0.0127,  0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0029,  0.0036, -0.0131, -0.0127,  0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0176,  0.0029, -0.1430, -0.0420,  0.0610], grad_fn=<SliceBackward0>)
  [Layer 8] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 8] Output sample values after mixer: tensor([-0.0176,  0.0029, -0.1430, -0.0420,  0.0610], grad_fn=<SliceBackward0>)
  [Layer 8] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 8] Residual connection sample values: tensor([-0.0075, -1.7002,  0.3904, -0.2748,  0.3867], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 9/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.8067], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1134], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0077, -1.3458,  0.2958, -0.2822,  0.3450], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.4020, -2.8970, -1.0159, -0.6202, -2.1016], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.4020, -2.8970, -1.0159, -0.6202, -2.1016], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.9979,  2.1030,  0.2552, -0.1691,  0.1225], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.9326, 2.6974, 2.2721, 2.1638, 1.7475], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([1.1386, 2.1009, 3.7295, 1.9979, 2.1195], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-1.3925,  0.3167, -0.4400, -0.1484, -0.0806], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-1.6459,  0.4073, -0.4442, -0.1417, -0.0992], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2661,  0.2445, -0.1736, -0.0658, -0.0472], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2661,  0.2445, -0.1736, -0.0658, -0.0472], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0510, -0.0478,  0.1534, -0.0755,  0.4904], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0467, -0.2453,  0.3092, -0.1735, -0.0905], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1701, -0.1135, -0.1054, -0.5864, -0.1497], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.4407, 3.5328, 4.0773, 1.0876, 2.0748], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6603, 0.6696, 0.6507, 0.5285, 0.7331], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2661,  0.2445, -0.1736, -0.0658, -0.0472], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0331,  0.0311, -0.0996,  0.0490, -0.3185], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0164,  0.0288, -0.3074,  0.2629, -0.3178], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.6055,  0.2577, -0.2210, -0.0881,  0.0722], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-1.3185,  0.9129, -0.6861, -0.2645, -0.0541], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-1.3185,  0.9129, -0.6861, -0.2645, -0.0541], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.3651, -0.1383,  0.1853,  0.0574,  0.0124], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([105.5160], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0974], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0309, -0.0218,  0.0195,  0.0069,  0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0309, -0.0218,  0.0195,  0.0069,  0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0413,  0.1979,  0.0342, -0.2266, -0.0088], grad_fn=<SliceBackward0>)
  [Layer 9] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 9] Output sample values after mixer: tensor([ 0.0413,  0.1979,  0.0342, -0.2266, -0.0088], grad_fn=<SliceBackward0>)
  [Layer 9] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 9] Residual connection sample values: tensor([ 0.0338, -1.5023,  0.4246, -0.5015,  0.3780], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 10/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.8487], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0855], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0362, -1.2294,  0.3391, -0.5284,  0.3428], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.6408, -0.1024, -1.2919, -4.6026, -1.4483], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.6408, -0.1024, -1.2919, -4.6026, -1.4483], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.1222, -2.3391, -0.3897,  2.1203,  1.8145], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.5135, 0.8667, 1.6484, 0.9130, 0.0293], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.8205, -2.0003,  0.1614,  1.1222,  1.5775], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1019,  0.5804,  0.2950,  0.4331, -0.6995], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2722,  0.5565,  0.2570,  1.0371, -0.6506], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1177,  0.3537,  0.1449,  0.7657, -0.2231], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1177,  0.3537,  0.1449,  0.7657, -0.2231], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2280,  0.2615,  0.0953, -0.1758, -0.1657], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2105, -0.2509, -0.2663, -0.2378,  0.0059], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0854, -0.0771, -0.0845, -0.0547, -0.0697], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.7777, 0.2071, 0.4008, 2.1380, 0.5780], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8592, 0.9842, 0.9667, 0.8897, 0.9605], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1177,  0.3537,  0.1449,  0.7657, -0.2231], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0477, -0.0547, -0.0199,  0.0368,  0.0347], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.1232, -0.9329, -0.0457,  0.4596, -0.0593], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-2.7744,  0.8850, -0.8458, 16.1976, -1.4465], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-3.3474,  2.6073, -0.1402, 19.9259, -2.5326], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-3.3474,  2.6073, -0.1402, 19.9259, -2.5326], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.5884, -0.1266,  0.0390, -0.9103,  0.6979], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([933.1276], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0327], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0117, -0.0054,  0.0018, -0.0328,  0.0305], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0117, -0.0054,  0.0018, -0.0328,  0.0305], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1637,  0.0875, -0.0827, -0.1397,  0.3520], grad_fn=<SliceBackward0>)
  [Layer 10] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 10] Output sample values after mixer: tensor([ 0.1637,  0.0875, -0.0827, -0.1397,  0.3520], grad_fn=<SliceBackward0>)
  [Layer 10] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 10] Residual connection sample values: tensor([ 0.1975, -1.4148,  0.3418, -0.6412,  0.7300], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 11/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.1570], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9297], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1326, -0.7707,  0.1806, -0.4700,  0.4338], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.0239, -1.6836, -2.3647,  1.5592, -1.0469], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.0239, -1.6836, -2.3647,  1.5592, -1.0469], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-6.4846e-01, -6.5560e-02, -9.1970e-05, -9.0672e-01,  3.7216e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-2.3844, -0.9083, -0.5607,  0.5057,  0.4946], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4402, -1.1526, -1.5225, -0.6485, -0.5750], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1479,  0.0050, -0.0245,  0.1410, -0.2917], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2944,  0.1962, -0.0005,  0.2485, -0.1767], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1687,  0.1077, -0.0003,  0.1396, -0.0806], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1687,  0.1077, -0.0003,  0.1396, -0.0806], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2776, -0.0364,  0.7401, -0.0444, -0.1432], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1167, -0.0176, -0.0526, -0.0301, -0.2745], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2593, -0.1261, -0.1036, -0.2378, -0.4305], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0209, 0.0290, 0.0893, 0.8393, 1.0049], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9946, 0.9963, 0.9908, 0.8191, 0.6488], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1687,  0.1077, -0.0003,  0.1396, -0.0806], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0010, -0.0001,  0.0026, -0.0002, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1879,  0.0120,  0.0211, -0.0816,  0.1093], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([0.3322, 0.3167, 0.3359, 0.1730, 0.4707], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2000, -0.0229,  0.3367, -0.2673,  0.7247], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2000, -0.0229,  0.3367, -0.2673,  0.7247], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1507,  0.0060, -0.0684, -0.3444, -0.1971], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([68.6675], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1207], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0064,  0.0019, -0.0385, -0.0364, -0.0243], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0064,  0.0019, -0.0385, -0.0364, -0.0243], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4633, -0.0824,  0.0303, -0.1920,  0.1892], grad_fn=<SliceBackward0>)
  [Layer 11] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 11] Output sample values after mixer: tensor([-0.4633, -0.0824,  0.0303, -0.1920,  0.1892], grad_fn=<SliceBackward0>)
  [Layer 11] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 11] Residual connection sample values: tensor([-0.2658, -1.4972,  0.3721, -0.8332,  0.9193], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 12/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.4805], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.8218], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1401, -0.6285,  0.1428, -0.4978,  0.4098], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.7065, -0.2618,  0.2172, -0.8412, -0.3802], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.7065, -0.2618,  0.2172, -0.8412, -0.3802], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([0.2865, 1.4185, 0.5341, 1.1387, 1.8012], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.6141, -0.0066, -0.3163, -1.8517,  0.5304], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5588, -0.7531, -2.4550,  0.2865,  0.3170], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6749,  0.6119, -0.0662,  0.0958, -0.7506], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.7421, -0.2225, -0.1310,  0.0516, -0.9173], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2394, -0.0989, -0.0612,  0.0265, -0.2619], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2394, -0.0989, -0.0612,  0.0265, -0.2619], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1211, -0.1796,  0.0927,  0.5023, -0.0224], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.3894, -0.1449,  0.0814, -0.2766,  1.2508], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1609, -0.1475, -0.2713, -0.1155, -0.0902], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6486, 0.5714, 0.9312, 0.4685, 0.1159], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9009, 0.9192, 0.7768, 0.9473, 0.9896], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2394, -0.0989, -0.0612,  0.0265, -0.2619], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0188,  0.0279, -0.0144, -0.0780,  0.0035], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0474,  0.0322,  0.0418, -0.2005, -0.0276], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.5246, -1.2452, -0.0890, -0.0358,  2.6475], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.9130, -1.4057, -0.1883,  0.0072,  2.2225], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.9130, -1.4057, -0.1883,  0.0072,  2.2225], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.4319,  0.1601, -0.0227, -0.0018, -0.3431], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([116.6779], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0926], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0607,  0.0131, -0.0036, -0.0006, -0.0415], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0607,  0.0131, -0.0036, -0.0006, -0.0415], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1167, -0.4979,  0.1722,  0.0516,  0.4634], grad_fn=<SliceBackward0>)
  [Layer 12] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 12] Output sample values after mixer: tensor([-0.1167, -0.4979,  0.1722,  0.0516,  0.4634], grad_fn=<SliceBackward0>)
  [Layer 12] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 12] Residual connection sample values: tensor([-0.3825, -1.9951,  0.5443, -0.7816,  1.3827], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 13/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.9896], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7090], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1466, -0.6243,  0.1621, -0.3222,  0.4753], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5061, -0.6817, -0.5524, -0.3083,  0.0962], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5061, -0.6817, -0.5524, -0.3083,  0.0962], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8991,  0.3613,  0.8337,  0.1480, -1.0314], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.2258, -0.9129,  0.4547,  0.7107, -0.3655], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1219,  0.5625, -0.9691, -0.8991,  0.4060], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.3209,  0.2850,  0.0632,  0.0134, -0.5670], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2588,  0.2664,  0.0711,  0.0017, -0.5975], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1461,  0.1508,  0.0368,  0.0008, -0.2121], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1461,  0.1508,  0.0368,  0.0008, -0.2121], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.5436, -0.2381,  0.1345, -0.1185, -0.2133], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1627, -0.1616,  0.1028,  0.1877, -0.2312], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0234, -1.0903, -0.5085, -0.6785, -0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1687, 0.0040, 0.0134, 0.0107, 0.1082], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9961, 0.9956, 0.9932, 0.9928, 0.9973], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1461,  0.1508,  0.0368,  0.0008, -0.2121], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0134, -0.0059,  0.0033, -0.0029, -0.0053], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0794,  0.0962, -0.2785,  0.0199, -0.0634], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0268,  0.0492,  0.0332,  0.0044,  0.3349], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0437,  0.0318,  0.0289,  0.0043,  0.3594], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0437,  0.0318,  0.0289,  0.0043,  0.3594], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0083, -0.0073, -0.0058, -0.0006,  0.0181], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.4757], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6356], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0026, -0.0015, -0.0042, -0.0009,  0.0066], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0026, -0.0015, -0.0042, -0.0009,  0.0066], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.3545,  0.2754, -0.0922, -0.1866,  0.1034], grad_fn=<SliceBackward0>)
  [Layer 13] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 13] Output sample values after mixer: tensor([ 0.3545,  0.2754, -0.0922, -0.1866,  0.1034], grad_fn=<SliceBackward0>)
  [Layer 13] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 13] Residual connection sample values: tensor([-0.0280, -1.7197,  0.4521, -0.9682,  1.4861], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 14/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.4576], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6379], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0085, -0.4499,  0.1157, -0.3320,  0.4219], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1759, -0.7978,  0.3006, -0.1331,  0.7266], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1759, -0.7978,  0.3006, -0.1331,  0.7266], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.4263, -1.0929, -1.0112, -2.2908,  0.8293], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.1173, -0.6015,  1.1500,  1.7164,  1.3108], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0043, -0.3358, -0.9533,  0.4263,  0.2673], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0930, -0.3776, -0.8128,  0.5916, -0.2290], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0226, -0.4270, -1.0046,  0.5439, -0.2428], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0112, -0.1686, -0.2693,  0.3442, -0.1067], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0112, -0.1686, -0.2693,  0.3442, -0.1067], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0490,  0.0678, -0.1069, -0.0344, -0.1138], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1786,  0.0774, -0.1696, -0.1134, -0.1784], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-7.2745, -0.0385, -2.2024, -0.0138, -5.3378], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0615, 0.0331, 0.0367, 0.2505, 0.0591], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6393, 0.9987, 0.9224, 0.9966, 0.7294], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0112, -0.1686, -0.2693,  0.3442, -0.1067], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 3.3631e-05, -4.6492e-05,  7.3320e-05,  2.3578e-05,  7.8045e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.7873e-04, -3.9142e-05, -3.3349e-04,  4.0535e-04, -4.8529e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0019, -0.0162, -0.0300,  0.0259, -0.0052], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0069, -0.1489, -0.2419,  0.2967, -0.0892], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0069, -0.1489, -0.2419,  0.2967, -0.0892], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0006,  0.0369, -0.0418, -0.0184, -0.0437], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.8006], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1176], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0015,  0.0677, -0.0526, -0.0336, -0.1013], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0015,  0.0677, -0.0526, -0.0336, -0.1013], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3181,  0.3083,  0.0589, -0.6310,  0.1372], grad_fn=<SliceBackward0>)
  [Layer 14] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 14] Output sample values after mixer: tensor([-0.3181,  0.3083,  0.0589, -0.6310,  0.1372], grad_fn=<SliceBackward0>)
  [Layer 14] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 14] Residual connection sample values: tensor([-0.3461, -1.4114,  0.5109, -1.5991,  1.6233], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 15/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.8769], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5896], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1242, -0.4165,  0.1514, -0.6799,  0.5435], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.0155,  2.2820, -0.1876, -0.7326, -4.3171], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.0155,  2.2820, -0.1876, -0.7326, -4.3171], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.1523, -0.8299,  0.0536, -1.6644,  0.2929], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.2659,  0.0349, -0.9659, -0.7993,  0.4528], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-3.2269,  0.9594,  1.5488,  0.1523, -0.2154], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0159,  0.0373,  0.2284, -0.3217, -0.2266], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3521,  0.0131,  1.5536,  0.1209, -0.2401], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1454,  0.0066,  1.2824,  0.0641, -0.1057], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1454,  0.0066,  1.2824,  0.0641, -0.1057], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1009, -0.1281, -0.0800, -0.0562, -0.1230], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0255,  0.0252,  0.0120, -0.0446, -0.0594], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.4414, -0.0592, -0.7390, -0.0051, -0.0087], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2047, 0.4665, 0.0084, 0.0221, 0.2114], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6067, 0.9727, 0.9938, 0.9999, 0.9982], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1454,  0.0066,  1.2824,  0.0641, -0.1057], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([0.0030, 0.0038, 0.0024, 0.0017, 0.0037], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0054, 0.0079, 0.0019, 0.0046, 0.0087], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0168,  0.0023,  0.1422,  0.0242, -0.0046], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2764,  0.0140,  2.4324,  0.1386, -0.1934], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2764,  0.0140,  2.4324,  0.1386, -0.1934], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0746,  0.0290, -0.2068, -0.0330,  0.0110], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([7.4404], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3666], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0604,  0.0172, -0.0359, -0.0151,  0.0091], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0604,  0.0172, -0.0359, -0.0151,  0.0091], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.4122, -0.3192,  0.5005,  0.0999,  0.2160], grad_fn=<SliceBackward0>)
  [Layer 15] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 15] Output sample values after mixer: tensor([ 0.4122, -0.3192,  0.5005,  0.0999,  0.2160], grad_fn=<SliceBackward0>)
  [Layer 15] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 15] Residual connection sample values: tensor([ 0.0660, -1.7306,  1.0114, -1.4992,  1.8393], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 16/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3.7194], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5185], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0155, -0.3348,  0.1823, -0.4452,  0.4070], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.0897,  1.2109, -4.9619,  0.4291,  0.4803], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.0897,  1.2109, -4.9619,  0.4291,  0.4803], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1827,  0.2212, -1.0751, -0.2342, -0.0516], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.6449, -0.3285,  1.7285,  0.3301,  0.9187], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.8545,  1.4791,  2.1004, -0.1827,  0.3433], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2081, -0.0369, -0.2633,  0.5845, -0.0098], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2062, -0.0281, -0.1266,  0.5463, -0.0023], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1137, -0.0138, -0.0593,  0.3460, -0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1137, -0.0138, -0.0593,  0.3460, -0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1365, -0.0772,  0.0282, -0.0371,  0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0392, -0.0452, -0.0437, -0.2762, -0.1339], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.1349e-03, -3.0370e-03, -2.7156e+00, -4.1511e-03, -4.2926e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1475, 0.0481, 0.1262, 0.0374, 0.0028], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9998, 0.9999, 0.7098, 0.9998, 0.9988], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1137, -0.0138, -0.0593,  0.3460, -0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.2899e-03, -1.2941e-03,  4.7239e-04, -6.2288e-04,  1.8561e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0357,  0.0932,  0.0321,  0.0010, -0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0082,  0.0261, -0.1534,  0.0967,  0.0286], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0183,  0.0293, -0.1396,  0.0162,  0.0288], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0183,  0.0293, -0.1396,  0.0162,  0.0288], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0149,  0.0273,  0.0048,  0.0042,  0.0086], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2722], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9165], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0125,  0.0131,  0.0093,  0.0014,  0.0085], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0125,  0.0131,  0.0093,  0.0014,  0.0085], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2972,  0.1633, -0.0321, -0.0323, -0.2094], grad_fn=<SliceBackward0>)
  [Layer 16] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 16] Output sample values after mixer: tensor([ 0.2972,  0.1633, -0.0321, -0.0323, -0.2094], grad_fn=<SliceBackward0>)
  [Layer 16] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 16] Residual connection sample values: tensor([ 0.3632, -1.5673,  0.9793, -1.5315,  1.6299], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 17/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.0597], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4963], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1217, -0.4520,  0.2822, -0.5883,  0.5032], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-4.9344, -2.0509,  0.4357, -0.9693, -1.9961], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-4.9344, -2.0509,  0.4357, -0.9693, -1.9961], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1690,  0.9230,  0.8067,  0.0480, -0.9840], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.9513, 1.4388, 0.5141, 0.9907, 0.3491], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 2.4675,  1.2513,  0.3392, -0.1690, -1.3283], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.7902, -0.0367,  0.2210,  0.0085, -0.2425], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.8852, -0.0146,  0.1065,  0.0429, -0.1473], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2586, -0.0072,  0.0561,  0.0219, -0.0682], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2586, -0.0072,  0.0561,  0.0219, -0.0682], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0518,  0.1787, -0.2774, -0.1237, -0.1924], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1675, -0.0787, -0.2784, -0.2139, -0.0690], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3863, -0.8773, -1.4027, -0.6828, -0.3905], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.7189, 0.3110, 0.2089, 0.5697, 0.4270], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.3691, 0.7612, 0.7460, 0.6777, 0.8464], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2586, -0.0072,  0.0561,  0.0219, -0.0682], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0096, -0.0332,  0.0516,  0.0230,  0.0358], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0070, -0.0290,  0.0371,  0.0249,  0.0228], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1007,  0.0269, -0.0016,  0.0309, -0.0193], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.7818,  0.0079,  0.1462,  0.0886, -0.1990], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.7818,  0.0079,  0.1462,  0.0886, -0.1990], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0276, -0.0018,  0.0387, -0.0236,  0.0475], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([24.7811], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2009], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0108, -0.0007,  0.0163, -0.0122,  0.0227], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0108, -0.0007,  0.0163, -0.0122,  0.0227], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2994, -0.1294, -0.2544,  0.3660, -1.1462], grad_fn=<SliceBackward0>)
  [Layer 17] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 17] Output sample values after mixer: tensor([-0.2994, -0.1294, -0.2544,  0.3660, -1.1462], grad_fn=<SliceBackward0>)
  [Layer 17] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 17] Residual connection sample values: tensor([ 0.0638, -1.6967,  0.7250, -1.1655,  0.4838], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 18/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.5300], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4698], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0144, -0.3307,  0.1392, -0.3193,  0.0965], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0874, -0.5243, -0.8109, -0.5787, -0.3866], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0874, -0.5243, -0.8109, -0.5787, -0.3866], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6630,  1.6620,  0.6071, -0.1924, -0.0329], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.2493,  2.6122,  2.1437,  2.2453, -0.1600], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6895, -0.5580, -0.2216, -0.6630, -0.8774], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1428, -0.8553, -0.1411, -0.0051, -0.1096], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1522, -1.2532, -0.1299,  0.0254, -0.1618], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0819, -0.2784, -0.0607,  0.0129, -0.0744], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0819, -0.2784, -0.0607,  0.0129, -0.0744], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0206,  0.0273,  0.0626, -0.1161,  0.0284], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0169,  0.1157,  0.0124, -0.1917,  0.0360], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.3195e-03, -6.5336e+00, -1.4897e+01, -1.3796e-03, -2.0873e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.8477, 3.7474, 3.6173, 0.7397, 0.1179], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9804e-01, 2.3271e-11, 3.9558e-24, 9.9898e-01, 9.9975e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0819, -0.2784, -0.0607,  0.0129, -0.0744], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0014,  0.0019,  0.0043, -0.0081,  0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0023, -0.0040,  0.0964, -0.0492,  0.0160], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1730, -1.4885,  0.1019, -0.1362, -0.3030], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1794, -1.4665,  0.1067, -0.1372, -0.2971], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1794, -1.4665,  0.1067, -0.1372, -0.2971], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0075,  0.2859, -0.0266,  0.0285,  0.0465], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([19.9354], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2240], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0083,  0.0774, -0.0065,  0.0162,  0.0124], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0083,  0.0774, -0.0065,  0.0162,  0.0124], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0416, -0.1731,  0.3755, -0.1829, -0.0989], grad_fn=<SliceBackward0>)
  [Layer 18] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 18] Output sample values after mixer: tensor([ 0.0416, -0.1731,  0.3755, -0.1829, -0.0989], grad_fn=<SliceBackward0>)
  [Layer 18] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 18] Residual connection sample values: tensor([ 0.1054, -1.8698,  1.1005, -1.3484,  0.3849], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 19/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.8233], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4553], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0286, -0.4215,  0.2508, -0.4527,  0.0928], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.7255, -0.5389, -0.5226, -1.5022, -1.5443], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.7255, -0.5389, -0.5226, -1.5022, -1.5443], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-2.6270,  1.8049,  0.1485,  0.8002,  0.8016], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.8941, 0.4651, 1.3609, 0.7423, 0.6520], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.5319, -1.0119, -0.5868, -2.6270,  1.2369], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0435,  0.3442,  0.0587, -0.7716,  0.1219], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0949,  0.3447,  0.0449, -0.9792,  0.1207], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0452,  0.2018,  0.0230, -0.2674,  0.0640], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0452,  0.2018,  0.0230, -0.2674,  0.0640], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0270, -0.0935,  1.0595, -0.0539,  0.5781], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1283,  0.0118, -0.1142, -0.0006,  0.0981], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1739, -1.5063, -1.5725, -0.1983, -0.0768], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.9970, 0.4190, 0.8978, 2.0339, 0.6130], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7065, 0.5320, 0.2437, 0.6682, 0.9540], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0452,  0.2018,  0.0230, -0.2674,  0.0640], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0024,  0.0084, -0.0956,  0.0049, -0.0522], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0124,  0.0271, -0.1789,  0.0299, -0.0385], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3229,  0.6173,  0.0793, -0.8107,  0.3308], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3918,  0.9245,  0.1143, -1.2179,  0.4283], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3918,  0.9245,  0.1143, -1.2179,  0.4283], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1915, -0.1836, -0.0222,  0.3331, -0.1163], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([38.6970], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1608], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0359, -0.0595, -0.0086,  0.0530, -0.0685], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0359, -0.0595, -0.0086,  0.0530, -0.0685], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.8332,  0.1600,  1.0540,  0.0363, -0.0202], grad_fn=<SliceBackward0>)
  [Layer 19] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 19] Output sample values after mixer: tensor([-0.8332,  0.1600,  1.0540,  0.0363, -0.0202], grad_fn=<SliceBackward0>)
  [Layer 19] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 19] Residual connection sample values: tensor([-0.7278, -1.7099,  2.1545, -1.3121,  0.3647], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 20/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([6.2852], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3989], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1071, -0.2303,  0.2904, -0.2363,  0.0524], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0514, -0.7613,  0.0095,  0.5643,  0.7334], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0514, -0.7613,  0.0095,  0.5643,  0.7334], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.0315, -1.0853, -0.6687,  0.5481, -1.0764], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.3763,  1.5502,  0.0269,  0.6329,  0.6559], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0231, -0.1964,  0.3091, -0.0315, -1.0546], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0005,  0.3461, -0.2683,  0.1209, -0.1868], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0140,  0.3079, -0.4479,  0.0999, -0.2334], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0069,  0.1775, -0.1746,  0.0524, -0.1031], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0069,  0.1775, -0.1746,  0.0524, -0.1031], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0319,  0.0136,  0.0011, -0.1738, -0.0531], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0366,  0.1386,  0.0666,  0.0529, -0.0021], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.0858e-01, -2.9306e+00, -5.2962e+00, -1.2326e+01, -8.1593e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0049, 0.1181, 0.0610, 0.1391, 0.0798], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9985, 0.7075, 0.7239, 0.1801, 0.9993], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0069,  0.1775, -0.1746,  0.0524, -0.1031], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.0764e-06, -4.6024e-07, -3.5716e-08,  5.8703e-06,  1.7920e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.2127e-04, -2.4489e-04, -1.9197e-04,  9.9578e-05, -4.6869e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0009,  0.0009,  0.0022, -0.0022, -0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0066,  0.1469, -0.1414,  0.0409, -0.0868], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0066,  0.1469, -0.1414,  0.0409, -0.0868], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0002, -0.0356, -0.0007,  0.0147, -0.0430], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1011], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.1455], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0013, -0.2415, -0.0031,  0.1129, -0.2155], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0013, -0.2415, -0.0031,  0.1129, -0.2155], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1773,  0.6713,  0.7233, -0.6951,  0.4799], grad_fn=<SliceBackward0>)
  [Layer 20] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 20] Output sample values after mixer: tensor([ 0.1773,  0.6713,  0.7233, -0.6951,  0.4799], grad_fn=<SliceBackward0>)
  [Layer 20] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 20] Residual connection sample values: tensor([-0.5505, -1.0386,  2.8777, -2.0072,  0.8447], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 21/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([6.2929], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3986], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1109, -0.1893,  0.5375, -0.4782,  0.1636], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0591, -1.2998, -0.1172, -0.0413, -1.1420], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0591, -1.2998, -0.1172, -0.0413, -1.1420], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.2195, -0.5812,  0.4072,  0.2191,  2.0294], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.2369, -0.1802, -0.1206,  0.2556,  0.1585], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.0821, -0.4285, -2.0421, -1.2195, -0.4590], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.5627, -0.1594, -0.0090, -0.1251,  0.5189], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.9202, -0.2568, -0.0347, -0.2231,  0.4649], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2622, -0.1120, -0.0170, -0.0992,  0.2855], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2622, -0.1120, -0.0170, -0.0992,  0.2855], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.5830,  0.0806, -0.1991, -0.2497, -0.0456], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0609, -0.1196,  0.0758, -0.1062, -0.0815], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3228, -0.3764, -0.1595, -0.1054, -0.3757], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6170, 0.5033, 0.7425, 0.5401, 0.6260], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8194, 0.8274, 0.8883, 0.9447, 0.7904], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2622, -0.1120, -0.0170, -0.0992,  0.2855], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0943, -0.0130,  0.0322,  0.0404,  0.0074], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0915,  0.0926,  0.0583,  0.0944,  0.0201], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.5185, -0.2174, -0.1018, -0.1748,  0.5407], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-1.0726, -0.4541, -0.1378, -0.3843,  1.1441], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-1.0726, -0.4541, -0.1378, -0.3843,  1.1441], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0326,  0.1264,  0.0076,  0.0078, -0.3161], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([9.6254], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3223], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0219,  0.1072,  0.0073,  0.0052, -0.1833], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0219,  0.1072,  0.0073,  0.0052, -0.1833], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.5887, -0.1763, -0.6633, -0.3101, -0.1456], grad_fn=<SliceBackward0>)
  [Layer 21] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 21] Output sample values after mixer: tensor([ 0.5887, -0.1763, -0.6633, -0.3101, -0.1456], grad_fn=<SliceBackward0>)
  [Layer 21] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 21] Residual connection sample values: tensor([ 0.0383, -1.2149,  2.2145, -2.3173,  0.6990], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 22/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([8.0635], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3522], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0070, -0.2046,  0.3734, -0.4985,  0.1233], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.1030,  1.5389,  0.8440, -4.0863,  0.4942], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.1030,  1.5389,  0.8440, -4.0863,  0.4942], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6606, -0.7795, -0.1196,  0.9623, -0.3769], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.1925, -0.5197, -0.2250,  1.1531, -0.1718], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.0115, -0.3442,  0.2561, -0.6606,  0.8055], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0212, -0.2029, -0.1606,  0.2580, -0.1371], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0294, -0.1384, -0.1480,  0.2396, -0.1365], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0149, -0.0644, -0.0685,  0.1341, -0.0636], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0149, -0.0644, -0.0685,  0.1341, -0.0636], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2754,  0.0523,  0.0679, -0.1393,  0.2005], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2763,  0.1020,  0.2869, -0.2741, -0.1153], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0709, -0.0702, -0.0699, -0.0895, -0.3897], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4307, 0.5213, 0.0933, 0.8038, 0.6328], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9699, 0.9641, 0.9935, 0.9306, 0.7814], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0149, -0.0644, -0.0685,  0.1341, -0.0636], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0018,  0.0003,  0.0004, -0.0009,  0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0033, 0.0234, 0.0053, 0.0118, 0.0441], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0241,  0.1358, -0.1944,  0.0351, -0.0102], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0498,  0.2468, -0.0763, -0.1961,  0.0995], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0498,  0.2468, -0.0763, -0.1961,  0.0995], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0412,  0.3127, -0.0450,  0.0132,  0.0305], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([13.7317], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2699], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0294,  0.0966, -0.0321,  0.0140,  0.0208], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0294,  0.0966, -0.0321,  0.0140,  0.0208], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0548,  0.2464, -1.0218, -0.3297,  0.6297], grad_fn=<SliceBackward0>)
  [Layer 22] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 22] Output sample values after mixer: tensor([ 0.0548,  0.2464, -1.0218, -0.3297,  0.6297], grad_fn=<SliceBackward0>)
  [Layer 22] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 22] Residual connection sample values: tensor([ 0.0931, -0.9685,  1.1927, -2.6470,  1.3288], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 23/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([9.2738], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3284], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0134, -0.1263,  0.1637, -0.4698,  0.1785], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1956,  1.6703, -2.2459,  0.9536, -1.0305], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1956,  1.6703, -2.2459,  0.9536, -1.0305], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1181, -0.2399,  0.9308, -0.2341,  0.7433], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.1134,  0.3470,  0.3327, -0.0649,  0.1109], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.5488,  0.0025,  0.2032, -0.1181, -0.2129], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1073,  0.0065,  0.1842, -0.0455,  0.2867], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0736, -0.0010,  0.1422, -0.0292,  0.2822], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0382, -0.0005,  0.0761, -0.0144,  0.1609], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0382, -0.0005,  0.0761, -0.0144,  0.1609], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1438,  0.0222,  0.0496,  0.2943,  0.0448], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0238, -0.0360,  0.1848,  0.0803, -0.0033], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1232, -0.2255, -0.2420, -0.0956, -0.2396], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0645, 0.2919, 0.2801, 0.0699, 0.1936], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9921, 0.9363, 0.9345, 0.9933, 0.9547], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0382, -0.0005,  0.0761, -0.0144,  0.1609], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-3.5396e-04,  5.4552e-05,  1.2220e-04,  7.2441e-04,  1.1020e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0251,  0.0122, -0.0013,  0.0769, -0.0113], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0390,  0.0098,  0.2384, -0.0402,  0.0444], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0408,  0.0098,  0.2348, -0.0396,  0.0369], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0408,  0.0098,  0.2348, -0.0396,  0.0369], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0036,  0.0138, -0.0505, -0.0272, -0.0100], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.8689], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0728], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0038,  0.0442, -0.2654, -0.1437, -0.0293], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0038,  0.0442, -0.2654, -0.1437, -0.0293], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2254, -0.4768, -0.1011,  0.2062, -1.4079], grad_fn=<SliceBackward0>)
  [Layer 23] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 23] Output sample values after mixer: tensor([-0.2254, -0.4768, -0.1011,  0.2062, -1.4079], grad_fn=<SliceBackward0>)
  [Layer 23] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 23] Residual connection sample values: tensor([-0.1322, -1.4453,  1.0916, -2.4408, -0.0792], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 24/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([11.9311], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2895], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0211, -0.2051,  0.1683, -0.4478, -0.0117], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.3240, -1.2103,  0.8109,  0.0346, -0.7383], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.3240, -1.2103,  0.8109,  0.0346, -0.7383], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.7085, -0.0937, -2.2439, -0.7281,  0.1510], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.0901,  0.6229,  1.0718,  0.0808,  1.0132], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2398, -0.4168,  0.1667,  0.7085, -1.8114], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3113, -0.0075, -0.2415, -0.1936, -0.0452], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1843,  0.0898, -0.2436, -0.2727, -0.0384], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0837,  0.0469, -0.1071, -0.1179, -0.0188], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0837,  0.0469, -0.1071, -0.1179, -0.0188], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.4236, -0.1653,  0.0737, -0.0678, -0.0108], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0012, -0.0159, -0.1144,  0.1638, -0.1263], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6296, -0.1967, -0.1434, -0.1402, -0.2238], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.7268, 1.1346, 1.1995, 1.2085, 0.9671], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6328, 0.8000, 0.8420, 0.8442, 0.8054], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0837,  0.0469, -0.1071, -0.1179, -0.0188], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0258,  0.0101, -0.0045,  0.0041,  0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0180,  0.0117, -0.0103,  0.0112, -0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0281, -0.0231, -0.0987, -0.1781, -0.0371], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3818,  0.2068, -0.6230, -0.7555, -0.1293], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3818,  0.2068, -0.6230, -0.7555, -0.1293], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.3993, -0.0575, -0.3498, -0.0133,  0.0309], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([16.6790], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2449], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1079, -0.0485, -0.2594, -0.0073,  0.0158], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1079, -0.0485, -0.2594, -0.0073,  0.0158], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5891, -2.2833, -0.6622,  0.4242,  0.4029], grad_fn=<SliceBackward0>)
  [Layer 24] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 24] Output sample values after mixer: tensor([-0.5891, -2.2833, -0.6622,  0.4242,  0.4029], grad_fn=<SliceBackward0>)
  [Layer 24] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 24] Residual connection sample values: tensor([-0.7213, -3.7286,  0.4294, -2.0166,  0.3237], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 25/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([16.0825], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2494], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0691, -0.3314,  0.0383, -0.2211,  0.0290], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.1248, -0.4450, -2.1032,  0.9072,  0.1319], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.1248, -0.4450, -2.1032,  0.9072,  0.1319], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5788, -0.1598,  1.1738, -0.6132, -0.2334], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.1198, 1.1462, 0.6279, 0.8275, 0.6464], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1364,  0.7093, -0.5925,  0.5788, -0.4162], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2030,  0.0214, -0.2822, -0.4251, -0.1389], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2223,  0.0248, -0.1796, -0.5302, -0.1775], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0988,  0.0125, -0.0817, -0.1964, -0.0809], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0988,  0.0125, -0.0817, -0.1964, -0.0809], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0414, -0.0718, -0.0693, -0.0368, -0.0298], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2191, -0.2248,  0.2541,  0.0183, -0.0257], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1626, -0.3327, -0.3294, -0.2016, -0.1541], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6371, 0.8477, 0.5691, 0.8139, 0.8434], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9016, 0.7543, 0.8290, 0.8487, 0.8781], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0988,  0.0125, -0.0817, -0.1964, -0.0809], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([0.0026, 0.0045, 0.0044, 0.0023, 0.0019], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0033,  0.0078,  0.0064,  0.0059, -0.0171], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0018,  0.0116, -0.1051, -0.3566, -0.1488], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0926,  0.0231, -0.1802, -0.5371, -0.2231], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0926,  0.0231, -0.1802, -0.5371, -0.2231], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0255, -0.0040,  0.0412, -0.3472, -0.0157], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4603], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.4739], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1308, -0.0161,  0.1382, -0.6531, -0.0455], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1308, -0.0161,  0.1382, -0.6531, -0.0455], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.3044, -0.3397, -0.9465,  0.7573, -1.8912], grad_fn=<SliceBackward0>)
  [Layer 25] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 25] Output sample values after mixer: tensor([ 0.3044, -0.3397, -0.9465,  0.7573, -1.8912], grad_fn=<SliceBackward0>)
  [Layer 25] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 25] Residual connection sample values: tensor([-0.4169, -4.0683, -0.5171, -1.2593, -1.5675], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 26/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([18.5798], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2320], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0462, -0.4203, -0.0562, -0.1678, -0.1663], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3939,  0.4085, -0.9908, -1.1138,  1.3752], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3939,  0.4085, -0.9908, -1.1138,  1.3752], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5482, -0.5526,  1.9438, -0.7674,  0.0696], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.7378, 1.3974, 0.5774, 1.1618, 1.5452], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.1091, -0.8268, -1.5061, -0.5482, -0.2470], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2118, -0.2018, -0.5501, -0.2299, -0.0579], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3028, -0.2557, -0.5754, -0.2932, -0.3257], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1286, -0.1116, -0.2071, -0.1253, -0.1366], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1286, -0.1116, -0.2071, -0.1253, -0.1366], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([0.0204, 0.0892, 0.0762, 0.0790, 0.0445], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0817, -0.2586, -0.2450,  0.0096, -0.0675], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3298, -0.0634, -0.2289, -0.1264, -0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.9415, 0.6140, 2.0655, 2.3402, 1.4591], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7331, 0.9618, 0.6233, 0.7440, 0.9183], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1286, -0.1116, -0.2071, -0.1253, -0.1366], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0025, -0.0108, -0.0092, -0.0096, -0.0054], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0359,  0.0133, -0.0068, -0.0446, -0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.4114, -0.4125, -0.4018,  0.0255, -0.6671], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.9302, -0.8626, -1.2372, -0.4798, -1.2179], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.9302, -0.8626, -1.2372, -0.4798, -1.2179], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1476, -0.2117,  0.3319,  0.1321, -1.3368], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([10.7220], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3054], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1067, -0.1068,  0.2211,  0.0967, -0.7204], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1067, -0.1068,  0.2211,  0.0967, -0.7204], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4940, -0.3696,  0.7401, -0.2552, -1.6153], grad_fn=<SliceBackward0>)
  [Layer 26] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 26] Output sample values after mixer: tensor([-0.4940, -0.3696,  0.7401, -0.2552, -1.6153], grad_fn=<SliceBackward0>)
  [Layer 26] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 26] Residual connection sample values: tensor([-0.9109, -4.4379,  0.2230, -1.5144, -3.1828], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 27/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([22.8035], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2094], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0795, -0.3687,  0.0188, -0.1528, -0.2797], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6977, -1.9497,  0.7666, -0.3324, -0.9749], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6977, -1.9497,  0.7666, -0.3324, -0.9749], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5523,  0.1930, -0.2688, -0.4154, -0.1834], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.8192, -0.2110,  1.2477,  2.2902,  0.2784], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.3812,  0.0210, -0.5378,  0.5523, -0.5171], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1199,  0.0776, -0.0640,  0.2717, -0.0248], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1366,  0.0258, -0.1191,  0.0715, -0.0230], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0636,  0.0131, -0.0560,  0.0370, -0.0113], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0636,  0.0131, -0.0560,  0.0370, -0.0113], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1116, -0.0122,  0.1985,  0.0629, -0.1920], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1706,  0.2377, -0.1677,  0.4521, -0.0846], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5626, -0.0303, -0.7559, -1.1613, -0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4005, 0.0363, 0.0321, 0.5824, 0.0417], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7983, 0.9989, 0.9761, 0.5084, 0.9983], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0636,  0.0131, -0.0560,  0.0370, -0.0113], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0028,  0.0003, -0.0051, -0.0016,  0.0049], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0042, -0.0078, -0.0076, -0.0065,  0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0623, -0.0118, -0.0174, -0.0051,  0.0123], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1888,  0.0143, -0.1288,  0.0685, -0.0102], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1888,  0.0143, -0.1288,  0.0685, -0.0102], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0438, -0.0035, -0.0674, -0.0095,  0.0027], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.1842], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9189], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0924, -0.0057, -0.1615, -0.0059,  0.0084], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0924, -0.0057, -0.1615, -0.0059,  0.0084], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.5603,  0.9899,  0.0074, -0.9881, -0.8498], grad_fn=<SliceBackward0>)
  [Layer 27] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 27] Output sample values after mixer: tensor([ 0.5603,  0.9899,  0.0074, -0.9881, -0.8498], grad_fn=<SliceBackward0>)
  [Layer 27] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 27] Residual connection sample values: tensor([-0.3506, -3.4480,  0.2303, -2.5025, -4.0325], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 28/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([24.7784], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2009], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0251, -0.2378,  0.0162, -0.2096, -0.2799], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.1399, -0.9269, -0.2187, -0.3374,  0.6798], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.1399, -0.9269, -0.2187, -0.3374,  0.6798], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.6444,  1.0505, -0.4812, -0.7121, -1.1701], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.3942, 0.6405, 0.3527, 0.3734, 1.3982], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.2641, -0.6237, -1.4452, -1.6444,  0.9191], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.5779,  0.4326, -0.1574,  0.1908, -0.2399], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.4500,  0.3432, -0.2865,  0.1007, -0.3056], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.2748,  0.2007, -0.1229,  0.0529, -0.1296], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.2748,  0.2007, -0.1229,  0.0529, -0.1296], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1208,  0.0552, -0.0667, -0.0096, -0.2216], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0497,  0.0011,  0.0715,  0.3026, -0.0754], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5442, -0.1843, -0.1064, -0.1124, -0.2523], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5844, 0.8139, 1.1385, 1.0750, 1.2518], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7276, 0.8607, 0.8859, 0.8862, 0.7291], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.2748,  0.2007, -0.1229,  0.0529, -0.1296], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0194,  0.0089, -0.0107, -0.0015, -0.0356], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0067,  0.0057, -0.0072, -0.0013, -0.0037], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0346,  0.0193, -0.0216,  0.0061, -0.0263], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.5472,  0.3938, -0.2509,  0.1048, -0.2681], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.5472,  0.3938, -0.2509,  0.1048, -0.2681], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1512, -0.1035,  0.0244, -0.0147, -0.1210], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2559], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9766], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.6093, -0.3920,  0.0884, -0.0615, -0.5880], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.6093, -0.3920,  0.0884, -0.0615, -0.5880], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1683, -0.4417,  0.2139,  1.8282,  2.5825], grad_fn=<SliceBackward0>)
  [Layer 28] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 28] Output sample values after mixer: tensor([ 0.1683, -0.4417,  0.2139,  1.8282,  2.5825], grad_fn=<SliceBackward0>)
  [Layer 28] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 28] Residual connection sample values: tensor([-0.1823, -3.8897,  0.4443, -0.6743, -1.4500], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 29/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([34.4432], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1704], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0137, -0.2880,  0.0336, -0.0625, -0.1092], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6663, -0.2611,  0.1309, -1.0761,  2.4115], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6663, -0.2611,  0.1309, -1.0761,  2.4115], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([0.5166, 0.4978, 1.7297, 0.4764, 1.1811], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.7958, 0.3048, 1.3982, 1.1430, 0.9512], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.1798, 0.7339, 0.0419, 0.5166, 0.2175], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0967, -0.1294, -0.4511, -0.0710,  0.1962], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1107, -0.2050, -0.5894,  0.2957,  1.6962], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0584, -0.0920, -0.2103,  0.1696,  1.4333], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0584, -0.0920, -0.2103,  0.1696,  1.4333], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1685,  0.1333, -0.0630, -0.0165,  0.0422], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2007, -0.1185, -0.1850,  0.1276,  0.2967], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6542, -0.1369, -1.4589, -0.3682, -0.1218], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4202, 0.0741, 0.3376, 0.2935, 0.6290], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7596, 0.9899, 0.6111, 0.8976, 0.9263], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0584, -0.0920, -0.2103,  0.1696,  1.4333], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0041,  0.0033, -0.0015, -0.0004,  0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.4804e-05,  2.8369e-03, -1.7325e-03, -2.3300e-03,  2.8969e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0046, -0.0128, -0.0148,  0.0438,  0.1614], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0936, -0.1675, -0.3683,  0.3288,  2.5707], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0936, -0.1675, -0.3683,  0.3288,  2.5707], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0212,  0.0190, -0.0257, -0.0900,  5.6890], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3336], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.7312], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1198,  0.0841, -0.0848, -0.3647,  3.5731], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1198,  0.0841, -0.0848, -0.3647,  3.5731], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.9764,  0.7267,  1.1684, -3.4649,  1.1027], grad_fn=<SliceBackward0>)
  [Layer 29] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 29] Output sample values after mixer: tensor([ 1.9764,  0.7267,  1.1684, -3.4649,  1.1027], grad_fn=<SliceBackward0>)
  [Layer 29] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 29] Residual connection sample values: tensor([ 1.7941, -3.1629,  1.6127, -4.1393, -0.3474], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 30/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([43.0257], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1525], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1116, -0.1878,  0.0976, -0.2940, -0.0210], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4936,  0.8064, -0.5596, -1.3766,  1.9570], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4936,  0.8064, -0.5596, -1.3766,  1.9570], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.9774,  1.0288, -0.9597,  0.1738,  1.7039], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.4000, 1.1941, 0.8454, 0.2881, 1.4079], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.0343, -0.6531,  1.6209, -0.9774,  1.0553], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.3718, -0.2101,  0.0148,  0.0360, -0.0921], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.3290, -0.2519,  0.5900,  0.0854, -0.1846], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1913, -0.1102,  0.3796,  0.0445, -0.0838], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1913, -0.1102,  0.3796,  0.0445, -0.0838], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0340, -0.0990, -0.0295,  0.0426, -0.2642], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2083, -0.1699, -0.1926,  0.0102, -0.2674], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2038, -0.3668, -0.2078, -0.0952, -0.4265], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.7081, 0.6339, 0.8321, 0.1303, 0.7837], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8656, 0.7925, 0.8412, 0.9877, 0.7159], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1913, -0.1102,  0.3796,  0.0445, -0.0838], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0046, -0.0134, -0.0040,  0.0058, -0.0358], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0030, -0.0415, -0.0114, -0.0059,  0.0146], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0177, -0.1149,  1.0680,  0.2006, -0.1422], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0139, -0.1331,  1.1307,  0.2080, -0.1560], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0139, -0.1331,  1.1307,  0.2080, -0.1560], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0026, -0.0742, -0.2301, -0.0577, -0.2676], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5239], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.3815], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0090, -0.2836, -0.5315, -0.2213, -0.3761], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0090, -0.2836, -0.5315, -0.2213, -0.3761], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.5963, -2.5583,  0.5319, -4.2062, -3.9822], grad_fn=<SliceBackward0>)
  [Layer 30] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 30] Output sample values after mixer: tensor([ 1.5963, -2.5583,  0.5319, -4.2062, -3.9822], grad_fn=<SliceBackward0>)
  [Layer 30] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 30] Residual connection sample values: tensor([ 3.3903, -5.7212,  2.1446, -8.3455, -4.3295], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 31/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([64.0903], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1249], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1169, -0.2001,  0.0743, -0.3260, -0.1496], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 2.0140,  0.3128,  1.8167, -0.4005, -0.0843], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 2.0140,  0.3128,  1.8167, -0.4005, -0.0843], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2352, -0.0450,  0.3375,  0.6420,  0.4865], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.3467,  1.0232,  0.6221, -0.5687,  1.4167], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.1196, -0.4060,  0.7385,  0.2352,  0.2736], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0411, -0.0024, -0.0597, -0.2381,  0.4356], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0440,  0.0326, -0.0703, -0.2563,  0.3753], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0215,  0.0166, -0.0339, -0.1118,  0.2224], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0215,  0.0166, -0.0339, -0.1118,  0.2224], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0565,  0.0457,  0.0086,  0.0232,  0.0218], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0132, -0.0742, -0.1147, -0.1218, -0.0642], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-9.5766e-03, -1.0642e-02, -2.6350e+01, -6.4468e+02, -1.6547e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0644, 0.1545, 1.4422, 0.9527, 0.2368], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9938e-01, 9.9836e-01, 3.1343e-17, 0.0000e+00, 9.9609e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0215,  0.0166, -0.0339, -0.1118,  0.2224], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 7.8278e-05, -6.3363e-05, -1.1894e-05, -3.2158e-05, -3.0283e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0166, -0.0108,  0.0078,  0.0156,  0.0060], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0092, -0.0257, -0.0067, -0.0728,  0.0190], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0119, -0.0278, -0.0025, -0.0587, -0.0089], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0119, -0.0278, -0.0025, -0.0587, -0.0089], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0211, -0.0050, -0.0039,  0.0094,  0.0004], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0212], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.8589], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.5761, -0.1240, -0.0965,  1.0446,  0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.5761, -0.1240, -0.0965,  1.0446,  0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.0216, -0.0333, -2.2227,  1.0622,  1.3275], grad_fn=<SliceBackward0>)
  [Layer 31] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 31] Output sample values after mixer: tensor([-1.0216, -0.0333, -2.2227,  1.0622,  1.3275], grad_fn=<SliceBackward0>)
  [Layer 31] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 31] Residual connection sample values: tensor([ 2.3687, -5.7545, -0.0781, -7.2833, -3.0021], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 32/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([78.5920], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1128], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1249, -0.2970, -0.0040, -0.4477, -0.1606], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.2736, -2.0029, -0.6351,  0.3589, -1.3330], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.2736, -2.0029, -0.6351,  0.3589, -1.3330], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0156, -0.0857,  0.0125, -1.0108,  0.8905], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.1660, -1.0087,  0.4156, -0.7263,  0.0788], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.0596, -0.3214, -0.7309,  0.0156,  0.3462], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2988,  0.1057, -0.0325,  0.0579, -0.0077], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2851, -0.2622, -0.0346,  0.0344, -0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1627, -0.1140, -0.0170,  0.0175, -0.0099], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1627, -0.1140, -0.0170,  0.0175, -0.0099], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0929,  0.2403,  0.0944, -0.1107,  0.0600], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2732, -0.1959, -0.2607, -0.2494, -0.1311], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0662, -0.0811, -0.5879, -0.0956, -0.5448], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4275, 0.5220, 0.5837, 0.5162, 0.6354], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9721, 0.9585, 0.7095, 0.9519, 0.7074], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1627, -0.1140, -0.0170,  0.0175, -0.0099], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0065,  0.0167,  0.0066, -0.0077,  0.0042], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0142, 0.1225, 0.1368, 0.2562, 0.1547], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.6414, -1.5275,  0.4892,  1.8144, -0.5159], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.6377, -1.5249,  0.4896,  1.8140, -0.5157], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.6377, -1.5249,  0.4896,  1.8140, -0.5157], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1776,  0.3631, -0.1077,  0.3833,  0.1434], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([3.6217], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5255], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1051,  0.4666, -0.1379,  0.3076,  0.1297], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1051,  0.4666, -0.1379,  0.3076,  0.1297], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-2.8870,  1.5606,  3.0422, -1.5176,  1.7496], grad_fn=<SliceBackward0>)
  [Layer 32] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 32] Output sample values after mixer: tensor([-2.8870,  1.5606,  3.0422, -1.5176,  1.7496], grad_fn=<SliceBackward0>)
  [Layer 32] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 32] Residual connection sample values: tensor([-0.5183, -4.1939,  2.9641, -8.8009, -1.2524], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 33/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([97.2063], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1014], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0253, -0.1997,  0.1437, -0.4507, -0.0617], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6519, -1.6376,  0.1777, -0.3337, -0.0733], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6519, -1.6376,  0.1777, -0.3337, -0.0733], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2932, -0.4517,  0.9482, -0.5844, -1.5919], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.1332,  0.5228, -0.7580, -0.7660, -0.0914], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([1.9687, 0.9715, 1.6152, 0.2932, 1.3173], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0949, -0.0638,  0.1464, -0.1955, -0.3078], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1753, -0.1004,  0.1331, -0.3184, -0.3422], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0800, -0.0477,  0.0709, -0.1341, -0.1421], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0800, -0.0477,  0.0709, -0.1341, -0.1421], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1640,  0.1936,  0.0468, -0.0518, -0.2608], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0688,  0.1081,  0.0896, -0.2735, -0.1304], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-13.0444,  -1.3850,  -0.1668,  -0.2359,  -5.2550],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0161, 0.0081, 0.0263, 0.0247, 0.0076], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8105, 0.9888, 0.9956, 0.9942, 0.9609], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0800, -0.0477,  0.0709, -0.1341, -0.1421], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.1122e-04, -2.4932e-04, -6.0265e-05,  6.6730e-05,  3.3590e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 7.9486e-04, -5.4200e-04, -1.1670e-04,  3.2125e-05,  4.0650e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0002, -0.0020, -0.0002,  0.0007, -0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0855, -0.0530,  0.0758, -0.1429, -0.1533], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0855, -0.0530,  0.0758, -0.1429, -0.1533], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0191, 0.0141, 0.0073, 0.0199, 0.0054], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0858], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.4131], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.1796, 0.1290, 0.0913, 0.2082, 0.0640], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.1796, 0.1290, 0.0913, 0.2082, 0.0640], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.0683, -6.5456, -0.4783,  3.4013,  5.7909], grad_fn=<SliceBackward0>)
  [Layer 33] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 33] Output sample values after mixer: tensor([-1.0683, -6.5456, -0.4783,  3.4013,  5.7909], grad_fn=<SliceBackward0>)
  [Layer 33] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 33] Residual connection sample values: tensor([ -1.5866, -10.7394,   2.4858,  -5.3996,   4.5384],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 34/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([123.8209], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0899], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0605, -0.4036,  0.0986, -0.2090,  0.1768], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.1452, -1.6144, -0.1114,  1.3796, -2.1186], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.1452, -1.6144, -0.1114,  1.3796, -2.1186], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.7558, -1.7026, -1.0418,  1.7768, -1.8488], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.9786, -1.8468,  1.5988,  0.4177,  2.1630], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3785, -0.1197, -0.4561, -1.7558, -0.6896], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3595,  0.8399,  0.2540, -0.3152, -0.5434], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4029,  0.7426,  0.2200, -0.3963, -0.6174], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1614,  0.5032,  0.1221, -0.1594, -0.2163], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1614,  0.5032,  0.1221, -0.1594, -0.2163], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0375,  0.0166, -0.0686, -0.0594,  0.0398], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2069, -0.0468, -0.0809,  0.2655, -0.0436], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2225, -0.1537, -0.8169, -0.8591, -2.0730], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0049, 0.0011, 0.7184, 0.1477, 0.9819], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9989, 0.9998, 0.5561, 0.8809, 0.1306], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1614,  0.5032,  0.1221, -0.1594, -0.2163], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.9937e-05, -1.3284e-05,  5.4786e-05,  4.7393e-05, -3.1759e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0030,  0.0074,  0.0035, -0.0065,  0.0105], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0469,  0.1611,  0.0795, -0.0353, -0.0624], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3644,  1.1511,  0.3197, -0.3489, -0.4880], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3644,  1.1511,  0.3197, -0.3489, -0.4880], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1007, -0.3084, -0.0168, -0.3846,  0.1109], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1846], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.3271], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.6264, -1.0725, -0.0874, -2.3633,  0.7266], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.6264, -1.0725, -0.0874, -2.3633,  0.7266], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2941, -1.9801, -2.8187, -1.3477,  2.8866], grad_fn=<SliceBackward0>)
  [Layer 34] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 34] Output sample values after mixer: tensor([ 0.2941, -1.9801, -2.8187, -1.3477,  2.8866], grad_fn=<SliceBackward0>)
  [Layer 34] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 34] Residual connection sample values: tensor([ -1.2925, -12.7195,  -0.3328,  -6.7473,   7.4250],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 35/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([137.6397], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0852], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0619, -0.6040, -0.0157, -0.3443,  0.3532], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.8269, -1.1889, -0.9486, -3.5388, -0.6688], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.8269, -1.1889, -0.9486, -3.5388, -0.6688], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.0327,  0.9422, -2.1003,  1.4072, -1.3436], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.4288, 2.8171, 0.6104, 2.2493, 3.2489], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4899, -0.1723,  1.0363, -1.0327,  0.0389], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1990,  0.2303, -0.4753,  0.2568, -0.3288], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1475,  0.2086, -0.5028,  0.2320, -0.4411], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0792,  0.1151, -0.1895,  0.1294, -0.1727], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0792,  0.1151, -0.1895,  0.1294, -0.1727], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2684, -0.0090,  0.2397, -0.1330, -0.1593], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2099, -0.1455, -0.2522,  0.0978, -0.1531], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2054, -0.1417, -0.1071, -0.1460, -0.2581], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([4.0029, 4.9958, 1.2687, 4.5954, 3.6238], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4395, 0.4927, 0.8730, 0.5111, 0.3925], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0792,  0.1151, -0.1895,  0.1294, -0.1727], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0851, -0.0029,  0.0760, -0.0422, -0.0505], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0647, -0.0098,  0.0480, -0.0792, -0.0714], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.2535,  0.6089, -1.0492,  0.2596, -0.6605], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.4609,  0.9105, -1.5454,  0.5985, -1.1127], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.4609,  0.9105, -1.5454,  0.5985, -1.1127], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1167, -0.2527,  0.4093, -0.0598,  0.2521], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([10.6748], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3061], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1358, -0.2852,  0.1598, -0.1006,  0.2458], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1358, -0.2852,  0.1598, -0.1006,  0.2458], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2864, -3.9206, -3.7854, -1.8786,  6.0813], grad_fn=<SliceBackward0>)
  [Layer 35] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 35] Output sample values after mixer: tensor([ 0.2864, -3.9206, -3.7854, -1.8786,  6.0813], grad_fn=<SliceBackward0>)
  [Layer 35] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 35] Residual connection sample values: tensor([ -1.0060, -16.6401,  -4.1182,  -8.6259,  13.5063],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 36/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([189.8864], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0726], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0365, -0.6173, -0.1503, -0.3341,  0.5020], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.0439, -1.1924, -1.4305, -0.3672, -1.6779], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.0439, -1.1924, -1.4305, -0.3672, -1.6779], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.9087,  1.4494, -0.6022,  0.5934, -0.4281], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.5758, 3.0652, 2.5000, 1.4481, 2.4858], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 2.9650, -0.4971,  1.1749,  0.9087,  2.6883], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3047,  0.3235, -0.1735,  0.1117, -0.0639], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2644,  0.2059, -0.2356, -0.0330, -0.0761], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1148,  0.1135, -0.1040, -0.0162, -0.0366], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1148,  0.1135, -0.1040, -0.0162, -0.0366], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1806, -0.0235, -0.0874, -0.0128, -0.0315], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1070, -0.1016, -0.2780, -0.1084, -0.2011], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.8655, -5.6378, -3.8976, -2.4260, -3.6937], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1212, 0.3150, 0.2014, 0.1586, 0.2638], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7066, 0.1693, 0.4561, 0.6806, 0.3774], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1148,  0.1135, -0.1040, -0.0162, -0.0366], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([0.0025, 0.0003, 0.0012, 0.0002, 0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0028,  0.0013,  0.0004, -0.0001,  0.0028], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0098,  0.0205, -0.0181, -0.0082, -0.0092], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3619,  0.3686, -0.3369, -0.0579, -0.1214], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3619,  0.3686, -0.3369, -0.0579, -0.1214], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0984, -0.1023,  0.0930,  0.0087,  0.0320], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7474], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1567], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2181, -0.4846,  0.3044,  0.0304,  0.1272], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.2181, -0.4846,  0.3044,  0.0304,  0.1272], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.5012, -3.6260,  3.3670,  1.1371,  4.2222], grad_fn=<SliceBackward0>)
  [Layer 36] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 36] Output sample values after mixer: tensor([ 2.5012, -3.6260,  3.3670,  1.1371,  4.2222], grad_fn=<SliceBackward0>)
  [Layer 36] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 36] Residual connection sample values: tensor([  1.4952, -20.2661,  -0.7512,  -7.4889,  17.7285],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 37/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([243.3123], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0641], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0462, -0.6433, -0.0244, -0.2371,  0.5622], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4135, -1.7759,  0.3035, -2.1210, -3.1082], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4135, -1.7759,  0.3035, -2.1210, -3.1082], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1605, -0.9572,  2.3497,  1.4174, -1.0436], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.0175, -0.2324,  0.6600, -2.5261, -0.1346], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6329, -0.1335, -0.5111, -0.1605,  0.6879], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0628,  0.2197, -0.7619, -0.2476,  0.7822], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0149,  0.1556, -0.8465, -0.2127,  0.6985], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0074,  0.0838, -0.2541, -0.0951,  0.4665], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0074,  0.0838, -0.2541, -0.0951,  0.4665], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1218, -0.1439, -0.1211, -0.1771, -0.0834], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2473, -0.2638, -0.2280, -0.2633, -0.2659], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.8179, -31.1699, -39.0195,  -0.4619,  -0.6477],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.2830e-04, 5.7354e-03, 6.4579e-03, 5.9284e-05, 1.4479e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9996, 0.8363, 0.7773, 1.0000, 0.9991], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0074,  0.0838, -0.2541, -0.0951,  0.4665], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([2.0607e-07, 2.4347e-07, 2.0484e-07, 2.9957e-07, 1.4103e-07],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0004,  0.0004, -0.0006,  0.0009, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0002,  0.0016, -0.0048,  0.0026,  0.0009], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0134,  0.1552, -0.4702, -0.1715,  0.8554], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0134,  0.1552, -0.4702, -0.1715,  0.8554], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0033, -0.0399, -0.0821,  0.0389, -0.1137], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2874], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.8653], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0232, -0.2005, -0.3879,  0.2911, -0.4537], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0232, -0.2005, -0.3879,  0.2911, -0.4537], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-2.5492,  0.6175, -8.2983,  1.3837, -0.0527], grad_fn=<SliceBackward0>)
  [Layer 37] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 37] Output sample values after mixer: tensor([-2.5492,  0.6175, -8.2983,  1.3837, -0.0527], grad_fn=<SliceBackward0>)
  [Layer 37] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 37] Residual connection sample values: tensor([ -1.0540, -19.6486,  -9.0495,  -6.1052,  17.6758],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 38/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([296.1487], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0581], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0314, -0.5854, -0.2683, -0.1763,  0.5301], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3780, -2.0375, -0.2236, -0.4517,  0.2569], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3780, -2.0375, -0.2236, -0.4517,  0.2569], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.4508, -1.5423,  0.1570,  0.4669, -0.3912], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.3005,  0.7943, -0.1268,  0.3636,  2.1422], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.8303,  0.5341,  0.8919,  0.4508, -0.9633], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2644,  0.4238, -0.5990, -0.2219,  0.3578], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2668,  0.1345, -0.6891, -0.2650,  0.4508], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1157,  0.0717, -0.2303, -0.1151,  0.2754], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1157,  0.0717, -0.2303, -0.1151,  0.2754], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1053, -0.2446,  0.0302,  0.0912, -0.0823], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2734,  0.0070,  0.3891, -0.2674,  0.1144], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1704, -2.0832, -0.1351, -0.4124, -3.5315], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.9749, 0.2458, 0.6094, 0.4048, 0.6315], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8469, 0.5993, 0.9210, 0.8462, 0.1075], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1157,  0.0717, -0.2303, -0.1151,  0.2754], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0119,  0.0276, -0.0034, -0.0103,  0.0093], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.1758e-04,  1.3664e-01, -9.7286e-03, -7.1892e-03,  5.1912e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.4007, -0.2374, -0.2769, -0.2489,  0.8168], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.4177, -0.2269, -0.3106, -0.2657,  0.8572], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.4177, -0.2269, -0.3106, -0.2657,  0.8572], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0642, 0.0533, 0.0309, 0.0467, 0.1242], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6595], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2314], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.2490, 0.1392, 0.0891, 0.2693, 0.4952], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.2490, 0.1392, 0.0891, 0.2693, 0.4952], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 3.4840, -4.8050,  3.6618, -4.7802, -1.6515], grad_fn=<SliceBackward0>)
  [Layer 38] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 38] Output sample values after mixer: tensor([ 3.4840, -4.8050,  3.6618, -4.7802, -1.6515], grad_fn=<SliceBackward0>)
  [Layer 38] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 38] Residual connection sample values: tensor([  2.4300, -24.4536,  -5.3876, -10.8854,  16.0243],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 39/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([497.2023], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0448], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0413, -0.4525, -0.0967, -0.2049,  0.2862], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.8436,  0.7587, -1.7514, -0.4211, -2.2579], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.8436,  0.7587, -1.7514, -0.4211, -2.2579], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([0.2505, 0.3019, 0.0784, 0.3169, 1.0400], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.1298,  3.5059, -1.7700,  2.5921, -1.0946], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6229,  1.8240, -1.2065,  0.2505,  1.6666], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0448, -0.0707,  0.0535,  0.0744,  0.2933], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1092, -0.1314,  0.0688,  0.6120,  0.2899], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0576, -0.0614,  0.0356,  0.3968,  0.1658], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0576, -0.0614,  0.0356,  0.3968,  0.1658], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0113,  0.0919, -0.2562,  0.0637, -0.0247], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2437, -0.2767,  0.0011, -0.1315, -0.1976], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.7351e+02, -2.3790e+00, -2.6079e-03, -1.4979e+00, -6.3307e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.2812, 2.4256, 0.0501, 1.0286, 0.0030], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.0000, 0.0031, 0.9999, 0.2142, 0.9998], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0576, -0.0614,  0.0356,  0.3968,  0.1658], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0008,  0.0068, -0.0189,  0.0047, -0.0018], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0008,  0.0068, -0.0189,  0.0047, -0.0018], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0069, -0.0074,  0.0043,  0.0478,  0.0200], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2676, -0.2853,  0.1652,  1.8434,  0.7702], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2676, -0.2853,  0.1652,  1.8434,  0.7702], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1578, -0.1474, -0.0428, -0.3076, -0.1646], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5376], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.3639], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 1.0065, -0.8906, -0.2446, -1.7159, -1.1077], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 1.0065, -0.8906, -0.2446, -1.7159, -1.1077], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-5.3195,  1.2033, -4.7367,  0.5497, -5.6080], grad_fn=<SliceBackward0>)
  [Layer 39] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 39] Output sample values after mixer: tensor([-5.3195,  1.2033, -4.7367,  0.5497, -5.6080], grad_fn=<SliceBackward0>)
  [Layer 39] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 39] Residual connection sample values: tensor([ -2.8895, -23.2503, -10.1243, -10.3357,  10.4163],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 40/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([613.1462], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0404], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0573, -0.4924, -0.2100, -0.1964,  0.2140], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 5.6432, -1.5308, -0.4309, -0.8132, -0.3611], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 5.6432, -1.5308, -0.4309, -0.8132, -0.3611], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-2.0063,  0.3283, -0.4083,  0.5125,  0.6225], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.5385,  1.2718,  1.1893, -0.6534,  2.7266], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0038, -0.8216, -0.1680, -2.0063,  1.1060], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3034, -0.0510, -0.0741, -0.1287,  0.1118], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0279, -0.0995, -0.1458, -0.1403,  0.1133], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0141, -0.0473, -0.0676, -0.0652,  0.0599], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0141, -0.0473, -0.0676, -0.0652,  0.0599], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0536, -0.2061, -0.0124, -0.0054, -0.0933], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1095, -0.2694,  0.6150,  0.3368,  0.2643], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5267, -0.6301, -0.3878, -2.7909, -0.4284], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2056, 0.0455, 0.0883, 0.0032, 0.2215], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8974, 0.9718, 0.9664, 0.9912, 0.9095], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0141, -0.0473, -0.0676, -0.0652,  0.0599], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.5564e-04, -5.9900e-04, -3.5951e-05, -1.5753e-05, -2.7125e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0026, -0.0390, -0.0065,  0.0007, -0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0075, -0.0132, -0.0183, -0.0096, -0.0080], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0275, -0.1302, -0.1856, -0.1711,  0.1402], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0275, -0.1302, -0.1856, -0.1711,  0.1402], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1547,  0.0354,  0.0315,  0.0427, -0.0208], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1598], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.5013], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 1.2408,  0.3367,  0.3046,  0.3266, -0.2617], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 1.2408,  0.3367,  0.3046,  0.3266, -0.2617], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([10.3765, -5.3880, -9.5615,  0.4571,  6.7945], grad_fn=<SliceBackward0>)
  [Layer 40] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 40] Output sample values after mixer: tensor([10.3765, -5.3880, -9.5615,  0.4571,  6.7945], grad_fn=<SliceBackward0>)
  [Layer 40] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 40] Residual connection sample values: tensor([  7.4870, -28.6383, -19.6858,  -9.8786,  17.2108],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 41/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([857.0153], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0342], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0893, -0.3654, -0.2423, -0.1165,  0.2058], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0121, -4.5084, -0.3514, -0.7378,  0.6377], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0121, -4.5084, -0.3514, -0.7378,  0.6377], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5914, -0.1944, -0.0667,  0.8970, -0.1163], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.0481, -0.5230,  1.0496,  0.8067,  0.9608], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.0690, -0.8642, -0.8012, -0.5914,  1.2318], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1598, -0.1221, -0.0138, -0.1491,  0.0261], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1915,  0.0003, -0.0137, -0.2418,  0.0165], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0866,  0.0002, -0.0068, -0.1064,  0.0083], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0866,  0.0002, -0.0068, -0.1064,  0.0083], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([0.0641, 0.1416, 0.0147, 0.0280, 0.0614], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 1.0002,  0.0287, -0.0968, -0.0337, -0.2508], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.0531, -1.1356, -0.8719, -1.5713, -1.7431], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4514, 0.1294, 0.2687, 0.2635, 0.2014], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6217, 0.8633, 0.7912, 0.6610, 0.7039], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0866,  0.0002, -0.0068, -0.1064,  0.0083], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0025, -0.0055, -0.0006, -0.0011, -0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0025, -0.0081, -0.0091, -0.0014, -0.0067], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0060, -0.0037, -0.0020, -0.0083,  0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1167, -0.0035, -0.0107, -0.1444,  0.0133], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1167, -0.0035, -0.0107, -0.1444,  0.0133], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0007, 0.0002, 0.0016, 0.0345, 0.0055], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0135], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([8.6067], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0194, 0.0063, 0.0494, 1.3299, 0.1985], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0194, 0.0063, 0.0494, 1.3299, 0.1985], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2134,  7.2717,  2.1369, -0.3418,  2.6900], grad_fn=<SliceBackward0>)
  [Layer 41] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 41] Output sample values after mixer: tensor([-0.2134,  7.2717,  2.1369, -0.3418,  2.6900], grad_fn=<SliceBackward0>)
  [Layer 41] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 41] Residual connection sample values: tensor([  7.2736, -21.3667, -17.5489, -10.2204,  19.9008],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 42/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1026.0187], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0312], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0818, -0.2581, -0.2109, -0.1147,  0.2354], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1901,  2.3578, -1.1232, -1.3273,  0.0745], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1901,  2.3578, -1.1232, -1.3273,  0.0745], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0918,  2.7927, -0.9328, -0.2846, -0.0330], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.6347, -0.6176,  1.0290, -1.0926,  1.5435], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2633, -0.0213, -0.8487,  0.0918,  0.5278], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0112,  0.5636,  0.2038,  0.0530, -0.0407], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0321,  0.5278,  0.2084,  0.0493, -0.0868], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0158,  0.3320,  0.1150,  0.0253, -0.0415], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0158,  0.3320,  0.1150,  0.0253, -0.0415], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0046, -0.0095, -0.0114, -0.0068,  0.0400], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0115, -0.0180, -0.0902, -0.2114, -0.2783], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.2458, -1.7474, -3.3797, -1.2264, -1.3705], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4446, 0.0724, 0.3279, 0.0070, 0.3198], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.3685, 0.8812, 0.3302, 0.9914, 0.6452], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0158,  0.3320,  0.1150,  0.0253, -0.0415], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-3.2381e-05,  6.6717e-05,  8.0292e-05,  4.7450e-05, -2.8124e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 7.0772e-06, -3.5808e-04,  6.3006e-04, -1.1371e-04, -7.3648e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0053,  0.1061,  0.0374,  0.0077, -0.0137], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0269,  0.5600,  0.1947,  0.0423, -0.0705], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0269,  0.5600,  0.1947,  0.0423, -0.0705], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0028,  1.2062, -0.0537, -0.0118, -0.0027], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0199], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([7.0881], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0778, 32.2272, -1.4762, -0.3277, -0.0517], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0778, 32.2272, -1.4762, -0.3277, -0.0517], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ -1.0963,   3.7966,   5.9740, -12.5208,   5.6063],
       grad_fn=<SliceBackward0>)
  [Layer 42] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 42] Output sample values after mixer: tensor([ -1.0963,   3.7966,   5.9740, -12.5208,   5.6063],
       grad_fn=<SliceBackward0>)
  [Layer 42] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 42] Residual connection sample values: tensor([  6.1773, -17.5701, -11.5749, -22.7412,  25.5072],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 43/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1174.9291], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0292], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0637, -0.1982, -0.1250, -0.2342,  0.2672], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0753, -0.9789, -0.3441, -0.4180, -0.6937], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0753, -0.9789, -0.3441, -0.4180, -0.6937], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5369,  0.6877,  1.3486, -0.0998, -0.1113], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.6191,  0.1650,  0.2831,  1.2084, -1.2758], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1455, -0.2589, -0.9998,  0.5369, -0.0715], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0823, -0.0980, -0.2794, -0.0235, -0.0224], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0677, -0.1522, -0.3074, -0.0713, -0.0307], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0350, -0.0703, -0.1303, -0.0344, -0.0151], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0350, -0.0703, -0.1303, -0.0344, -0.0151], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0018,  0.0168, -0.0073, -0.1890,  0.0893], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0647, -0.0847, -0.2526, -0.2782, -0.0718], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.7046, -2.6553, -8.2110, -2.2382, -4.0926], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.1157e-01, 9.2921e-02, 8.2206e-02, 8.8540e-01, 3.5760e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6614, 0.7813, 0.5092, 0.1378, 0.9985], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0350, -0.0703, -0.1303, -0.0344, -0.0151], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-7.1771e-06,  6.5664e-05, -2.8340e-05, -7.3743e-04,  3.4854e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0037, -0.0002, -0.0024,  0.0065, -0.0054], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0079, -0.0081, -0.0090, -0.0078, -0.0032], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0498, -0.1241, -0.2238, -0.0645, -0.0281], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0498, -0.1241, -0.2238, -0.0645, -0.0281], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0019, 0.0332, 0.0319, 0.0107, 0.0065], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0104], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([9.8246], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0494, 1.1295, 0.8704, 0.2937, 0.1844], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0494, 1.1295, 0.8704, 0.2937, 0.1844], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.9727, -8.8029,  0.5125, -0.3779,  0.6869], grad_fn=<SliceBackward0>)
  [Layer 43] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 43] Output sample values after mixer: tensor([ 1.9727, -8.8029,  0.5125, -0.3779,  0.6869], grad_fn=<SliceBackward0>)
  [Layer 43] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 43] Residual connection sample values: tensor([  8.1500, -26.3731, -11.0624, -23.1191,  26.1941],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 44/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1333.7896], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0274], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0799, -0.2673, -0.1124, -0.2215,  0.2599], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4835,  0.5009, -0.5189, -1.0157,  0.9504], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4835,  0.5009, -0.5189, -1.0157,  0.9504], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8355, -0.7204, -0.4704, -0.4134, -0.6305], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.4376,  0.8083,  0.7458,  2.0731, -0.1899], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5637,  0.6244, -1.0672, -0.8355, -0.0423], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1705,  0.1557, -0.0791,  0.0736, -0.1166], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1490,  0.0986, -0.1079,  0.0604, -0.1100], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0690,  0.0517, -0.0510,  0.0311, -0.0520], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0690,  0.0517, -0.0510,  0.0311, -0.0520], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0169, -0.2723, -0.2752,  0.0591,  0.0955], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.2438, -0.2679, -0.1775, -0.0678, -0.1615], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-4.6876, -0.9753, -0.8255, -1.2938, -0.4953], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1499, 0.0971, 0.0510, 0.3140, 0.0064], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4953, 0.9097, 0.9587, 0.6661, 0.9968], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0690,  0.0517, -0.0510,  0.0311, -0.0520], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0002,  0.0028,  0.0028, -0.0006, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.4019e-05,  5.8776e-03,  6.3317e-03, -1.1220e-03, -1.0282e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0055,  0.0043, -0.0040,  0.0024, -0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1253,  0.0942, -0.0927,  0.0565, -0.0929], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1253,  0.0942, -0.0927,  0.0565, -0.0929], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0375,  0.0294,  0.0179, -0.0153, -0.0637], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0129], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([8.8166], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-1.0650,  0.7646,  0.5917, -0.4327, -1.7697], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-1.0650,  0.7646,  0.5917, -0.4327, -1.7697], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-18.6508,   0.7926,   5.5839,  19.2600,  -3.2454],
       grad_fn=<SliceBackward0>)
  [Layer 44] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 44] Output sample values after mixer: tensor([-18.6508,   0.7926,   5.5839,  19.2600,  -3.2454],
       grad_fn=<SliceBackward0>)
  [Layer 44] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 44] Residual connection sample values: tensor([-10.5008, -25.5805,  -5.4785,  -3.8591,  22.9487],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 45/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1522.1594], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0256], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1155, -0.3038, -0.0633, -0.0426,  0.2558], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4899, -1.5588, -0.0534, -1.0161, -0.7417], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4899, -1.5588, -0.0534, -1.0161, -0.7417], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8807, -0.7050,  1.2421, -0.9092, -0.1545], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 5.2638e-01, -9.5808e-01,  1.9430e-01,  8.8534e-01, -1.7923e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2402, -0.3617,  0.1007, -0.8807,  1.3189], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1491, -0.0700,  0.2045,  0.1822, -0.0272], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1548,  0.1881,  0.1822,  0.1262, -0.0380], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0714,  0.1029,  0.0994,  0.0671, -0.0186], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0714,  0.1029,  0.0994,  0.0671, -0.0186], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1200,  0.1841, -0.1477, -0.2521, -0.0744], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1672,  0.0513, -0.2572,  0.0116, -0.1562], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3039e+00, -3.9385e-02, -6.8874e+00, -8.0559e-01, -1.9935e+03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0038, 0.0072, 0.0094, 0.0015, 0.0191], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9512e-01, 9.9972e-01, 9.3747e-01, 9.9877e-01, 2.7951e-17],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0714,  0.1029,  0.0994,  0.0671, -0.0186], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 3.2171e-05, -4.9363e-05,  3.9588e-05,  6.7573e-05,  1.9950e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0017, 0.0009, 0.0013, 0.0003, 0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0033,  0.0323, -0.0020, -0.0047,  0.0083], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1886,  0.2992,  0.2560,  0.1695, -0.0401], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1886,  0.2992,  0.2560,  0.1695, -0.0401], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0351, -0.0811, -0.0067, -0.0458,  0.0096], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0729], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.7026], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.5042, -0.8736, -0.0856, -0.5576,  0.1403], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.5042, -0.8736, -0.0856, -0.5576,  0.1403], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.1603, -4.0021,  3.2209,  8.1041, -6.4900], grad_fn=<SliceBackward0>)
  [Layer 45] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 45] Output sample values after mixer: tensor([-1.1603, -4.0021,  3.2209,  8.1041, -6.4900], grad_fn=<SliceBackward0>)
  [Layer 45] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 45] Residual connection sample values: tensor([-11.6611, -29.5826,  -2.2576,   4.2451,  16.4587],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 46/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1701.9861], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0242], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1152, -0.3142, -0.0235,  0.0427,  0.1609], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.4284, -0.5666,  0.3567, -0.4467,  0.8916], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.4284, -0.5666,  0.3567, -0.4467,  0.8916], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.3816,  0.8631, -1.5097, -0.2132,  1.6089], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.1108,  1.6536, -0.0416,  1.0037,  1.3755], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.2188,  0.8542,  0.2080,  1.3816, -1.1098], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0507, -0.1592, -0.2980,  0.0377, -0.2619], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1062, -0.1966, -0.0951,  0.0422, -0.2671], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0559, -0.0887, -0.0453,  0.0215, -0.1158], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0559, -0.0887, -0.0453,  0.0215, -0.1158], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1873, -0.0440,  0.0314,  0.2452, -0.0810], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0523, -0.1001,  0.0932, -0.0431,  0.1184], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.4426,  -0.9830, -10.1590,  -1.3638,  -1.7559],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0264, 0.0708, 0.0010, 0.0352, 0.0424], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9626, 0.9328, 0.9894, 0.9531, 0.9283], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0559, -0.0887, -0.0453,  0.0215, -0.1158], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-2.7691e-04, -6.5075e-05,  4.6451e-05,  3.6240e-04, -1.1979e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.6706e-03,  2.1972e-04, -1.0142e-05,  7.5185e-04, -9.0018e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0030, -0.0015,  0.0071, -0.0010, -0.0059], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0715, -0.1101, -0.0484,  0.0254, -0.1478], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0715, -0.1101, -0.0484,  0.0254, -0.1478], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0197,  0.0226, -0.0102, -0.0044, -0.0935], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0117], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([9.2459], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.8113,  0.8628, -0.3312, -0.1430, -3.0144], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.8113,  0.8628, -0.3312, -0.1430, -3.0144], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 8.8670,  1.3965, -4.7911, -8.4737, -5.5745], grad_fn=<SliceBackward0>)
  [Layer 46] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 46] Output sample values after mixer: tensor([ 8.8670,  1.3965, -4.7911, -8.4737, -5.5745], grad_fn=<SliceBackward0>)
  [Layer 46] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 46] Residual connection sample values: tensor([ -2.7941, -28.1861,  -7.0487,  -4.2287,  10.8842],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 47/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1913.2938], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0229], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0234, -0.2462, -0.0603, -0.0334,  0.0912], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0581,  0.6335, -0.7680, -1.8200,  0.0166], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0581,  0.6335, -0.7680, -1.8200,  0.0166], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.1000, -0.1829, -0.0601, -0.5417,  0.3939], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.7350, 2.2837, 1.0738, 0.9135, 2.3643], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2363, -0.7600, -0.5188, -1.1000,  0.2168], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2496, -0.0315, -0.0101,  0.0976,  0.0630], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2367, -0.0164, -0.0112,  0.1044,  0.0611], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1323, -0.0082, -0.0056,  0.0549,  0.0315], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1323, -0.0082, -0.0056,  0.0549,  0.0315], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.4506, -0.0571, -0.0026, -0.0545, -0.2733], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2371, -0.1932, -0.0223, -0.2746, -0.2603], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-5.7667e+01, -2.2024e+00, -3.8371e+00, -4.6046e-02, -2.0700e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2381, 0.0428, 0.0374, 0.0436, 0.0426], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([1.0913e-06, 9.1009e-01, 8.6616e-01, 9.9799e-01, 9.1569e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1323, -0.0082, -0.0056,  0.0549,  0.0315], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.4191e-02, -1.7988e-03, -8.1922e-05, -1.7175e-03, -8.6076e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 1.4191e-02, -1.7988e-03, -8.1922e-05, -1.7175e-03, -8.6076e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0089, -0.0006, -0.0004,  0.0037,  0.0021], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2174, -0.0134, -0.0092,  0.0903,  0.0518], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2174, -0.0134, -0.0092,  0.0903,  0.0518], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0065, -0.0055,  0.0022, -0.0229,  0.0004], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0108], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([9.6169], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2132, -0.2014,  0.0744, -1.0919,  0.0166], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.2132, -0.2014,  0.0744, -1.0919,  0.0166], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-11.8236,  16.6222, -12.9970, -13.4927,  -6.2303],
       grad_fn=<SliceBackward0>)
  [Layer 47] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 47] Output sample values after mixer: tensor([-11.8236,  16.6222, -12.9970, -13.4927,  -6.2303],
       grad_fn=<SliceBackward0>)
  [Layer 47] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 47] Residual connection sample values: tensor([-14.6177, -11.5639, -20.0456, -17.7214,   4.6539],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 48/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2845.4763], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0187], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1000, -0.0854, -0.1462, -0.1183,  0.0330], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0856, -0.7648, -0.4067,  0.1119, -0.9536], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0856, -0.7648, -0.4067,  0.1119, -0.9536], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.9858,  0.1174, -0.7984, -0.7965, -1.8126], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.0931, -2.7329,  1.0596,  0.4500,  1.4713], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2116,  0.5649,  0.0768, -0.9858,  0.9581], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1510,  0.0210, -0.0867, -0.0934, -0.2859], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1550, -0.0096, -0.0988, -0.1735, -0.3682], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0835, -0.0048, -0.0470, -0.0792, -0.1506], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0835, -0.0048, -0.0470, -0.0792, -0.1506], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0251, -0.0375, -0.2774,  0.0506, -0.0107], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0386, -0.0669, -0.2446, -0.0261, -0.0139], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.7304,  -7.3891,  -3.3797,  -1.8028, -17.7601],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.0470e-02, 1.3976e-05, 1.8381e-02, 3.0120e-02, 3.6029e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9820, 0.9999, 0.9398, 0.9471, 0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0835, -0.0048, -0.0470, -0.0792, -0.1506], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-2.1963e-05, -3.2797e-05, -2.4238e-04,  4.4178e-05, -9.3788e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.8155e-04,  4.6984e-04,  6.1461e-04, -1.6792e-04, -4.1298e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-6.7122e-05,  1.0348e-03, -1.0230e-03, -4.1214e-03, -2.8619e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1187, -0.0057, -0.0678, -0.1168, -0.2170], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1187, -0.0057, -0.0678, -0.1168, -0.2170], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0049,  0.0014,  0.0110, -0.0069,  0.0576], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0036], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([16.5858], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2861,  0.0916,  0.6877, -0.3790,  4.3043], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2861,  0.0916,  0.6877, -0.3790,  4.3043], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 37.4492,  -5.8501, -16.2781,   8.5707,  33.4188],
       grad_fn=<SliceBackward0>)
  [Layer 48] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 48] Output sample values after mixer: tensor([ 37.4492,  -5.8501, -16.2781,   8.5707,  33.4188],
       grad_fn=<SliceBackward0>)
  [Layer 48] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 48] Residual connection sample values: tensor([ 22.8315, -17.4139, -36.3237,  -9.1507,  38.0727],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([5435.6567], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0136], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.3169, -0.3492, -0.5769, -0.1147,  0.5436], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Final backbone norm output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Final backbone norm output sample values: tensor([ 0.3169, -0.3492, -0.5769, -0.1147,  0.5436], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Logits shape: torch.Size([1, 1, 50288])
[Mamba2LMHeadModel] Logits sample values: tensor([57.8865, 50.1280, 56.7517, 57.4770, 55.4776], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Forward pass input_ids shape: torch.Size([1, 1])
[Mamba2LMHeadModel] input_ids sample values: tensor([253])
[Mamba2LMHeadModel] Embedding output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Embedding sample values: tensor([-0.1349, -0.0366, -0.2664, -0.0213,  0.2356], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 1/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0317], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([5.6186], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1819, -0.0628, -0.3939, -0.0246,  0.2975], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2101,  0.8613,  0.3215,  0.2665, -0.1894], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2101,  0.8613,  0.3215,  0.2665, -0.1894], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.6464,  3.4875,  0.7014, -0.7221,  1.2974], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.4149,  0.0916,  0.1986,  0.2136, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.6464, 0.0886, 0.0774, 0.6464, 3.4875], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0038, -0.2144,  0.0194, -0.1456, -0.0281], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0463, -0.2220,  0.1322, -0.3551, -0.2252], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0237, -0.0987,  0.0704, -0.1464, -0.1000], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0237, -0.0987,  0.0704, -0.1464, -0.1000], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2192, -0.0906,  0.0135,  0.6476,  0.0207], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2536, -0.0505,  0.2606, -0.2015,  0.0178], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4384, -1.0011, -1.2129, -1.1530, -1.4844], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0832, 0.0371, 0.0296, 0.0322, 0.0210], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9642, 0.9635, 0.9647, 0.9635, 0.9692], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0237, -0.0987,  0.0704, -0.1464, -0.1000], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-4.3227e-04, -1.7875e-04,  2.6537e-05,  1.2770e-03,  4.0846e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0194, -0.0040, -0.0007,  0.0476, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1715,  0.0142,  0.4882, -0.7881, -0.5782], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2121, -0.1551,  0.6090, -1.0391, -0.7497], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2121, -0.1551,  0.6090, -1.0391, -0.7497], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0246, -0.0939,  0.1135, -0.1568,  0.0643], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([87.1646], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1071], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0024, -0.0074,  0.0090, -0.0102,  0.0213], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0024, -0.0074,  0.0090, -0.0102,  0.0213], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0832, -0.0849, -0.0180, -0.0171, -0.0413], grad_fn=<SliceBackward0>)
  [Layer 1] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 1] Output sample values after mixer: tensor([ 0.0832, -0.0849, -0.0180, -0.0171, -0.0413], grad_fn=<SliceBackward0>)
  [Layer 1] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 1] Residual connection sample values: tensor([-0.0517, -0.1215, -0.2843, -0.0384,  0.1943], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 2/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0516], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([4.4034], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1314, -0.2595, -0.5606, -0.1026,  0.4499], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.3209, -0.6212,  0.2865,  2.8418, -0.9250], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.3209, -0.6212,  0.2865,  2.8418, -0.9250], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0691, -0.0844, -0.2308,  0.5160, -0.2488], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.1639,  1.4270, -0.2892,  0.9091,  1.0527], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1390,  1.8233, -0.5496,  0.0691,  0.0078], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0867, -0.0156, -0.0795,  0.4046, -0.1184], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0773, -0.0455, -0.1913,  0.2606, -0.1150], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0402, -0.0222, -0.0865,  0.1472, -0.0542], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0402, -0.0222, -0.0865,  0.1472, -0.0542], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0257,  0.0336,  0.1152,  0.0519, -0.0159], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0593, -0.0898, -0.2565, -0.1652,  0.0315], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-12.6926, -19.4296,  -0.2289,  -2.1057,  -5.0389],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0591, 0.1382, 0.0185, 0.1489, 0.1545], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4723, 0.0682, 0.9958, 0.7309, 0.4590], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0402, -0.0222, -0.0865,  0.1472, -0.0542], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-6.0905e-05,  7.9803e-05,  2.7344e-04,  1.2310e-04, -3.7770e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 1.9582e-05,  5.6038e-04,  4.5605e-04, -4.7205e-04, -1.3580e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0028, -0.0012, -0.0049,  0.0093,  0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0240, -0.0160, -0.0626,  0.1075, -0.0358], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0240, -0.0160, -0.0626,  0.1075, -0.0358], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0045,  0.0035, -0.0102,  0.2885,  0.0094], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([45.5811], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1481], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0013,  0.0014, -0.0037,  0.0682,  0.0039], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0013,  0.0014, -0.0037,  0.0682,  0.0039], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1148,  0.0709, -0.0152,  0.1272, -0.0535], grad_fn=<SliceBackward0>)
  [Layer 2] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 2] Output sample values after mixer: tensor([ 0.1148,  0.0709, -0.0152,  0.1272, -0.0535], grad_fn=<SliceBackward0>)
  [Layer 2] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 2] Residual connection sample values: tensor([ 0.0631, -0.0506, -0.2995,  0.0888,  0.1408], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 3/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0942], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([3.2574], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1785, -0.1200, -0.6331,  0.2689,  0.3800], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3412,  0.7429, -1.8498, -0.4244, -0.9850], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3412,  0.7429, -1.8498, -0.4244, -0.9850], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2860, -0.1163,  2.7931, -0.4742,  0.5401], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.4801, 0.3261, 0.7433, 0.3948, 0.2906], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2154, -0.5941,  0.3079, -0.2860, -0.0261], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0079, -0.2518, -0.2786,  0.1063,  0.1956], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0527, -0.3295, -0.3297,  0.0596,  0.1288], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0257, -0.1379, -0.1379,  0.0307,  0.0685], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0257, -0.1379, -0.1379,  0.0307,  0.0685], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0732,  0.0280,  0.1012,  0.0015, -0.2725], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2779,  0.3200,  0.4975,  0.6482,  0.5308], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-20.9265,  -0.8803,  -0.6735,  -0.6461,  -0.2726],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([5.4036e-02, 6.7021e-03, 9.4718e-05, 7.7573e-03, 1.3752e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.3228, 0.9941, 0.9999, 0.9950, 0.9963], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0257, -0.1379, -0.1379,  0.0307,  0.0685], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.0162e-04, -3.8877e-05, -1.4034e-04, -2.1332e-06,  3.7806e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 1.2130e-04, -2.4286e-04, -1.9270e-04,  6.7679e-06,  3.8961e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0017,  0.0088,  0.0058, -0.0014, -0.0066], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0165, -0.0891, -0.0922,  0.0204,  0.0420], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0165, -0.0891, -0.0922,  0.0204,  0.0420], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0023, -0.0448,  0.0232, -0.0034, -0.0113], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([56.6502], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1329], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0006, -0.0095,  0.0039, -0.0006, -0.0031], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0006, -0.0095,  0.0039, -0.0006, -0.0031], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0467, -0.0367, -0.0760,  0.0579,  0.0315], grad_fn=<SliceBackward0>)
  [Layer 3] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 3] Output sample values after mixer: tensor([-0.0467, -0.0367, -0.0760,  0.0579,  0.0315], grad_fn=<SliceBackward0>)
  [Layer 3] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 3] Residual connection sample values: tensor([ 0.0164, -0.0873, -0.3755,  0.1467,  0.1723], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 4/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1224], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([2.8582], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0275, -0.1268, -0.5136,  0.2617,  0.2719], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 3.0712,  0.2010, -0.3815,  0.5048,  1.1913], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 3.0712,  0.2010, -0.3815,  0.5048,  1.1913], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.0433, -0.6150,  0.0382, -1.6472,  1.5263], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.3715, 0.3846, 0.4842, 0.0145, 0.3550], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0591, -0.1960, -0.5310, -1.0433, -0.3051], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1184,  0.0491,  0.2022, -0.5676,  0.0464], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1404,  0.0617,  0.1618, -0.6323,  0.3054], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0751,  0.0318,  0.0874, -0.2194,  0.1759], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0751,  0.0318,  0.0874, -0.2194,  0.1759], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2699,  0.2026, -0.0233,  0.0602,  0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2769, -0.2174,  0.7987, -0.0308,  0.1442], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4907, -0.5048, -0.6491, -0.5552, -0.4657], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0645, 0.0827, 0.1321, 0.0401, 0.4430], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9688, 0.9591, 0.9178, 0.9780, 0.8136], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0751,  0.0318,  0.0874, -0.2194,  0.1759], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.3081e-03,  9.8195e-04, -1.1302e-04,  2.9189e-04,  7.9278e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0325, -0.0027,  0.0004,  0.0025, -0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0636,  0.0023,  0.0132, -0.1599,  0.2626], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1135,  0.0234,  0.0712, -0.3054,  0.3792], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1135,  0.0234,  0.0712, -0.3054,  0.3792], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.3330,  0.0026, -0.0110, -0.0961,  0.3465], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([56.8866], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1326], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1330,  0.0011, -0.0039, -0.0379,  0.0995], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1330,  0.0011, -0.0039, -0.0379,  0.0995], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0295, -0.0048,  0.0202,  0.0678, -0.0682], grad_fn=<SliceBackward0>)
  [Layer 4] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 4] Output sample values after mixer: tensor([-0.0295, -0.0048,  0.0202,  0.0678, -0.0682], grad_fn=<SliceBackward0>)
  [Layer 4] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 4] Residual connection sample values: tensor([-0.0131, -0.0921, -0.3553,  0.2145,  0.1040], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 5/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1569], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([2.5247], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0275, -0.1622, -0.5470,  0.4469,  0.2062], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4197, -0.5147, -0.8238, -0.0901, -0.1337], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4197, -0.5147, -0.8238, -0.0901, -0.1337], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.2362, -1.2378, -1.3290,  0.8210,  1.2489], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.6617,  0.4827, -0.2368,  0.7893,  1.3590], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8512, -2.9134, -0.0104, -1.2362,  0.0495], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6160, -1.2744, -0.3155, -0.1576, -0.3086], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.6794, -1.5158, -0.3228, -0.1307, -0.2977], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2285, -0.2730, -0.1356, -0.0611, -0.1269], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2285, -0.2730, -0.1356, -0.0611, -0.1269], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0783,  0.1320, -0.2422, -0.0576, -0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0266,  0.1259, -0.2193, -0.2761, -0.1311], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0759, -0.5319, -0.0470, -1.4939, -3.6258], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2856, 0.0226, 0.0292, 0.0307, 0.0617], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9785, 0.9881, 0.9986, 0.9552, 0.7995], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2285, -0.2730, -0.1356, -0.0611, -0.1269], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0051, -0.0086,  0.0158,  0.0038,  0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0120, -0.0048,  0.5109,  0.0469,  0.0085], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-1.0247, -1.2204, -0.8846, -0.3851, -0.3387], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-1.3463, -1.6046, -1.0754, -0.4710, -0.5172], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-1.3463, -1.6046, -1.0754, -0.4710, -0.5172], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.2241, 0.3089, 0.2702, 0.0203, 0.0323], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([128.0229], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0884], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0065, 0.0095, 0.0171, 0.0014, 0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0065, 0.0095, 0.0171, 0.0014, 0.0024], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0056, -0.1318,  0.0509,  0.1373,  0.1461], grad_fn=<SliceBackward0>)
  [Layer 5] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 5] Output sample values after mixer: tensor([ 0.0056, -0.1318,  0.0509,  0.1373,  0.1461], grad_fn=<SliceBackward0>)
  [Layer 5] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 5] Residual connection sample values: tensor([-0.0076, -0.2239, -0.3043,  0.3519,  0.2501], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 6/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3513], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.6873], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0094, -0.2287, -0.2933,  0.4171,  0.2763], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.7149,  0.1236,  0.1707, -1.5859,  0.0070], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.7149,  0.1236,  0.1707, -1.5859,  0.0070], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.8933, -0.4443, -1.1515,  0.8881, -0.4869], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.2333, 0.5995, 1.4600, 1.4425, 1.5094], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.1231,  0.0604, -0.7968,  0.8933, -0.9853], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1852,  0.0487, -0.2760,  0.0472, -0.1425], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1380,  0.0627, -0.1948,  0.0355, -0.0043], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0737,  0.0323, -0.0879,  0.0181, -0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0737,  0.0323, -0.0879,  0.0181, -0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0331, -0.0597, -0.2776,  0.0225, -0.0638], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.2470, -0.1044, -0.2740, -0.0158,  0.0993], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5110, -0.2862, -0.5421, -0.3954, -0.5986], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4411, 0.2025, 0.3094, 0.4883, 0.3726], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7982, 0.9437, 0.8456, 0.8244, 0.8001], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0737,  0.0323, -0.0879,  0.0181, -0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0011, -0.0019, -0.0090,  0.0007, -0.0021], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0046, -0.0067,  0.0063,  0.0046,  0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-8.2686e-03,  4.3315e-05, -2.4503e-02,  3.7353e-03,  1.3095e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0763,  0.0371, -0.1254,  0.0245,  0.1285], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0763,  0.0371, -0.1254,  0.0245,  0.1285], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1109,  0.0024, -0.0116, -0.0066,  0.0004], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([104.8161], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0977], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0315,  0.0007, -0.0030, -0.0021,  0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0315,  0.0007, -0.0030, -0.0021,  0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1067, -0.1716, -0.2203, -0.0330,  0.1826], grad_fn=<SliceBackward0>)
  [Layer 6] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 6] Output sample values after mixer: tensor([-0.1067, -0.1716, -0.2203, -0.0330,  0.1826], grad_fn=<SliceBackward0>)
  [Layer 6] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 6] Residual connection sample values: tensor([-0.1143, -0.3955, -0.5246,  0.3188,  0.4327], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 7/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4114], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.5591], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1297, -0.3646, -0.4696,  0.3653,  0.4259], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2577, -1.4595, -1.4851,  0.7735, -0.5967], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2577, -1.4595, -1.4851,  0.7735, -0.5967], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-2.6750, -0.9526, -0.4971, -0.2501,  1.6342], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.6590,  2.2829,  3.0261,  1.3643, -0.3714], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.3474,  0.3541, -1.0369, -2.6750, -2.3347], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.5502, -0.1969, -0.0774,  0.0783,  0.1044], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.5839, -0.2682, -0.2084,  0.0868,  0.1017], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2090, -0.1162, -0.0934,  0.0453,  0.0534], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2090, -0.1162, -0.0934,  0.0453,  0.0534], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0215,  0.0570, -0.0996, -0.0508,  0.1171], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0752, -0.0946,  0.1117,  0.0837, -0.0919], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-6.5957e-02, -4.5478e+00, -5.8281e+00, -4.2034e-01, -1.9005e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.8097, 0.2854, 0.5669, 0.4606, 0.1373], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9480, 0.2731, 0.0367, 0.8240, 0.9997], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2090, -0.1162, -0.0934,  0.0453,  0.0534], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0036, -0.0097,  0.0169,  0.0086, -0.0198], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0949,  0.0021, -0.0063,  0.0171,  0.0489], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1278, -0.0970, -0.0872,  0.0086,  0.0124], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.6125, -0.3665, -0.3037,  0.1135,  0.1362], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.6125, -0.3665, -0.3037,  0.1135,  0.1362], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0688,  0.1009,  0.0833,  0.0601, -0.0289], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([23.7393], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2052], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0169,  0.0298,  0.0148,  0.0129, -0.0136], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0169,  0.0298,  0.0148,  0.0129, -0.0136], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0291,  0.1454,  0.0360, -0.0331, -0.1888], grad_fn=<SliceBackward0>)
  [Layer 7] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 7] Output sample values after mixer: tensor([ 0.0291,  0.1454,  0.0360, -0.0331, -0.1888], grad_fn=<SliceBackward0>)
  [Layer 7] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 7] Residual connection sample values: tensor([-0.0852, -0.2501, -0.4886,  0.2857,  0.2439], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 8/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5719], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.3223], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1076, -0.2366, -0.4319,  0.3516,  0.2582], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.1168,  1.2664, -3.4048, -0.1315, -0.7347], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.1168,  1.2664, -3.4048, -0.1315, -0.7347], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.8329,  0.5714, -1.4419,  1.0541,  0.7907], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.5503, 4.2471, 2.9822, 2.3588, 4.0630], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.0933,  1.9844,  0.5381, -1.8329, -0.4146], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2782, -0.2281,  0.3230,  0.1074, -0.0145], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3556, -0.1470,  0.3893,  0.0105, -0.0771], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1465, -0.0681,  0.2321,  0.0053, -0.0370], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1465, -0.0681,  0.2321,  0.0053, -0.0370], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0469,  0.2660, -0.0220,  0.0840,  0.0014], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0065, -0.0062, -0.1181,  0.0312, -0.0903], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6851, -0.1380, -0.4118, -0.2678, -0.1244], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0858, 5.5683, 2.1500, 1.8149, 5.1673], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9429, 0.4637, 0.4126, 0.6150, 0.5257], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1465, -0.0681,  0.2321,  0.0053, -0.0370], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 5.8976e-04, -3.3436e-03,  2.7646e-04, -1.0561e-03, -1.7582e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0038, -0.0254,  0.0003, -0.0287,  0.0079], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1409, -0.0261,  0.0704, -0.0699,  0.0414], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.6928, -0.2827,  0.9445, -0.0500, -0.0981], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.6928, -0.2827,  0.9445, -0.0500, -0.0981], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1908, -0.2793, -0.1034,  0.0031,  0.0234], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([386.2111], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0509], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0225, -0.0174, -0.0198,  0.0005,  0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0225, -0.0174, -0.0198,  0.0005,  0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1706,  0.3581, -0.1589,  0.0486, -0.1480], grad_fn=<SliceBackward0>)
  [Layer 8] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 8] Output sample values after mixer: tensor([ 0.1706,  0.3581, -0.1589,  0.0486, -0.1480], grad_fn=<SliceBackward0>)
  [Layer 8] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 8] Residual connection sample values: tensor([ 0.0855,  0.1080, -0.6475,  0.3343,  0.0958], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 9/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.8720], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0709], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0842,  0.0822, -0.4720,  0.3302,  0.0822], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.9844, -2.5397, -0.3071, -0.9360,  0.3670], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.9844, -2.5397, -0.3071, -0.9360,  0.3670], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([2.8399, 2.0542, 0.0698, 1.6938, 0.1929], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.6761, 3.8779, 1.9475, 3.0853, 2.3977], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([2.1009, 3.7295, 1.9979, 2.8399, 0.8116], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-1.3193, -0.0912,  0.0296,  0.1287,  0.0452], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-1.5727e+00, -6.7022e-04,  2.5401e-02,  1.3538e-01,  2.6575e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2702, -0.0003,  0.0129,  0.0723,  0.0135], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2702, -0.0003,  0.0129,  0.0723,  0.0135], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0313, -0.0100,  0.2076, -0.1193,  0.1406], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0923, -0.2687, -0.1005, -0.1417, -0.0813], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1701, -0.1135, -0.1054, -0.5864, -0.1497], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.1375, 4.6928, 3.7592, 1.7823, 2.6631], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5865, 0.5870, 0.6729, 0.3516, 0.6713], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2702, -0.0003,  0.0129,  0.0723,  0.0135], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0265,  0.0085, -0.1760,  0.1012, -0.1192], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0362,  0.0254, -0.3563,  0.2554, -0.3056], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2719,  0.1181,  0.0087,  0.0089,  0.0252], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.9960,  0.1172,  0.0432,  0.2025,  0.0613], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.9960,  0.1172,  0.0432,  0.2025,  0.0613], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.2667, -0.0218, -0.0056, -0.0534,  0.0133], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([89.2888], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1058], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0245, -0.0037, -0.0006, -0.0070,  0.0018], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0245, -0.0037, -0.0006, -0.0070,  0.0018], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0840, -0.0703,  0.2163, -0.0256,  0.1207], grad_fn=<SliceBackward0>)
  [Layer 9] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 9] Output sample values after mixer: tensor([ 0.0840, -0.0703,  0.2163, -0.0256,  0.1207], grad_fn=<SliceBackward0>)
  [Layer 9] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 9] Residual connection sample values: tensor([ 0.1695,  0.0376, -0.4312,  0.3087,  0.2165], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 10/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.9607], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0203], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1707,  0.0290, -0.3237,  0.3058,  0.1845], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.2099, -1.0804,  0.7369, -3.4103,  0.5409], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.2099, -1.0804,  0.7369, -3.4103,  0.5409], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.1176, -0.5647, -2.0712,  2.0794, -0.2631], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.7670, 1.1406, 1.4049, 2.4193, 0.6214], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.0003,  0.1614,  1.1222, -1.1176,  1.3544], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4802,  0.4996,  0.3792,  0.5084, -0.0823], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.3100,  0.4757,  0.3412,  1.1124, -0.0334], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1788,  0.2934,  0.1994,  0.8372, -0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1788,  0.2934,  0.1994,  0.8372, -0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0742,  0.0245, -0.0463, -0.0771,  0.2956], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2420, -0.2779, -0.2375, -0.2207,  0.1539], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0854, -0.0771, -0.0845, -0.0547, -0.0697], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.8673, 0.2644, 0.3268, 3.5481, 0.8815], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7189, 0.9798, 0.9728, 0.8236, 0.9404], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1788,  0.2934,  0.1994,  0.8372, -0.0164], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0513,  0.0170, -0.0320, -0.0533,  0.2044], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0373, -0.6537, -0.0649,  0.2771,  0.1618], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-1.0244,  0.9552, -0.0704,  9.3911, -0.7273], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1538,  2.3837,  0.9007, 13.4676, -0.8072], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1538,  2.3837,  0.9007, 13.4676, -0.8072], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0336, -0.6527,  0.4489, -1.4686, -0.2759], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([518.3163], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0439], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0009, -0.0374,  0.0282, -0.0709, -0.0162], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0009, -0.0374,  0.0282, -0.0709, -0.0162], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2724, -0.1462,  0.3846, -0.0343,  0.0636], grad_fn=<SliceBackward0>)
  [Layer 10] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 10] Output sample values after mixer: tensor([ 0.2724, -0.1462,  0.3846, -0.0343,  0.0636], grad_fn=<SliceBackward0>)
  [Layer 10] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 10] Residual connection sample values: tensor([ 0.4419, -0.1086, -0.0465,  0.2744,  0.2801], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 11/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.2014], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9123], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2911, -0.0581, -0.0241,  0.1974,  0.1633], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.9724, -1.4061, -2.6755,  0.7037, -1.0506], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.9724, -1.4061, -2.6755,  0.7037, -1.0506], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2036, -1.4010, -0.8336, -0.1146, -1.3078], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.6674, -0.5652, -0.2806,  3.0933,  2.6866], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.1526, -1.5225, -0.6485,  0.2036, -0.2364], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1124,  0.2208,  0.2291,  0.0197, -0.2313], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0341,  0.4120,  0.2531,  0.1271, -0.1163], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0173,  0.2478,  0.1425,  0.0676, -0.0548], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0173,  0.2478,  0.1425,  0.0676, -0.0548], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2642,  0.0559, -0.1448, -0.0478, -0.1247], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2135, -0.1344, -0.0206,  0.0003, -0.2784], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2593, -0.1261, -0.1036, -0.2378, -0.4305], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1113, 0.0407, 0.1165, 2.9169, 2.8035], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9715, 0.9949, 0.9880, 0.4998, 0.2991], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0173,  0.2478,  0.1425,  0.0676, -0.0548], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.0994e-04,  1.0791e-04, -2.7945e-04, -9.2288e-05, -2.4068e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1831,  0.0117,  0.0203, -0.0794,  0.1060], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([0.3558, 0.3616, 0.3560, 0.1896, 0.4933], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.3012, -0.4201, -0.0933, -0.0236,  0.6660], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.3012, -0.4201, -0.0933, -0.0236,  0.6660], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.5215,  0.1163,  0.0161, -0.0111, -0.1813], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([65.9141], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1232], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0225,  0.0372,  0.0092, -0.0012, -0.0228], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0225,  0.0372,  0.0092, -0.0012, -0.0228], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1720, -0.0810,  0.2709,  0.4351,  0.1100], grad_fn=<SliceBackward0>)
  [Layer 11] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 11] Output sample values after mixer: tensor([-0.1720, -0.0810,  0.2709,  0.4351,  0.1100], grad_fn=<SliceBackward0>)
  [Layer 11] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 11] Residual connection sample values: tensor([ 0.2699, -0.1896,  0.2244,  0.7095,  0.3901], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 12/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.5969], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7913], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1369, -0.0766,  0.0829,  0.4082,  0.1675], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2770, -1.1193,  1.1502, -0.8100,  0.2233], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2770, -1.1193,  1.1502, -0.8100,  0.2233], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1646,  1.1182, -0.3405,  1.4909, -1.3295], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.6177, 0.6922, 0.0568, 0.2688, 0.7291], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.7531, -2.4550,  0.2865, -0.1646,  1.3497], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1364, -1.2440, -0.0208,  0.1806, -0.3430], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0692, -2.0785, -0.0855,  0.1364, -0.5096], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0358, -0.2311, -0.0409,  0.0729, -0.1912], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0358, -0.2311, -0.0409,  0.0729, -0.1912], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.2407, -0.0314, -0.0881,  0.5126, -0.0140], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1624, -0.2428, -0.1265, -0.2729,  0.4196], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1609, -0.1475, -0.2713, -0.1155, -0.0902], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.4180, 0.9361, 1.1735, 1.7887, 0.1397], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7960, 0.8711, 0.7274, 0.8133, 0.9875], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0358, -0.2311, -0.0409,  0.0729, -0.1912], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0122, -0.0016, -0.0045,  0.0260, -0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0255,  0.0241,  0.0288, -0.1336, -0.0227], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1975, -0.7467, -0.1063,  0.0400,  1.1424], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1394, -1.1218, -0.1728,  0.1582,  0.8320], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1394, -1.1218, -0.1728,  0.1582,  0.8320], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0166,  0.3091, -0.1510, -0.0395,  0.1032], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([42.4896], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1534], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0039,  0.0420, -0.0402, -0.0198,  0.0207], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0039,  0.0420, -0.0402, -0.0198,  0.0207], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0576, -0.0801, -0.0605,  0.2155, -0.3756], grad_fn=<SliceBackward0>)
  [Layer 12] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 12] Output sample values after mixer: tensor([ 0.0576, -0.0801, -0.0605,  0.2155, -0.3756], grad_fn=<SliceBackward0>)
  [Layer 12] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 12] Residual connection sample values: tensor([ 0.3275, -0.2697,  0.1638,  0.9250,  0.0145], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 13/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.7633], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7531], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1333, -0.0897,  0.0518,  0.4051,  0.0053], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0813,  0.0327, -0.1043, -0.7229, -0.5185], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0813,  0.0327, -0.1043, -0.7229, -0.5185], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1159, -0.2956,  0.2280, -0.2764, -0.1991], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.7169, -0.9378,  0.7926,  0.6285, -0.2104], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5625, -0.9691, -0.8991, -0.1159, -0.7664], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.3045,  0.1549, -0.1614, -0.0089, -0.1232], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2424,  0.1363, -0.1536, -0.0206, -0.1537], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1358,  0.0728, -0.0709, -0.0102, -0.0709], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1358,  0.0728, -0.0709, -0.0102, -0.0709], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.1067, -0.2235,  0.1363, -0.0095, -0.1059], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.2844, -0.1954,  0.1518,  0.1248, -0.2054], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0234, -1.0903, -0.5085, -0.6785, -0.0251], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1048, 0.0039, 0.0187, 0.0098, 0.1253], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9976, 0.9957, 0.9905, 0.9934, 0.9969], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1358,  0.0728, -0.0709, -0.0102, -0.0709], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0015, -0.0032,  0.0019, -0.0001, -0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0776,  0.0927, -0.2759,  0.0197, -0.0648], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0136, -0.0421,  0.1078, -0.0082,  0.2486], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0292, -0.0505,  0.1160, -0.0071,  0.2568], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0292, -0.0505,  0.1160, -0.0071,  0.2568], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0011, -0.0008, -0.0057,  0.0017, -0.0497], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.4795], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6351], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0004, -0.0002, -0.0041,  0.0028, -0.0182], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0004, -0.0002, -0.0041,  0.0028, -0.0182], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.1450e-01,  2.5687e-04,  3.0959e-01,  2.1788e-01, -1.0991e-01],
       grad_fn=<SliceBackward0>)
  [Layer 13] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 13] Output sample values after mixer: tensor([ 1.1450e-01,  2.5687e-04,  3.0959e-01,  2.1788e-01, -1.0991e-01],
       grad_fn=<SliceBackward0>)
  [Layer 13] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 13] Residual connection sample values: tensor([ 0.4420, -0.2695,  0.4734,  1.1429, -0.0954], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 14/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.2230], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6707], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1408, -0.0741,  0.1274,  0.4121, -0.0285], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1320, -0.0434, -0.3412,  0.3551, -0.3378], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1320, -0.0434, -0.3412,  0.3551, -0.3378], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5062, -1.5005, -0.3499, -0.2552,  0.8023], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.0306, -0.1664,  1.9005,  0.5139,  1.7846], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.3358, -0.9533,  0.4263,  0.5062, -0.9601], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1117, -0.5173, -0.5338,  0.1363, -0.2251], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0413, -0.5667, -0.7256,  0.0887, -0.2389], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0202, -0.2051, -0.2367,  0.0463, -0.1052], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0202, -0.2051, -0.2367,  0.0463, -0.1052], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0079, -0.0182, -0.0202, -0.0143, -0.0501], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1371, -0.1062, -0.0626, -0.1717, -0.1231], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-7.2745, -0.0385, -2.2024, -0.0138, -5.3378], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1468, 0.0507, 0.0761, 0.0821, 0.0933], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.3437, 0.9980, 0.8456, 0.9989, 0.6077], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0202, -0.2051, -0.2367,  0.0463, -0.1052], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([2.3403e-05, 5.4008e-05, 5.9859e-05, 4.2521e-05, 1.4878e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-3.8035e-05,  4.0553e-05, -5.4778e-05,  1.8186e-04, -1.8037e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0021, -0.0303, -0.0374,  0.0108, -0.0146], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0180, -0.1918, -0.2236,  0.0473, -0.0975], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0180, -0.1918, -0.2236,  0.0473, -0.0975], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0011, 0.0041, 0.0317, 0.0099, 0.0137], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6790], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2135], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0032, 0.0081, 0.0434, 0.0196, 0.0345], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0032, 0.0081, 0.0434, 0.0196, 0.0345], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.5066,  0.4102, -0.2532, -0.0680,  0.1706], grad_fn=<SliceBackward0>)
  [Layer 14] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 14] Output sample values after mixer: tensor([ 0.5066,  0.4102, -0.2532, -0.0680,  0.1706], grad_fn=<SliceBackward0>)
  [Layer 14] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 14] Residual connection sample values: tensor([0.9486, 0.1408, 0.2202, 1.0748, 0.0752], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 15/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.7680], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6011], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([0.3469, 0.0423, 0.0665, 0.4659, 0.0257], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.4401,  0.8020,  0.6050, -0.6043, -2.4869], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.4401,  0.8020,  0.6050, -0.6043, -2.4869], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.0156, -0.5624, -0.1082, -1.6577, -0.2145], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.1242, 1.2489, 0.3440, 1.5812, 0.6813], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.9594,  1.5488,  0.1523,  1.0156, -1.1692], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1037, -0.0157,  0.0522, -0.3342,  0.0100], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4399, -0.0399,  1.3774,  0.1084, -0.0035], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1723, -0.0196,  1.0999,  0.0572, -0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1723, -0.0196,  1.0999,  0.0572, -0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0527,  0.0003,  0.0073, -0.0242, -0.0753], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0225,  0.0203, -0.0123, -0.0241, -0.0632], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.4414, -0.0592, -0.7390, -0.0051, -0.0087], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1799, 1.0990, 0.0307, 0.2160, 0.2591], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6445, 0.9370, 0.9775, 0.9989, 0.9977], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1723, -0.0196,  1.0999,  0.0572, -0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.6330e-03, -9.5815e-06, -2.2703e-04,  7.4955e-04,  2.3350e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0051, 0.0051, 0.0010, 0.0037, 0.0079], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0091,  0.0003,  0.0732,  0.0141, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3168, -0.0347,  2.0374,  0.1162, -0.0035], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3168, -0.0347,  2.0374,  0.1162, -0.0035], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 8.7381e-02, -1.9192e-02,  7.9724e-01, -2.4801e-02,  6.7752e-04],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([4.6497], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4638], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0895, -0.0144,  0.1752, -0.0143,  0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0895, -0.0144,  0.1752, -0.0143,  0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2822, -0.4563, -0.1898,  0.0373,  0.1794], grad_fn=<SliceBackward0>)
  [Layer 15] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 15] Output sample values after mixer: tensor([-0.2822, -0.4563, -0.1898,  0.0373,  0.1794], grad_fn=<SliceBackward0>)
  [Layer 15] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 15] Residual connection sample values: tensor([ 0.6664, -0.3155,  0.0304,  1.1121,  0.2546], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 16/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3.5967], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5273], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1586, -0.0621,  0.0056,  0.3359,  0.0573], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1500, -0.3139, -4.4492, -0.0245, -1.5289], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1500, -0.3139, -4.4492, -0.0245, -1.5289], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.4267,  0.3462,  0.0049, -0.3465, -1.5879], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 5.5639, -0.9152,  2.2675, -0.2555,  0.8141], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.4791,  2.1004, -0.1827,  0.4267,  0.0553], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0168, -0.0579, -0.2216,  0.0531,  0.0202], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0187, -0.0491, -0.0848,  0.0149,  0.0277], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0092, -0.0239, -0.0406,  0.0075,  0.0141], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0092, -0.0239, -0.0406,  0.0075,  0.0141], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0535, -0.0433, -0.0320, -0.0734,  0.0129], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0510,  0.0234, -0.0261, -0.2169,  0.0269], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.1349e-03, -3.0370e-03, -2.7156e+00, -4.1511e-03, -4.2926e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.1245e+00, 2.7040e-02, 2.0754e-01, 2.0991e-02, 2.5383e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9965, 0.9999, 0.5691, 0.9999, 0.9989], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0092, -0.0239, -0.0406,  0.0075,  0.0141], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0015,  0.0013,  0.0009,  0.0021, -0.0004], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0340,  0.0941,  0.0329,  0.0031, -0.0028], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0102, -0.0136, -0.0488,  0.0305,  0.0121], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0081, -0.0080, -0.0393,  0.0288,  0.0088], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0081, -0.0080, -0.0393,  0.0288,  0.0088], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0006,  0.0011,  0.0020, -0.0003, -0.0024], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2008], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.2316], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0005,  0.0006,  0.0045, -0.0001, -0.0028], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0005,  0.0006,  0.0045, -0.0001, -0.0028], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3214, -0.1029, -0.1088,  0.0894,  0.1367], grad_fn=<SliceBackward0>)
  [Layer 16] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 16] Output sample values after mixer: tensor([-0.3214, -0.1029, -0.1088,  0.0894,  0.1367], grad_fn=<SliceBackward0>)
  [Layer 16] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 16] Residual connection sample values: tensor([ 0.3450, -0.4184, -0.0784,  1.2015,  0.3913], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 17/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.3689], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4784], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1115, -0.1163, -0.0218,  0.4449,  0.1165], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-3.7168, -0.6128, -0.2704, -0.9130, -2.3024], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-3.7168, -0.6128, -0.2704, -0.9130, -2.3024], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.6221, -0.9966, -0.2058,  0.1002, -1.5158], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.7799, 2.2917, 1.5799, 2.5552, 2.1530], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.2513,  0.3392, -0.1690,  0.6221, -1.7858], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2255, -0.1210,  0.0563,  0.0233, -0.3842], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3205, -0.0989, -0.0581,  0.0577, -0.2890], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1348, -0.0470, -0.0282,  0.0297, -0.1237], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1348, -0.0470, -0.0282,  0.0297, -0.1237], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0555,  0.2254, -0.2547, -0.1222, -0.1955], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1030, -0.0554, -0.2375, -0.1554, -0.0151], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3863, -0.8773, -1.4027, -0.6828, -0.3905], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.2266, 0.6184, 0.5155, 1.5413, 1.4434], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.1826, 0.5813, 0.4852, 0.3491, 0.5692], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1348, -0.0470, -0.0282,  0.0297, -0.1237], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0092, -0.0373,  0.0421,  0.0202,  0.0323], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0105, -0.0426,  0.0489,  0.0248,  0.0365], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1233, -0.0330, -0.0238,  0.0281, -0.1019], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.4783, -0.1568, -0.0981,  0.1063, -0.4278], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.4783, -0.1568, -0.0981,  0.1063, -0.4278], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0422,  0.0338,  0.0115, -0.0278,  0.0896], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([18.7892], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2307], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0190,  0.0155,  0.0056, -0.0165,  0.0492], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0190,  0.0155,  0.0056, -0.0165,  0.0492], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.7364, -0.1741, -0.4936, -0.4289,  0.0449], grad_fn=<SliceBackward0>)
  [Layer 17] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 17] Output sample values after mixer: tensor([ 0.7364, -0.1741, -0.4936, -0.4289,  0.0449], grad_fn=<SliceBackward0>)
  [Layer 17] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 17] Residual connection sample values: tensor([ 1.0813, -0.5925, -0.5720,  0.7726,  0.4363], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 18/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([5.0436], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4453], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2310, -0.1094, -0.1041,  0.2006,  0.0825], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4759, -0.3001, -2.1661,  0.2770, -1.1041], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4759, -0.3001, -2.1661,  0.2770, -1.1041], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.8443, -0.5031,  0.2195,  0.3454,  0.7038], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.3999,  2.4991,  1.4189,  0.2434, -0.5782], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5580, -0.2216, -0.6630, -0.8443, -1.9548], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1806, -0.1985, -0.0325,  0.0469,  0.0468], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1899, -0.5965, -0.0212,  0.0775, -0.0055], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1040, -0.2118, -0.0105,  0.0402, -0.0027], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1040, -0.2118, -0.0105,  0.0402, -0.0027], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0406,  0.0550, -0.0337, -0.1702,  0.0184], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0044,  0.0760, -0.0633, -0.1558,  0.0915], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.3195e-03, -6.5336e+00, -1.4897e+01, -1.3796e-03, -2.0873e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4515, 3.6371, 2.9206, 0.1380, 0.0792], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9895e-01, 4.7848e-11, 1.2725e-19, 9.9981e-01, 9.9983e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1040, -0.2118, -0.0105,  0.0402, -0.0027], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0019,  0.0026, -0.0016, -0.0080,  0.0009], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0042, -0.0014,  0.0947, -0.0572,  0.0168], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1741, -1.8026,  0.1427, -0.1074, -0.3009], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1823, -1.7858,  0.1435, -0.1106, -0.3007], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1823, -1.7858,  0.1435, -0.1106, -0.3007], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0333,  0.2281, -0.0320, -0.0174,  0.0827], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([12.0379], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2882], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0473,  0.0794, -0.0100, -0.0127,  0.0284], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0473,  0.0794, -0.0100, -0.0127,  0.0284], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1897,  0.4986, -0.1559, -0.5145,  0.1157], grad_fn=<SliceBackward0>)
  [Layer 18] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 18] Output sample values after mixer: tensor([-0.1897,  0.4986, -0.1559, -0.5145,  0.1157], grad_fn=<SliceBackward0>)
  [Layer 18] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 18] Residual connection sample values: tensor([ 0.8917, -0.0938, -0.7279,  0.2580,  0.5520], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 19/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([5.9970], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4084], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2171, -0.0190, -0.1488,  0.0777,  0.1193], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0743, -0.7757, -0.3607, -0.4736, -0.9697], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0743, -0.7757, -0.3607, -0.4736, -0.9697], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.6527, -0.3944, -0.1627,  0.5810, -0.3827], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.3011, 0.3607, 1.3456, 2.3582, 1.1590], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.0119, -0.5868, -2.6270, -0.6527,  0.7380], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.5748,  0.3660, -0.0167, -0.3903, -0.0976], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.6262,  0.3665, -0.0305, -0.5979, -0.0988], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2182,  0.2165, -0.0150, -0.2122, -0.0470], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2182,  0.2165, -0.0150, -0.2122, -0.0470], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0037,  0.0476, -0.2743,  0.1670,  0.4460], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0385,  0.1014, -0.1777,  0.0117, -0.0882], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1739, -1.5063, -1.5725, -0.1983, -0.0768], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.2959, 0.3845, 0.8888, 3.5390, 0.8773], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5637, 0.5604, 0.2472, 0.4958, 0.9348], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2182,  0.2165, -0.0150, -0.2122, -0.0470], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0027, -0.0342,  0.1972, -0.1201, -0.3206], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0097, -0.0190,  0.0964, -0.1032, -0.3423], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.6147,  0.7767,  0.0110, -0.8066,  0.0124], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.9469,  1.1064, -0.0118, -1.1296, -0.0591], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.9469,  1.1064, -0.0118, -1.1296, -0.0591], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0365, -0.2706,  0.0017,  0.2053,  0.0158], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([26.7350], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1934], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0082, -0.1056,  0.0008,  0.0393,  0.0112], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0082, -0.1056,  0.0008,  0.0393,  0.0112], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.5411,  0.8033, -0.2124,  0.2587, -0.0214], grad_fn=<SliceBackward0>)
  [Layer 19] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 19] Output sample values after mixer: tensor([-1.5411,  0.8033, -0.2124,  0.2587, -0.0214], grad_fn=<SliceBackward0>)
  [Layer 19] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 19] Residual connection sample values: tensor([-0.6494,  0.7094, -0.9404,  0.5167,  0.5306], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 20/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([8.5472], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3420], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0819,  0.0819, -0.1087,  0.0798,  0.0654], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5515, -0.4654,  0.5281,  0.4358,  0.2636], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5515, -0.4654,  0.5281,  0.4358,  0.2636], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.0304,  0.3253,  0.2168,  0.6299, -1.9674], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.1175,  2.4600,  1.4610,  0.5378,  0.1654], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1964,  0.3091, -0.0315,  0.0304, -1.7616], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0075,  0.0049,  0.0477,  0.1528, -0.3388], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0070, -0.0333, -0.1318,  0.1317, -0.3853], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0035, -0.0164, -0.0616,  0.0702, -0.1560], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0035, -0.0164, -0.0616,  0.0702, -0.1560], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([0.0197, 0.0682, 0.0658, 0.0618, 0.0216], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0183, -0.0055,  0.0031, -0.0667, -0.0657], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.0858e-01, -2.9306e+00, -5.2962e+00, -1.2326e+01, -8.1593e-03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0063, 0.2710, 0.2342, 0.1272, 0.0496], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9981, 0.4519, 0.2892, 0.2084, 0.9996], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0035, -0.0164, -0.0616,  0.0702, -0.1560], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-4.3380e-07, -1.4986e-06, -1.4460e-06, -1.3564e-06, -4.7392e-07],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.2127e-04, -2.4591e-04, -1.9304e-04,  9.8028e-05, -4.7251e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-1.1009e-03,  9.2771e-04, -1.0941e-03,  3.5066e-04, -6.9483e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0040, -0.0125, -0.0517,  0.0581, -0.1284], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0040, -0.0125, -0.0517,  0.0581, -0.1284], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0008,  0.0022, -0.0172,  0.0154, -0.0191], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0754], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.6413], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0073,  0.0177, -0.0929,  0.1365, -0.1110], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0073,  0.0177, -0.0929,  0.1365, -0.1110], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0057, -0.3283,  0.2188, -0.5538,  0.3948], grad_fn=<SliceBackward0>)
  [Layer 20] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 20] Output sample values after mixer: tensor([-0.0057, -0.3283,  0.2188, -0.5538,  0.3948], grad_fn=<SliceBackward0>)
  [Layer 20] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 20] Residual connection sample values: tensor([-0.6552,  0.3812, -0.7216, -0.0371,  0.9254], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 21/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([9.8343], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3189], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1056,  0.0556, -0.1078, -0.0071,  0.1434], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0862, -1.1673, -0.5996, -0.1372, -1.3044], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0862, -1.1673, -0.5996, -0.1372, -1.3044], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.0095, -0.3893, -0.3059,  1.1313,  0.6985], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.3535, 1.2706, 0.4488, 0.4055, 0.8416], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4285, -2.0421, -1.2195, -0.0095,  0.8622], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1289, -0.1285, -0.0527, -0.3321,  0.3303], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4863, -0.2259, -0.0784, -0.4301,  0.2764], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1852, -0.1003, -0.0376, -0.1695,  0.1571], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1852, -0.1003, -0.0376, -0.1695,  0.1571], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.7109, -0.2204, -0.1518, -0.2749, -0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0086, -0.0896,  0.1249, -0.0950,  0.1854], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3228, -0.3764, -0.1595, -0.1054, -0.3757], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.9323, 1.3326, 1.0805, 0.6055, 1.0017], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7402, 0.6056, 0.8417, 0.9382, 0.6864], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1852, -0.1003, -0.0376, -0.1695,  0.1571], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.1227,  0.0381,  0.0262,  0.0475,  0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1905,  0.1066,  0.0693,  0.1174,  0.0152], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3628, -0.1622, -0.0702, -0.1640,  0.3633], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.7541, -0.3741, -0.1498, -0.5223,  0.6954], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.7541, -0.3741, -0.1498, -0.5223,  0.6954], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0311,  0.1036,  0.0318,  0.0334, -0.1936], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([4.5706], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4677], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0303,  0.1275,  0.0443,  0.0326, -0.1629], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0303,  0.1275,  0.0443,  0.0326, -0.1629], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2223, -0.3613,  0.0356,  0.0996,  0.6166], grad_fn=<SliceBackward0>)
  [Layer 21] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 21] Output sample values after mixer: tensor([ 0.2223, -0.3613,  0.0356,  0.0996,  0.6166], grad_fn=<SliceBackward0>)
  [Layer 21] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 21] Residual connection sample values: tensor([-0.4328,  0.0198, -0.6860,  0.0624,  1.5420], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 22/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([12.0737], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2878], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0644,  0.0027, -0.0945,  0.0110,  0.2223], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5758,  0.2722,  0.8965, -3.5416,  0.3075], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5758,  0.2722,  0.8965, -3.5416,  0.3075], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.1092, -0.4597,  0.5947,  0.1025,  0.2244], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.6128, -0.4889,  0.0174,  0.9710,  0.8410], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.3442,  0.2561, -0.6606, -1.1092, -0.9945], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0801,  0.1541, -0.0139,  0.0045, -0.0328], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0719,  0.2186, -0.0012, -0.0138, -0.0321], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0347,  0.1212, -0.0006, -0.0069, -0.0158], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0347,  0.1212, -0.0006, -0.0069, -0.0158], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-2.7651e-01,  2.4931e-01,  7.8455e-06, -2.3290e-01,  1.5852e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2782, -0.1461, -0.0190, -0.2318,  0.0986], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0709, -0.0702, -0.0699, -0.0895, -0.3897], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.7905, 0.5340, 0.1175, 0.7073, 1.2329], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9455, 0.9632, 0.9918, 0.9387, 0.6185], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0347,  0.1212, -0.0006, -0.0069, -0.0158], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 7.5770e-03, -6.8318e-03, -2.1499e-07,  6.3819e-03, -4.3439e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0107, 0.0153, 0.0050, 0.0175, 0.0413], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0123,  0.0985, -0.0710,  0.0239, -0.0523], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0474, -0.1105, -0.0700,  0.0357, -0.0250], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0474, -0.1105, -0.0700,  0.0357, -0.0250], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0175, -0.0171, -0.0446, -0.0036, -0.0044], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([6.9010], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3807], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0176, -0.0074, -0.0448, -0.0053, -0.0043], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0176, -0.0074, -0.0448, -0.0053, -0.0043], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4883, -0.2246, -0.5182, -0.1854, -0.5633], grad_fn=<SliceBackward0>)
  [Layer 22] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 22] Output sample values after mixer: tensor([-0.4883, -0.2246, -0.5182, -0.1854, -0.5633], grad_fn=<SliceBackward0>)
  [Layer 22] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 22] Residual connection sample values: tensor([-0.9211, -0.2048, -1.2041, -0.1230,  0.9788], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 23/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([12.9569], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2778], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1125, -0.0226, -0.1398, -0.0185,  0.1113], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.3553,  0.6783, -1.7802,  0.4595,  0.0140], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.3553,  0.6783, -1.7802,  0.4595,  0.0140], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.7288, -0.7027,  0.4144, -0.6267, -0.3456], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.2293, 0.7482, 0.7742, 0.1019, 0.6191], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0025,  0.2032, -0.1181, -0.7288, -1.3988], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0054,  0.0065,  0.1964,  0.0260, -0.1310], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0283, -0.0010,  0.1544,  0.0424, -0.1355], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0140, -0.0005,  0.0831,  0.0216, -0.0632], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0140, -0.0005,  0.0831,  0.0216, -0.0632], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2049,  0.0730,  0.0264,  0.5689,  0.0436], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0476,  0.0012,  0.1066, -0.0082,  0.1232], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1232, -0.2255, -0.2420, -0.0956, -0.2396], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0897, 0.4097, 0.4073, 0.0821, 0.3039], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9890, 0.9117, 0.9061, 0.9922, 0.9298], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0140, -0.0005,  0.0831,  0.0216, -0.0632], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.5664e-04, -9.1467e-05, -3.3017e-05, -7.1248e-04, -5.4653e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0251,  0.0120, -0.0013,  0.0753, -0.0112], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0062,  0.0062,  0.2100, -0.0295,  0.0129], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0056,  0.0062,  0.2061, -0.0305,  0.0158], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0056,  0.0062,  0.2061, -0.0305,  0.0158], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0012,  0.0028, -0.0529, -0.0086,  0.0001], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3495], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.6915], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0019,  0.0140, -0.4390, -0.0716,  0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0019,  0.0140, -0.4390, -0.0716,  0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2756, -0.7202, -0.3208, -0.0994, -0.9696], grad_fn=<SliceBackward0>)
  [Layer 23] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 23] Output sample values after mixer: tensor([-0.2756, -0.7202, -0.3208, -0.0994, -0.9696], grad_fn=<SliceBackward0>)
  [Layer 23] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 23] Residual connection sample values: tensor([-1.1967, -0.9250, -1.5250, -0.2224,  0.0092], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 24/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([15.0266], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2580], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1705, -0.1170, -0.2096, -0.0364,  0.0012], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0173, -1.0673, -0.2118, -1.8915, -0.2277], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0173, -1.0673, -0.2118, -1.8915, -0.2277], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3718, -1.5434, -1.2655,  0.0400, -0.7007], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.1666,  0.4462,  0.5843, -0.0140,  0.1309], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4168,  0.1667,  0.7085,  0.3718, -2.0091], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-2.2015e-01, -1.8028e-01, -1.6461e-01, -1.7677e-04,  1.6884e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0932, -0.0829, -0.1668, -0.0793,  0.1757], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0444, -0.0397, -0.0765, -0.0381,  0.0955], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0444, -0.0397, -0.0765, -0.0381,  0.0955], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2660,  0.0765, -0.0350,  0.0183,  0.0840], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0575,  0.0106, -0.0200,  0.1512, -0.2276], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6296, -0.1967, -0.1434, -0.1402, -0.2238], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6880, 1.0182, 0.8853, 1.1430, 0.5156], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6484, 0.8185, 0.8808, 0.8520, 0.8910], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0444, -0.0397, -0.0765, -0.0381,  0.0955], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0081, -0.0023,  0.0011, -0.0006, -0.0026], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0036,  0.0052, -0.0056,  0.0067, -0.0037], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0130, -0.0171, -0.0760, -0.0905,  0.0193], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2306, -0.2117, -0.4505, -0.2769,  0.4873], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2306, -0.2117, -0.4505, -0.2769,  0.4873], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0020,  0.0578,  0.0427,  0.0687, -0.0492], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([8.3808], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3454], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0008,  0.0688,  0.0447,  0.0534, -0.0354], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0008,  0.0688,  0.0447,  0.0534, -0.0354], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1111, -2.7748, -1.1585, -0.4474,  0.2444], grad_fn=<SliceBackward0>)
  [Layer 24] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 24] Output sample values after mixer: tensor([-0.1111, -2.7748, -1.1585, -0.4474,  0.2444], grad_fn=<SliceBackward0>)
  [Layer 24] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 24] Residual connection sample values: tensor([-1.3078, -3.6998, -2.6834, -0.6697,  0.2536], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 25/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([18.1202], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2349], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1180, -0.3098, -0.2256, -0.0692,  0.0214], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4457, -0.2479, -2.6472,  0.6957, -0.3012], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4457, -0.2479, -2.6472,  0.6957, -0.3012], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.1918, -0.4293,  0.9867, -0.9573,  0.2710], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.3460, 0.3076, 0.6426, 0.6629, 0.8288], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.7093, -0.5925,  0.5788,  1.1918,  0.1249], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2687, -0.0037, -0.2501, -0.4016, -0.0127], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-2.8802e-01, -3.3583e-04, -1.4740e-01, -5.0672e-01, -5.1299e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-1.2341e-01, -1.6789e-04, -6.8277e-02, -1.9051e-01, -2.4992e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-1.2341e-01, -1.6789e-04, -6.8277e-02, -1.9051e-01, -2.4992e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0150, -0.0611, -0.1057, -0.0120,  0.0388], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2099, -0.1922,  0.1264, -0.1831, -0.1433], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1626, -0.3327, -0.3294, -0.2016, -0.1541], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.7501, 0.4554, 0.5755, 0.7255, 0.9514], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8852, 0.8594, 0.8273, 0.8639, 0.8636], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-1.2341e-01, -1.6789e-04, -6.8277e-02, -1.9051e-01, -2.4992e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0014,  0.0057,  0.0098,  0.0011, -0.0036], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0043,  0.0125,  0.0154,  0.0063, -0.0188], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0075,  0.0100, -0.0542, -0.1720, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1209,  0.0098, -0.1169, -0.3470, -0.0883], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1209,  0.0098, -0.1169, -0.3470, -0.0883], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0210, -0.0011,  0.0205, -0.1611,  0.0113], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2209], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.1278], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1557, -0.0062,  0.0992, -0.4375,  0.0473], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1557, -0.0062,  0.0992, -0.4375,  0.0473], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.6830, -0.1180, -0.9439,  0.5015, -1.4109], grad_fn=<SliceBackward0>)
  [Layer 25] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 25] Output sample values after mixer: tensor([-0.6830, -0.1180, -0.9439,  0.5015, -1.4109], grad_fn=<SliceBackward0>)
  [Layer 25] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 25] Residual connection sample values: tensor([-1.9909, -3.8178, -3.6274, -0.1683, -1.1573], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 26/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([19.7595], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2250], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2141, -0.3825, -0.3821, -0.0217, -0.1190], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4352,  0.7014, -0.2225, -0.0508,  0.5517], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4352,  0.7014, -0.2225, -0.0508,  0.5517], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2418, -0.6754,  0.6923, -0.3189, -0.9943], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([1.1443, 1.2306, 1.9247, 1.6359, 1.0665], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8268, -1.5061, -0.5482, -0.2418, -0.3152], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0980, -0.2227, -0.2851, -0.0813, -0.3149], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1890, -0.2766, -0.3104, -0.1446, -0.5827], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0856, -0.1193, -0.1313, -0.0671, -0.2088], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0856, -0.1193, -0.1313, -0.0671, -0.2088], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([0.1575, 0.0907, 0.0959, 0.0318, 0.0935], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0208, -0.2671, -0.1615, -0.1057, -0.0627], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3298, -0.0634, -0.2289, -0.1264, -0.0584], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.2083, 0.5409, 3.3143, 2.7773, 1.1138], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6714, 0.9663, 0.4684, 0.7040, 0.9370], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0856, -0.1193, -0.1313, -0.0671, -0.2088], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0163, -0.0094, -0.0099, -0.0033, -0.0097], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0404, -0.0005, -0.0145, -0.0332, -0.0127], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3452, -0.3886, -0.3981, -0.0763, -0.6409], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.6904, -0.8697, -0.9277, -0.3469, -1.4829], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.6904, -0.8697, -0.9277, -0.3469, -1.4829], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1824, -0.4078,  0.0918,  0.0086, -0.5191], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([9.6505], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3219], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1390, -0.2168,  0.0644,  0.0066, -0.2949], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1390, -0.2168,  0.0644,  0.0066, -0.2949], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.9276,  0.0316, -0.0587, -1.2033, -1.5741], grad_fn=<SliceBackward0>)
  [Layer 26] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 26] Output sample values after mixer: tensor([-0.9276,  0.0316, -0.0587, -1.2033, -1.5741], grad_fn=<SliceBackward0>)
  [Layer 26] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 26] Residual connection sample values: tensor([-2.9185, -3.7862, -3.6861, -1.3715, -2.7314], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 27/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([23.3438], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2070], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2517, -0.3109, -0.3068, -0.1367, -0.2373], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1390, -0.9129,  1.3078, -0.8557, -0.8743], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1390, -0.9129,  1.3078, -0.8557, -0.8743], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.5896,  0.1311, -0.0693,  0.1493, -0.5751], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.6728, -1.0896,  1.2531,  1.8396, -0.5157], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0210, -0.5378,  0.5523,  0.5896, -1.2730], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1683,  0.0598, -0.0265, -0.1042, -0.0637], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1850,  0.0080, -0.0815, -0.3044, -0.0618], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0840,  0.0040, -0.0391, -0.1292, -0.0300], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0840,  0.0040, -0.0391, -0.1292, -0.0300], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0092,  0.0651, -0.0036,  0.6673, -0.0206], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0211,  0.4246, -0.1243, -0.1137, -0.1730], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5626, -0.0303, -0.7559, -1.1613, -0.0406], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3545, 0.0152, 0.0322, 0.4079, 0.0190], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8192, 0.9995, 0.9759, 0.6227, 0.9992], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0840,  0.0040, -0.0391, -0.1292, -0.0300], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0003, -0.0019,  0.0001, -0.0199,  0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0037, -0.0083, -0.0061, -0.0252,  0.0017], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0622,  0.0104, -0.0211, -0.0851,  0.0032], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2292,  0.0184, -0.0989, -0.3421, -0.0564], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2292,  0.0184, -0.0989, -0.3421, -0.0564], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0170, -0.0048, -0.1018,  0.0873,  0.0145], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7910], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1244], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0440, -0.0098, -0.2985,  0.0659,  0.0543], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0440, -0.0098, -0.2985,  0.0659,  0.0543], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.6680,  0.7311,  0.4672, -0.0600, -0.5455], grad_fn=<SliceBackward0>)
  [Layer 27] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 27] Output sample values after mixer: tensor([ 0.6680,  0.7311,  0.4672, -0.0600, -0.5455], grad_fn=<SliceBackward0>)
  [Layer 27] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 27] Residual connection sample values: tensor([-2.2505, -3.0551, -3.2189, -1.4315, -3.2769], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 28/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([26.0933], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1958], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1571, -0.2053, -0.2211, -0.1169, -0.2216], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6511, -0.5671, -0.3891, -0.6173, -0.2792], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6511, -0.5671, -0.3891, -0.6173, -0.2792], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.0201,  0.3110, -0.1710, -0.9539, -1.0274], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([2.2031, 1.1006, 0.7759, 0.5757, 1.9471], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6237, -1.4452, -1.6444, -0.0201,  0.8165], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1448,  0.1974, -0.0846,  0.2505, -0.2449], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0169,  0.1080, -0.2138,  0.1604, -0.3105], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0085,  0.0569, -0.0955,  0.0866, -0.1313], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0085,  0.0569, -0.0955,  0.0866, -0.1313], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2689, -0.1221, -0.0468,  0.0492, -0.1715], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0094,  0.0070, -0.0362, -0.0283, -0.0151], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5442, -0.1843, -0.1064, -0.1124, -0.2523], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.0234, 1.0955, 1.4445, 1.2128, 1.6720], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5729, 0.8172, 0.8575, 0.8725, 0.6558], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0085,  0.0569, -0.0955,  0.0866, -0.1313], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0023, -0.0011, -0.0004,  0.0004, -0.0015], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0015,  0.0022, -0.0045, -0.0003, -0.0036], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0063,  0.0090, -0.0155,  0.0130, -0.0215], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0221,  0.1152, -0.1936,  0.1747, -0.2666], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0221,  0.1152, -0.1936,  0.1747, -0.2666], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0049, -0.0236,  0.0304, -0.0378,  0.0320], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1366], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.7052], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0272, -0.1225,  0.1506, -0.2160,  0.2132], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0272, -0.1225,  0.1506, -0.2160,  0.2132], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.7228,  0.4746, -0.0880,  0.7080,  1.4289], grad_fn=<SliceBackward0>)
  [Layer 28] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 28] Output sample values after mixer: tensor([ 1.7228,  0.4746, -0.0880,  0.7080,  1.4289], grad_fn=<SliceBackward0>)
  [Layer 28] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 28] Residual connection sample values: tensor([-0.5277, -2.5805, -3.3069, -0.7235, -1.8480], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 29/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([36.1728], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1663], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0386, -0.1865, -0.2439, -0.0654, -0.1359], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5303, -0.2993, -0.3363, -1.3158,  1.3570], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5303, -0.2993, -0.3363, -1.3158,  1.3570], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2557,  0.5775,  1.1717,  0.8095,  0.4443], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.3625, -0.0920,  1.6509,  1.0392,  1.0238], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.7339,  0.0419,  0.5166, -0.2557,  0.2297], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0265, -0.1559, -0.3884, -0.1400,  0.2956], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0125, -0.2315, -0.5267,  0.2267,  1.7956], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0062, -0.1024, -0.1956,  0.1261,  1.5400], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0062, -0.1024, -0.1956,  0.1261,  1.5400], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1731,  0.0966, -0.0885, -0.0056,  0.0923], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1226, -0.0602, -0.1697,  0.0582,  0.5057], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6542, -0.1369, -1.4589, -0.3682, -0.1218], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2917, 0.0505, 0.4168, 0.2681, 0.6635], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8263, 0.9931, 0.5444, 0.9060, 0.9224], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0062, -0.1024, -0.1956,  0.1261,  1.5400], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 3.1322e-04, -1.7484e-04,  1.6009e-04,  1.0138e-05, -1.6705e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0003,  0.0022, -0.0013, -0.0019,  0.0022], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0021, -0.0124, -0.0185,  0.0272,  0.1791], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0125, -0.1846, -0.3472,  0.2392,  2.7677], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0125, -0.1846, -0.3472,  0.2392,  2.7677], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 2.4628e-03,  2.3522e-02,  4.8658e-02, -6.6572e-02,  2.9869e+00],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2606], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9587], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0158,  0.1176,  0.1818, -0.3054,  2.1226], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0158,  0.1176,  0.1818, -0.3054,  2.1226], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.6767, -0.9101,  1.5445, -0.8983,  0.3966], grad_fn=<SliceBackward0>)
  [Layer 29] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 29] Output sample values after mixer: tensor([ 0.6767, -0.9101,  1.5445, -0.8983,  0.3966], grad_fn=<SliceBackward0>)
  [Layer 29] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 29] Residual connection sample values: tensor([ 0.1490, -3.4906, -1.7624, -1.6219, -1.4515], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 30/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([41.7472], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1548], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0094, -0.2104, -0.1083, -0.1169, -0.0891], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2460,  0.8036,  0.2018, -0.1834,  1.6964], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2460,  0.8036,  0.2018, -0.1834,  1.6964], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.4668,  0.1823, -0.9196, -0.4668,  0.8894], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.6472, 0.4359, 1.0320, 0.1779, 0.9543], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6531,  1.6209, -0.9774, -0.4668,  1.5907], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3220, -0.1917,  0.2995,  0.0509, -0.9101], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3648, -0.2335,  0.8747,  0.1003, -1.0027], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1495, -0.1032,  0.6173,  0.0527, -0.2691], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1495, -0.1032,  0.6173,  0.0527, -0.2691], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0606, -0.0617,  0.0077,  0.0044, -0.2571], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1993, -0.1417, -0.2183, -0.2307, -0.2559], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2038, -0.3668, -0.2078, -0.0952, -0.4265], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.8411, 0.3468, 0.9417, 0.1175, 0.5629], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8425, 0.8805, 0.8223, 0.9889, 0.7866], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1495, -0.1032,  0.6173,  0.0527, -0.2691], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0076,  0.0078, -0.0010, -0.0005,  0.0323], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0051, -0.0272, -0.0105, -0.0055,  0.0446], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0744, -0.1309,  1.1085,  0.1934, -0.2364], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0991, -0.1479,  1.2104,  0.2021, -0.2808], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0991, -0.1479,  1.2104,  0.2021, -0.2808], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0137, -0.0821,  0.1344, -0.0168, -0.4025], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4703], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.4582], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0499, -0.3311,  0.3276, -0.0681, -0.5973], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0499, -0.3311,  0.3276, -0.0681, -0.5973], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.6361, -1.6125, -1.2636, -3.5111, -3.6726], grad_fn=<SliceBackward0>)
  [Layer 30] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 30] Output sample values after mixer: tensor([ 2.6361, -1.6125, -1.2636, -3.5111, -3.6726], grad_fn=<SliceBackward0>)
  [Layer 30] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 30] Residual connection sample values: tensor([ 2.7851, -5.1030, -3.0261, -5.1329, -5.1241], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 31/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([60.5606], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1285], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0988, -0.1836, -0.1078, -0.2063, -0.1821], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.1116, -0.1265,  1.0187, -0.2624,  0.1288], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.1116, -0.1265,  1.0187, -0.2624,  0.1288], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.2394,  0.1537, -0.0799,  0.2325,  0.2006], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.1606,  0.1235,  0.8088,  0.2205,  0.2614], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4060,  0.7385,  0.2352,  0.2394,  0.4710], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0404, -0.0354,  0.0291, -0.0491,  0.1658], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0433, -0.0005,  0.0185, -0.0673,  0.1054], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0212, -0.0002,  0.0093, -0.0325,  0.0555], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0212, -0.0002,  0.0093, -0.0325,  0.0555], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0118,  0.0089, -0.0022, -0.0124,  0.0037], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0121, -0.0751, -0.0826, -0.1019, -0.0766], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-9.5766e-03, -1.0642e-02, -2.6350e+01, -6.4468e+02, -1.6547e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0393, 0.0657, 1.5877, 1.5056, 0.0808], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9962e-01, 9.9930e-01, 6.7705e-19, 0.0000e+00, 9.9866e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0212, -0.0002,  0.0093, -0.0325,  0.0555], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-9.7932e-06, -7.3773e-06,  1.7987e-06,  1.0303e-05, -3.0951e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0165, -0.0108,  0.0078,  0.0156,  0.0060], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0014, -0.0264, -0.0010, -0.0516, -0.0084], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0041, -0.0263, -0.0021, -0.0475, -0.0153], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0041, -0.0263, -0.0021, -0.0475, -0.0153], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0034,  0.0016, -0.0016,  0.0054, -0.0011], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0392], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([5.0475], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0683,  0.0284, -0.0294,  0.4419, -0.0056], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0683,  0.0284, -0.0294,  0.4419, -0.0056], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.6567,  0.3405, -1.0225,  0.0249,  1.0996], grad_fn=<SliceBackward0>)
  [Layer 31] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 31] Output sample values after mixer: tensor([-0.6567,  0.3405, -1.0225,  0.0249,  1.0996], grad_fn=<SliceBackward0>)
  [Layer 31] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 31] Residual connection sample values: tensor([ 2.1284, -4.7626, -4.0486, -5.1080, -4.0245], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 32/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([78.1105], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1131], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1126, -0.2465, -0.2081, -0.3149, -0.2160], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.7648, -0.7443, -0.6602,  0.4429, -1.0619], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.7648, -0.7443, -0.6602,  0.4429, -1.0619], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3560, -0.1574, -0.1267, -1.6046,  0.0597], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.0757, 0.2907, 1.4062, 0.4693, 0.3590], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.3214, -0.7309,  0.0156,  0.3560, -0.2636], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0193, -0.0328, -0.0028,  0.1293, -0.2015], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0056, -0.4007, -0.0049,  0.1058, -0.2138], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0028, -0.1607, -0.0024,  0.0557, -0.0955], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0028, -0.1607, -0.0024,  0.0557, -0.0955], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0157,  0.0876,  0.0272, -0.0714,  0.0055], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2738, -0.2144, -0.2785, -0.2024, -0.2300], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0662, -0.0811, -0.5879, -0.0956, -0.5448], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.0461, 1.2565, 1.1425, 1.1735, 0.7770], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9331, 0.9031, 0.5109, 0.8939, 0.6549], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0028, -0.1607, -0.0024,  0.0557, -0.0955], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-4.6215e-05,  2.5846e-04,  8.0156e-05, -2.1059e-04,  1.6243e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0132, 0.1146, 0.1278, 0.2388, 0.1444], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.4641, -1.3537,  0.2697,  1.2743, -0.4838], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.4640, -1.3501,  0.2698,  1.2731, -0.4816], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.4640, -1.3501,  0.2698,  1.2731, -0.4816], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1127,  0.3236, -0.0607,  0.3433,  0.1314], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([3.3844], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5436], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0690,  0.4302, -0.0804,  0.2851,  0.1229], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0690,  0.4302, -0.0804,  0.2851,  0.1229], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.2297,  3.1979,  0.7462, -2.5138,  3.2325], grad_fn=<SliceBackward0>)
  [Layer 32] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 32] Output sample values after mixer: tensor([-1.2297,  3.1979,  0.7462, -2.5138,  3.2325], grad_fn=<SliceBackward0>)
  [Layer 32] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 32] Residual connection sample values: tensor([ 0.8987, -1.5647, -3.3023, -7.6218, -0.7920], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 33/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([100.4555], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0998], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0431, -0.0733, -0.1575, -0.3839, -0.0384], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4847, -0.8358, -0.3723,  0.6560, -0.7861], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4847, -0.8358, -0.3723,  0.6560, -0.7861], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.7261,  0.1242,  0.6140, -0.3645, -0.2453], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.1648,  0.6146, -0.6931, -0.8244,  0.3561], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.9715, 1.6152, 0.2932, 1.7261, 1.4759], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4422,  0.0263,  0.0942, -0.1474, -0.0394], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1719, -0.0103,  0.0809, -0.2703, -0.0737], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0933, -0.0051,  0.0421, -0.1170, -0.0355], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0933, -0.0051,  0.0421, -0.1170, -0.0355], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.1333,  0.1221, -0.0035, -0.0284, -0.1889], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0509, -0.0668,  0.2260, -0.2382, -0.0883], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-13.0444,  -1.3850,  -0.1668,  -0.2359,  -5.2550],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0445, 0.0089, 0.0281, 0.0233, 0.0119], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5594, 0.9878, 0.9953, 0.9945, 0.9396], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0933, -0.0051,  0.0421, -0.1170, -0.0355], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.5421e-04,  5.0770e-04, -1.4684e-05, -1.1820e-04, -7.8522e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.0959e-04,  2.0452e-04, -7.9963e-05, -1.0023e-04, -5.5783e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 3.6235e-04, -9.3815e-04, -2.7034e-05,  2.8348e-04, -4.1368e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1003, -0.0064,  0.0450, -0.1250, -0.0384], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1003, -0.0064,  0.0450, -0.1250, -0.0384], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0185,  0.0016, -0.0068, -0.0540,  0.0095], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0597], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([4.0925], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2090,  0.0178, -0.1021, -0.6773,  0.1342], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2090,  0.0178, -0.1021, -0.6773,  0.1342], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-3.9242, -3.8216, -0.6302,  2.2967,  4.1260], grad_fn=<SliceBackward0>)
  [Layer 33] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 33] Output sample values after mixer: tensor([-3.9242, -3.8216, -0.6302,  2.2967,  4.1260], grad_fn=<SliceBackward0>)
  [Layer 33] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 33] Residual connection sample values: tensor([-3.0256, -5.3863, -3.9326, -5.3250,  3.3340], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 34/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([136.2281], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0857], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1101, -0.1930, -0.1487, -0.1965,  0.1239], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6139, -0.6209, -0.1137,  0.2945, -1.9235], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6139, -0.6209, -0.1137,  0.2945, -1.9235], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.5601, -1.7975, -0.0915,  1.6277, -0.6097], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.7447, -1.2159,  1.5329,  1.0657,  1.1684], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1197, -0.4561, -1.7558, -0.5601, -1.0826], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1591,  0.9333,  0.0371, -0.2830, -0.2466], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2024,  0.8361,  0.0031, -0.3641, -0.3206], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0910,  0.5833,  0.0016, -0.1493, -0.1348], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0910,  0.5833,  0.0016, -0.1493, -0.1348], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0304,  0.0115,  0.0373,  0.1296, -0.0115], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1706,  0.0130, -0.0725,  0.1638, -0.0455], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2225, -0.1537, -0.8169, -0.8591, -2.0730], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0023, 0.0021, 0.6852, 0.2656, 0.4809], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9995, 0.9997, 0.5714, 0.7960, 0.3690], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0910,  0.5833,  0.0016, -0.1493, -0.1348], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 6.3676e-06, -2.4035e-06, -7.8170e-06, -2.7160e-05,  2.4182e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0030,  0.0074,  0.0035, -0.0065,  0.0105], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0365,  0.1421,  0.0676, -0.0319, -0.0593], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2156,  1.2898,  0.0706, -0.3256, -0.3245], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2156,  1.2898,  0.0706, -0.3256, -0.3245], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0465, -0.2799, -0.0038, -0.0550,  0.0796], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1571], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.5228], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.3132, -1.0552, -0.0214, -0.3662,  0.5650], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.3132, -1.0552, -0.0214, -0.3662,  0.5650], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.8151, -1.4421, -0.6402, -3.1254,  1.2872], grad_fn=<SliceBackward0>)
  [Layer 34] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 34] Output sample values after mixer: tensor([ 0.8151, -1.4421, -0.6402, -3.1254,  1.2872], grad_fn=<SliceBackward0>)
  [Layer 34] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 34] Residual connection sample values: tensor([-2.2104, -6.8284, -4.5728, -8.4504,  4.6212], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 35/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([160.1691], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0790], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0981, -0.3006, -0.1999, -0.3997,  0.2038], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.1333, -0.7969, -0.8327, -2.0382, -1.6145], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.1333, -0.7969, -0.8327, -2.0382, -1.6145], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.1649,  1.2403, -0.7802,  0.5674, -0.8379], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.6067,  3.5714, -0.2884,  3.4464,  2.4896], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1723,  1.0363, -1.0327, -1.1649,  0.8958], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2270,  0.2980, -0.5544,  0.1427, -0.2109], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1756,  0.2763, -0.5818,  0.1179, -0.3231], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0955,  0.1571, -0.2086,  0.0624, -0.1357], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0955,  0.1571, -0.2086,  0.0624, -0.1357], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2511, -0.0769,  0.1784, -0.0160,  0.0097], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0525,  0.0278, -0.2712,  0.2111,  0.0488], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2054, -0.1417, -0.1071, -0.1460, -0.2581], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([4.1778, 5.7465, 0.7132, 5.7854, 2.8944], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4240, 0.4430, 0.9265, 0.4296, 0.4738], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0955,  0.1571, -0.2086,  0.0624, -0.1357], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.1001, -0.0307,  0.0711, -0.0064,  0.0039], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1276, -0.0348,  0.0915, -0.0399, -0.0264], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.4286,  0.8022, -1.1222,  0.2812, -0.7068], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.6786,  1.2136, -1.6684,  0.4446, -1.0621], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.6786,  1.2136, -1.6684,  0.4446, -1.0621], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1873, -0.3005,  0.4211, -0.1044,  0.2846], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([8.3863], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3453], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2460, -0.3826,  0.1854, -0.1982,  0.3131], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2460, -0.3826,  0.1854, -0.1982,  0.3131], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-2.2253, -0.1278,  0.5054,  2.3495,  4.4106], grad_fn=<SliceBackward0>)
  [Layer 35] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 35] Output sample values after mixer: tensor([-2.2253, -0.1278,  0.5054,  2.3495,  4.4106], grad_fn=<SliceBackward0>)
  [Layer 35] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 35] Residual connection sample values: tensor([-4.4357, -6.9562, -4.0673, -6.1009,  9.0318], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 36/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([229.6647], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0660], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1463, -0.2347, -0.1350, -0.2149,  0.3053], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.3836, -1.7472, -0.5183, -0.8279, -0.8418], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.3836, -1.7472, -0.5183, -0.8279, -0.8418], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.8936,  0.1060, -0.3926, -0.8825, -0.6955], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.8203, 1.4159, 1.9764, 0.9991, 1.5272], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4971,  1.1749,  0.9087, -1.8936,  1.6251], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.3570,  0.0069, -0.1111, -0.1921, -0.1132], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.3973, -0.1106, -0.1732, -0.3367, -0.1253], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.2376, -0.0523, -0.0791, -0.1403, -0.0587], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.2376, -0.0523, -0.0791, -0.1403, -0.0587], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0767, -0.0547, -0.1080,  0.0722, -0.0166], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0452, -0.0391, -0.2602,  0.0377, -0.1119], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.8655, -5.6378, -3.8976, -2.4260, -3.6937], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1523, 0.0687, 0.1241, 0.1041, 0.1095], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6463, 0.6787, 0.6164, 0.7768, 0.6673], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.2376, -0.0523, -0.0791, -0.1403, -0.0587], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0028, -0.0020, -0.0039,  0.0026, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0046, -0.0011, -0.0036,  0.0025,  0.0012], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0034,  0.0182, -0.0065, -0.0168, -0.0128], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.7253, -0.1421, -0.2491, -0.4470, -0.1929], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.7253, -0.1421, -0.2491, -0.4470, -0.1929], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.2012,  0.0368,  0.0482,  0.1125,  0.0489], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7285], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1716], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.4518,  0.1767,  0.1596,  0.3976,  0.1966], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.4518,  0.1767,  0.1596,  0.3976,  0.1966], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.8239, -5.5736,  0.8694, -1.7326,  6.0524], grad_fn=<SliceBackward0>)
  [Layer 36] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 36] Output sample values after mixer: tensor([ 1.8239, -5.5736,  0.8694, -1.7326,  6.0524], grad_fn=<SliceBackward0>)
  [Layer 36] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 36] Residual connection sample values: tensor([ -2.6118, -12.5298,  -3.1980,  -7.8334,  15.0842],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 37/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([301.8556], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0576], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0725, -0.3571, -0.0931, -0.2227,  0.4294], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2428, -0.5368, -0.2333, -1.4126,  1.1768], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2428, -0.5368, -0.2333, -1.4126,  1.1768], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.0615, -0.1669,  2.7630,  0.4083,  0.9075], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-1.0162, -1.1238,  1.5137, -1.7272, -0.4083], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1335, -0.5111, -0.1605, -0.0615,  1.0873], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0255,  0.0667, -0.8957, -0.0998,  0.4809], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0523,  0.0026, -0.9803, -0.0650,  0.3973], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0254,  0.0013, -0.2675, -0.0314,  0.2376], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0254,  0.0013, -0.2675, -0.0314,  0.2376], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0034, -0.2555, -0.0067, -0.2122, -0.0566], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0810, -0.2735, -0.1451, -0.2742, -0.2654], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.8179, -31.1699, -39.0195,  -0.4619,  -0.6477],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0002, 0.0024, 0.0151, 0.0001, 0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9996, 0.9292, 0.5548, 0.9999, 0.9993], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0254,  0.0013, -0.2675, -0.0314,  0.2376], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([2.0013e-08, 1.4865e-06, 3.8865e-08, 1.2344e-06, 3.2952e-07],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0004,  0.0004, -0.0006,  0.0009, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0013,  0.0051, -0.0117,  0.0078, -0.0045], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0453,  0.0075, -0.5016, -0.0498,  0.4307], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0453,  0.0075, -0.5016, -0.0498,  0.4307], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0048, -0.0015,  0.0517,  0.0138,  0.3874], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2416], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.0346], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0366, -0.0081,  0.2666,  0.1122,  1.6860], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0366, -0.0081,  0.2666,  0.1122,  1.6860], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5649, -1.8801, -1.7248,  3.8810, -1.9798], grad_fn=<SliceBackward0>)
  [Layer 37] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 37] Output sample values after mixer: tensor([-0.5649, -1.8801, -1.7248,  3.8810, -1.9798], grad_fn=<SliceBackward0>)
  [Layer 37] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 37] Residual connection sample values: tensor([ -3.1767, -14.4099,  -4.9227,  -3.9525,  13.1044],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 38/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([353.6731], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0532], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0866, -0.3928, -0.1336, -0.1044,  0.3596], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1726, -1.9971,  1.2591, -0.2495, -0.6823], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1726, -1.9971,  1.2591, -0.2495, -0.6823], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2220, -0.0540,  0.4189,  0.1004,  0.1181], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.2274,  0.5047, -0.4631,  0.0960,  0.7859], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5341,  0.8919,  0.4508, -0.2220, -1.0287], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0590, -0.9562,  0.0010, -0.1151, -0.1383], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0613, -1.2455, -0.0890, -0.1583, -0.0454], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0297, -0.2783, -0.0425, -0.0729, -0.0222], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0297, -0.2783, -0.0425, -0.0729, -0.0222], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0352, -0.2778,  0.0603, -0.0424, -0.0282], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2730, -0.0427, -0.2325, -0.2718, -0.1082], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1704, -2.0832, -0.1351, -0.4124, -3.5315], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6799, 0.1894, 0.4698, 0.3235, 0.2044], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8906, 0.6739, 0.9385, 0.8751, 0.4858], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0297, -0.2783, -0.0425, -0.0729, -0.0222], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0007,  0.0056, -0.0012,  0.0009,  0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0006,  0.1273, -0.0099, -0.0055,  0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2841, -0.2762, -0.2029, -0.1986,  0.4678], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2884, -0.3170, -0.2092, -0.2093,  0.4646], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2884, -0.3170, -0.2092, -0.2093,  0.4646], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0228,  0.0757, -0.2051,  0.0229, -0.1064], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6274], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2625], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0905,  0.2026, -0.6075,  0.1352, -0.4351], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0905,  0.2026, -0.6075,  0.1352, -0.4351], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 3.8633, -4.5410,  3.3818, -1.0674, -2.5525], grad_fn=<SliceBackward0>)
  [Layer 38] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 38] Output sample values after mixer: tensor([ 3.8633, -4.5410,  3.3818, -1.0674, -2.5525], grad_fn=<SliceBackward0>)
  [Layer 38] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 38] Residual connection sample values: tensor([  0.6866, -18.9509,  -1.5409,  -5.0199,  10.5519],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 39/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([512.2357], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0442], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0115, -0.3455, -0.0272, -0.0931,  0.1856], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.3673,  0.6534, -1.8985, -0.5924, -1.8171], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.3673,  0.6534, -1.8985, -0.5924, -1.8171], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1133,  0.2990, -0.4423,  1.2322,  0.0476], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.1078,  3.4342, -1.6118,  2.8522, -0.5394], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.8240, -1.2065,  0.2505, -0.1133,  0.7514], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0202, -0.0628, -0.0744,  0.3011, -0.0040], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0443, -0.1235, -0.0591,  0.8387, -0.0074], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0226, -0.0580, -0.0287,  0.5856, -0.0037], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0226, -0.0580, -0.0287,  0.5856, -0.0037], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0335, -0.0421, -0.1695,  0.0328,  0.0502], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2558, -0.2693,  0.0073, -0.1375, -0.2088], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.7351e+02, -2.3790e+00, -2.6079e-03, -1.4979e+00, -6.3307e-02],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.2654, 2.3605, 0.0585, 1.2033, 0.0052], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.0000, 0.0036, 0.9998, 0.1649, 0.9997], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0226, -0.0580, -0.0287,  0.5856, -0.0037], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0010, -0.0012, -0.0049,  0.0009,  0.0014], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0010, -0.0012, -0.0049,  0.0009,  0.0014], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0034, -0.0086, -0.0043,  0.0871, -0.0005], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1058, -0.2709, -0.1340,  2.7368, -0.0172], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1058, -0.2709, -0.1340,  2.7368, -0.0172], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0230, -0.1164,  0.0332, -0.5773,  0.0044], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6874], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2061], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1295, -0.6220,  0.1676, -2.8479,  0.0260], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1295, -0.6220,  0.1676, -2.8479,  0.0260], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-7.7980, -2.5300,  0.3436,  1.6069,  0.7056], grad_fn=<SliceBackward0>)
  [Layer 39] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 39] Output sample values after mixer: tensor([-7.7980, -2.5300,  0.3436,  1.6069,  0.7056], grad_fn=<SliceBackward0>)
  [Layer 39] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 39] Residual connection sample values: tensor([ -7.1114, -21.4809,  -1.1972,  -3.4129,  11.2575],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 40/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([635.4669], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0397], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1386, -0.4469, -0.0244, -0.0637,  0.2272], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 2.1494e+00, -1.2306e+00,  1.0636e+00, -1.6641e-03, -4.1856e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 2.1494e+00, -1.2306e+00,  1.0636e+00, -1.6641e-03, -4.1856e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-3.3809,  0.1379,  0.1356,  0.7907,  1.0394], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.6625,  0.9970,  0.9499, -1.2048,  1.8530], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8216, -0.1680, -2.0063, -3.3809,  0.6326], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.5114, -0.0179,  0.0311, -0.1746,  0.1801], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1801, -0.0664, -0.0405, -0.1862,  0.1816], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0820, -0.0321, -0.0199, -0.0844,  0.0990], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0820, -0.0321, -0.0199, -0.0844,  0.0990], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0401, -0.1385,  0.0295,  0.0619,  0.0062], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0932, -0.2541,  0.5344,  0.2045,  0.4099], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5267, -0.6301, -0.3878, -2.7909, -0.4284], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2299, 0.0347, 0.0701, 0.0018, 0.0985], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8860, 0.9784, 0.9732, 0.9949, 0.9587], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0820, -0.0321, -0.0199, -0.0844,  0.0990], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0008,  0.0026, -0.0006, -0.0012, -0.0001], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0016, -0.0319, -0.0063, -0.0005, -0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0018, -0.0138, -0.0168, -0.0113,  0.0039], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2048, -0.0933, -0.0659, -0.2204,  0.2491], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2048, -0.0933, -0.0659, -0.2204,  0.2491], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-3.9415e-01,  2.5949e-02, -5.2114e-02,  1.8321e-04, -4.1370e-02],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1689], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.4335], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-3.0761e+00,  2.3976e-01, -4.9018e-01,  1.3619e-03, -5.0651e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-3.0761e+00,  2.3976e-01, -4.9018e-01,  1.3619e-03, -5.0651e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.4809, -6.9940, -3.7097, -3.4778,  6.7274], grad_fn=<SliceBackward0>)
  [Layer 40] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 40] Output sample values after mixer: tensor([ 0.4809, -6.9940, -3.7097, -3.4778,  6.7274], grad_fn=<SliceBackward0>)
  [Layer 40] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 40] Residual connection sample values: tensor([ -6.6305, -28.4749,  -4.9070,  -6.8907,  17.9849],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 41/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([904.0792], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0333], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0770, -0.3537, -0.0588, -0.0791,  0.2094], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4484, -3.0908, -0.9330, -0.5432,  0.1999], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4484, -3.0908, -0.9330, -0.5432,  0.1999], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.4399,  0.4429, -0.1232,  0.5481, -0.4621], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 2.1289, -0.5246,  1.0661, -0.0379,  1.1491], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8642, -0.8012, -0.5914, -0.4399,  0.7782], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1198,  0.0212, -0.0268, -0.0972,  0.1012], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1514,  0.1436, -0.0267, -0.1899,  0.0917], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0700,  0.0769, -0.0132, -0.0860,  0.0479], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0700,  0.0769, -0.0132, -0.0860,  0.0479], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0359,  0.0935,  0.0447, -0.0206,  0.0287], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.6150, -0.1023, -0.0785, -0.0514, -0.2419], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.0531, -1.1356, -0.8719, -1.5713, -1.7431], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4815, 0.1293, 0.2726, 0.1218, 0.2385], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6023, 0.8635, 0.7885, 0.8258, 0.6599], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0700,  0.0769, -0.0132, -0.0860,  0.0479], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0012, -0.0032, -0.0015,  0.0007, -0.0010], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0003, -0.0080, -0.0070, -0.0001, -0.0050], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0143,  0.0086, -0.0022, -0.0178,  0.0061], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1038,  0.1070, -0.0191, -0.1277,  0.0675], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1038,  0.1070, -0.0191, -0.1277,  0.0675], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0284, -0.0144,  0.0050,  0.0255,  0.0074], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0173], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([7.6111], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.6922, -0.4678,  0.1414,  0.8702,  0.2350], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.6922, -0.4678,  0.1414,  0.8702,  0.2350], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.4953, -4.2766,  2.1727,  1.0731,  4.6859], grad_fn=<SliceBackward0>)
  [Layer 41] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 41] Output sample values after mixer: tensor([ 0.4953, -4.2766,  2.1727,  1.0731,  4.6859], grad_fn=<SliceBackward0>)
  [Layer 41] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 41] Residual connection sample values: tensor([ -6.1352, -32.7515,  -2.7343,  -5.8176,  22.6708],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 42/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1085.5507], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0304], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0671, -0.3847, -0.0320, -0.0635,  0.2607], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2355,  1.7600, -0.1421, -1.3801, -0.6447], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2355,  1.7600, -0.1421, -1.3801, -0.6447], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2839,  2.3854, -1.0463, -0.6014, -0.3441], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.2199, -0.8392, -0.1508, -0.8563,  1.2950], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.0213, -0.8487,  0.0918, -0.2839,  0.7890], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0576,  0.5033,  0.2276,  0.1193, -0.0983], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0367,  0.4675,  0.2322,  0.1156, -0.1444], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0187,  0.2874,  0.1295,  0.0611, -0.0670], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0187,  0.2874,  0.1295,  0.0611, -0.0670], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0864,  0.0110, -0.0768, -0.0242,  0.0134], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.0545, -0.1964, -0.0301, -0.2416, -0.2568], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.2458, -1.7474, -3.3797, -1.2264, -1.3705], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3146, 0.0584, 0.1127, 0.0089, 0.2577], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4933, 0.9030, 0.6833, 0.9892, 0.7025], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0187,  0.2874,  0.1295,  0.0611, -0.0670], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.0839e-04,  6.4803e-05, -4.5183e-04, -1.4224e-04,  7.8767e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0005, -0.0001, -0.0001, -0.0002, -0.0003], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0027,  0.1436,  0.0597,  0.0225, -0.0280], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0283,  0.5365,  0.2368,  0.1060, -0.1196], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0283,  0.5365,  0.2368,  0.1060, -0.1196], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0037,  0.8057, -0.0156, -0.0294,  0.0265], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0222], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.7162], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0980, 20.3984, -0.4073, -0.7767,  0.4772], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0980, 20.3984, -0.4073, -0.7767,  0.4772], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0769, -6.5762,  6.7138, -1.0284, -3.9958], grad_fn=<SliceBackward0>)
  [Layer 42] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 42] Output sample values after mixer: tensor([-0.0769, -6.5762,  6.7138, -1.0284, -3.9958], grad_fn=<SliceBackward0>)
  [Layer 42] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 42] Residual connection sample values: tensor([ -6.2121, -39.3277,   3.9795,  -6.8460,  18.6749],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 43/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1219.9034], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0286], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0628, -0.4354,  0.0422, -0.0692,  0.1920], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.3754, -0.9385, -0.5854,  0.0509, -1.2989], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.3754, -0.9385, -0.5854,  0.0509, -1.2989], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 0.3107,  0.0925,  1.0227, -0.6897, -0.3924], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.1514, -0.1300, -0.6619,  0.7710, -0.6253], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2589, -0.9998,  0.5369,  0.3107, -0.2500], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0699, -0.0131, -0.2154, -0.1270, -0.0709], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0553, -0.0673, -0.2434, -0.1749, -0.0792], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0284, -0.0325, -0.1070, -0.0798, -0.0380], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0284, -0.0325, -0.1070, -0.0798, -0.0380], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0016, -0.0228,  0.0421, -0.1595,  0.1535], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1603, -0.0639, -0.2058, -0.2453,  0.0524], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.7046, -2.6553, -8.2110, -2.2382, -4.0926], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1831, 0.0700, 0.0328, 0.6520, 0.0007], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5074, 0.8304, 0.7641, 0.2324, 0.9972], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0284, -0.0325, -0.1070, -0.0798, -0.0380], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 8.5415e-06, -1.1886e-04,  2.1937e-04, -8.3051e-04,  7.9936e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0019, -0.0002, -0.0010,  0.0025, -0.0020], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0005, -0.0041, -0.0077, -0.0056, -0.0025], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0464, -0.0577, -0.1841, -0.1372, -0.0653], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0464, -0.0577, -0.1841, -0.1372, -0.0653], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0103,  0.0152,  0.0385, -0.0036,  0.0182], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0111], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([9.4852], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.2533,  0.5007,  1.0141, -0.0949,  0.4977], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.2533,  0.5007,  1.0141, -0.0949,  0.4977], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 3.1840, -2.8764, -2.9636, -2.1661, -9.8797], grad_fn=<SliceBackward0>)
  [Layer 43] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 43] Output sample values after mixer: tensor([ 3.1840, -2.8764, -2.9636, -2.1661, -9.8797], grad_fn=<SliceBackward0>)
  [Layer 43] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 43] Residual connection sample values: tensor([ -3.0281, -42.2040,   1.0160,  -9.0121,   8.7952],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 44/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1365.8842], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0271], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0293, -0.4227,  0.0102, -0.0853,  0.0862], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.7298,  0.7096, -0.4028, -1.1212,  0.8368], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.7298,  0.7096, -0.4028, -1.1212,  0.8368], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.2039, -0.6863, -0.1830, -0.3834, -0.2312], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 0.0645, -0.2875, -0.1644,  1.2316, -0.4826], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.6244, -1.0672, -0.8355, -0.2039,  0.0391], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0439,  0.1468, -0.0246,  0.0680, -0.0444], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0224,  0.0898, -0.0534,  0.0548, -0.0378], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0111,  0.0469, -0.0260,  0.0282, -0.0185], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0111,  0.0469, -0.0260,  0.0282, -0.0185], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0290, -0.2268, -0.2741,  0.0342,  0.0626], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([ 0.1928, -0.2561, -0.1676, -0.0560, -0.1320], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-4.6876, -0.9753, -0.8255, -1.2938, -0.4953], grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1056, 0.0335, 0.0209, 0.1476, 0.0048], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6097, 0.9679, 0.9829, 0.8262, 0.9976], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0111,  0.0469, -0.0260,  0.0282, -0.0185], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 3.3897e-05,  2.6524e-04,  3.2054e-04, -3.9993e-05, -7.3170e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 2.5350e-05,  3.8487e-03,  4.1809e-03, -7.2404e-04, -7.0003e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0029,  0.0030, -0.0024,  0.0017, -0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0222,  0.0845, -0.0476,  0.0507, -0.0335], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0222,  0.0845, -0.0476,  0.0507, -0.0335], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0109,  0.0402,  0.0077, -0.0140, -0.0196], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0129], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([8.8081], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.3101,  1.0453,  0.2529, -0.3954, -0.5431], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.3101,  1.0453,  0.2529, -0.3954, -0.5431], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ -4.4245,   0.9444,   0.9416,   8.9287, -12.1975],
       grad_fn=<SliceBackward0>)
  [Layer 44] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 44] Output sample values after mixer: tensor([ -4.4245,   0.9444,   0.9416,   8.9287, -12.1975],
       grad_fn=<SliceBackward0>)
  [Layer 44] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 44] Residual connection sample values: tensor([ -7.4526, -41.2597,   1.9575,  -0.0834,  -3.4024],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 45/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1483.7743], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0260], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0830, -0.4963,  0.0229, -0.0009, -0.0384], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.7567, -0.4374, -0.1269, -0.7595, -0.1054], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.7567, -0.4374, -0.1269, -0.7595, -0.1054], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1622,  0.2833,  0.6873, -0.4572,  0.2806], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([ 1.0754, -0.5204,  0.5994,  0.2403, -0.1947], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.3617,  0.1007, -0.8807, -0.1622,  0.9198], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0347,  0.0327,  0.1321,  0.1004,  0.0440], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0404,  0.2908,  0.1098,  0.0444,  0.0332], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0198,  0.1664,  0.0579,  0.0227,  0.0169], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0198,  0.1664,  0.0579,  0.0227,  0.0169], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([ 0.0623,  0.2470, -0.1107, -0.2784,  0.0130], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.2336, -0.0682, -0.1533,  0.0517, -0.2420], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3039e+00, -3.9385e-02, -6.8874e+00, -8.0559e-01, -1.9935e+03],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0065, 0.0111, 0.0140, 0.0008, 0.0158], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9157e-01, 9.9956e-01, 9.0793e-01, 9.9936e-01, 2.2369e-14],
       grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0198,  0.1664,  0.0579,  0.0227,  0.0169], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-7.9920e-06, -3.1697e-05,  1.4207e-05,  3.5731e-05, -1.6749e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0017, 0.0009, 0.0013, 0.0003, 0.0016], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0011,  0.0348, -0.0045, -0.0090,  0.0068], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0524,  0.4666,  0.1458,  0.0500,  0.0507], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0524,  0.4666,  0.1458,  0.0500,  0.0507], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0127, -0.0801, -0.0087, -0.0121, -0.0025], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0742], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.6718], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1805, -0.8557, -0.1106, -0.1461, -0.0367], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1805, -0.8557, -0.1106, -0.1461, -0.0367], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.4044, -6.1449,  0.8858,  3.1265, -4.2628], grad_fn=<SliceBackward0>)
  [Layer 45] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 45] Output sample values after mixer: tensor([-1.4044, -6.1449,  0.8858,  3.1265, -4.2628], grad_fn=<SliceBackward0>)
  [Layer 45] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 45] Residual connection sample values: tensor([ -8.8569, -47.4045,   2.8433,   3.0431,  -7.6652],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 46/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1610.0995], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0249], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0899, -0.5177,  0.0304,  0.0315, -0.0770], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5410, -0.9056,  0.4325, -0.9271,  0.3927], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5410, -0.9056,  0.4325, -0.9271,  0.3927], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([ 1.4707,  0.5736, -1.1778,  0.0734,  1.1004], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.5299, 1.2690, 0.3824, 0.4054, 1.4986], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.8542,  0.2080,  1.3816,  1.4707, -0.6489], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0112, -0.1048, -0.2288, -0.0108, -0.1796], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0443, -0.1421, -0.0260, -0.0063, -0.1849], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0226, -0.0660, -0.0128, -0.0031, -0.0839], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0226, -0.0660, -0.0128, -0.0031, -0.0839], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.2260, -0.0469, -0.0530, -0.0656,  0.0102], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([0.0729, 0.0391, 0.0524, 0.0636, 0.1030], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.4426,  -0.9830, -10.1590,  -1.3638,  -1.7559],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0149, 0.0487, 0.0016, 0.0195, 0.0478], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9788, 0.9532, 0.9839, 0.9737, 0.9195], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0226, -0.0660, -0.0128, -0.0031, -0.0839], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-7.6099e-05, -1.5778e-05, -1.7834e-05, -2.2076e-05,  3.4397e-06],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.6900e-03,  1.9928e-04, -2.7760e-05,  7.1381e-04, -8.7763e-04],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0032, -0.0020,  0.0079, -0.0013, -0.0064], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0309, -0.0829, -0.0077, -0.0051, -0.1092], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0309, -0.0829, -0.0077, -0.0051, -0.1092], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0061,  0.0216, -0.0020,  0.0013, -0.0256], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0114], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([9.3574], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2557,  0.8356, -0.0670,  0.0436, -0.8354], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2557,  0.8356, -0.0670,  0.0436, -0.8354], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([10.9393, -3.4984, -2.9887, -6.1585, -4.7171], grad_fn=<SliceBackward0>)
  [Layer 46] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 46] Output sample values after mixer: tensor([10.9393, -3.4984, -2.9887, -6.1585, -4.7171], grad_fn=<SliceBackward0>)
  [Layer 46] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 46] Residual connection sample values: tensor([  2.0824, -50.9029,  -0.1453,  -3.1153, -12.3822],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 47/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1819.2990], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0234], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0179, -0.4560, -0.0013, -0.0253, -0.1065], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0658,  0.1005, -0.6491, -0.8004,  0.4084], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0658,  0.1005, -0.6491, -0.8004,  0.4084], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-1.1328,  0.4746,  0.2089, -0.5371, -0.1719], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([0.8575, 1.6546, 1.0546, 1.0296, 2.0684], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.7600, -0.5188, -1.1000, -1.1328,  0.4322], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2686,  0.0756,  0.0406,  0.0944, -0.0255], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2557,  0.0907,  0.0395,  0.1012, -0.0274], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1441,  0.0474,  0.0201,  0.0531, -0.0135], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1441,  0.0474,  0.0201,  0.0531, -0.0135], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0234, -0.0205,  0.0074, -0.0340, -0.2235], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.1536, -0.2555, -0.0487, -0.2491, -0.2736], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-5.7667e+01, -2.2024e+00, -3.8371e+00, -4.6046e-02, -2.0700e+00],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1059, 0.0230, 0.0367, 0.0489, 0.0318], grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.0022, 0.9505, 0.8685, 0.9978, 0.9363], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1441,  0.0474,  0.0201,  0.0531, -0.0135], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0004, -0.0003,  0.0001, -0.0005, -0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0003, -0.0003,  0.0001, -0.0005, -0.0034], grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0065,  0.0021,  0.0009,  0.0024, -0.0006], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2336,  0.0768,  0.0326,  0.0861, -0.0219], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2336,  0.0768,  0.0326,  0.0861, -0.0219], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0074,  0.0041, -0.0073, -0.0214, -0.0054], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0101], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([9.9233], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2517,  0.1520, -0.2495, -1.0512, -0.2133], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2517,  0.1520, -0.2495, -1.0512, -0.2133], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-10.6626,  17.5719,  -3.1891,  -7.4086,   4.8374],
       grad_fn=<SliceBackward0>)
  [Layer 47] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 47] Output sample values after mixer: tensor([-10.6626,  17.5719,  -3.1891,  -7.4086,   4.8374],
       grad_fn=<SliceBackward0>)
  [Layer 47] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 47] Residual connection sample values: tensor([ -8.5802, -33.3311,  -3.3344, -10.5239,  -7.5448],
       grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Processing layer 48/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2457.3340], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0202], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0632, -0.2648, -0.0262, -0.0756, -0.0575], grad_fn=<SliceBackward0>)
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1146, -1.0120, -0.6256,  0.0671, -0.5396], grad_fn=<SliceBackward0>)
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1146, -1.0120, -0.6256,  0.0671, -0.5396], grad_fn=<SliceBackward0>)
  [Mamba2] xBC (step) sample values: tensor([-0.1618, -0.3667, -0.6310, -0.5076, -1.9141], grad_fn=<SliceBackward0>)
  [Mamba2] dt (step) sample values: tensor([-0.6201, -3.7753,  0.7838, -0.0147,  0.9811], grad_fn=<SliceBackward0>)
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5649,  0.0768, -0.9858, -0.1618,  0.6336], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0316, -0.0541, -0.0710, -0.0594, -0.3039], grad_fn=<SliceBackward0>)
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0356, -0.0846, -0.0830, -0.1394, -0.3862], grad_fn=<SliceBackward0>)
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0181, -0.0405, -0.0398, -0.0649, -0.1563], grad_fn=<SliceBackward0>)
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0181, -0.0405, -0.0398, -0.0649, -0.1563], grad_fn=<SliceBackward0>)
  [Mamba2] B (step) sample values: tensor([-0.0958, -0.0528, -0.2783,  0.1808,  0.0011], grad_fn=<SliceBackward0>)
  [Mamba2] C (step) sample values: tensor([-0.0067, -0.0747, -0.2042, -0.0991, -0.0169], grad_fn=<SliceBackward0>)
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.7304,  -7.3891,  -3.3797,  -1.8028, -17.7601],
       grad_fn=<SliceBackward0>)
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([6.1940e-03, 4.9280e-06, 1.3981e-02, 1.9030e-02, 2.3560e-01],
       grad_fn=<SliceBackward0>)
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9893, 1.0000, 0.9538, 0.9663, 0.0152], grad_fn=<SliceBackward0>)
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0181, -0.0405, -0.0398, -0.0649, -0.1563], grad_fn=<SliceBackward0>)
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.0742e-05, -5.9207e-06, -3.1194e-05,  2.0268e-05,  1.2758e-07],
       grad_fn=<SliceBackward0>)
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.9035e-04,  4.5891e-04,  5.7687e-04, -1.4586e-04, -4.0730e-05],
       grad_fn=<SliceBackward0>)
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0002,  0.0007, -0.0006, -0.0020, -0.0013], grad_fn=<SliceBackward0>)
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0256, -0.0569, -0.0571, -0.0943, -0.2235], grad_fn=<SliceBackward0>)
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0256, -0.0569, -0.0571, -0.0943, -0.2235], grad_fn=<SliceBackward0>)
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0015,  0.0154,  0.0125, -0.0033,  0.0444], grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0038], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([16.2841], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0894,  0.9939,  0.7630, -0.1761,  3.2611], grad_fn=<SliceBackward0>)
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0894,  0.9939,  0.7630, -0.1761,  3.2611], grad_fn=<SliceBackward0>)
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([  2.5523, -19.6832,   4.7013,  14.1282,  30.5257],
       grad_fn=<SliceBackward0>)
  [Layer 48] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 48] Output sample values after mixer: tensor([  2.5523, -19.6832,   4.7013,  14.1282,  30.5257],
       grad_fn=<SliceBackward0>)
  [Layer 48] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 48] Residual connection sample values: tensor([ -6.0280, -53.0143,   1.3669,   3.6043,  22.9809],
       grad_fn=<SliceBackward0>)
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4231.6455], grad_fn=<SliceBackward0>)
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0154], grad_fn=<SliceBackward0>)
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0948, -1.2049,  0.0246,  0.0512,  0.3719], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Final backbone norm output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Final backbone norm output sample values: tensor([-0.0948, -1.2049,  0.0246,  0.0512,  0.3719], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Logits shape: torch.Size([1, 1, 50288])
[Mamba2LMHeadModel] Logits sample values: tensor([22.4723, 14.8861, 21.3294, 18.5393, 18.9128], grad_fn=<SliceBackward0>)
[Mamba2LMHeadModel] Forward pass input_ids shape: torch.Size([1, 1])
[Mamba2LMHeadModel] input_ids sample values: tensor([209])
[Mamba2LMHeadModel] Embedding output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Embedding sample values: tensor([ 0.0219,  0.1156, -0.1829,  0.0668,  0.0504])
[Mamba2LMHeadModel] Processing layer 1/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0525])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([4.3644])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0229,  0.1541, -0.2100,  0.0598,  0.0494])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2445,  0.4942,  0.1522, -0.3012, -0.5489])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2445,  0.4942,  0.1522, -0.3012, -0.5489])
  [Mamba2] xBC (step) sample values: tensor([ 0.4554, -0.3516, -0.1342,  0.2267,  0.1820])
  [Mamba2] dt (step) sample values: tensor([0.3152, 0.2469, 0.2560, 0.2712, 0.0334])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0886,  0.0774,  0.6464,  0.4554, -0.3855])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0741,  0.5511,  0.0841, -0.1034, -0.1066])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1166,  0.5435,  0.1968, -0.3129, -0.3037])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0617,  0.3438,  0.1081, -0.1322, -0.1290])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0617,  0.3438,  0.1081, -0.1322, -0.1290])
  [Mamba2] B (step) sample values: tensor([-0.2292, -0.0262, -0.0361,  0.6450, -0.0134])
  [Mamba2] C (step) sample values: tensor([-0.2634, -0.0039, -0.1555, -0.1224,  0.0391])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4384, -1.0011, -1.2129, -1.1530, -1.4844])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0756, 0.0432, 0.0313, 0.0341, 0.0232])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9674, 0.9577, 0.9627, 0.9615, 0.9661])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0617,  0.3438,  0.1081, -0.1322, -0.1290])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.0693e-03, -1.2207e-04, -1.6854e-04,  3.0092e-03, -6.2297e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0198, -0.0040, -0.0009,  0.0490, -0.0007])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0731,  0.0378,  0.1525, -0.2449, -0.1932])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1790,  0.6274,  0.3379, -0.4716, -0.4144])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1790,  0.6274,  0.3379, -0.4716, -0.4144])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0192,  0.1926,  0.0277,  0.0604,  0.0833])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7438])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1595])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0199,  0.1649,  0.0237,  0.0424,  0.2991])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0199,  0.1649,  0.0237,  0.0424,  0.2991])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1277, -0.0113,  0.4722, -0.1883, -0.1772])
  [Layer 1] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 1] Output sample values after mixer: tensor([ 0.1277, -0.0113,  0.4722, -0.1883, -0.1772])
  [Layer 1] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 1] Residual connection sample values: tensor([ 0.1495,  0.1043,  0.2893, -0.1214, -0.1268])
[Mamba2LMHeadModel] Processing layer 2/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2630])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9499])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1684,  0.0987,  0.2526, -0.1438, -0.1300])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.3108, -0.7517, -0.8902,  2.8219, -0.2188])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.3108, -0.7517, -0.8902,  2.8219, -0.2188])
  [Mamba2] xBC (step) sample values: tensor([ 0.5476, -0.9346,  1.3485, -1.2895, -0.3273])
  [Mamba2] dt (step) sample values: tensor([ 2.5755, -0.9517, -0.8664,  2.4941,  2.2597])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.8233, -0.5496,  0.0691,  0.5476,  0.4484])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0239,  0.0185, -0.1549, -0.0480, -0.0431])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0146, -0.0114, -0.2667, -0.1921, -0.0397])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0074, -0.0057, -0.1157, -0.0868, -0.0195])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0074, -0.0057, -0.1157, -0.0868, -0.0195])
  [Mamba2] B (step) sample values: tensor([ 0.0859, -0.0069, -0.0084, -0.0464,  0.0367])
  [Mamba2] C (step) sample values: tensor([-0.1209,  0.0300,  0.2479,  0.2003, -0.1031])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-12.6926, -19.4296,  -0.2289,  -2.1057,  -5.0389])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5181, 0.0136, 0.0104, 0.5785, 0.4439])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.0014, 0.7671, 0.9976, 0.2958, 0.1068])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0074, -0.0057, -0.1157, -0.0868, -0.0195])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 3.2771e-04, -2.6414e-05, -3.2089e-05, -1.7702e-04,  1.4018e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 3.2774e-04, -2.5634e-05, -3.1454e-05, -1.7768e-04,  1.3999e-04])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0007,  0.0005,  0.0108,  0.0081,  0.0018])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0042, -0.0033, -0.0664, -0.0498, -0.0112])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0042, -0.0033, -0.0664, -0.0498, -0.0112])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0044,  0.0008,  0.0172, -0.1326,  0.0011])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([13.7061])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2701])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0022,  0.0006,  0.0112, -0.0571,  0.0008])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0022,  0.0006,  0.0112, -0.0571,  0.0008])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5422, -0.8659,  0.6901,  0.5344,  0.0078])
  [Layer 2] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 2] Output sample values after mixer: tensor([-0.5422, -0.8659,  0.6901,  0.5344,  0.0078])
  [Layer 2] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 2] Residual connection sample values: tensor([-0.3927, -0.7616,  0.9794,  0.4129, -0.1190])
[Mamba2LMHeadModel] Processing layer 3/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7035])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1923])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4064, -0.6616,  0.7578,  0.4575, -0.1176])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.4015, -0.3827, -2.4750, -0.7951, -2.8887])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.4015, -0.3827, -2.4750, -0.7951, -2.8887])
  [Mamba2] xBC (step) sample values: tensor([ 1.6465, -0.8986,  1.8588, -0.3547,  1.9695])
  [Mamba2] dt (step) sample values: tensor([ 2.2326,  1.4432, -0.5031,  0.6421,  0.5426])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5941,  0.3079, -0.2860,  1.6465, -0.7755])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2250, -0.0320,  0.4703, -0.0909,  0.0691])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1801, -0.1098,  0.4192, -0.1375,  0.0023])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0982, -0.0519,  0.2529, -0.0640,  0.0012])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0982, -0.0519,  0.2529, -0.0640,  0.0012])
  [Mamba2] B (step) sample values: tensor([-0.0742, -0.1738, -0.0131,  0.1917, -0.2766])
  [Mamba2] C (step) sample values: tensor([-0.2415,  0.8068,  0.6869,  0.7600,  0.5372])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-20.9265,  -0.8803,  -0.6735,  -0.6461,  -0.2726])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.1139e-01, 2.0342e-02, 2.7236e-05, 9.9235e-03, 1.7659e-02])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.0972, 0.9823, 1.0000, 0.9936, 0.9952])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0982, -0.0519,  0.2529, -0.0640,  0.0012])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0008, -0.0019, -0.0001,  0.0021, -0.0030])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0008, -0.0019, -0.0002,  0.0021, -0.0030])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0306,  0.0163, -0.0788,  0.0199, -0.0005])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0391, -0.0206,  0.1007, -0.0256,  0.0003])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0391, -0.0206,  0.1007, -0.0256,  0.0003])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-7.7956e-03,  3.1900e-03, -1.9355e-02,  6.3225e-03, -5.1239e-05])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([33.6081])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1725])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-2.4110e-03,  8.8020e-04, -4.2190e-03,  1.5337e-03, -1.8471e-05])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-2.4110e-03,  8.8020e-04, -4.2190e-03,  1.5337e-03, -1.8471e-05])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2187, -0.1101, -0.0895,  0.5004, -0.0768])
  [Layer 3] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 3] Output sample values after mixer: tensor([-0.2187, -0.1101, -0.0895,  0.5004, -0.0768])
  [Layer 3] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 3] Residual connection sample values: tensor([-0.6113, -0.8717,  0.8900,  0.9133, -0.1958])
[Mamba2LMHeadModel] Processing layer 4/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.8380])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0924])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.3919, -0.4840,  0.4652,  0.6226, -0.1181])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1451,  0.1264,  0.1978, -0.2885,  0.8929])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1451,  0.1264,  0.1978, -0.2885,  0.8929])
  [Mamba2] xBC (step) sample values: tensor([-0.2234,  0.0674, -0.2140, -0.5467,  1.6087])
  [Mamba2] dt (step) sample values: tensor([0.5959, 1.1689, 1.4058, 0.7957, 0.7137])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1960, -0.5310, -1.0433, -0.2234,  1.8550])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1334,  0.0374,  0.0333, -0.5369,  0.2123])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1554,  0.0500, -0.0071, -0.6016,  0.4714])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0837,  0.0256, -0.0035, -0.2130,  0.2902])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0837,  0.0256, -0.0035, -0.2130,  0.2902])
  [Mamba2] B (step) sample values: tensor([-0.2752,  0.0738,  0.0332,  0.0025, -0.0802])
  [Mamba2] C (step) sample values: tensor([-0.2707, -0.2329,  0.3385, -0.0170,  0.2639])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4907, -0.5048, -0.6491, -0.5552, -0.4657])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0801, 0.1729, 0.3038, 0.0856, 0.5866])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9615, 0.9164, 0.8210, 0.9536, 0.7609])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0837,  0.0256, -0.0035, -0.2130,  0.2902])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.8459e-03,  4.9534e-04,  2.2275e-04,  1.6628e-05, -5.3773e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0331, -0.0021,  0.0006,  0.0024, -0.0012])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0887,  0.0150,  0.0151, -0.2541,  0.3755])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1443,  0.0320,  0.0128, -0.3954,  0.5680])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1443,  0.0320,  0.0128, -0.3954,  0.5680])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0112, 0.0021, 0.0014, 0.0489, 0.3598])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([28.8709])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1861])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0063, 0.0013, 0.0007, 0.0271, 0.1450])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0063, 0.0013, 0.0007, 0.0271, 0.1450])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0420,  0.0021,  0.0507,  0.2056, -0.0813])
  [Layer 4] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 4] Output sample values after mixer: tensor([ 0.0420,  0.0021,  0.0507,  0.2056, -0.0813])
  [Layer 4] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 4] Residual connection sample values: tensor([-0.5693, -0.8696,  0.9407,  1.1189, -0.2771])
[Mamba2LMHeadModel] Processing layer 5/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.9100])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0483])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.4939, -0.6360,  0.6014,  0.9679, -0.2280])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.5084,  0.4365, -3.8224,  1.3467, -1.9396])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.5084,  0.4365, -3.8224,  1.3467, -1.9396])
  [Mamba2] xBC (step) sample values: tensor([-0.3890,  1.4952, -0.6022,  1.1399,  1.2343])
  [Mamba2] dt (step) sample values: tensor([0.8079, 1.6373, 1.5226, 1.6416, 2.2251])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.9134, -0.0104, -1.2362, -0.3890, -2.2761])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6321, -0.5727, -0.3705, -0.1817, -0.2850])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.6954, -0.8140, -0.3779, -0.1548, -0.2740])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2315, -0.2499, -0.1537, -0.0714, -0.1184])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2315, -0.2499, -0.1537, -0.0714, -0.1184])
  [Mamba2] B (step) sample values: tensor([ 0.0690,  0.0674, -0.1764, -0.0508,  0.0193])
  [Mamba2] C (step) sample values: tensor([-0.0224,  0.0294, -0.2751, -0.2733,  0.0271])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0759, -0.5319, -0.0470, -1.4939, -3.6258])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3240, 0.0700, 0.1587, 0.0705, 0.1409])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9757, 0.9635, 0.9926, 0.9000, 0.5999])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2315, -0.2499, -0.1537, -0.0714, -0.1184])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0052, -0.0051,  0.0132,  0.0038, -0.0014])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0169, -0.0097,  0.5117,  0.0496,  0.0069])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-1.6800, -2.1425, -1.3845, -0.6084, -0.6012])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-2.0057, -2.4942, -1.6007, -0.7089, -0.7678])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-2.0057, -2.4942, -1.6007, -0.7089, -0.7678])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-2.4773, -0.6614,  0.1310, -0.7576,  0.1872])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([64.0565])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1249])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1023, -0.0289,  0.0117, -0.0744,  0.0200])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1023, -0.0289,  0.0117, -0.0744,  0.0200])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1960, -0.4586,  0.2504,  0.4182,  0.5907])
  [Layer 5] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 5] Output sample values after mixer: tensor([-0.1960, -0.4586,  0.2504,  0.4182,  0.5907])
  [Layer 5] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 5] Residual connection sample values: tensor([-0.7653, -1.3281,  1.1911,  1.5371,  0.3137])
[Mamba2LMHeadModel] Processing layer 6/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.1714])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9240])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.5182, -0.7430,  0.6287,  0.9979,  0.1898])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6263,  1.4148, -0.9885, -1.3619, -1.1807])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6263,  1.4148, -0.9885, -1.3619, -1.1807])
  [Mamba2] xBC (step) sample values: tensor([ 0.8282, -0.6492, -0.7342,  1.4676,  0.2964])
  [Mamba2] dt (step) sample values: tensor([1.1221, 1.2026, 2.0815, 1.0934, 1.4945])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0604, -0.7968,  0.8933,  0.8282,  2.1113])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1612, -0.0905, -0.2904, -0.0886, -0.0577])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2084, -0.0765, -0.2091, -0.1003,  0.0804])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0934, -0.0368, -0.0937, -0.0476,  0.0418])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0934, -0.0368, -0.0937, -0.0476,  0.0418])
  [Mamba2] B (step) sample values: tensor([ 0.1271,  0.0524, -0.2772, -0.0432, -0.1010])
  [Mamba2] C (step) sample values: tensor([ 0.0591,  0.0459, -0.2739,  0.1433, -0.0316])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5110, -0.2862, -0.5421, -0.3954, -0.5986])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4028, 0.3437, 0.5158, 0.3674, 0.3680])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8140, 0.9063, 0.7561, 0.8648, 0.8023])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0934, -0.0368, -0.0937, -0.0476,  0.0418])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0048, -0.0020,  0.0104,  0.0016,  0.0038])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0085, -0.0074,  0.0155,  0.0054,  0.0075])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0351,  0.0094, -0.0716, -0.0159,  0.1501])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1423, -0.0328, -0.1791, -0.0705,  0.1981])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1423, -0.0328, -0.1791, -0.0705,  0.1981])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0310, -0.0374,  0.0480,  0.0196, -0.0550])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([74.3428])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1160])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0105, -0.0120,  0.0147,  0.0074, -0.0151])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0105, -0.0120,  0.0147,  0.0074, -0.0151])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0883,  0.0864,  0.0183,  0.0814,  0.0636])
  [Layer 6] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 6] Output sample values after mixer: tensor([-0.0883,  0.0864,  0.0183,  0.0814,  0.0636])
  [Layer 6] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 6] Residual connection sample values: tensor([-0.8536, -1.2418,  1.2094,  1.6184,  0.3772])
[Mamba2LMHeadModel] Processing layer 7/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1.2360])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.8995])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.5590, -0.6604,  0.6246,  1.0697,  0.2142])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.2388, -2.3889, -1.6964, -1.6090, -1.1193])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.2388, -2.3889, -1.6964, -1.6090, -1.1193])
  [Mamba2] xBC (step) sample values: tensor([-0.2596, -1.3251, -2.1675, -0.4228, -1.1059])
  [Mamba2] dt (step) sample values: tensor([0.2701, 3.2303, 4.7776, 0.9830, 0.1138])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3541, -1.0369, -2.6750, -0.2596, -1.3051])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1610, -0.2601, -0.4364, -0.0574, -0.1659])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1946, -0.3313, -0.5674, -0.0489, -0.1686])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0879, -0.1385, -0.2053, -0.0239, -0.0772])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0879, -0.1385, -0.2053, -0.0239, -0.0772])
  [Mamba2] B (step) sample values: tensor([-0.0930, -0.1092,  0.1025,  0.0745, -0.0923])
  [Mamba2] C (step) sample values: tensor([ 0.0186,  0.1329,  0.0177,  0.0157, -0.0545])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-6.5957e-02, -4.5478e+00, -5.8281e+00, -4.2034e-01, -1.9005e-03])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6127, 0.6162, 1.6857, 0.3362, 0.2143])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.6039e-01, 6.0667e-02, 5.4120e-05, 8.6823e-01, 9.9959e-01])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0879, -0.1385, -0.2053, -0.0239, -0.0772])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0050,  0.0059, -0.0055, -0.0040,  0.0050])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0961,  0.0079, -0.0116,  0.0124,  0.0520])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1904, -0.0463, -0.2477,  0.1718, -0.0305])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3941, -0.3673, -0.7237,  0.1165, -0.2096])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3941, -0.3673, -0.7237,  0.1165, -0.2096])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.3786,  0.0737,  0.1902, -0.0312,  0.0577])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([15.0187])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2580])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1167,  0.0274,  0.0424, -0.0084,  0.0341])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1167,  0.0274,  0.0424, -0.0084,  0.0341])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.6464,  0.0960,  0.2781,  0.3375, -0.4326])
  [Layer 7] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 7] Output sample values after mixer: tensor([ 0.6464,  0.0960,  0.2781,  0.3375, -0.4326])
  [Layer 7] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 7] Residual connection sample values: tensor([-0.2072, -1.1458,  1.4874,  1.9560, -0.0554])
[Mamba2LMHeadModel] Processing layer 8/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.1680])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6792])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1345, -0.5567,  0.6753,  1.2363, -0.0301])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.6562, -1.1551, -0.6616,  0.9973, -1.4271])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.6562, -1.1551, -0.6616,  0.9973, -1.4271])
  [Mamba2] xBC (step) sample values: tensor([-2.0454,  0.5990,  0.7641, -0.2837, -0.4865])
  [Mamba2] dt (step) sample values: tensor([2.7757, 2.3605, 2.8340, 1.7464, 1.9103])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.9844,  0.5381, -1.8329, -2.0454,  1.8163])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-4.6534e-01, -2.4707e-01,  2.5652e-01, -2.0898e-02, -2.8571e-04])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.5427, -0.1660,  0.3229, -0.1178, -0.0628])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1995, -0.0761,  0.1873, -0.0554, -0.0304])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1995, -0.0761,  0.1873, -0.0554, -0.0304])
  [Mamba2] B (step) sample values: tensor([ 0.0514,  0.0475, -0.1145, -0.0095,  0.0103])
  [Mamba2] C (step) sample values: tensor([ 0.2204,  0.0312,  0.0414,  0.0667, -0.0854])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6851, -0.1380, -0.4118, -0.2678, -0.1244])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2663, 3.7029, 2.0203, 1.3314, 3.0571])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8333, 0.5999, 0.4352, 0.7001, 0.6836])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1995, -0.0761,  0.1873, -0.0554, -0.0304])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0027, -0.0025,  0.0061,  0.0005, -0.0005])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0059, -0.0236,  0.0064, -0.0234,  0.0060])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1085, -0.0288,  0.0663, -0.0505, -0.0046])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.8598, -0.3155,  0.7716, -0.2593, -0.1193])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.8598, -0.3155,  0.7716, -0.2593, -0.1193])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.2282,  0.0873, -0.1738, -0.1889,  0.0329])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([114.1257])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0936])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0495,  0.0100, -0.0613, -0.0567,  0.0068])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0495,  0.0100, -0.0613, -0.0567,  0.0068])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1151,  0.3143,  0.1616, -0.1335,  0.2514])
  [Layer 8] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 8] Output sample values after mixer: tensor([ 0.1151,  0.3143,  0.1616, -0.1335,  0.2514])
  [Layer 8] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 8] Residual connection sample values: tensor([-0.0921, -0.8315,  1.6490,  1.8224,  0.1961])
[Mamba2LMHeadModel] Processing layer 9/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([2.6264])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6171])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0523, -0.3648,  0.6926,  1.0372,  0.0969])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0214, -1.1290, -3.5781, -1.2040, -0.5986])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0214, -1.1290, -3.5781, -1.2040, -0.5986])
  [Mamba2] xBC (step) sample values: tensor([-0.7172, -0.4369, -0.7479, -0.9201, -0.3822])
  [Mamba2] dt (step) sample values: tensor([3.0660, 5.3774, 2.6696, 3.2823, 2.9182])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 3.7295,  1.9979,  2.8399, -0.7172, -0.9914])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.9143, -0.4014, -0.0296, -0.4253, -0.0330])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-1.1677, -0.3109, -0.0338, -0.4185, -0.0517])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2771, -0.1315, -0.0166, -0.1661, -0.0252])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2771, -0.1315, -0.0166, -0.1661, -0.0252])
  [Mamba2] B (step) sample values: tensor([ 0.0388, -0.0274,  0.2083, -0.1223,  0.2819])
  [Mamba2] C (step) sample values: tensor([-0.0259, -0.2768, -0.1380, -0.1323, -0.0980])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1701, -0.1135, -0.1054, -0.5864, -0.1497])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.5132, 6.1852, 4.4692, 1.9487, 3.1549])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5502, 0.4955, 0.6243, 0.3189, 0.6237])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2771, -0.1315, -0.0166, -0.1661, -0.0252])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0377,  0.0266, -0.2028,  0.1190, -0.2744])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0178,  0.0406, -0.3988,  0.2596, -0.4425])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.4671,  0.0023, -0.0415, -0.0896,  0.0100])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-1.2095, -0.3500, -0.0861, -0.5346, -0.0574])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-1.2095, -0.3500, -0.0861, -0.5346, -0.0574])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0131,  0.0965,  0.0084,  0.1485,  0.0122])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([68.7825])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1206])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0014,  0.0188,  0.0011,  0.0222,  0.0018])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0014,  0.0188,  0.0011,  0.0222,  0.0018])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0740, -0.0759,  0.0637,  0.0251, -0.4212])
  [Layer 9] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 9] Output sample values after mixer: tensor([ 0.0740, -0.0759,  0.0637,  0.0251, -0.4212])
  [Layer 9] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 9] Residual connection sample values: tensor([-0.0182, -0.9074,  1.7128,  1.8476, -0.2252])
[Mamba2LMHeadModel] Processing layer 10/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3.0376])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5738])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0103, -0.3925,  0.7231,  1.0290, -0.1079])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.6644,  0.2827,  1.1304, -1.5837,  0.5300])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.6644,  0.2827,  1.1304, -1.5837,  0.5300])
  [Mamba2] xBC (step) sample values: tensor([ 1.5412,  0.4970, -0.7280,  2.9034,  0.6584])
  [Mamba2] dt (step) sample values: tensor([ 0.6636,  1.3954,  0.7479, -0.0910,  0.2490])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1614,  1.1222, -1.1176,  1.5412, -1.8032])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.4896,  0.0117,  0.3234,  0.6507, -0.0946])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.6599, -0.0123,  0.2855,  1.2547, -0.0457])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2249, -0.0061,  0.1630,  0.9763, -0.0224])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2249, -0.0061,  0.1630,  0.9763, -0.0224])
  [Mamba2] B (step) sample values: tensor([ 0.0317, -0.1164, -0.0039, -0.1434,  0.0719])
  [Mamba2] C (step) sample values: tensor([-0.2726, -0.2617, -0.1754, -0.1686, -0.1250])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0854, -0.0771, -0.0845, -0.0547, -0.0697])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.9040, 0.3296, 0.1826, 1.3196, 0.6804])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8500, 0.9749, 0.9847, 0.9304, 0.9537])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2249, -0.0061,  0.1630,  0.9763, -0.0224])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0136,  0.0498,  0.0017,  0.0614, -0.0308])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0181, -0.5058, -0.0535,  0.2970,  0.1068])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-1.2233,  0.5381,  0.3144,  8.3780, -0.3491])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-2.3182,  0.5083,  1.1079, 13.1316, -0.4579])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-2.3182,  0.5083,  1.1079, 13.1316, -0.4579])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.6142,  0.0819,  0.9466, -3.5411, -0.1528])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([345.0336])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0538])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0202,  0.0058,  0.0729, -0.2096, -0.0110])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0202,  0.0058,  0.0729, -0.2096, -0.0110])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0021, -0.0834,  0.1058, -0.0184,  0.0745])
  [Layer 10] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 10] Output sample values after mixer: tensor([-0.0021, -0.0834,  0.1058, -0.0184,  0.0745])
  [Layer 10] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 10] Residual connection sample values: tensor([-0.0203, -0.9908,  1.8186,  1.8292, -0.1507])
[Mamba2LMHeadModel] Processing layer 11/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3.4262])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5402])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0079, -0.3136,  0.5584,  0.7793, -0.0520])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.6190, -1.5695, -3.2542,  1.0299,  0.1959])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.6190, -1.5695, -3.2542,  1.0299,  0.1959])
  [Mamba2] xBC (step) sample values: tensor([ 0.0525, -1.1465, -2.9368, -1.1261, -1.2692])
  [Mamba2] dt (step) sample values: tensor([-1.8026, -0.3975, -1.0105,  2.1802,  2.0724])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.5225, -0.6485,  0.2036,  0.0525,  0.9414])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0274,  0.1867,  0.8038,  0.1696, -0.5642])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1191,  0.3778,  0.8277,  0.2771, -0.4492])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0631,  0.2242,  0.5760,  0.1576, -0.1750])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0631,  0.2242,  0.5760,  0.1576, -0.1750])
  [Mamba2] B (step) sample values: tensor([-0.2669,  0.2005, -0.0734, -0.0181, -0.0281])
  [Mamba2] C (step) sample values: tensor([-0.1567, -0.2356,  0.0235, -0.0267, -0.2716])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2593, -0.1261, -0.1036, -0.2378, -0.4305])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0371, 0.0479, 0.0578, 2.0814, 2.2395])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9904, 0.9940, 0.9940, 0.6097, 0.3813])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0631,  0.2242,  0.5760,  0.1576, -0.1750])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-6.2556e-04,  4.6979e-04, -1.7206e-04, -4.2526e-05, -6.5883e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1819,  0.0121,  0.0199, -0.0787,  0.1049])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([0.5254, 0.5182, 0.5189, 0.2830, 0.7580])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.3265, -0.1890, -1.2978, -0.2141,  1.3100])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.3265, -0.1890, -1.2978, -0.2141,  1.3100])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.4411,  0.0511,  0.1570, -0.1624,  0.1408])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([37.7811])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1627])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0252,  0.0216,  0.1190, -0.0232,  0.0234])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0252,  0.0216,  0.1190, -0.0232,  0.0234])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0787, -0.0928,  0.0183, -0.2286,  0.1785])
  [Layer 11] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 11] Output sample values after mixer: tensor([ 0.0787, -0.0928,  0.0183, -0.2286,  0.1785])
  [Layer 11] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 11] Residual connection sample values: tensor([ 0.0584, -1.0836,  1.8368,  1.6006,  0.0278])
[Mamba2LMHeadModel] Processing layer 12/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3.9809])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5012])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0188, -0.2774,  0.4300,  0.5833,  0.0076])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.0514, -1.7139,  3.7781, -0.4973,  1.5055])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.0514, -1.7139,  3.7781, -0.4973,  1.5055])
  [Mamba2] xBC (step) sample values: tensor([ 1.2160,  1.1991, -1.9253,  1.9177, -1.6276])
  [Mamba2] dt (step) sample values: tensor([0.5776, 0.6363, 1.4418, 0.3962, 0.4642])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.4550,  0.2865, -0.1646,  1.2160,  3.5918])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0057, -0.9177,  0.2796,  0.2794,  0.6702])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0615, -1.7522,  0.2148,  0.2352,  0.5036])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0298, -0.2589,  0.1189,  0.1314,  0.3139])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0298, -0.2589,  0.1189,  0.1314,  0.3139])
  [Mamba2] B (step) sample values: tensor([ 0.2918,  0.1460,  0.1232,  0.5527, -0.0604])
  [Mamba2] C (step) sample values: tensor([-0.0976, -0.2785, -0.2784, -0.2565, -0.2708])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1609, -0.1475, -0.2713, -0.1155, -0.0902])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.3877, 0.9025, 2.2946, 1.8959, 0.1089])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7999, 0.8754, 0.5366, 0.8033, 0.9902])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0298, -0.2589,  0.1189,  0.1314,  0.3139])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0121, -0.0060, -0.0051, -0.0228,  0.0025])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0325,  0.0132,  0.0180, -0.1297, -0.0156])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0638, -0.6190,  0.1109,  0.1784,  0.5746])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1121, -1.0392,  0.3038,  0.3916,  1.0839])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1121, -1.0392,  0.3038,  0.3916,  1.0839])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0305,  0.2719,  1.1221, -0.0737,  1.3355])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([34.8905])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1693])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0078,  0.0408,  0.3299, -0.0409,  0.2952])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0078,  0.0408,  0.3299, -0.0409,  0.2952])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2492,  0.5773,  0.4337, -0.7615, -0.4670])
  [Layer 12] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 12] Output sample values after mixer: tensor([ 0.2492,  0.5773,  0.4337, -0.7615, -0.4670])
  [Layer 12] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 12] Residual connection sample values: tensor([ 0.3076, -0.5063,  2.2706,  0.8391, -0.4392])
[Mamba2LMHeadModel] Processing layer 13/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.3797])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4778])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0794, -0.1068,  0.4559,  0.2332, -0.1018])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.9306, -0.5560, -1.0241,  1.2022,  1.4220])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.9306, -0.5560, -1.0241,  1.2022,  1.4220])
  [Mamba2] xBC (step) sample values: tensor([-0.9278,  0.4060, -0.1111, -0.0563,  0.6120])
  [Mamba2] dt (step) sample values: tensor([ 1.1958, -0.3680,  0.3236, -0.1040, -0.1046])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.9691, -0.8991, -0.1159, -0.9278,  0.7766])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0327, -0.0862, -0.0356, -0.0093,  0.1890])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0948, -0.1048, -0.0277, -0.0211,  0.1585])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0451, -0.0497, -0.0136, -0.0104,  0.0855])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0451, -0.0497, -0.0136, -0.0104,  0.0855])
  [Mamba2] B (step) sample values: tensor([ 0.1354, -0.0854,  0.0037, -0.0399, -0.1098])
  [Mamba2] C (step) sample values: tensor([-0.1651, -0.2587, -0.0509,  0.2847, -0.0572])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0234, -1.0903, -0.5085, -0.6785, -0.0251])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1641, 0.0069, 0.0117, 0.0047, 0.1383])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9962, 0.9925, 0.9940, 0.9968, 0.9965])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0451, -0.0497, -0.0136, -0.0104,  0.0855])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.0029e-03,  6.3245e-04, -2.7721e-05,  2.9583e-04,  8.1318e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0784,  0.0930, -0.2749,  0.0199, -0.0637])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0119, -0.2100,  0.1359, -0.0194,  0.0395])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0171, -0.2043,  0.1375, -0.0182,  0.0296])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0171, -0.2043,  0.1375, -0.0182,  0.0296])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0114,  0.0414, -0.0372, -0.0168,  0.0339])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.0835])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9607])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0055,  0.0132, -0.0402, -0.0428,  0.0188])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0055,  0.0132, -0.0402, -0.0428,  0.0188])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1807,  0.0468,  0.2679, -0.3426, -0.1479])
  [Layer 13] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 13] Output sample values after mixer: tensor([-0.1807,  0.0468,  0.2679, -0.3426, -0.1479])
  [Layer 13] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 13] Residual connection sample values: tensor([ 0.1269, -0.4595,  2.5385,  0.4966, -0.5871])
[Mamba2LMHeadModel] Processing layer 14/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.8717])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4531])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0273, -0.0854,  0.4613,  0.1209, -0.1184])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0680, -0.1375,  0.3619,  0.3365,  0.4569])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0680, -0.1375,  0.3619,  0.3365,  0.4569])
  [Mamba2] xBC (step) sample values: tensor([-0.8609, -0.4040, -0.6572, -1.0922,  0.3122])
  [Mamba2] dt (step) sample values: tensor([2.4485, 0.4176, 1.7242, 0.8388, 1.7147])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.9533,  0.4263,  0.5062, -0.8609, -0.7754])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1843, -0.3198, -0.4405,  0.2866, -0.0848])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2548, -0.3692, -0.6323,  0.2390, -0.0986])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1435, -0.1509, -0.2194,  0.1337, -0.0469])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1435, -0.1509, -0.2194,  0.1337, -0.0469])
  [Mamba2] B (step) sample values: tensor([-0.0337,  0.0522,  0.0308,  0.0122, -0.0301])
  [Mamba2] C (step) sample values: tensor([-0.0978,  0.0235,  0.0160, -0.1231, -0.0199])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-7.2745, -0.0385, -2.2024, -0.0138, -5.3378])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2152, 0.0892, 0.0642, 0.1119, 0.0873])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.2090, 0.9966, 0.8681, 0.9985, 0.6276])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1435, -0.1509, -0.2194,  0.1337, -0.0469])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0010,  0.0016,  0.0010,  0.0004, -0.0009])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0010,  0.0016,  0.0009,  0.0004, -0.0009])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0477, -0.0535, -0.0770,  0.0454, -0.0172])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1606, -0.1723, -0.2497,  0.1506, -0.0541])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1606, -0.1723, -0.2497,  0.1506, -0.0541])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0056,  0.0110, -0.0533,  0.0296, -0.0151])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5681])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.3267])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0177,  0.0241, -0.0797,  0.0640, -0.0416])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0177,  0.0241, -0.0797,  0.0640, -0.0416])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.3219,  0.7825,  1.1354, -0.0790,  0.3030])
  [Layer 14] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 14] Output sample values after mixer: tensor([ 0.3219,  0.7825,  1.1354, -0.0790,  0.3030])
  [Layer 14] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 14] Residual connection sample values: tensor([ 0.4488,  0.3230,  3.6738,  0.4175, -0.2840])
[Mamba2LMHeadModel] Processing layer 15/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([6.5241])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3915])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1069,  0.0633,  0.7227,  0.1179, -0.0632])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.0157,  0.6043,  0.7044,  0.1662, -3.7679])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.0157,  0.6043,  0.7044,  0.1662, -3.7679])
  [Mamba2] xBC (step) sample values: tensor([-0.4345,  0.7943,  1.6371, -1.5807, -1.8675])
  [Mamba2] dt (step) sample values: tensor([ 2.7179,  0.6072,  0.6630, -0.9523,  0.4835])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.5488,  0.1523,  1.0156, -0.4345, -0.1879])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0451, -0.1668,  0.1509, -0.3251,  0.2671])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2911, -0.1909,  1.4761,  0.1175,  0.2536])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1245, -0.0864,  1.2015,  0.0622,  0.1428])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1245, -0.0864,  1.2015,  0.0622,  0.1428])
  [Mamba2] B (step) sample values: tensor([-0.0447,  0.0421,  0.0027, -0.0129, -0.0373])
  [Mamba2] C (step) sample values: tensor([-0.0380,  0.0905,  0.1070, -0.0714, -0.0437])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.4414, -0.0592, -0.7390, -0.0051, -0.0087])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.6782, 0.7195, 0.0421, 0.0190, 0.2173])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.1909, 0.9583, 0.9694, 0.9999, 0.9981])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1245, -0.0864,  1.2015,  0.0622,  0.1428])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0038, -0.0036, -0.0002,  0.0011,  0.0031])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 4.7472e-03, -2.5846e-03, -4.1114e-05,  1.7959e-03,  4.6602e-03])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0014, -0.0010,  0.0134,  0.0007,  0.0014])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2237, -0.1553,  2.1591,  0.1118,  0.2564])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2237, -0.1553,  2.1591,  0.1118,  0.2564])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0604, -0.0607,  1.0177,  0.0101, -0.0218])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([3.6414])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5240])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0699, -0.0513,  0.2527,  0.0066, -0.0258])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0699, -0.0513,  0.2527,  0.0066, -0.0258])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4470, -0.2576,  0.7139, -0.5106,  0.0806])
  [Layer 15] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 15] Output sample values after mixer: tensor([-0.4470, -0.2576,  0.7139, -0.5106,  0.0806])
  [Layer 15] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 15] Residual connection sample values: tensor([ 1.8065e-03,  6.5376e-02,  4.3877e+00, -9.3087e-02, -2.0349e-01])
[Mamba2LMHeadModel] Processing layer 16/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([7.9256])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3552])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 2.8966e-04,  8.6630e-03,  5.4185e-01, -1.8938e-02, -3.0846e-02])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.9751, -0.8460, -4.0891, -1.2521, -1.2377])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.9751, -0.8460, -4.0891, -1.2521, -1.2377])
  [Mamba2] xBC (step) sample values: tensor([-2.4088,  0.7910, -0.3772,  1.2015, -0.6355])
  [Mamba2] dt (step) sample values: tensor([ 4.8676, -0.9400,  2.2571,  2.5800,  0.4900])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 2.1004, -0.1827,  0.4267, -2.4088,  0.0799])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0400, -0.1336, -0.0375,  0.0889,  0.1469])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0382, -0.1248,  0.0992,  0.0508,  0.1544])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0194, -0.0585,  0.0520,  0.0260,  0.0831])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0194, -0.0585,  0.0520,  0.0260,  0.0831])
  [Mamba2] B (step) sample values: tensor([ 0.0582,  0.0147, -0.0223, -0.0366,  0.0481])
  [Mamba2] C (step) sample values: tensor([-0.0435, -0.1067,  0.1917, -0.1519, -0.1159])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.1349e-03, -3.0370e-03, -2.7156e+00, -4.1511e-03, -4.2926e-01])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.4715e+00, 2.6389e-02, 2.0560e-01, 3.0854e-01, 1.8363e-03])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9972, 0.9999, 0.5722, 0.9987, 0.9992])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0194, -0.0585,  0.0520,  0.0260,  0.0831])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0028,  0.0007, -0.0011, -0.0018,  0.0023])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0367,  0.0945,  0.0317,  0.0014, -0.0004])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0246, -0.0170, -0.1256, -0.0610,  0.0469])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0201, -0.0034, -0.1377, -0.0670,  0.0276])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0201, -0.0034, -0.1377, -0.0670,  0.0276])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0348,  0.0009,  0.0093,  0.0187, -0.0077])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1992])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.2406])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0342,  0.0005,  0.0209,  0.0073, -0.0089])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0342,  0.0005,  0.0209,  0.0073, -0.0089])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2257,  0.2291, -0.0819,  0.0382, -0.0794])
  [Layer 16] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 16] Output sample values after mixer: tensor([-0.2257,  0.2291, -0.0819,  0.0382, -0.0794])
  [Layer 16] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 16] Residual connection sample values: tensor([-0.2239,  0.2945,  4.3058, -0.0549, -0.2828])
[Mamba2LMHeadModel] Processing layer 17/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([9.6684])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3216])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0486,  0.0550,  0.8040, -0.0137, -0.0566])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.1311, -3.0284, -0.4709, -0.5652, -2.2666])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.1311, -3.0284, -0.4709, -0.5652, -2.2666])
  [Mamba2] xBC (step) sample values: tensor([ 0.2083,  0.7662, -0.8546, -0.1899, -2.2729])
  [Mamba2] dt (step) sample values: tensor([2.4982, 1.9608, 1.7560, 2.0114, 2.5114])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3392, -0.1690,  0.6221,  0.2083,  0.2056])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0239,  0.1285, -0.1782, -0.0389, -0.5697])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1189,  0.1506, -0.2927, -0.0045, -0.4744])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0559,  0.0810, -0.1251, -0.0022, -0.1820])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0559,  0.0810, -0.1251, -0.0022, -0.1820])
  [Mamba2] B (step) sample values: tensor([ 0.0226,  0.1246, -0.2364, -0.0914, -0.1068])
  [Mamba2] C (step) sample values: tensor([-0.0483, -0.0033, -0.2464, -0.1236,  0.0759])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3863, -0.8773, -1.4027, -0.6828, -0.3905])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.0361, 0.4792, 0.5902, 1.1413, 1.7280])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.2378, 0.6568, 0.4370, 0.4587, 0.5093])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0559,  0.0810, -0.1251, -0.0022, -0.1820])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0013, -0.0072,  0.0137,  0.0053,  0.0062])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0012, -0.0173,  0.0253,  0.0112,  0.0149])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0497,  0.0332, -0.0647,  0.0039, -0.1067])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1970,  0.2464, -0.3941, -0.0020, -0.5860])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1970,  0.2464, -0.3941, -0.0020, -0.5860])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0445, -0.0345,  0.0713,  0.0004,  0.1248])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([11.6946])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2924])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0254, -0.0201,  0.0437,  0.0003,  0.0868])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0254, -0.0201,  0.0437,  0.0003,  0.0868])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1459,  0.4048, -0.3885, -0.7458, -0.9074])
  [Layer 17] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 17] Output sample values after mixer: tensor([-0.1459,  0.4048, -0.3885, -0.7458, -0.9074])
  [Layer 17] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 17] Residual connection sample values: tensor([-0.3698,  0.6992,  3.9173, -0.8007, -1.1902])
[Mamba2LMHeadModel] Processing layer 18/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([11.0036])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3015])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0535,  0.0874,  0.4826, -0.1407, -0.1523])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.0144e-03, -1.8153e-01, -1.6295e+00, -5.3202e-01, -1.1729e+00])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.0144e-03, -1.8153e-01, -1.6295e+00, -5.3202e-01, -1.1729e+00])
  [Mamba2] xBC (step) sample values: tensor([-0.3103, -1.4708,  0.2343,  0.8265, -0.2634])
  [Mamba2] dt (step) sample values: tensor([-1.4930,  5.1258,  5.4389,  3.7005,  2.6203])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.2216, -0.6630, -0.8443, -0.3103,  1.0389])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0907,  0.5702, -0.0505,  0.1266, -0.2149])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1001,  0.1723, -0.0392,  0.1572, -0.2671])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0526,  0.0936, -0.0192,  0.0848, -0.1158])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0526,  0.0936, -0.0192,  0.0848, -0.1158])
  [Mamba2] B (step) sample values: tensor([ 0.0259,  0.0846, -0.0417, -0.1760,  0.0771])
  [Mamba2] C (step) sample values: tensor([-0.0327,  0.0345, -0.1461, -0.0862,  0.0577])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.3195e-03, -6.5336e+00, -1.4897e+01, -1.3796e-03, -2.0873e-03])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0311, 6.2391, 6.8862, 1.7393, 1.1047])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9993e-01, 1.9795e-18, 2.8026e-45, 9.9760e-01, 9.9770e-01])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0526,  0.0936, -0.0192,  0.0848, -0.1158])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 4.2307e-05,  1.3836e-04, -6.8208e-05, -2.8787e-04,  1.2619e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0042, -0.0013,  0.0946, -0.0574,  0.0170])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1168, -1.1523,  0.1413, -0.0350, -0.1661])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1210, -1.1597,  0.1429, -0.0417, -0.1569])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1210, -1.1597,  0.1429, -0.0417, -0.1569])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 6.1329e-05,  9.5734e-02, -3.8156e-02,  8.2123e-03,  4.3488e-02])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([14.3152])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2643])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 7.9970e-05,  3.0566e-02, -1.0971e-02,  5.4984e-03,  1.3683e-02])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 7.9970e-05,  3.0566e-02, -1.0971e-02,  5.4984e-03,  1.3683e-02])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4559,  0.0213, -0.0487,  0.1790,  0.3581])
  [Layer 18] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 18] Output sample values after mixer: tensor([-0.4559,  0.0213, -0.0487,  0.1790,  0.3581])
  [Layer 18] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 18] Residual connection sample values: tensor([-0.8257,  0.7205,  3.8686, -0.6217, -0.8321])
[Mamba2LMHeadModel] Processing layer 19/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([14.1479])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2659])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1309,  0.0948,  0.5148, -0.1219, -0.1171])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4266, -1.8543, -1.1682, -1.7696,  0.7660])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4266, -1.8543, -1.1682, -1.7696,  0.7660])
  [Mamba2] xBC (step) sample values: tensor([-1.3606, -0.5227, -0.7337, -0.4802, -1.2973])
  [Mamba2] dt (step) sample values: tensor([1.9208, 1.7853, 1.2632, 2.2324, 0.9250])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5868, -2.6270, -0.6527, -1.3606,  0.8876])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0286, -0.0905, -0.1588,  0.1102, -0.2326])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0800, -0.0900, -0.1726, -0.0975, -0.2338])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0384, -0.0430, -0.0789, -0.0464, -0.1033])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0384, -0.0430, -0.0789, -0.0464, -0.1033])
  [Mamba2] B (step) sample values: tensor([ 0.0651, -0.0207, -0.2463,  0.1723, -0.0769])
  [Mamba2] C (step) sample values: tensor([-0.1144, -0.0681, -0.0999,  0.0525, -0.0457])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1739, -1.5063, -1.5725, -0.1983, -0.0768])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.9326, 1.0814, 0.8411, 3.4171, 0.7474])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6004, 0.1962, 0.2664, 0.5079, 0.9442])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0384, -0.0430, -0.0789, -0.0464, -0.1033])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0073,  0.0023,  0.0277, -0.0194,  0.0087])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0131, -0.0091,  0.0856, -0.0814, -0.1969])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.3375,  0.2513, -0.1580, -0.4473, -0.2112])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3960,  0.1859, -0.2781, -0.5179, -0.3685])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3960,  0.1859, -0.2781, -0.5179, -0.3685])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0667, -0.0467,  0.0770,  0.1334, -0.1927])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([14.6812])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2610])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0203, -0.0246,  0.0483,  0.0344, -0.1841])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0203, -0.0246,  0.0483,  0.0344, -0.1841])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0182,  0.7387, -0.1407,  0.2962,  0.2211])
  [Layer 19] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 19] Output sample values after mixer: tensor([-0.0182,  0.7387, -0.1407,  0.2962,  0.2211])
  [Layer 19] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 19] Residual connection sample values: tensor([-0.8439,  1.4592,  3.7279, -0.3255, -0.6110])
[Mamba2LMHeadModel] Processing layer 20/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([15.2062])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2564])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0798,  0.1263,  0.3230, -0.0377, -0.0565])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.7374,  0.0360,  0.4386,  0.2409,  0.5612])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.7374,  0.0360,  0.4386,  0.2409,  0.5612])
  [Mamba2] xBC (step) sample values: tensor([ 0.1990, -0.8674, -0.8127,  0.4587, -0.1693])
  [Mamba2] dt (step) sample values: tensor([1.5118, 1.4933, 0.4948, 0.7627, 1.5247])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3091, -0.0315,  0.0304,  0.1990, -1.4873])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0436,  0.2124, -0.2845,  0.1307, -0.2397])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0291,  0.1743, -0.4641,  0.1097, -0.2862])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0148,  0.0947, -0.1791,  0.0578, -0.1228])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0148,  0.0947, -0.1791,  0.0578, -0.1228])
  [Mamba2] B (step) sample values: tensor([ 0.0209,  0.0231,  0.0439, -0.0063, -0.0118])
  [Mamba2] C (step) sample values: tensor([-0.0745, -0.0741, -0.1503, -0.0818, -0.0300])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.0858e-01, -2.9306e+00, -5.2962e+00, -1.2326e+01, -8.1593e-03])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0318, 0.1119, 0.0957, 0.1569, 0.1806])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9902, 0.7204, 0.6023, 0.1445, 0.9985])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0148,  0.0947, -0.1791,  0.0578, -0.1228])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 9.7941e-06,  1.0825e-05,  2.0585e-05, -2.9494e-06, -5.5121e-06])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.0932e-04, -2.3269e-04, -1.7058e-04,  9.4122e-05, -5.2303e-05])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0005,  0.0006,  0.0002, -0.0002,  0.0004])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0116,  0.0785, -0.1471,  0.0474, -0.1005])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0116,  0.0785, -0.1471,  0.0474, -0.1005])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0028,  0.0014, -0.0392,  0.0064, -0.0359])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0750])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.6517])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0253,  0.0113, -0.2126,  0.0569, -0.2090])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0253,  0.0113, -0.2126,  0.0569, -0.2090])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5174, -0.9773, -0.2334, -0.2099,  0.3703])
  [Layer 20] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 20] Output sample values after mixer: tensor([-0.5174, -0.9773, -0.2334, -0.2099,  0.3703])
  [Layer 20] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 20] Residual connection sample values: tensor([-1.3613,  0.4819,  3.4945, -0.5354, -0.2407])
[Mamba2LMHeadModel] Processing layer 21/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([19.6352])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2257])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1553,  0.0497,  0.3695, -0.0722, -0.0264])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0994, -1.2661, -0.8269, -0.5794,  0.2281])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0994, -1.2661, -0.8269, -0.5794,  0.2281])
  [Mamba2] xBC (step) sample values: tensor([-1.2507e+00,  2.8186e-01,  5.0317e-01, -5.1375e-02,  9.2497e-04])
  [Mamba2] dt (step) sample values: tensor([ 0.0453,  0.8433, -0.2275, -1.3377,  0.6462])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.0421, -1.2195, -0.0095, -1.2507,  0.1544])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3810,  0.0704,  0.0344, -0.0484,  0.0533])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-7.3841e-01, -2.7059e-02,  8.7683e-03, -1.4645e-01, -7.2963e-04])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2388, -0.0133,  0.0044, -0.0679, -0.0004])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2388, -0.0133,  0.0044, -0.0679, -0.0004])
  [Mamba2] B (step) sample values: tensor([ 0.0734, -0.2766, -0.0738, -0.2171, -0.0139])
  [Mamba2] C (step) sample values: tensor([-0.0059, -0.0950, -0.1487, -0.0714,  0.0669])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3228, -0.3764, -0.1595, -0.1054, -0.3757])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.7569, 1.0369, 0.6879, 0.1359, 0.8825])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7833, 0.6769, 0.8961, 0.9858, 0.7178])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2388, -0.0133,  0.0044, -0.0679, -0.0004])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0133,  0.0500,  0.0133,  0.0392,  0.0025])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1625,  0.1335,  0.0676,  0.1312,  0.0144])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1543, -0.0378, -0.0161, -0.0498,  0.0685])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.6590, -0.0660, -0.0068, -0.1933,  0.0677])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.6590, -0.0660, -0.0068, -0.1933,  0.0677])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0344,  0.0184,  0.0017,  0.0402,  0.0086])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([3.2536])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5544])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0397,  0.0268,  0.0028,  0.0465,  0.0086])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0397,  0.0268,  0.0028,  0.0465,  0.0086])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2674, -0.3258,  0.3663,  0.0261, -0.2608])
  [Layer 21] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 21] Output sample values after mixer: tensor([-0.2674, -0.3258,  0.3663,  0.0261, -0.2608])
  [Layer 21] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 21] Residual connection sample values: tensor([-1.6287,  0.1562,  3.8609, -0.5093, -0.5015])
[Mamba2LMHeadModel] Processing layer 22/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([21.0823])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2178])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1834,  0.0163,  0.4026, -0.0678, -0.0547])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1242,  0.5850, -0.5581, -3.2798, -0.1319])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1242,  0.5850, -0.5581, -3.2798, -0.1319])
  [Mamba2] xBC (step) sample values: tensor([ 0.1399,  0.5686, -0.4567,  0.2770, -0.7620])
  [Mamba2] dt (step) sample values: tensor([-0.6901, -1.0064, -0.3799, -0.2932,  1.1460])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2561, -0.6606, -1.1092,  0.1399,  1.3061])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1137,  0.0665,  0.0782,  0.0560,  0.0173])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1056,  0.1310,  0.0908,  0.0376,  0.0179])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0500,  0.0698,  0.0475,  0.0192,  0.0090])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0500,  0.0698,  0.0475,  0.0192,  0.0090])
  [Mamba2] B (step) sample values: tensor([-0.2783,  0.2861,  0.1967, -0.1194, -0.0331])
  [Mamba2] C (step) sample values: tensor([-0.2750, -0.1330, -0.1874,  0.1578, -0.0680])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0709, -0.0702, -0.0699, -0.0895, -0.3897])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2832, 0.3511, 0.0805, 0.2551, 1.4582])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9801, 0.9757, 0.9944, 0.9774, 0.5665])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0500,  0.0698,  0.0475,  0.0192,  0.0090])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0039, -0.0041, -0.0028,  0.0017,  0.0005])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0144, 0.0109, 0.0021, 0.0189, 0.0409])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0127,  0.1352, -0.0977,  0.0188, -0.0077])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0735,  0.0149, -0.1796, -0.0143, -0.0233])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0735,  0.0149, -0.1796, -0.0143, -0.0233])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0048, 0.0056, 0.0365, 0.0017, 0.0014])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([9.7845])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3197])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0041, 0.0020, 0.0308, 0.0021, 0.0012])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0041, 0.0020, 0.0308, 0.0021, 0.0012])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2350,  0.1343, -0.1699, -0.3873,  0.2971])
  [Layer 22] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 22] Output sample values after mixer: tensor([ 0.2350,  0.1343, -0.1699, -0.3873,  0.2971])
  [Layer 22] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 22] Residual connection sample values: tensor([-1.3937,  0.2904,  3.6909, -0.8966, -0.2044])
[Mamba2LMHeadModel] Processing layer 23/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([21.9667])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2134])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1307,  0.0246,  0.3292, -0.1034, -0.0178])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.3213,  0.6150, -1.5514, -0.0203,  0.2083])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.3213,  0.6150, -1.5514, -0.0203,  0.2083])
  [Mamba2] xBC (step) sample values: tensor([-0.3220, -0.8368,  1.1511,  0.2605,  0.4260])
  [Mamba2] dt (step) sample values: tensor([-0.0976,  0.2738,  0.3758, -0.2624,  0.1961])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2032, -0.1181, -0.7288, -0.3220, -0.0412])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3685,  0.1097,  0.0107,  0.0813,  0.0350])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4022,  0.1021, -0.0312,  0.0977,  0.0305])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1612,  0.0537, -0.0154,  0.0512,  0.0155])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1612,  0.0537, -0.0154,  0.0512,  0.0155])
  [Mamba2] B (step) sample values: tensor([0.1769, 0.1398, 0.0533, 0.8424, 0.0127])
  [Mamba2] C (step) sample values: tensor([-0.0097, -0.0513,  0.0545,  0.0729,  0.0373])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1232, -0.2255, -0.2420, -0.0956, -0.2396])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0655, 0.2739, 0.2908, 0.0577, 0.2092])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9920, 0.9401, 0.9320, 0.9945, 0.9511])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1612,  0.0537, -0.0154,  0.0512,  0.0155])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0019, -0.0015, -0.0006, -0.0089, -0.0001])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0230,  0.0104, -0.0018,  0.0658, -0.0113])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0086,  0.0176,  0.1903, -0.0274,  0.0135])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0161,  0.0151,  0.1910, -0.0298,  0.0128])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0161,  0.0151,  0.1910, -0.0298,  0.0128])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0030,  0.0060, -0.0518,  0.0003,  0.0015])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4163])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.5498])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0046,  0.0278, -0.3937,  0.0023,  0.0062])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0046,  0.0278, -0.3937,  0.0023,  0.0062])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0887,  0.0437,  0.1433,  0.5927, -0.2008])
  [Layer 23] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 23] Output sample values after mixer: tensor([ 0.0887,  0.0437,  0.1433,  0.5927, -0.2008])
  [Layer 23] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 23] Residual connection sample values: tensor([-1.3050,  0.3342,  3.8342, -0.3039, -0.4052])
[Mamba2LMHeadModel] Processing layer 24/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([22.9703])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2086])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1504,  0.0342,  0.4262, -0.0402, -0.0430])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4013, -0.1585, -0.6708, -0.8243, -1.0884])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4013, -0.1585, -0.6708, -0.8243, -1.0884])
  [Mamba2] xBC (step) sample values: tensor([-0.3341, -0.5452, -1.7180, -0.2985, -0.2817])
  [Mamba2] dt (step) sample values: tensor([-0.9933,  0.4921, -0.2147, -0.4491, -0.2821])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1667,  0.7085,  0.3718, -0.3341, -1.8085])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0887, -0.0605, -0.2035, -0.0789,  0.0849])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2156,  0.0368, -0.2057, -0.1580,  0.0918])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1194,  0.0188, -0.0923, -0.0728,  0.0480])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1194,  0.0188, -0.0923, -0.0728,  0.0480])
  [Mamba2] B (step) sample values: tensor([-0.2692,  0.0338,  0.0588,  0.0357,  0.0832])
  [Mamba2] C (step) sample values: tensor([ 0.0320, -0.1305, -0.2295, -0.1772, -0.2226])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6296, -0.1967, -0.1434, -0.1402, -0.2238])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3598, 1.0477, 0.4950, 0.8681, 0.3691])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7973, 0.8137, 0.9315, 0.8854, 0.9207])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1194,  0.0188, -0.0923, -0.0728,  0.0480])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0116,  0.0015,  0.0025,  0.0015,  0.0036])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0144,  0.0056, -0.0019,  0.0069,  0.0006])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0197, -0.0035, -0.0322, -0.0300,  0.0125])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.6044,  0.0884, -0.4843, -0.3864,  0.2476])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.6044,  0.0884, -0.4843, -0.3864,  0.2476])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1453, -0.0064,  0.1099,  0.0971, -0.0679])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([10.2638])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3121])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0500, -0.0069,  0.1039,  0.0682, -0.0442])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0500, -0.0069,  0.1039,  0.0682, -0.0442])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1448, -0.4988,  0.0422, -0.1426, -0.3860])
  [Layer 24] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 24] Output sample values after mixer: tensor([ 0.1448, -0.4988,  0.0422, -0.1426, -0.3860])
  [Layer 24] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 24] Residual connection sample values: tensor([-1.1603, -0.1647,  3.8764, -0.4465, -0.7912])
[Mamba2LMHeadModel] Processing layer 25/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([24.3205])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2028])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0904, -0.0119,  0.2813, -0.0398, -0.0577])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4770,  0.2035, -0.8459,  0.0395, -0.3639])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4770,  0.2035, -0.8459,  0.0395, -0.3639])
  [Mamba2] xBC (step) sample values: tensor([ 0.9603,  0.2999, -0.2695,  0.0293, -0.7117])
  [Mamba2] dt (step) sample values: tensor([-0.2269, -0.3445, -0.3055, -0.0448, -0.1072])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5925,  0.5788,  1.1918,  0.9603,  0.1079])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1213, -0.0681,  0.0286, -0.2839, -0.0456])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1406, -0.0647,  0.1312, -0.3890, -0.0843])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0654, -0.0313,  0.0699, -0.1572, -0.0404])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0654, -0.0313,  0.0699, -0.1572, -0.0404])
  [Mamba2] B (step) sample values: tensor([-0.0058, -0.1010, -0.0486, -0.0032, -0.0407])
  [Mamba2] C (step) sample values: tensor([-0.2121, -0.2474, -0.2510, -0.2451, -0.0289])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1626, -0.3327, -0.3294, -0.2016, -0.1541])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4886, 0.2627, 0.2635, 0.4221, 0.4845])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9236, 0.9163, 0.9169, 0.9184, 0.9281])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0654, -0.0313,  0.0699, -0.1572, -0.0404])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([0.0002, 0.0032, 0.0016, 0.0001, 0.0013])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0042,  0.0148,  0.0158,  0.0059, -0.0160])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0134,  0.0011, -0.0042, -0.0465, -0.0142])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0735, -0.0277,  0.0600, -0.1909, -0.0513])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0735, -0.0277,  0.0600, -0.1909, -0.0513])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0134, -0.0031, -0.0153, -0.0038,  0.0077])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4361])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.5143])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0706, -0.0128, -0.0526, -0.0074,  0.0228])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0706, -0.0128, -0.0526, -0.0074,  0.0228])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5688, -0.0289,  0.2289, -1.7500, -1.3682])
  [Layer 25] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 25] Output sample values after mixer: tensor([-0.5688, -0.0289,  0.2289, -1.7500, -1.3682])
  [Layer 25] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 25] Residual connection sample values: tensor([-1.7291, -0.1936,  4.1053, -2.1965, -2.1594])
[Mamba2LMHeadModel] Processing layer 26/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([27.0764])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1922])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1588, -0.0166,  0.3694, -0.2424, -0.1898])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2732,  1.4369, -0.2523,  0.2709, -0.3032])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2732,  1.4369, -0.2523,  0.2709, -0.3032])
  [Mamba2] xBC (step) sample values: tensor([ 0.6041, -1.2302, -0.3782,  0.2988,  0.2833])
  [Mamba2] dt (step) sample values: tensor([ 0.5125,  0.1391,  0.8658,  0.3451, -0.2579])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.5061, -0.5482, -0.2418,  0.6041, -1.6325])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1219, -0.3965,  0.0259,  0.0974,  0.0126])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0309, -0.4504,  0.0006,  0.0342, -0.2552])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0157, -0.1753,  0.0003,  0.0174, -0.1114])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0157, -0.1753,  0.0003,  0.0174, -0.1114])
  [Mamba2] B (step) sample values: tensor([ 0.3588,  0.0093, -0.0619, -0.0652,  0.1904])
  [Mamba2] C (step) sample values: tensor([ 0.0875, -0.2140, -0.1313, -0.1489, -0.2339])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3298, -0.0634, -0.2289, -0.1264, -0.0584])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.8102, 0.2158, 2.3216, 1.6383, 0.4345])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7655, 0.9864, 0.5878, 0.8130, 0.9749])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0157, -0.1753,  0.0003,  0.0174, -0.1114])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0046,  0.0001, -0.0008, -0.0008,  0.0024])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0264, -0.0002, -0.0119, -0.0263, -0.0073])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1505, -0.3890, -0.2005, -0.0100, -0.4324])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0873, -1.0961, -0.1993,  0.0601, -0.8818])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0873, -1.0961, -0.1993,  0.0601, -0.8818])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0135, -1.2725,  0.0220,  0.0092,  0.1136])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([11.5243])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2946])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0094, -0.6190,  0.0141,  0.0065,  0.0590])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0094, -0.6190,  0.0141,  0.0065,  0.0590])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1058,  0.2448,  0.4431,  0.0297, -0.6960])
  [Layer 26] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 26] Output sample values after mixer: tensor([ 0.1058,  0.2448,  0.4431,  0.0297, -0.6960])
  [Layer 26] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 26] Residual connection sample values: tensor([-1.6233,  0.0512,  4.5484, -2.1669, -2.8553])
[Mamba2LMHeadModel] Processing layer 27/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([28.6895])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1867])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1263,  0.0038,  0.3415, -0.1949, -0.2237])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0162, -0.1103,  0.5205, -0.8523, -0.3797])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0162, -0.1103,  0.5205, -0.8523, -0.3797])
  [Mamba2] xBC (step) sample values: tensor([-0.3301,  0.1073,  0.1421, -1.1220, -0.3094])
  [Mamba2] dt (step) sample values: tensor([ 1.0173, -0.7817,  0.2279,  0.4591,  0.3081])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5378,  0.5523,  0.5896, -0.3301,  1.1548])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0583,  0.0556,  0.0221,  0.7331, -0.0433])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0417,  0.0038, -0.0329,  0.5329, -0.0414])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0213,  0.0019, -0.0162,  0.3358, -0.0203])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0213,  0.0019, -0.0162,  0.3358, -0.0203])
  [Mamba2] B (step) sample values: tensor([ 0.1693,  0.2917, -0.0319,  0.2555, -0.0682])
  [Mamba2] C (step) sample values: tensor([-0.2226,  0.2603, -0.0005, -0.1196, -0.2456])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5626, -0.0303, -0.7559, -1.1613, -0.0406])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1996, 0.0207, 0.0117, 0.1193, 0.0429])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8938, 0.9994, 0.9912, 0.8707, 0.9983])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0213,  0.0019, -0.0162,  0.3358, -0.0203])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0007,  0.0012, -0.0001,  0.0011, -0.0003])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0041, -0.0062, -0.0056, -0.0214,  0.0012])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0156, -0.0017, -0.0057,  0.0135,  0.0015])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0267,  0.0021, -0.0379,  0.6813, -0.0389])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0267,  0.0021, -0.0379,  0.6813, -0.0389])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 2.1776e-04, -1.0966e-04, -1.2367e-02, -1.7360e-01,  6.0005e-03])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.9888])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0056])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0005, -0.0002, -0.0324, -0.1171,  0.0201])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0005, -0.0002, -0.0324, -0.1171,  0.0201])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5662, -0.4815,  0.4232, -0.4091, -0.2719])
  [Layer 27] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 27] Output sample values after mixer: tensor([-0.5662, -0.4815,  0.4232, -0.4091, -0.2719])
  [Layer 27] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 27] Residual connection sample values: tensor([-2.1894, -0.4303,  4.9716, -2.5760, -3.1273])
[Mamba2LMHeadModel] Processing layer 28/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([31.4644])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1783])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1392, -0.0263,  0.3109, -0.1915, -0.1926])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2092,  0.4390,  0.0637, -0.1191, -0.0678])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2092,  0.4390,  0.0637, -0.1191, -0.0678])
  [Mamba2] xBC (step) sample values: tensor([-0.5044, -0.6089,  0.5868, -1.0540,  0.6427])
  [Mamba2] dt (step) sample values: tensor([0.9275, 0.8370, 0.3482, 0.3438, 1.2455])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.4452, -1.6444, -0.0201, -0.5044,  1.6297])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1998, -0.1174,  0.1135,  0.2801,  0.0892])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0719, -0.2069, -0.0156,  0.1900,  0.0235])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0372, -0.0928, -0.0077,  0.1040,  0.0119])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0372, -0.0928, -0.0077,  0.1040,  0.0119])
  [Mamba2] B (step) sample values: tensor([-0.2708, -0.0951,  0.0229,  0.0626, -0.2531])
  [Mamba2] C (step) sample values: tensor([ 0.0165, -0.0962, -0.0022, -0.0463, -0.0103])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5442, -0.1843, -0.1064, -0.1124, -0.2523])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4040, 0.9280, 1.1354, 1.0557, 1.1453])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8026, 0.8428, 0.8862, 0.8881, 0.7490])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0372, -0.0928, -0.0077,  0.1040,  0.0119])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0041, -0.0014,  0.0003,  0.0009, -0.0038])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0029,  0.0003, -0.0033,  0.0007, -0.0067])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0009, -0.0066, -0.0011,  0.0114, -0.0018])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0704, -0.1797, -0.0156,  0.2054,  0.0204])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0704, -0.1797, -0.0156,  0.2054,  0.0204])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0066, -0.0480, -0.0005, -0.0115, -0.0007])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2756])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.9049])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0256, -0.1751, -0.0018, -0.0463, -0.0031])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0256, -0.1751, -0.0018, -0.0463, -0.0031])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1246, -0.5841,  1.0761, -0.0953,  0.7827])
  [Layer 28] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 28] Output sample values after mixer: tensor([ 0.1246, -0.5841,  1.0761, -0.0953,  0.7827])
  [Layer 28] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 28] Residual connection sample values: tensor([-2.0648, -1.0144,  6.0477, -2.6713, -2.3445])
[Mamba2LMHeadModel] Processing layer 29/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([32.4357])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1756])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1596, -0.0774,  0.4711, -0.2551, -0.1820])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2905,  0.4771, -0.2335, -0.9464,  0.3385])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2905,  0.4771, -0.2335, -0.9464,  0.3385])
  [Mamba2] xBC (step) sample values: tensor([ 0.2696,  0.8462,  0.2224, -0.9596,  0.1588])
  [Mamba2] dt (step) sample values: tensor([0.6785, 0.1520, 0.7094, 0.9068, 0.9295])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0419,  0.5166, -0.2557,  0.2696,  0.3009])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0459, -0.2233, -0.1561,  0.1888,  0.2316])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0599, -0.2989, -0.2944,  0.5555,  1.7316])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0309, -0.1273, -0.1257,  0.3530,  1.4712])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0309, -0.1273, -0.1257,  0.3530,  1.4712])
  [Mamba2] B (step) sample values: tensor([-0.1347, -0.0597, -0.0387,  0.0139,  0.0362])
  [Mamba2] C (step) sample values: tensor([-0.0390, -0.0221, -0.0213, -0.0986,  0.3576])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6542, -0.1369, -1.4589, -0.3682, -0.1218])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1578, 0.0640, 0.1837, 0.2385, 0.6189])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9019, 0.9913, 0.7649, 0.9159, 0.9274])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0309, -0.1273, -0.1257,  0.3530,  1.4712])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-6.5587e-04, -2.9067e-04, -1.8838e-04,  6.7921e-05,  1.7631e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0004,  0.0017, -0.0013, -0.0017,  0.0022])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0018, -0.0016,  0.0035,  0.0050,  0.0107])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0500, -0.2156, -0.2078,  0.5983,  2.4836])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0500, -0.2156, -0.2078,  0.5983,  2.4836])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0083, -0.0635,  0.0214, -0.1583,  0.4909])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5389])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.3622])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0370, -0.2207,  0.0557, -0.5050,  0.2426])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0370, -0.2207,  0.0557, -0.5050,  0.2426])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5038, -0.3314, -0.2469, -0.3160, -0.2793])
  [Layer 29] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 29] Output sample values after mixer: tensor([-0.5038, -0.3314, -0.2469, -0.3160, -0.2793])
  [Layer 29] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 29] Residual connection sample values: tensor([-2.5686, -1.3458,  5.8008, -2.9872, -2.6238])
[Mamba2LMHeadModel] Processing layer 30/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([33.8524])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1719])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1801, -0.0901,  0.3958, -0.2392, -0.1788])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1249, -0.6552,  0.1442, -0.4585,  1.1006])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1249, -0.6552,  0.1442, -0.4585,  1.1006])
  [Mamba2] xBC (step) sample values: tensor([ 0.1417, -0.5551, -1.0054, -1.0190, -1.1824])
  [Mamba2] dt (step) sample values: tensor([-0.0620, -1.0764,  0.0755,  0.4574, -0.4140])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.6209, -0.9774, -0.4668,  0.1417,  0.4424])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1359,  0.1026,  0.3036,  0.3118, -0.5022])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1787,  0.0608,  0.8788,  0.3612, -0.5948])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0814,  0.0313,  0.6209,  0.2129, -0.2115])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0814,  0.0313,  0.6209,  0.2129, -0.2115])
  [Mamba2] B (step) sample values: tensor([-0.0496, -0.0379,  0.0289,  0.0594, -0.2060])
  [Mamba2] C (step) sample values: tensor([-0.0860, -0.0216, -0.1519, -0.2321, -0.2103])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2038, -0.3668, -0.2078, -0.0952, -0.4265])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5002, 0.0874, 0.4707, 0.1526, 0.1759])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9031, 0.9684, 0.9068, 0.9856, 0.9277])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0814,  0.0313,  0.6209,  0.2129, -0.2115])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0020,  0.0015, -0.0012, -0.0024,  0.0084])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0066, -0.0230, -0.0107, -0.0074,  0.0487])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0785, -0.0570,  0.7326,  0.1523, -0.1898])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0919, -0.0518,  0.8352,  0.1875, -0.2247])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0919, -0.0518,  0.8352,  0.1875, -0.2247])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0061,  0.0116,  0.0646, -0.0333, -0.1856])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7069])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1894])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0182,  0.0382,  0.1284, -0.1099, -0.2246])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0182,  0.0382,  0.1284, -0.1099, -0.2246])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.4953, -0.1454, -0.5607, -0.7463, -0.7630])
  [Layer 30] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 30] Output sample values after mixer: tensor([ 0.4953, -0.1454, -0.5607, -0.7463, -0.7630])
  [Layer 30] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 30] Residual connection sample values: tensor([-2.0733, -1.4912,  5.2401, -3.7336, -3.3868])
[Mamba2LMHeadModel] Processing layer 31/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([36.2176])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1662])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0951, -0.0694,  0.2415, -0.1940, -0.1557])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.6037,  0.1219,  0.2581, -0.1083, -0.3011])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.6037,  0.1219,  0.2581, -0.1083, -0.3011])
  [Mamba2] xBC (step) sample values: tensor([ 0.2241,  0.4402, -0.8453, -0.0283,  0.2064])
  [Mamba2] dt (step) sample values: tensor([1.4946, 1.1012, 1.4030, 1.2020, 0.3324])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.7385, 0.2352, 0.2394, 0.2241, 0.5896])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0426, -0.0979,  0.1829,  0.0482,  0.1635])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0455, -0.0630,  0.1723,  0.0300,  0.1032])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0222, -0.0305,  0.0936,  0.0152,  0.0543])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0222, -0.0305,  0.0936,  0.0152,  0.0543])
  [Mamba2] B (step) sample values: tensor([ 0.0169, -0.0016,  0.0068, -0.0026, -0.0054])
  [Mamba2] C (step) sample values: tensor([-0.0601, -0.0551, -0.0689, -0.0279, -0.0083])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-9.5766e-03, -1.0642e-02, -2.6350e+01, -6.4468e+02, -1.6547e-02])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1904, 0.1661, 2.0859, 2.3377, 0.0865])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9818e-01, 9.9823e-01, 1.3459e-24, 0.0000e+00, 9.9857e-01])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0222, -0.0305,  0.0936,  0.0152,  0.0543])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-7.1559e-05,  6.6526e-06, -2.8915e-05,  1.1051e-05,  2.2834e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0164, -0.0108,  0.0078,  0.0156,  0.0060])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0169, -0.0176,  0.0034,  0.0179, -0.0546])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0141, -0.0138, -0.0083,  0.0160, -0.0614])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0141, -0.0138, -0.0083,  0.0160, -0.0614])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0055, -0.0009, -0.0012, -0.0008,  0.0079])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0426])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([4.8472])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1060, -0.0156, -0.0215, -0.0639,  0.0401])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1060, -0.0156, -0.0215, -0.0639,  0.0401])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.0357,  0.2474,  1.3366, -0.3909,  1.0313])
  [Layer 31] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 31] Output sample values after mixer: tensor([-1.0357,  0.2474,  1.3366, -0.3909,  1.0313])
  [Layer 31] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 31] Residual connection sample values: tensor([-3.1090, -1.2438,  6.5768, -4.1245, -2.3556])
[Mamba2LMHeadModel] Processing layer 32/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([38.1793])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1618])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2352, -0.0921,  0.4836, -0.3637, -0.1808])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3242, -0.3238,  0.6198,  0.8914, -0.2123])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3242, -0.3238,  0.6198,  0.8914, -0.2123])
  [Mamba2] xBC (step) sample values: tensor([-1.2513, -0.2080, -0.1609, -1.5503,  2.0013])
  [Mamba2] dt (step) sample values: tensor([-0.1058, -0.0785,  0.9412, -0.0418, -0.2200])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.7309,  0.0156,  0.3560, -1.2513,  0.6075])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2032, -0.0506, -0.0117,  0.2737,  0.0767])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2169, -0.4186, -0.0138,  0.2502,  0.0644])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0967, -0.1661, -0.0069,  0.1407,  0.0332])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0967, -0.1661, -0.0069,  0.1407,  0.0332])
  [Mamba2] B (step) sample values: tensor([-0.0442, -0.0166,  0.1892, -0.0393,  0.0058])
  [Mamba2] C (step) sample values: tensor([-0.2769, -0.1050, -0.2738, -0.2604, -0.2314])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0662, -0.0811, -0.5879, -0.0956, -0.5448])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.9322, 1.0070, 0.8505, 0.8500, 0.5059])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9401, 0.9216, 0.6065, 0.9220, 0.7591])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0967, -0.1661, -0.0069,  0.1407,  0.0332])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0040,  0.0015, -0.0171,  0.0035, -0.0005])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0164, 0.1092, 0.1030, 0.2281, 0.1352])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.1387, -0.9152,  0.0542,  0.6985, -0.1897])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1409, -0.9114,  0.0543,  0.6953, -0.1904])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1409, -0.9114,  0.0543,  0.6953, -0.1904])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0192,  0.1239,  0.0219,  0.4395,  0.0181])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([8.7848])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3374])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0073,  0.1022,  0.0180,  0.2265,  0.0105])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0073,  0.1022,  0.0180,  0.2265,  0.0105])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2893, -0.2994,  1.6408, -1.2983,  0.8254])
  [Layer 32] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 32] Output sample values after mixer: tensor([ 0.2893, -0.2994,  1.6408, -1.2983,  0.8254])
  [Layer 32] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 32] Residual connection sample values: tensor([-2.8197, -1.5431,  8.2176, -5.4227, -1.5301])
[Mamba2LMHeadModel] Processing layer 33/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([40.4260])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1573])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2132, -0.1139,  0.6178, -0.4306, -0.1170])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1872, -0.2007, -0.0933,  0.3568, -1.3852])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1872, -0.2007, -0.0933,  0.3568, -1.3852])
  [Mamba2] xBC (step) sample values: tensor([ 0.5544,  0.2439, -0.9974,  1.1659,  0.9625])
  [Mamba2] dt (step) sample values: tensor([-0.3809,  0.4741, -0.6167, -0.3722,  0.3463])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.6152,  0.2932,  1.7261,  0.5544, -0.1215])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1565,  0.0515, -0.1520,  0.2968,  0.1987])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1138,  0.0149, -0.1653,  0.1739,  0.1643])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0536,  0.0075, -0.0759,  0.0945,  0.0889])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0536,  0.0075, -0.0759,  0.0945,  0.0889])
  [Mamba2] B (step) sample values: tensor([-0.1111,  0.0803,  0.0671,  0.0065, -0.0853])
  [Mamba2] C (step) sample values: tensor([-0.0071, -0.0862,  0.1143, -0.1730, -0.0379])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-13.0444,  -1.3850,  -0.1668,  -0.2359,  -5.2550])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0097, 0.0077, 0.0303, 0.0364, 0.0117])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8816, 0.9893, 0.9950, 0.9914, 0.9402])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0536,  0.0075, -0.0759,  0.0945,  0.0889])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 5.7589e-05, -4.1635e-05, -3.4761e-05, -3.3938e-06,  4.4226e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-3.9029e-05,  1.3867e-04, -1.0526e-04, -9.1755e-05, -4.4756e-04])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-6.6653e-05, -4.4643e-04, -2.5015e-04,  6.7655e-04,  7.9804e-05])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0575,  0.0076, -0.0815,  0.1019,  0.0953])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0575,  0.0076, -0.0815,  0.1019,  0.0953])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0049, -0.0007,  0.0036,  0.0214, -0.0264])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2067])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.1997])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0296, -0.0040,  0.0291,  0.1442, -0.2014])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0296, -0.0040,  0.0291,  0.1442, -0.2014])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1111, -0.4302, -0.5290,  0.1236, -0.3117])
  [Layer 33] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 33] Output sample values after mixer: tensor([ 0.1111, -0.4302, -0.5290,  0.1236, -0.3117])
  [Layer 33] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 33] Residual connection sample values: tensor([-2.7086, -1.9734,  7.6886, -5.2991, -1.8419])
[Mamba2LMHeadModel] Processing layer 34/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([48.5979])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1434])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1650, -0.1184,  0.4868, -0.3274, -0.1146])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1008,  0.1929, -0.1553,  1.4064, -1.1322])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1008,  0.1929, -0.1553,  1.4064, -1.1322])
  [Mamba2] xBC (step) sample values: tensor([ 0.0642, -2.1746, -0.6089, -0.8764, -0.2465])
  [Mamba2] dt (step) sample values: tensor([-0.4329,  0.0708,  0.0182, -0.5730,  0.5960])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.4561, -1.7558, -0.5601,  0.0642, -1.2736])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0272,  1.1136,  0.1503,  0.1906, -0.1170])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0705,  1.0163,  0.1163,  0.1095, -0.1911])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0340,  0.7463,  0.0615,  0.0578, -0.0864])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0340,  0.7463,  0.0615,  0.0578, -0.0864])
  [Mamba2] B (step) sample values: tensor([-0.0128,  0.0578, -0.0403, -0.0067, -0.0647])
  [Mamba2] C (step) sample values: tensor([-0.2621, -0.0105, -0.0776, -0.0451, -0.0808])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2225, -0.1537, -0.8169, -0.8591, -2.0730])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0085, 0.0077, 0.1959, 0.0574, 0.2989])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9981, 0.9988, 0.8521, 0.9519, 0.5381])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0340,  0.7463,  0.0615,  0.0578, -0.0864])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 3.7151e-06, -1.6768e-05,  1.1693e-05,  1.9416e-06,  1.8757e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0030,  0.0074,  0.0035, -0.0065,  0.0105])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0226,  0.0841,  0.0392, -0.0160, -0.0305])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0896,  1.5524,  0.1602,  0.0976, -0.2006])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0896,  1.5524,  0.1602,  0.0976, -0.2006])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0047,  0.1641, -0.0115,  0.1102,  0.0554])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.4533])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.4852])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0188,  0.3642, -0.0381,  0.4324,  0.2314])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0188,  0.3642, -0.0381,  0.4324,  0.2314])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.8939,  1.2636,  1.5473, -1.6494, -1.0968])
  [Layer 34] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 34] Output sample values after mixer: tensor([ 0.8939,  1.2636,  1.5473, -1.6494, -1.0968])
  [Layer 34] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 34] Residual connection sample values: tensor([-1.8147, -0.7098,  9.2359, -6.9485, -2.9387])
[Mamba2LMHeadModel] Processing layer 35/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([52.6405])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1378])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1404, -0.0545,  0.7042, -0.5733, -0.2261])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6043, -1.8278,  0.7295, -2.0317,  0.3163])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6043, -1.8278,  0.7295, -2.0317,  0.3163])
  [Mamba2] xBC (step) sample values: tensor([ 0.2697,  0.1457, -0.4943, -0.3359, -0.7312])
  [Mamba2] dt (step) sample values: tensor([ 1.2486,  1.6419, -1.2002,  1.1165,  0.4835])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.0363, -1.0327, -1.1649,  0.2697,  0.7590])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0675,  0.0507, -0.1848, -0.0621, -0.1656])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1189,  0.0290, -0.2122, -0.0869, -0.2778])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0559,  0.0147, -0.0949, -0.0416, -0.1197])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0559,  0.0147, -0.0949, -0.0416, -0.1197])
  [Mamba2] B (step) sample values: tensor([ 2.2346e-02,  6.9291e-06,  2.2801e-01, -1.2113e-02,  1.6598e-01])
  [Mamba2] C (step) sample values: tensor([ 0.1177, -0.0300, -0.2338, -0.0653,  0.0103])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2054, -0.1417, -0.1071, -0.1460, -0.2581])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.8630, 3.8356, 0.3493, 3.4836, 1.1929])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5555, 0.5807, 0.9633, 0.6012, 0.7350])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0559,  0.0147, -0.0949, -0.0416, -0.1197])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-3.5781e-03, -1.1095e-06, -3.6509e-02,  1.9396e-03, -2.6576e-02])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0744, -0.0193,  0.0143, -0.0203, -0.0412])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0318,  0.3209, -0.6782, -0.0333, -0.6169])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1782,  0.3595, -0.9267, -0.1422, -0.9305])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1782,  0.3595, -0.9267, -0.1422, -0.9305])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0381, -0.0910, -0.4561,  0.0335, -0.1703])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([14.4385])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2632])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0381, -0.0883, -0.1531,  0.0484, -0.1427])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0381, -0.0883, -0.1531,  0.0484, -0.1427])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0289, -0.1065,  0.0092, -0.1149,  1.4483])
  [Layer 35] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 35] Output sample values after mixer: tensor([-0.0289, -0.1065,  0.0092, -0.1149,  1.4483])
  [Layer 35] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 35] Residual connection sample values: tensor([-1.8436, -0.8162,  9.2450, -7.0635, -1.4904])
[Mamba2LMHeadModel] Processing layer 36/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([61.0948])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1279])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1179, -0.0534,  0.5949, -0.4823, -0.0977])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.6159, -2.3132, -0.9429, -1.1270, -1.0533])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.6159, -2.3132, -0.9429, -1.1270, -1.0533])
  [Mamba2] xBC (step) sample values: tensor([ 0.2715,  1.0128,  0.3280, -1.0019, -0.5560])
  [Mamba2] dt (step) sample values: tensor([-1.5456,  0.8175, -0.4476, -0.4517, -0.1999])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.1749,  0.9087, -1.8936,  0.2715,  2.3699])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0662,  0.2187,  0.0936, -0.2479, -0.0884])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1065,  0.1011,  0.0315, -0.3926, -0.1005])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0561,  0.0531,  0.0160, -0.1583, -0.0477])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0561,  0.0531,  0.0160, -0.1583, -0.0477])
  [Mamba2] B (step) sample values: tensor([ 0.1860, -0.1689, -0.0161, -0.0127, -0.1328])
  [Mamba2] C (step) sample values: tensor([ 0.0181, -0.1073, -0.2479, -0.0891, -0.1139])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.8655, -5.6378, -3.8976, -2.4260, -3.6937])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0153, 0.0384, 0.0116, 0.0254, 0.0204])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9570, 0.8055, 0.9557, 0.9403, 0.9275])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0561,  0.0531,  0.0160, -0.1583, -0.0477])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.5987e-04, -1.4516e-04, -1.3804e-05, -1.0932e-05, -1.1415e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0042, -0.0012, -0.0035,  0.0024,  0.0010])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0021,  0.0128, -0.0057, -0.0155, -0.0096])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1741,  0.1756,  0.0433, -0.5008, -0.1560])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1741,  0.1756,  0.0433, -0.5008, -0.1560])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0310, -0.0366, -0.0114,  0.1381,  0.0425])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.7094])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7648])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0455, -0.1145, -0.0248,  0.3186,  0.1115])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0455, -0.1145, -0.0248,  0.3186,  0.1115])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0243, -0.5461,  2.0440,  0.3006,  2.1938])
  [Layer 36] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 36] Output sample values after mixer: tensor([ 0.0243, -0.5461,  2.0440,  0.3006,  2.1938])
  [Layer 36] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 36] Residual connection sample values: tensor([-1.8193, -1.3624, 11.2891, -6.7628,  0.7034])
[Mamba2LMHeadModel] Processing layer 37/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([74.7001])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1157])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1015, -0.0780,  0.6607, -0.3865,  0.0403])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.9080, -0.5475, -0.2904, -0.0839, -2.6806])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.9080, -0.5475, -0.2904, -0.0839, -2.6806])
  [Mamba2] xBC (step) sample values: tensor([ 0.5326,  0.6576,  0.3898, -0.2471,  0.5880])
  [Mamba2] dt (step) sample values: tensor([-0.7676, -1.2054,  0.1359, -0.9243,  0.0798])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5111, -0.1605, -0.0615,  0.5326,  0.2203])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1283, -0.1546, -0.2763,  0.0424, -0.1176])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2061, -0.2187, -0.3609,  0.0772, -0.2012])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0925, -0.0974, -0.1482,  0.0401, -0.0905])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0925, -0.0974, -0.1482,  0.0401, -0.0905])
  [Mamba2] B (step) sample values: tensor([ 0.0422, -0.1857, -0.1027, -0.0838, -0.0687])
  [Mamba2] C (step) sample values: tensor([-0.2562, -0.2709, -0.2758, -0.2606, -0.2779])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.8179, -31.1699, -39.0195,  -0.4619,  -0.6477])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0003, 0.0022, 0.0038, 0.0003, 0.0018])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9995, 0.9345, 0.8612, 0.9999, 0.9988])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0925, -0.0974, -0.1482,  0.0401, -0.0905])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.1435e-06,  5.0322e-06,  2.7843e-06,  2.2710e-06,  1.8618e-06])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0004,  0.0004, -0.0006,  0.0009, -0.0006])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0003,  0.0041, -0.0067,  0.0050, -0.0025])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1697, -0.1744, -0.2782,  0.0784, -0.1683])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1697, -0.1744, -0.2782,  0.0784, -0.1683])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1098,  0.0350,  0.0346, -0.0032,  0.0289])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6217])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2682])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.5187,  0.1195,  0.1110, -0.0160,  0.0785])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.5187,  0.1195,  0.1110, -0.0160,  0.0785])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.2083,  1.5741,  2.8836,  2.3510, -3.7146])
  [Layer 37] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 37] Output sample values after mixer: tensor([-1.2083,  1.5741,  2.8836,  2.3510, -3.7146])
  [Layer 37] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 37] Residual connection sample values: tensor([-3.0276,  0.2117, 14.1727, -4.4118, -3.0112])
[Mamba2LMHeadModel] Processing layer 38/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([91.2896])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1047])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1625,  0.0114,  0.7569, -0.2294, -0.1627])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.2117, -2.3194, -0.4803, -1.5834, -0.0923])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.2117, -2.3194, -0.4803, -1.5834, -0.0923])
  [Mamba2] xBC (step) sample values: tensor([ 1.8935, -0.0148,  0.3548,  0.4067,  0.1646])
  [Mamba2] dt (step) sample values: tensor([-1.0982, -0.6226, -1.3015, -0.5942,  0.1506])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.8919,  0.4508, -0.2220,  1.8935, -0.3671])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3584, -0.1622,  0.2350, -0.1023,  0.0242])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3607, -0.4515,  0.1449, -0.1455,  0.1172])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1482, -0.1756,  0.0777, -0.0675,  0.0620])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1482, -0.1756,  0.0777, -0.0675,  0.0620])
  [Mamba2] B (step) sample values: tensor([ 0.0426,  0.1397, -0.0436,  0.0168,  0.0073])
  [Mamba2] C (step) sample values: tensor([-0.2635, -0.0375, -0.1698, -0.2526, -0.1119])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1704, -2.0832, -0.1351, -0.4124, -3.5315])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3419, 0.0654, 0.2306, 0.1752, 0.1135])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9434, 0.8727, 0.9693, 0.9303, 0.6698])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1482, -0.1756,  0.0777, -0.0675,  0.0620])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0022, -0.0071,  0.0022, -0.0009, -0.0004])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0016,  0.1130, -0.0071, -0.0061,  0.0006])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2006, -0.2468, -0.0583, -0.1198,  0.2411])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2223, -0.2725, -0.0469, -0.1296,  0.2502])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2223, -0.2725, -0.0469, -0.1296,  0.2502])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0618,  0.0566,  0.0086,  0.0350, -0.0110])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.2216])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6709])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1306,  0.0805,  0.0136,  0.1099, -0.0239])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1306,  0.0805,  0.0136,  0.1099, -0.0239])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([  6.2053,   1.2766,   1.7173, -14.2197,  -0.5898])
  [Layer 38] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 38] Output sample values after mixer: tensor([  6.2053,   1.2766,   1.7173, -14.2197,  -0.5898])
  [Layer 38] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 38] Residual connection sample values: tensor([  3.1777,   1.4883,  15.8899, -18.6316,  -3.6010])
[Mamba2LMHeadModel] Processing layer 39/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([262.2832])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0617])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0744,  0.0379,  0.3926, -0.4828, -0.0885])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1789, -1.7240, -2.4880, -1.1960, -0.9542])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1789, -1.7240, -2.4880, -1.1960, -0.9542])
  [Mamba2] xBC (step) sample values: tensor([ 0.2238,  0.7000,  0.2916,  0.0068, -1.8010])
  [Mamba2] dt (step) sample values: tensor([ 4.4046,  4.8552,  1.0643,  0.9961, -0.1410])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.2065,  0.2505, -0.1133,  0.2238,  0.0533])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0409, -0.1276,  0.0645,  0.0109, -0.5239])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1053, -0.1883,  0.0798,  0.5485, -0.5273])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0554, -0.0853,  0.0415,  0.3476, -0.1957])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0554, -0.0853,  0.0415,  0.3476, -0.1957])
  [Mamba2] B (step) sample values: tensor([ 0.0166, -0.0172, -0.1247, -0.1992,  0.0266])
  [Mamba2] C (step) sample values: tensor([-0.2747, -0.2779, -0.0139,  0.0058, -0.2782])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.7351e+02, -2.3790e+00, -2.6079e-03, -1.4979e+00, -6.3307e-02])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([3.2695, 3.7072, 0.6284, 0.3106, 0.0078])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.0000e+00, 1.4782e-04, 9.9836e-01, 6.2794e-01, 9.9951e-01])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0554, -0.0853,  0.0415,  0.3476, -0.1957])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0030, -0.0031, -0.0226, -0.0361,  0.0048])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0030, -0.0031, -0.0226, -0.0361,  0.0048])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0223, -0.0343,  0.0166,  0.1396, -0.0786])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2731, -0.4203,  0.2043,  1.7126, -0.9642])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2731, -0.4203,  0.2043,  1.7126, -0.9642])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0222,  0.1097, -0.0390, -0.4756,  0.2558])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.9506])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.0256])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1067,  0.4983, -0.1676, -1.9949,  1.2944])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1067,  0.4983, -0.1676, -1.9949,  1.2944])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 4.3361, -1.9085,  7.8128, -0.7142, -1.3372])
  [Layer 39] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 39] Output sample values after mixer: tensor([ 4.3361, -1.9085,  7.8128, -0.7142, -1.3372])
  [Layer 39] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 39] Residual connection sample values: tensor([  7.5138,  -0.4202,  23.7028, -19.3458,  -4.9382])
[Mamba2LMHeadModel] Processing layer 40/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([298.6075])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0579])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2137, -0.0128,  0.7046, -0.5267, -0.1454])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.7793,  0.0795,  0.0782, -1.1426,  0.5897])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.7793,  0.0795,  0.0782, -1.1426,  0.5897])
  [Mamba2] xBC (step) sample values: tensor([-0.4869,  0.4706,  0.6995, -1.0584, -1.3926])
  [Mamba2] dt (step) sample values: tensor([-0.5685, -0.0388,  1.4151, -4.0431,  1.1459])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1680, -2.0063, -3.3809, -0.4869,  0.9552])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0760, -0.0824,  0.1370,  0.1483, -0.2337])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2553, -0.1309,  0.0654,  0.1368, -0.2321])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1439, -0.0612,  0.0337,  0.0731, -0.1027])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1439, -0.0612,  0.0337,  0.0731, -0.1027])
  [Mamba2] B (step) sample values: tensor([-0.0450,  0.1064, -0.0629, -0.0709,  0.0936])
  [Mamba2] C (step) sample values: tensor([-0.1756, -0.2247,  0.1356, -0.2745, -0.1162])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5267, -0.6301, -0.3878, -2.7909, -0.4284])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.0161e-02, 1.2464e-02, 1.0944e-01, 1.0678e-04, 4.9779e-02])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9947, 0.9922, 0.9584, 0.9997, 0.9789])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1439, -0.0612,  0.0337,  0.0731, -0.1027])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-6.5813e-05,  1.5558e-04, -9.1974e-05, -1.0359e-04,  1.3687e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0015, -0.0316, -0.0064, -0.0006, -0.0006])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0274, -0.0184, -0.0182, -0.0141,  0.0204])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.3836, -0.1699,  0.0653,  0.1667, -0.2338])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.3836, -0.1699,  0.0653,  0.1667, -0.2338])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0985, -0.0070,  0.0027, -0.0461, -0.0887])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1950])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.2647])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.7157, -0.0604,  0.0232, -0.3187, -1.0103])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.7157, -0.0604,  0.0232, -0.3187, -1.0103])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 3.4527,  2.8410, -8.2721,  0.1768, -2.4450])
  [Layer 40] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 40] Output sample values after mixer: tensor([ 3.4527,  2.8410, -8.2721,  0.1768, -2.4450])
  [Layer 40] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 40] Residual connection sample values: tensor([ 10.9665,   2.4208,  15.4307, -19.1690,  -7.3832])
[Mamba2LMHeadModel] Processing layer 41/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([351.0103])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0534])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2045,  0.0483,  0.2968, -0.3532, -0.1380])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.7385, -2.5878, -1.1355, -0.2952,  0.7656])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.7385, -2.5878, -1.1355, -0.2952,  0.7656])
  [Mamba2] xBC (step) sample values: tensor([-0.3109,  0.5971,  2.3065, -0.0999,  0.2436])
  [Mamba2] dt (step) sample values: tensor([-0.3971, -0.7406,  1.3662, -1.3398,  2.0632])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8012, -0.5914, -0.4399, -0.3109,  0.6232])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0856, -0.0662,  0.5116,  0.0097, -0.0569])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1173,  0.0562,  0.5116, -0.0830, -0.0665])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0552,  0.0289,  0.3199, -0.0398, -0.0321])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0552,  0.0289,  0.3199, -0.0398, -0.0321])
  [Mamba2] B (step) sample values: tensor([ 0.1116,  0.1687, -0.0773, -0.0475,  0.2750])
  [Mamba2] C (step) sample values: tensor([-0.1510, -0.0597,  0.0041, -0.1601, -0.2152])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.0531, -1.1356, -0.8719, -1.5713, -1.7431])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0483, 0.1054, 0.3528, 0.0346, 0.5139])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9504, 0.8872, 0.7352, 0.9470, 0.4083])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0552,  0.0289,  0.3199, -0.0398, -0.0321])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0003, -0.0004,  0.0002,  0.0001, -0.0007])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 9.5004e-07, -8.0917e-03, -6.4312e-03, -4.8468e-06, -5.4706e-03])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0163,  0.0080, -0.0011, -0.0201,  0.0053])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0869,  0.0450,  0.4080, -0.0709, -0.0358])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0869,  0.0450,  0.4080, -0.0709, -0.0358])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0434, -0.0081, -0.1127,  0.0089, -0.0187])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0202])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([7.0336])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.9776, -0.2446, -2.9233,  0.2819, -0.5477])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.9776, -0.2446, -2.9233,  0.2819, -0.5477])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 5.4896, -4.3193, -5.8906,  0.8084, -1.7892])
  [Layer 41] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 41] Output sample values after mixer: tensor([ 5.4896, -4.3193, -5.8906,  0.8084, -1.7892])
  [Layer 41] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 41] Residual connection sample values: tensor([ 16.4561,  -1.8985,   9.5401, -18.3606,  -9.1724])
[Mamba2LMHeadModel] Processing layer 42/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([423.9608])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0486])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2878, -0.0357,  0.1784, -0.3207, -0.1688])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.8334,  0.2605, -1.1101, -1.0222,  0.0128])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.8334,  0.2605, -1.1101, -1.0222,  0.0128])
  [Mamba2] xBC (step) sample values: tensor([-0.0387,  1.2820,  2.0525,  1.3183, -0.1574])
  [Mamba2] dt (step) sample values: tensor([ 1.3994, -0.5038,  0.7342, -3.3922, -0.8645])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8487,  0.0918, -0.2839, -0.0387,  0.8345])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0113,  0.2918, -0.4337, -0.2572, -0.0538])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0096,  0.2560, -0.4291, -0.2609, -0.0999])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0048,  0.1443, -0.1692, -0.1135, -0.0475])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0048,  0.1443, -0.1692, -0.1135, -0.0475])
  [Mamba2] B (step) sample values: tensor([-0.0306,  0.0533, -0.2182,  0.0843, -0.0479])
  [Mamba2] C (step) sample values: tensor([ 0.0227, -0.2428, -0.2456, -0.2601, -0.2686])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.2458, -1.7474, -3.3797, -1.2264, -1.3705])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3663, 0.0808, 0.2538, 0.0007, 0.0333])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4392, 0.8684, 0.4240, 0.9991, 0.9553])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0048,  0.1443, -0.1692, -0.1135, -0.0475])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 5.3635e-05, -9.3463e-05,  3.8283e-04, -1.4788e-04,  8.3969e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.6812e-04, -1.4259e-04,  3.2090e-04, -2.3499e-04, -4.1014e-05])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0002,  0.0576, -0.0053, -0.0086, -0.0135])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0067,  0.2549, -0.2367, -0.1638, -0.0784])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0067,  0.2549, -0.2367, -0.1638, -0.0784])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0017,  0.0375,  0.0651,  0.0443, -0.0005])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0251])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.3045])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0420,  0.8910,  1.5931,  1.0983, -0.0085])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0420,  0.8910,  1.5931,  1.0983, -0.0085])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-4.0445, -1.8879,  2.6283,  2.9734,  5.4862])
  [Layer 42] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 42] Output sample values after mixer: tensor([-4.0445, -1.8879,  2.6283,  2.9734,  5.4862])
  [Layer 42] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 42] Residual connection sample values: tensor([ 12.4116,  -3.7864,  12.1684, -15.3872,  -3.6862])
[Mamba2LMHeadModel] Processing layer 43/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([486.7414])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0453])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1987, -0.0664,  0.2041, -0.2462, -0.0600])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1600,  1.4201, -1.2108,  0.2259, -1.3574])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1600,  1.4201, -1.2108,  0.2259, -1.3574])
  [Mamba2] xBC (step) sample values: tensor([ 0.0510, -0.5715, -1.1794, -0.3276,  0.6297])
  [Mamba2] dt (step) sample values: tensor([-2.1054, -0.4556, -0.3725, -0.0571, -1.3194])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.9998,  0.5369,  0.3107,  0.0510,  0.2731])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0161,  0.0818,  0.2434, -0.0679,  0.1069])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0015,  0.0276,  0.2153, -0.1157,  0.0986])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0007,  0.0140,  0.1192, -0.0545,  0.0517])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0007,  0.0140,  0.1192, -0.0545,  0.0517])
  [Mamba2] B (step) sample values: tensor([ 0.0327,  0.0191, -0.1902, -0.2752,  0.1719])
  [Mamba2] C (step) sample values: tensor([ 0.1413,  0.1708, -0.1625, -0.2650, -0.0863])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.7046, -2.6553, -8.2110, -2.2382, -4.0926])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0077, 0.0510, 0.0435, 0.3377, 0.0003])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9718, 0.8733, 0.6995, 0.4696, 0.9986])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0007,  0.0140,  0.1192, -0.0545,  0.0517])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.8520e-07,  1.0856e-07, -1.0788e-06, -1.5606e-06,  9.7502e-07])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0018, -0.0002, -0.0010,  0.0024, -0.0019])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0019, -0.0041, -0.0100, -0.0072, -0.0033])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0031,  0.0189,  0.1866, -0.0971,  0.0820])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0031,  0.0189,  0.1866, -0.0971,  0.0820])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0002,  0.0216, -0.0519, -0.0122, -0.0228])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0143])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([8.3465])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0050,  0.6251, -1.2006, -0.2843, -0.5491])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0050,  0.6251, -1.2006, -0.2843, -0.5491])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.3001, -0.8033, -3.7444, -3.8204, -5.2509])
  [Layer 43] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 43] Output sample values after mixer: tensor([-1.3001, -0.8033, -3.7444, -3.8204, -5.2509])
  [Layer 43] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 43] Residual connection sample values: tensor([ 11.1115,  -4.5897,   8.4241, -19.2075,  -8.9372])
[Mamba2LMHeadModel] Processing layer 44/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([550.8693])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0426])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1694, -0.0724,  0.1332, -0.2863, -0.1380])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.6249, -0.4263,  0.1226, -0.3295, -0.0603])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.6249, -0.4263,  0.1226, -0.3295, -0.0603])
  [Mamba2] xBC (step) sample values: tensor([ 0.9756,  0.6332, -0.0700, -1.9996,  0.2005])
  [Mamba2] dt (step) sample values: tensor([ 0.5265, -0.7208, -0.5666, -1.9193, -0.5830])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.0672, -0.8355, -0.2039,  0.9756, -0.9473])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2000, -0.1315, -0.0076,  0.3499,  0.0345])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2215, -0.1886, -0.0364,  0.3367,  0.0411])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1230, -0.0854, -0.0178,  0.1965,  0.0210])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1230, -0.0854, -0.0178,  0.1965,  0.0210])
  [Mamba2] B (step) sample values: tensor([ 0.0515, -0.2778, -0.2761,  0.0066, -0.0715])
  [Mamba2] C (step) sample values: tensor([ 0.2245, -0.1524, -0.1440,  0.1429,  0.1900])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-4.6876, -0.9753, -0.8255, -1.2938, -0.4953])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1627, 0.0218, 0.0140, 0.0068, 0.0043])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.4664, 0.9789, 0.9885, 0.9913, 0.9979])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1230, -0.0854, -0.0178,  0.1965,  0.0210])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0010, -0.0056, -0.0055,  0.0001, -0.0014])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0010, -0.0038, -0.0036, -0.0002, -0.0018])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0014,  0.0013, -0.0006, -0.0003, -0.0002])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2124, -0.1472, -0.0317,  0.3411,  0.0363])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2124, -0.1472, -0.0317,  0.3411,  0.0363])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0864,  0.0248, -0.0021, -0.0470, -0.0011])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0139])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([8.4884])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 2.3641,  0.6209, -0.0654, -1.2830, -0.0284])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 2.3641,  0.6209, -0.0654, -1.2830, -0.0284])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 8.2534,  3.4295,  2.5731, -3.9960,  4.6332])
  [Layer 44] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 44] Output sample values after mixer: tensor([ 8.2534,  3.4295,  2.5731, -3.9960,  4.6332])
  [Layer 44] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 44] Residual connection sample values: tensor([ 19.3649,  -1.1603,  10.9972, -23.2035,  -4.3040])
[Mamba2LMHeadModel] Processing layer 45/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([626.0425])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0400])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.3322, -0.0215,  0.1982, -0.3994, -0.0748])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.5347, -3.5811, -0.6796, -1.7706, -1.0234])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.5347, -3.5811, -0.6796, -1.7706, -1.0234])
  [Mamba2] xBC (step) sample values: tensor([ 1.3445, -2.6221,  0.8006, -0.3356,  1.0507])
  [Mamba2] dt (step) sample values: tensor([ 0.4606,  4.1336,  0.6685,  2.3149, -0.4294])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1007, -0.8807, -0.1622,  1.3445,  0.5763])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2284, -0.2856,  0.1491,  0.0716,  0.1759])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2228, -0.0276,  0.1268,  0.0156,  0.1652])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1237, -0.0136,  0.0674,  0.0079,  0.0894])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1237, -0.0136,  0.0674,  0.0079,  0.0894])
  [Mamba2] B (step) sample values: tensor([-0.0473,  0.0863, -0.0108,  0.0519, -0.0606])
  [Mamba2] C (step) sample values: tensor([-0.2776, -0.1268, -0.1876,  0.1241, -0.0361])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3039e+00, -3.9385e-02, -6.8874e+00, -8.0559e-01, -1.9935e+03])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0035, 0.7737, 0.0150, 0.0063, 0.0125])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9543e-01, 9.6999e-01, 9.0173e-01, 9.9490e-01, 1.5391e-11])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1237, -0.0136,  0.0674,  0.0079,  0.0894])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-2.0590e-05,  3.7561e-05, -4.7179e-06,  2.2567e-05, -2.6341e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0016, 0.0009, 0.0013, 0.0003, 0.0016])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0022,  0.0176, -0.0037, -0.0045,  0.0044])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.3189, -0.0177,  0.1712,  0.0159,  0.2364])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.3189, -0.0177,  0.1712,  0.0159,  0.2364])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0630,  0.0017, -0.0391, -0.0041, -0.0639])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0737])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.6841])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.9002,  0.0184, -0.5011, -0.0497, -0.9300])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.9002,  0.0184, -0.5011, -0.0497, -0.9300])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.9714,  2.4296, -2.8330,  4.1794,  1.1360])
  [Layer 45] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 45] Output sample values after mixer: tensor([-0.9714,  2.4296, -2.8330,  4.1794,  1.1360])
  [Layer 45] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 45] Residual connection sample values: tensor([ 18.3935,   1.2693,   8.1642, -19.0241,  -3.1680])
[Mamba2LMHeadModel] Processing layer 46/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([698.3451])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0378])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2836,  0.0210,  0.1327, -0.2986, -0.0484])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5100, -0.4720, -0.5701, -1.7128,  0.6190])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5100, -0.4720, -0.5701, -1.7128,  0.6190])
  [Mamba2] xBC (step) sample values: tensor([0.0305, 0.3795, 0.7517, 1.1784, 0.4643])
  [Mamba2] dt (step) sample values: tensor([-0.9494, -0.3343,  0.0829, -1.4055,  0.2036])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2080,  1.3816,  1.4707,  0.0305, -0.1183])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0994, -0.0694,  0.1481, -0.2003, -0.0748])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0439, -0.1067,  0.3510, -0.1958, -0.0800])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0215, -0.0505,  0.2060, -0.0884, -0.0384])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0215, -0.0505,  0.2060, -0.0884, -0.0384])
  [Mamba2] B (step) sample values: tensor([-0.1098, -0.0347,  0.1085,  0.0781, -0.1091])
  [Mamba2] C (step) sample values: tensor([-0.0129, -0.1748, -0.0393, -0.0885,  0.1833])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.4426,  -0.9830, -10.1590,  -1.3638,  -1.7559])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0034, 0.0100, 0.0012, 0.0032, 0.0133])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9951, 0.9902, 0.9880, 0.9956, 0.9769])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0215, -0.0505,  0.2060, -0.0884, -0.0384])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 8.0441e-06,  2.5448e-06, -7.9437e-06, -5.7213e-06,  7.9920e-06])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.6687e-03,  2.0085e-04, -3.5568e-05,  7.0459e-04, -8.6534e-04])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0027, -0.0011, -0.0115,  0.0015,  0.0032])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0290, -0.0629,  0.2409, -0.1067, -0.0438])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0290, -0.0629,  0.2409, -0.1067, -0.0438])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0092,  0.0114, -0.0496,  0.0279, -0.0176])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0113])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([9.4102])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.3868,  0.4439, -1.6455,  0.9174, -0.5789])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.3868,  0.4439, -1.6455,  0.9174, -0.5789])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-4.5323, -1.8540, -3.8667, -1.6189, -0.5442])
  [Layer 46] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 46] Output sample values after mixer: tensor([-4.5323, -1.8540, -3.8667, -1.6189, -0.5442])
  [Layer 46] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 46] Residual connection sample values: tensor([ 13.8611,  -0.5847,   4.2975, -20.6430,  -3.7122])
[Mamba2LMHeadModel] Processing layer 47/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([822.4822])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0349])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1771, -0.0078,  0.0561, -0.2490, -0.0475])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4316,  0.7936, -1.6279, -1.3288,  0.3940])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4316,  0.7936, -1.6279, -1.3288,  0.3940])
  [Mamba2] xBC (step) sample values: tensor([-2.0536, -0.3522,  0.5509, -0.0401, -0.2280])
  [Mamba2] dt (step) sample values: tensor([ 2.4339,  0.5867, -1.1803,  2.9274,  2.5033])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5188, -1.1000, -1.1328, -2.0536, -0.5438])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4682, -0.0558,  0.1061,  0.0081, -0.0376])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.4553, -0.0407,  0.1050,  0.0149, -0.0395])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.2786, -0.0199,  0.0552,  0.0075, -0.0194])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.2786, -0.0199,  0.0552,  0.0075, -0.0194])
  [Mamba2] B (step) sample values: tensor([-0.0572,  0.0072, -0.1166,  0.0227, -0.1264])
  [Mamba2] C (step) sample values: tensor([-0.2281, -0.2460, -0.1716, -0.2602, -0.2484])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-5.7667e+01, -2.2024e+00, -3.8371e+00, -4.6046e-02, -2.0700e+00])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4322, 0.0080, 0.0040, 0.2883, 0.0487])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([1.4953e-11, 9.8259e-01, 9.8478e-01, 9.8681e-01, 9.0402e-01])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.2786, -0.0199,  0.0552,  0.0075, -0.0194])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0069,  0.0009, -0.0140,  0.0027, -0.0152])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0069,  0.0009, -0.0140,  0.0027, -0.0152])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-2.1171e-03,  1.5149e-04, -4.1984e-04, -5.7205e-05,  1.4720e-04])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.4369, -0.0313,  0.0866,  0.0118, -0.0304])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.4369, -0.0313,  0.0866,  0.0118, -0.0304])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0742, -0.0171, -0.0231, -0.0033, -0.0071])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0136])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([8.5782])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-2.1731, -0.5532, -0.6872, -0.1396, -0.2452])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-2.1731, -0.5532, -0.6872, -0.1396, -0.2452])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([10.4846,  8.8750, 28.5412, -8.5168, 29.4311])
  [Layer 47] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 47] Output sample values after mixer: tensor([10.4846,  8.8750, 28.5412, -8.5168, 29.4311])
  [Layer 47] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 47] Residual connection sample values: tensor([ 24.3458,   8.2902,  32.8387, -29.1598,  25.7189])
[Mamba2LMHeadModel] Processing layer 48/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1345.7653])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0273])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2422,  0.0890,  0.3484, -0.2829,  0.2648])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.1562, -1.0644, -1.7947, -0.6183,  1.1094])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.1562, -1.0644, -1.7947, -0.6183,  1.1094])
  [Mamba2] xBC (step) sample values: tensor([-1.2685,  0.2082,  0.0662,  1.0872,  0.7850])
  [Mamba2] dt (step) sample values: tensor([-0.6574, -2.5026, -2.8984, -2.1431,  3.1220])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0768, -0.9858, -0.1618, -1.2685,  0.1977])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([0.1982, 0.0319, 0.0033, 0.1281, 0.1189])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2021,  0.0014, -0.0087,  0.0480,  0.0366])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1112,  0.0007, -0.0043,  0.0246,  0.0186])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1112,  0.0007, -0.0043,  0.0246,  0.0186])
  [Mamba2] B (step) sample values: tensor([ 0.1946, -0.0822, -0.2363, -0.0108,  0.0760])
  [Mamba2] C (step) sample values: tensor([ 0.1226, -0.1129, -0.2151, -0.0364, -0.0421])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.7304,  -7.3891,  -3.3797,  -1.8028, -17.7601])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([5.9682e-03, 1.7594e-05, 3.5427e-04, 2.2843e-03, 1.1817e+00])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.8973e-01, 9.9987e-01, 9.9880e-01, 9.9589e-01, 7.6745e-10])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1112,  0.0007, -0.0043,  0.0246,  0.0186])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.2918e-04, -5.4563e-05, -1.5686e-04, -7.2029e-06,  5.0454e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-5.9214e-05,  3.9963e-04,  4.1408e-04, -1.5157e-04,  1.0143e-05])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0002, -0.0003,  0.0001,  0.0008,  0.0010])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1581,  0.0006, -0.0061,  0.0358,  0.0276])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1581,  0.0006, -0.0061,  0.0358,  0.0276])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0133, -0.0002,  0.0015, -0.0078,  0.0230])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0053])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([13.7142])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.6472, -0.0095,  0.0799, -0.3521,  1.4221])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.6472, -0.0095,  0.0799, -0.3521,  1.4221])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 13.9518,  10.1601,  16.7120,  14.5246, -14.0900])
  [Layer 48] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 48] Output sample values after mixer: tensor([ 13.9518,  10.1601,  16.7120,  14.5246, -14.0900])
  [Layer 48] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 48] Residual connection sample values: tensor([ 38.2976,  18.4503,  49.5507, -14.6352,  11.6290])
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([1636.9535])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0247])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.9688,  0.6742,  1.4340, -0.3344,  0.3026])
[Mamba2LMHeadModel] Final backbone norm output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Final backbone norm output sample values: tensor([ 0.9688,  0.6742,  1.4340, -0.3344,  0.3026])
[Mamba2LMHeadModel] Logits shape: torch.Size([1, 1, 50288])
[Mamba2LMHeadModel] Logits sample values: tensor([11.9064, -0.0174, -6.2274, -2.4497, -0.0726])
ript[Mamba2LMHeadModel] Forward pass input_ids shape: torch.Size([1, 1])
[Mamba2LMHeadModel] input_ids sample values: tensor([1122])
[Mamba2LMHeadModel] Embedding output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Embedding sample values: tensor([ 0.3411,  0.5820,  0.0828, -0.0092,  0.0249])
[Mamba2LMHeadModel] Processing layer 1/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1253])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([2.8247])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2312,  0.5021,  0.0616, -0.0053,  0.0158])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3405, -0.6200, -0.3304,  0.1265, -0.0007])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3405, -0.6200, -0.3304,  0.1265, -0.0007])
  [Mamba2] xBC (step) sample values: tensor([-0.2476,  0.0837, -1.0692,  0.0479, -0.4937])
  [Mamba2] dt (step) sample values: tensor([ 0.1585,  0.1000,  0.1540,  0.2115, -0.0793])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0774,  0.6464,  0.4554, -0.2476, -0.6667])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0582, -0.0473,  0.0025,  0.0272, -0.0664])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1008, -0.0549,  0.1152, -0.1823, -0.2635])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0529, -0.0267,  0.0609, -0.0829, -0.1145])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0529, -0.0267,  0.0609, -0.0829, -0.1145])
  [Mamba2] B (step) sample values: tensor([-0.2429,  0.1326,  0.0540,  0.6474, -0.0123])
  [Mamba2] C (step) sample values: tensor([-0.2525,  0.1769,  0.0988, -0.2481, -0.0864])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4384, -1.0011, -1.2129, -1.1530, -1.4844])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0650, 0.0374, 0.0283, 0.0321, 0.0208])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9719, 0.9632, 0.9662, 0.9636, 0.9697])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0529, -0.0267,  0.0609, -0.0829, -0.1145])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-8.3542e-04,  4.5605e-04,  1.8558e-04,  2.2270e-03, -4.2357e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0201, -0.0034, -0.0007,  0.0499, -0.0007])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0153, -0.0090,  0.0424, -0.0704, -0.0529])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1061, -0.0547,  0.1469, -0.2126, -0.2493])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1061, -0.0547,  0.1469, -0.2126, -0.2493])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-1.5019e-02,  1.1870e-02, -2.0292e-02, -1.4298e-02,  8.6622e-05])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0062])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([12.6527])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1700,  0.1109, -0.1894, -0.1094,  0.0034])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1700,  0.1109, -0.1894, -0.1094,  0.0034])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.6487, -1.0103,  0.6819, -0.7822, -0.9795])
  [Layer 1] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 1] Output sample values after mixer: tensor([ 0.6487, -1.0103,  0.6819, -0.7822, -0.9795])
  [Layer 1] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 1] Residual connection sample values: tensor([ 0.9897, -0.4282,  0.7647, -0.7914, -0.9546])
[Mamba2LMHeadModel] Processing layer 2/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3.3078])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5498])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.3143, -0.1142,  0.1883, -0.2643, -0.2760])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 2.5369, -0.6791, -1.5235, -0.0470, -2.5149])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 2.5369, -0.6791, -1.5235, -0.0470, -2.5149])
  [Mamba2] xBC (step) sample values: tensor([ 0.4979, -0.1507,  1.5882,  0.5249,  2.8400])
  [Mamba2] dt (step) sample values: tensor([-0.6147,  0.1617,  0.2891,  0.1498,  1.0552])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5496,  0.0691,  0.5476,  0.4979,  0.0887])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0757,  0.1590, -0.4820,  0.2474, -0.0545])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0850,  0.1291, -0.5938,  0.1033, -0.0512])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0407,  0.0687, -0.2113,  0.0543, -0.0249])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0407,  0.0687, -0.2113,  0.0543, -0.0249])
  [Mamba2] B (step) sample values: tensor([-0.0676, -0.0471,  0.1372,  0.1184, -0.0325])
  [Mamba2] C (step) sample values: tensor([-0.0399,  0.1988, -0.1754, -0.2233, -0.1682])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-12.6926, -19.4296,  -0.2289,  -2.1057,  -5.0389])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0276, 0.0410, 0.0328, 0.0724, 0.1549])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7048, 0.4511, 0.9925, 0.8585, 0.4582])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0407,  0.0687, -0.2113,  0.0543, -0.0249])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 7.5756e-05,  5.2792e-05, -1.5388e-04, -1.3274e-04,  3.6480e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 3.0675e-04,  3.4725e-05, -1.7605e-04, -2.5797e-04,  1.3515e-04])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0011, -0.0013, -0.0065, -0.0076, -0.0012])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0260,  0.0445, -0.1473,  0.0286, -0.0178])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0260,  0.0445, -0.1473,  0.0286, -0.0178])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0612, -0.0102,  0.0402, -0.0007,  0.0034])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.1470])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9337])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1087, -0.0254,  0.0908, -0.0010,  0.0087])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1087, -0.0254,  0.0908, -0.0010,  0.0087])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4951, -0.6376,  0.5292,  0.6871, -0.2585])
  [Layer 2] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 2] Output sample values after mixer: tensor([-0.4951, -0.6376,  0.5292,  0.6871, -0.2585])
  [Layer 2] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 2] Residual connection sample values: tensor([ 0.4946, -1.0658,  1.2939, -0.1043, -1.2130])
[Mamba2LMHeadModel] Processing layer 3/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3.5612])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5299])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2275, -0.4115,  0.4449, -0.0513, -0.5326])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5147, -5.1486,  0.1735, -2.9942,  0.3284])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5147, -5.1486,  0.1735, -2.9942,  0.3284])
  [Mamba2] xBC (step) sample values: tensor([-3.0346, -1.2019, -1.2824,  0.6273,  0.1220])
  [Mamba2] dt (step) sample values: tensor([ 0.2060, -0.0273, -1.1996,  0.1827,  0.1126])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.3079, -0.2860,  1.6465, -3.0346, -1.0469])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2622, -0.2001,  0.4123, -0.0896,  0.3432])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3071, -0.2778,  0.3612, -0.1362,  0.2763])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1302, -0.1197,  0.2128, -0.0635,  0.1571])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1302, -0.1197,  0.2128, -0.0635,  0.1571])
  [Mamba2] B (step) sample values: tensor([-0.2505,  0.2185,  0.0546,  0.0677, -0.2339])
  [Mamba2] C (step) sample values: tensor([-0.2781,  0.3657,  0.1940,  0.2856,  0.1723])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-20.9265,  -0.8803,  -0.6735,  -0.6461,  -0.2726])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.5410e-02, 4.7113e-03, 1.3573e-05, 6.2796e-03, 1.1523e-02])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7244, 0.9959, 1.0000, 0.9960, 0.9969])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1302, -0.1197,  0.2128, -0.0635,  0.1571])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0005, -0.0004, -0.0001, -0.0001,  0.0005])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-7.6648e-05, -1.8321e-03, -2.2678e-04,  1.3829e-03, -1.6943e-03])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0066, -0.0056,  0.0243, -0.0063,  0.0020])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0858, -0.0906,  0.1754, -0.0514,  0.1135])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0858, -0.0906,  0.1754, -0.0514,  0.1135])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0276,  0.0027,  0.0165,  0.0073,  0.0217])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.7733])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7509])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0372,  0.0032,  0.0157,  0.0077,  0.0340])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0372,  0.0032,  0.0157,  0.0077,  0.0340])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.3090, -0.7441, -0.0429,  0.6568, -0.1341])
  [Layer 3] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 3] Output sample values after mixer: tensor([ 0.3090, -0.7441, -0.0429,  0.6568, -0.1341])
  [Layer 3] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 3] Residual connection sample values: tensor([ 0.8036, -1.8100,  1.2510,  0.5526, -1.3472])
[Mamba2LMHeadModel] Processing layer 4/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([3.9752])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5016])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2366, -0.4614,  0.3002,  0.1729, -0.3731])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 1.5885, -0.3356,  0.1804,  0.5619,  0.7733])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 1.5885, -0.3356,  0.1804,  0.5619,  0.7733])
  [Mamba2] xBC (step) sample values: tensor([-0.7614,  0.9857, -0.2582, -0.8367,  1.2284])
  [Mamba2] dt (step) sample values: tensor([0.3054, 0.5689, 0.9393, 0.6975, 0.3140])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5310, -1.0433, -0.2234, -0.7614, -0.4639])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0949, -0.0700,  0.0587, -0.3893,  0.2851])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1170, -0.0574,  0.0183, -0.4539,  0.5441])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0619, -0.0279,  0.0092, -0.1763,  0.3443])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0619, -0.0279,  0.0092, -0.1763,  0.3443])
  [Mamba2] B (step) sample values: tensor([-0.2671, -0.0264, -0.1251, -0.0392,  0.0561])
  [Mamba2] C (step) sample values: tensor([-0.2694, -0.1845, -0.2301, -0.0632, -0.1379])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.4907, -0.5048, -0.6491, -0.5552, -0.4657])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0605, 0.0986, 0.2010, 0.0779, 0.4286])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9707, 0.9514, 0.8777, 0.9577, 0.8191])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0619, -0.0279,  0.0092, -0.1763,  0.3443])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.0004e-03, -9.8810e-05, -4.6864e-04, -1.4690e-04,  2.1026e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0331, -0.0022,  0.0001,  0.0022, -0.0009])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0379,  0.0054,  0.0134, -0.0880,  0.1274])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0790, -0.0131,  0.0196, -0.2050,  0.3558])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0790, -0.0131,  0.0196, -0.2050,  0.3558])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1042,  0.0018,  0.0019, -0.0733,  0.1882])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.4611])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6374])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1999,  0.0038,  0.0033, -0.1391,  0.2599])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1999,  0.0038,  0.0033, -0.1391,  0.2599])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0216, -0.0023, -0.0024,  0.0473, -0.4907])
  [Layer 4] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 4] Output sample values after mixer: tensor([ 0.0216, -0.0023, -0.0024,  0.0473, -0.4907])
  [Layer 4] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 4] Residual connection sample values: tensor([ 0.8252, -1.8123,  1.2486,  0.5998, -1.8378])
[Mamba2LMHeadModel] Processing layer 5/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.1630])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4901])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.3347, -0.6198,  0.3732,  0.2426, -0.7072])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4236, -0.8001, -0.9489, -1.5972, -0.4130])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4236, -0.8001, -0.9489, -1.5972, -0.4130])
  [Mamba2] xBC (step) sample values: tensor([-0.5521, -1.4812, -0.7657, -2.0380, -1.9968])
  [Mamba2] dt (step) sample values: tensor([0.7210, 0.8530, 0.0320, 1.3515, 1.0650])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.0104, -1.2362, -0.3890, -0.5521, -1.2028])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3884,  0.1716, -0.2291,  0.1694,  0.0301])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4517, -0.0697, -0.2364,  0.1963,  0.0411])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1757, -0.0337, -0.1043,  0.1077,  0.0210])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1757, -0.0337, -0.1043,  0.1077,  0.0210])
  [Mamba2] B (step) sample values: tensor([ 0.2959,  0.0251, -0.2142, -0.0925, -0.0189])
  [Mamba2] C (step) sample values: tensor([-0.0487, -0.0962, -0.2780, -0.2784, -0.0037])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0759, -0.5319, -0.0470, -1.4939, -3.6258])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3007, 0.0325, 0.0380, 0.0532, 0.0463])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9774, 0.9828, 0.9982, 0.9236, 0.8453])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1757, -0.0337, -0.1043,  0.1077,  0.0210])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0156, -0.0013,  0.0113,  0.0049,  0.0010])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0321, -0.0108,  0.5115,  0.0533,  0.0077])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.6207, -0.6872, -0.5735, -0.1907, -0.2059])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.8679, -0.7346, -0.7203, -0.0391, -0.1764])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.8679, -0.7346, -0.7203, -0.0391, -0.1764])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.2222,  0.1822,  0.1908,  0.0105,  0.0290])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([8.5071])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3429])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0252,  0.0218,  0.0468,  0.0028,  0.0085])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0252,  0.0218,  0.0468,  0.0028,  0.0085])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.4745, -0.3493,  0.3107, -0.1132,  0.1253])
  [Layer 5] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 5] Output sample values after mixer: tensor([-0.4745, -0.3493,  0.3107, -0.1132,  0.1253])
  [Layer 5] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 5] Residual connection sample values: tensor([ 0.3507, -2.1616,  1.5593,  0.4867, -1.7125])
[Mamba2LMHeadModel] Processing layer 6/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([4.3869])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4774])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1227, -0.6249,  0.4253,  0.1633, -0.5354])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.8779,  0.7987, -1.3955, -3.5318, -0.8404])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.8779,  0.7987, -1.3955, -3.5318, -0.8404])
  [Mamba2] xBC (step) sample values: tensor([-1.2680,  2.4124, -0.0520, -1.8077,  0.6539])
  [Mamba2] dt (step) sample values: tensor([1.1171, 1.9525, 1.3954, 0.8108, 0.9573])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.7968,  0.8933,  0.8282, -1.2680,  0.1228])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2137, -0.0918, -0.1511, -0.3397,  0.1022])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2610, -0.0778, -0.0699, -0.3514,  0.2404])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1136, -0.0374, -0.0337, -0.1451,  0.1346])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1136, -0.0374, -0.0337, -0.1451,  0.1346])
  [Mamba2] B (step) sample values: tensor([ 0.0612,  0.0406, -0.2678, -0.0171,  0.5991])
  [Mamba2] C (step) sample values: tensor([-0.2745,  0.1036, -0.2779, -0.0160,  0.3620])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5110, -0.2862, -0.5421, -0.3954, -0.5986])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4011, 0.6250, 0.2926, 0.2887, 0.2311])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8147, 0.8362, 0.8533, 0.8921, 0.8708])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1136, -0.0374, -0.0337, -0.1451,  0.1346])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0028, -0.0019,  0.0122,  0.0008, -0.0273])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0097, -0.0079,  0.0249,  0.0052, -0.0212])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0242, -0.0141, -0.0024, -0.0228, -0.0014])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1545, -0.0570, -0.0411, -0.1893,  0.1530])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1545, -0.0570, -0.0411, -0.1893,  0.1530])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0385, -0.0314,  0.0114,  0.0190, -0.0388])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([4.7854])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4571])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0511, -0.0399,  0.0138,  0.0282, -0.0419])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0511, -0.0399,  0.0138,  0.0282, -0.0419])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2776,  1.7630,  0.6214, -0.5009, -1.2139])
  [Layer 6] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 6] Output sample values after mixer: tensor([-0.2776,  1.7630,  0.6214, -0.5009, -1.2139])
  [Layer 6] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 6] Residual connection sample values: tensor([ 0.0731, -0.3986,  2.1807, -0.0142, -2.9264])
[Mamba2LMHeadModel] Processing layer 7/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([5.5719])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4236])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0225, -0.0999,  0.5305, -0.0044, -0.7827])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-3.0749, -2.2167, -0.9602, -1.1181, -1.6599])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-3.0749, -2.2167, -0.9602, -1.1181, -1.6599])
  [Mamba2] xBC (step) sample values: tensor([-3.2950,  0.1873,  2.0918,  0.8990, -2.0726])
  [Mamba2] dt (step) sample values: tensor([-0.6042,  1.4025,  1.3877, -0.8343,  1.0509])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.0369, -2.6750, -0.2596, -3.2950, -1.6285])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6826,  0.0227,  0.1638,  0.0720,  0.0329])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.7162, -0.0486,  0.0329,  0.0805,  0.0302])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2351, -0.0237,  0.0167,  0.0419,  0.0153])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2351, -0.0237,  0.0167,  0.0419,  0.0153])
  [Mamba2] B (step) sample values: tensor([-0.0044,  0.0846,  0.0234, -0.0069, -0.0573])
  [Mamba2] C (step) sample values: tensor([-0.0038,  0.2546, -0.0555, -0.1389, -0.0548])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-6.5957e-02, -4.5478e+00, -5.8281e+00, -4.2034e-01, -1.9005e-03])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3021, 0.1284, 0.1382, 0.0629, 0.4763])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9803, 0.5578, 0.4469, 0.9739, 0.9991])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2351, -0.0237,  0.0167,  0.0419,  0.0153])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0003, -0.0060, -0.0017,  0.0005,  0.0041])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0945,  0.0017, -0.0130,  0.0126,  0.0550])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1467, -0.0914, -0.0687, -0.0269,  0.0163])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.6917, -0.1464, -0.0300,  0.0702,  0.0518])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.6917, -0.1464, -0.0300,  0.0702,  0.0518])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0939,  0.0319,  0.0080, -0.0193, -0.0137])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([5.2093])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4381])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0491,  0.0201,  0.0030, -0.0089, -0.0138])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0491,  0.0201,  0.0030, -0.0089, -0.0138])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3523,  0.0708,  0.2141,  0.0882, -0.2292])
  [Layer 7] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 7] Output sample values after mixer: tensor([-0.3523,  0.0708,  0.2141,  0.0882, -0.2292])
  [Layer 7] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 7] Residual connection sample values: tensor([-0.2792, -0.3278,  2.3947,  0.0740, -3.1556])
[Mamba2LMHeadModel] Processing layer 8/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([6.3670])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3963])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1057, -0.0929,  0.6344,  0.0273, -1.0014])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0642, -2.3209, -3.2787,  0.8061, -5.5471])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0642, -2.3209, -3.2787,  0.8061, -5.5471])
  [Mamba2] xBC (step) sample values: tensor([-0.4483, -1.3997,  0.5602,  1.2427,  1.0322])
  [Mamba2] dt (step) sample values: tensor([2.8213, 0.1471, 2.2383, 2.0797, 1.6273])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5381, -1.8329, -2.0454, -0.4483,  0.3010])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2613,  0.2531, -0.0555,  0.1310,  0.1226])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3387,  0.3342,  0.0108,  0.0341,  0.0601])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1409,  0.1948,  0.0054,  0.0173,  0.0309])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1409,  0.1948,  0.0054,  0.0173,  0.0309])
  [Mamba2] B (step) sample values: tensor([-0.0514, -0.1366,  0.0812, -0.1122, -0.0652])
  [Mamba2] C (step) sample values: tensor([-0.2278, -0.0170, -0.0396,  0.0516, -0.0715])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6851, -0.1380, -0.4118, -0.2678, -0.1244])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2771, 1.6725, 1.5271, 1.5869, 2.7893])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8271, 0.7939, 0.5332, 0.6538, 0.7067])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1409,  0.1948,  0.0054,  0.0173,  0.0309])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0020,  0.0053, -0.0032,  0.0044,  0.0025])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0028, -0.0142,  0.0021, -0.0149,  0.0075])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0984,  0.0206,  0.0491, -0.0263,  0.0106])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.6292,  0.7542,  0.0696,  0.0390,  0.1271])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.6292,  0.7542,  0.0696,  0.0390,  0.1271])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0208, -0.1565, -0.0083,  0.0217, -0.0027])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([76.5871])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1143])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0055, -0.0219, -0.0036,  0.0080, -0.0007])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0055, -0.0219, -0.0036,  0.0080, -0.0007])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1919,  0.4236, -0.2852, -0.6248, -0.0750])
  [Layer 8] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 8] Output sample values after mixer: tensor([-0.1919,  0.4236, -0.2852, -0.6248, -0.0750])
  [Layer 8] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 8] Residual connection sample values: tensor([-0.4711,  0.0958,  2.1096, -0.5509, -3.2306])
[Mamba2LMHeadModel] Processing layer 9/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([7.1744])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3733])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1618,  0.0254,  0.5361, -0.1897, -0.9664])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.6543, -1.5938, -1.0240,  0.0940, -1.0042])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.6543, -1.5938, -1.0240,  0.0940, -1.0042])
  [Mamba2] xBC (step) sample values: tensor([ 3.8332,  0.4908, -2.2037, -2.9841,  1.5938])
  [Mamba2] dt (step) sample values: tensor([2.0250, 3.2798, 1.2290, 2.8116, 1.2367])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.9979,  2.8399, -0.7172,  3.8332,  2.1030])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.7581,  0.0463, -0.3592, -0.1092,  0.1957])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-1.0116,  0.1368, -0.3634, -0.1025,  0.1771])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2698,  0.0731, -0.1490, -0.0486,  0.0964])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2698,  0.0731, -0.1490, -0.0486,  0.0964])
  [Mamba2] B (step) sample values: tensor([-0.0641, -0.0448,  0.0803, -0.1126,  0.1781])
  [Mamba2] C (step) sample values: tensor([-0.1141, -0.2599, -0.0592, -0.0954, -0.0176])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1701, -0.1135, -0.1054, -0.5864, -0.1497])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.5254, 4.1022, 3.0649, 1.5601, 1.6444])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6508, 0.6277, 0.7239, 0.4005, 0.7818])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2698,  0.0731, -0.1490, -0.0486,  0.0964])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0437,  0.0305, -0.0547,  0.0767, -0.1213])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0321,  0.0570, -0.3142,  0.2456, -0.4094])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1468,  0.0026, -0.0131, -0.0325,  0.0081])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.8696,  0.1984, -0.4124, -0.1628,  0.2663])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.8696,  0.1984, -0.4124, -0.1628,  0.2663])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.2309, -0.0534,  0.1116, -0.0080, -0.0717])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([21.5843])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2152])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0432, -0.0186,  0.0260, -0.0021, -0.0192])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0432, -0.0186,  0.0260, -0.0021, -0.0192])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3274,  0.7374, -0.3895,  0.3173, -0.3078])
  [Layer 9] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 9] Output sample values after mixer: tensor([-0.3274,  0.7374, -0.3895,  0.3173, -0.3078])
  [Layer 9] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 9] Residual connection sample values: tensor([-0.7985,  0.8332,  1.7201, -0.2336, -3.5383])
[Mamba2LMHeadModel] Processing layer 10/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([7.8418])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3571])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.2814,  0.2243,  0.4520, -0.0810, -1.0556])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.4135, -4.3577, -0.6203,  0.2907, -0.3933])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.4135, -4.3577, -0.6203,  0.2907, -0.3933])
  [Mamba2] xBC (step) sample values: tensor([ 1.6904,  3.9020, -4.2143,  3.6112, -1.4954])
  [Mamba2] dt (step) sample values: tensor([-0.9013,  0.5998,  0.4737, -2.2907, -1.6582])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.1222, -1.1176,  1.5412,  1.6904, -2.3391])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2558, -0.4576,  0.7924,  0.8309,  0.2508])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0855, -0.4816,  0.7545,  1.4349,  0.2997])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0446, -0.1839,  0.5131,  1.1590,  0.1721])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0446, -0.1839,  0.5131,  1.1590,  0.1721])
  [Mamba2] B (step) sample values: tensor([ 0.1650, -0.0740, -0.0500, -0.1439,  0.0460])
  [Mamba2] C (step) sample values: tensor([-0.2344,  0.0007, -0.1731, -0.1612, -0.0804])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0854, -0.0771, -0.0845, -0.0547, -0.0697])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.7860, 0.1623, 0.1418, 0.2653, 0.1352])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9351, 0.9876, 0.9881, 0.9856, 0.9906])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0446, -0.1839,  0.5131,  1.1590,  0.1721])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0058, -0.0026, -0.0018, -0.0050,  0.0016])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0227, -0.4755, -0.0518,  0.2726,  0.1014])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.7039,  0.0694,  0.8421,  6.8628,  0.0148])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.4868, -0.8260,  3.3407, 12.5059,  0.8529])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.4868, -0.8260,  3.3407, 12.5059,  0.8529])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0965,  0.0455, -0.7247,  2.0801, -0.1352])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([137.3857])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0853])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0050,  0.0051, -0.0884,  0.1951, -0.0154])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0050,  0.0051, -0.0884,  0.1951, -0.0154])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2767, -0.8092, -0.8078,  0.0725,  0.5496])
  [Layer 10] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 10] Output sample values after mixer: tensor([ 0.2767, -0.8092, -0.8078,  0.0725,  0.5496])
  [Layer 10] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 10] Residual connection sample values: tensor([-0.5218,  0.0240,  0.9123, -0.1610, -2.9888])
[Mamba2LMHeadModel] Processing layer 11/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([9.0340])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3327])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.1254,  0.0047,  0.1725, -0.0422, -0.6356])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.4321, -2.4037, -4.4416,  2.9086, -3.8445])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.4321, -2.4037, -4.4416,  2.9086, -3.8445])
  [Mamba2] xBC (step) sample values: tensor([ 0.2425, -0.5546, -2.3729,  0.3081, -0.1476])
  [Mamba2] dt (step) sample values: tensor([-3.5816, -2.9470, -2.2055, -0.0595,  0.0480])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6485,  0.2036,  0.0525,  0.2425, -0.0656])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0743,  0.0903,  0.6147, -0.0503, -0.3834])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0721,  0.2814,  0.6387,  0.0571, -0.2684])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0374,  0.1604,  0.4180,  0.0294, -0.1163])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0374,  0.1604,  0.4180,  0.0294, -0.1163])
  [Mamba2] B (step) sample values: tensor([-0.2784, -0.0235, -0.0489,  0.1735,  0.0120])
  [Mamba2] C (step) sample values: tensor([-0.0716, -0.2092,  0.0307, -0.0402, -0.2155])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2593, -0.1261, -0.1036, -0.2378, -0.4305])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0064, 0.0038, 0.0179, 0.5579, 0.7456])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9983, 0.9995, 0.9982, 0.8758, 0.7254])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0374,  0.1604,  0.4180,  0.0294, -0.1163])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-6.6265e-05, -5.5984e-06, -1.1628e-05,  4.1284e-05,  2.8560e-06])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1817,  0.0121,  0.0199, -0.0785,  0.1047])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([0.3817, 0.3759, 0.3420, 0.1923, 0.4994])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2639, -0.1299, -0.9764,  0.0996,  0.8662])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2639, -0.1299, -0.9764,  0.0996,  0.8662])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0728,  0.0259,  0.0505,  0.2748, -0.0698])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([34.0265])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1714])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0044,  0.0115,  0.0403,  0.0413, -0.0122])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0044,  0.0115,  0.0403,  0.0413, -0.0122])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0824, -0.1556, -0.1941,  0.1832, -0.1865])
  [Layer 11] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 11] Output sample values after mixer: tensor([ 0.0824, -0.1556, -0.1941,  0.1832, -0.1865])
  [Layer 11] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 11] Residual connection sample values: tensor([-0.4394, -0.1316,  0.7182,  0.0221, -3.1753])
[Mamba2LMHeadModel] Processing layer 12/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([9.8382])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3188])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0898, -0.0214,  0.1069,  0.0051, -0.5492])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.8984, -2.6728,  0.9065, -0.9678, -1.1445])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.8984, -2.6728,  0.9065, -0.9678, -1.1445])
  [Mamba2] xBC (step) sample values: tensor([-0.0516,  2.4704,  1.4103,  0.3505, -0.1481])
  [Mamba2] dt (step) sample values: tensor([-0.1748, -0.6692,  1.5199, -0.0788,  0.1532])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2865, -0.1646,  1.2160, -0.0516,  1.4185])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.3144, -0.1107, -0.0550, -0.1209,  0.5552])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2472, -0.9452, -0.1197, -0.1651,  0.3886])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1388, -0.2645, -0.0563, -0.0758,  0.2316])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1388, -0.2645, -0.0563, -0.0758,  0.2316])
  [Mamba2] B (step) sample values: tensor([ 0.2396,  0.0111,  0.0370,  0.6445, -0.0604])
  [Mamba2] C (step) sample values: tensor([-0.2414, -0.2600, -0.2761, -0.2703, -0.2785])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1609, -0.1475, -0.2713, -0.1155, -0.0902])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.8823, 0.3345, 2.3651, 1.5082, 0.0809])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8677, 0.9519, 0.5265, 0.8401, 0.9927])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1388, -0.2645, -0.0563, -0.0758,  0.2316])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0293,  0.0014,  0.0045,  0.0789, -0.0074])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0012,  0.0128,  0.0201, -0.0336, -0.0210])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0605, -0.8161,  0.1077,  0.1750,  0.4045])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2857, -1.2454,  0.0164,  0.0521,  0.7803])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2857, -1.2454,  0.0164,  0.0521,  0.7803])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0743,  0.2150,  0.0106, -0.0139, -0.2157])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([34.7718])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1696])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0191,  0.0323,  0.0031, -0.0077, -0.0478])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0191,  0.0323,  0.0031, -0.0077, -0.0478])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2151,  0.2709, -0.2646, -0.2845, -0.3527])
  [Layer 12] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 12] Output sample values after mixer: tensor([ 0.2151,  0.2709, -0.2646, -0.2845, -0.3527])
  [Layer 12] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 12] Residual connection sample values: tensor([-0.2243,  0.1393,  0.4536, -0.2624, -3.5280])
[Mamba2LMHeadModel] Processing layer 13/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([10.9717])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3019])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([-0.0366,  0.0186,  0.0575, -0.0461, -0.5164])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.3736,  0.1807, -1.4719, -0.9579,  0.7466])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.3736,  0.1807, -1.4719, -0.9579,  0.7466])
  [Mamba2] xBC (step) sample values: tensor([-0.5400,  1.6374, -1.8325, -2.0923, -1.1987])
  [Mamba2] dt (step) sample values: tensor([ 0.0736, -0.4651,  0.3191,  0.0218,  0.5992])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8991, -0.1159, -0.9278, -0.5400,  0.3613])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2869,  0.2302,  0.0130, -0.1001, -0.1142])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2248,  0.2115,  0.0208, -0.1118, -0.1446])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1250,  0.1169,  0.0105, -0.0528, -0.0671])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1250,  0.1169,  0.0105, -0.0528, -0.0671])
  [Mamba2] B (step) sample values: tensor([-0.1670, -0.0034,  0.0143,  0.3807, -0.0225])
  [Mamba2] C (step) sample values: tensor([-0.0024, -0.2779, -0.1292, -0.0487,  0.0438])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0234, -1.0903, -0.5085, -0.6785, -0.0251])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0564, 0.0063, 0.0117, 0.0054, 0.2622])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9987, 0.9931, 0.9941, 0.9964, 0.9934])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1250,  0.1169,  0.0105, -0.0528, -0.0671])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.1779e-03, -2.4050e-05,  1.0101e-04,  2.6851e-03, -1.5843e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0794,  0.0929, -0.2744,  0.0226, -0.0638])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2088, -0.1390, -0.0996, -0.0035,  0.1404])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2232, -0.1525, -0.1008,  0.0026,  0.1482])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2232, -0.1525, -0.1008,  0.0026,  0.1482])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0494, -0.0150,  0.0277, -0.0007,  0.0751])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.1535])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9311])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0231, -0.0046,  0.0290, -0.0017,  0.0403])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0231, -0.0046,  0.0290, -0.0017,  0.0403])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.4099, -0.1131, -0.0261,  0.1331, -0.0683])
  [Layer 13] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 13] Output sample values after mixer: tensor([ 0.4099, -0.1131, -0.0261,  0.1331, -0.0683])
  [Layer 13] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 13] Residual connection sample values: tensor([ 0.1857,  0.0262,  0.4276, -0.1293, -3.5963])
[Mamba2LMHeadModel] Processing layer 14/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([11.8264])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2908])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0256,  0.0031,  0.0499, -0.0202, -0.4654])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6917, -0.6927, -0.9869, -1.3867, -0.4206])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6917, -0.6927, -0.9869, -1.3867, -0.4206])
  [Mamba2] xBC (step) sample values: tensor([-0.9931, -1.0763, -1.0220, -1.9949, -0.2225])
  [Mamba2] dt (step) sample values: tensor([ 1.0976, -0.1806,  1.8326,  0.7781,  1.0242])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.4263,  0.5062, -0.8609, -0.9931, -1.0929])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2144, -0.3687, -0.4951,  0.5582,  0.0643])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.2848, -0.4181, -0.6869,  0.5106,  0.0505])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1626, -0.1660, -0.2299,  0.3191,  0.0259])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1626, -0.1660, -0.2299,  0.3191,  0.0259])
  [Mamba2] B (step) sample values: tensor([-0.0522,  0.0571,  0.0121, -0.0017, -0.1146])
  [Mamba2] C (step) sample values: tensor([-0.2067, -0.0030,  0.0625, -0.1424, -0.2046])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-7.2745, -0.0385, -2.2024, -0.0138, -5.3378])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0603, 0.0500, 0.0713, 0.1056, 0.0447])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.6447, 0.9981, 0.8547, 0.9985, 0.7877])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1626, -0.1660, -0.2299,  0.3191,  0.0259])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.1219e-04,  5.6021e-04,  1.1910e-04, -1.6237e-05, -1.1243e-03])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0012,  0.0016,  0.0007,  0.0003, -0.0017])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0252, -0.0268, -0.0376,  0.0429,  0.0004])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1532, -0.1574, -0.2185,  0.2940,  0.0208])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1532, -0.1574, -0.2185,  0.2940,  0.0208])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0354,  0.0363,  0.0586, -0.0815, -0.0035])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.5851])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.3074])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1090,  0.0781,  0.0863, -0.1739, -0.0094])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1090,  0.0781,  0.0863, -0.1739, -0.0094])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.7105,  0.0326, -0.8989,  0.3406, -0.0681])
  [Layer 14] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 14] Output sample values after mixer: tensor([ 0.7105,  0.0326, -0.8989,  0.3406, -0.0681])
  [Layer 14] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 14] Residual connection sample values: tensor([ 0.8961,  0.0588, -0.4713,  0.2112, -3.6644])
[Mamba2LMHeadModel] Processing layer 15/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([13.7589])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2696])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1470,  0.0079, -0.0638,  0.0411, -0.5610])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.6143,  1.4566,  0.8679, -2.1492, -3.3599])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.6143,  1.4566,  0.8679, -2.1492, -3.3599])
  [Mamba2] xBC (step) sample values: tensor([ 1.0987,  0.1175,  1.3799,  1.0573, -0.6432])
  [Mamba2] dt (step) sample values: tensor([ 1.6337, -1.2636,  0.1794,  0.9809,  1.1338])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.1523,  1.0156, -0.4345,  1.0987, -0.8299])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1127, -0.0140,  0.4276,  0.1994,  0.0832])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.4489, -0.0382,  1.7528,  0.6420,  0.0697])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1749, -0.0187,  1.4939,  0.4207,  0.0361])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1749, -0.0187,  1.4939,  0.4207,  0.0361])
  [Mamba2] B (step) sample values: tensor([-0.0457,  0.0548,  0.0955, -0.0895, -0.0455])
  [Mamba2] C (step) sample values: tensor([-0.0495,  0.0064,  0.1875, -0.0324, -0.0477])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.4414, -0.0592, -0.7390, -0.0051, -0.0087])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2838, 0.1503, 0.0261, 0.1242, 0.3819])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5002, 0.9911, 0.9809, 0.9994, 0.9967])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1749, -0.0187,  1.4939,  0.4207,  0.0361])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0023, -0.0027, -0.0047,  0.0044,  0.0023])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0046, -0.0040, -0.0048,  0.0053,  0.0046])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0067, -0.0028,  0.0620,  0.0093,  0.0049])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3190, -0.0362,  2.7298,  0.7606,  0.0693])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3190, -0.0362,  2.7298,  0.7606,  0.0693])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0855, -0.0428,  1.6686, -0.1707, -0.0078])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([3.3458])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.5467])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1032, -0.0377,  0.4323, -0.1162, -0.0096])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1032, -0.0377,  0.4323, -0.1162, -0.0096])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3190,  0.5675,  0.0788, -0.0295, -0.0012])
  [Layer 15] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 15] Output sample values after mixer: tensor([-0.3190,  0.5675,  0.0788, -0.0295, -0.0012])
  [Layer 15] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 15] Residual connection sample values: tensor([ 0.5772,  0.6263, -0.3926,  0.1817, -3.6656])
[Mamba2LMHeadModel] Processing layer 16/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([16.2886])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2478])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0646,  0.0579, -0.0338,  0.0258, -0.3876])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.6553, -0.5735, -4.7336, -0.3494, -1.9253])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.6553, -0.5735, -4.7336, -0.3494, -1.9253])
  [Mamba2] xBC (step) sample values: tensor([-1.1816, -0.1228,  0.0136, -0.0399, -1.4960])
  [Mamba2] dt (step) sample values: tensor([1.2812, 2.7514, 0.4588, 4.0266, 2.3069])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1827,  0.4267, -2.4088, -1.1816,  0.2212])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2407,  0.0229, -0.0783, -0.3154,  0.0839])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2425,  0.0317,  0.0584, -0.3536,  0.0915])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1066,  0.0161,  0.0301, -0.1459,  0.0478])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1066,  0.0161,  0.0301, -0.1459,  0.0478])
  [Mamba2] B (step) sample values: tensor([-0.0269, -0.0848,  0.1874, -0.0004,  0.0179])
  [Mamba2] C (step) sample values: tensor([ 0.0106,  0.0720,  0.3270, -0.2008, -0.1768])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.1349e-03, -3.0370e-03, -2.7156e+00, -4.1511e-03, -4.2926e-01])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2626, 0.7286, 0.0371, 0.9304, 0.0112])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9997, 0.9978, 0.9042, 0.9961, 0.9952])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1066,  0.0161,  0.0301, -0.1459,  0.0478])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 7.5216e-04,  2.3732e-03, -5.2461e-03,  1.1330e-05, -5.0064e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0374,  0.0969,  0.0265,  0.0014, -0.0009])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0574,  0.0092,  0.2183,  0.0691, -0.0056])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0822,  0.0054,  0.2113,  0.1030, -0.0167])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0822,  0.0054,  0.2113,  0.1030, -0.0167])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0355, -0.0011, -0.0087, -0.0149,  0.0041])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.2223])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.1208])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0330, -0.0006, -0.0186, -0.0055,  0.0045])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0330, -0.0006, -0.0186, -0.0055,  0.0045])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0209,  0.9179, -0.2399,  0.2933,  0.0911])
  [Layer 16] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 16] Output sample values after mixer: tensor([-0.0209,  0.9179, -0.2399,  0.2933,  0.0911])
  [Layer 16] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 16] Residual connection sample values: tensor([ 0.5563,  1.5442, -0.6324,  0.4750, -3.5745])
[Mamba2LMHeadModel] Processing layer 17/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([17.5103])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2390])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0898,  0.2144, -0.0877,  0.0878, -0.5314])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-5.2683, -3.2112, -1.9812, -0.8285, -2.6949])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-5.2683, -3.2112, -1.9812, -0.8285, -2.6949])
  [Mamba2] xBC (step) sample values: tensor([ 0.8429, -0.7235, -1.3937,  1.1032, -2.7001])
  [Mamba2] dt (step) sample values: tensor([1.3825, 1.6097, 1.3495, 2.2467, 1.1582])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1690,  0.6221,  0.2083,  0.8429,  0.9230])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0052, -0.0959, -0.4095,  0.2399, -0.6741])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1003, -0.0738, -0.5240,  0.2744, -0.5789])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0476, -0.0355, -0.1949,  0.1559, -0.2079])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0476, -0.0355, -0.1949,  0.1559, -0.2079])
  [Mamba2] B (step) sample values: tensor([ 0.0113,  0.0143, -0.2282,  0.0214, -0.2175])
  [Mamba2] C (step) sample values: tensor([-0.0106,  0.1092, -0.2338, -0.1239,  0.2842])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3863, -0.8773, -1.4027, -0.6828, -0.3905])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4674, 0.3596, 0.4290, 1.3073, 0.7867])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.5231, 0.7294, 0.5478, 0.4096, 0.7355])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0476, -0.0355, -0.1949,  0.1559, -0.2079])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0003, -0.0003,  0.0051, -0.0005,  0.0048])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0004, -0.0094,  0.0183,  0.0054,  0.0126])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0407,  0.0115, -0.1097,  0.0560, -0.1361])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1662, -0.0821, -0.6229,  0.4666, -0.6838])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1662, -0.0821, -0.6229,  0.4666, -0.6838])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0045,  0.0102,  0.1496, -0.1175,  0.1166])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([12.1312])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2871])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0025,  0.0058,  0.0900, -0.0870,  0.0796])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0025,  0.0058,  0.0900, -0.0870,  0.0796])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.5204,  0.4104,  0.0164, -0.1400, -0.2927])
  [Layer 17] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 17] Output sample values after mixer: tensor([ 0.5204,  0.4104,  0.0164, -0.1400, -0.2927])
  [Layer 17] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 17] Residual connection sample values: tensor([ 1.0766,  1.9546, -0.6160,  0.3350, -3.8672])
[Mamba2LMHeadModel] Processing layer 18/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([19.4865])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2265])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1170,  0.1837, -0.0570,  0.0442, -0.3719])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4521, -0.3870, -1.6064, -0.7551, -1.7062])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4521, -0.3870, -1.6064, -0.7551, -1.7062])
  [Mamba2] xBC (step) sample values: tensor([ 0.0209, -0.7432,  0.6477, -1.0505,  1.3369])
  [Mamba2] dt (step) sample values: tensor([0.7969, 4.2725, 4.7472, 2.6975, 2.2059])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6630, -0.8443, -0.3103,  0.0209,  1.6620])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0249,  0.8439, -0.1318, -0.0591,  0.1323])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0342,  0.4460, -0.1205, -0.0286,  0.0801])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0174,  0.2719, -0.0566, -0.0141,  0.0417])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0174,  0.2719, -0.0566, -0.0141,  0.0417])
  [Mamba2] B (step) sample values: tensor([-0.0162,  0.0741, -0.1433, -0.0972,  0.0586])
  [Mamba2] C (step) sample values: tensor([ 0.0247,  0.1729, -0.2041, -0.0037,  0.0232])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.3195e-03, -6.5336e+00, -1.4897e+01, -1.3796e-03, -2.0873e-03])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2717, 5.3885, 6.1955, 1.0012, 0.8474])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9937e-01, 5.1323e-16, 8.2517e-41, 9.9862e-01, 9.9823e-01])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0174,  0.2719, -0.0566, -0.0141,  0.0417])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-7.6875e-05,  3.5040e-04, -6.7809e-04, -4.5968e-04,  2.7703e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0041, -0.0009,  0.0939, -0.0579,  0.0172])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0297, -0.1181,  0.0396,  0.0182,  0.0344])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0311, -0.1397,  0.0440,  0.0193,  0.0311])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0311, -0.1397,  0.0440,  0.0193,  0.0311])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0055,  0.0219, -0.0118, -0.0047, -0.0082])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([12.0997])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2875])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0077,  0.0076, -0.0037, -0.0034, -0.0028])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0077,  0.0076, -0.0037, -0.0034, -0.0028])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.7768, -0.6511, -0.1479,  0.3489, -0.0504])
  [Layer 18] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 18] Output sample values after mixer: tensor([-0.7768, -0.6511, -0.1479,  0.3489, -0.0504])
  [Layer 18] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 18] Residual connection sample values: tensor([ 0.2998,  1.3035, -0.7639,  0.6839, -3.9175])
[Mamba2LMHeadModel] Processing layer 19/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([20.3606])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2216])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0396,  0.1430, -0.0847,  0.1117, -0.4595])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4875, -1.3738, -1.5545, -0.2657, -0.0979])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4875, -1.3738, -1.5545, -0.2657, -0.0979])
  [Mamba2] xBC (step) sample values: tensor([-0.3103,  0.4284,  1.8721,  0.9325,  0.3841])
  [Mamba2] dt (step) sample values: tensor([-0.4865,  0.7559,  0.8356, -0.3765, -0.8867])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.6270, -0.6527, -1.3606, -0.3103,  1.8049])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2230, -0.0751,  0.4516, -0.2997,  0.1135])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2745, -0.0746,  0.4378, -0.5074,  0.1123])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1185, -0.0359,  0.2661, -0.1907,  0.0593])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1185, -0.0359,  0.2661, -0.1907,  0.0593])
  [Mamba2] B (step) sample values: tensor([-0.0212, -0.1510,  0.0702,  0.2363, -0.1049])
  [Mamba2] C (step) sample values: tensor([-0.2311, -0.1260, -0.0271,  0.0254, -0.1115])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1739, -1.5063, -1.5725, -0.1983, -0.0768])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.9559, 0.5283, 0.6206, 1.1538, 0.1669])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8468, 0.4512, 0.3768, 0.7955, 0.9873])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1185, -0.0359,  0.2661, -0.1907,  0.0593])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0024,  0.0171, -0.0080, -0.0268,  0.0119])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0087,  0.0094,  0.0646, -0.0957, -0.1548])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2398,  0.0373,  0.2009, -0.3857, -0.0707])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.4203, -0.0174,  0.6060, -0.6760,  0.0196])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.4203, -0.0174,  0.6060, -0.6760,  0.0196])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1269,  0.0048, -0.1643,  0.0779, -0.0009])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([16.9730])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2427])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0360,  0.0024, -0.0958,  0.0187, -0.0008])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0360,  0.0024, -0.0958,  0.0187, -0.0008])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 1.0991,  0.6550, -0.3374, -0.4458, -0.2021])
  [Layer 19] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 19] Output sample values after mixer: tensor([ 1.0991,  0.6550, -0.3374, -0.4458, -0.2021])
  [Layer 19] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 19] Residual connection sample values: tensor([ 1.3990,  1.9585, -1.1012,  0.2381, -4.1196])
[Mamba2LMHeadModel] Processing layer 20/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([21.6241])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2150])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1110,  0.1422, -0.0800,  0.0231, -0.3192])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.1828, -0.6185,  0.4260, -0.1998, -0.1106])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.1828, -0.6185,  0.4260, -0.1998, -0.1106])
  [Mamba2] xBC (step) sample values: tensor([ 0.3584, -0.0170, -0.7391, -0.0562, -0.5799])
  [Mamba2] dt (step) sample values: tensor([-0.1100, -0.3204,  0.1068,  1.2532,  2.6737])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.0315,  0.0304,  0.1990,  0.3584, -1.0853])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0803,  0.0455, -0.2800,  0.0321, -0.1581])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0658,  0.0074, -0.4596,  0.0111, -0.2046])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0340,  0.0037, -0.1779,  0.0056, -0.0919])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0340,  0.0037, -0.1779,  0.0056, -0.0919])
  [Mamba2] B (step) sample values: tensor([ 0.0052, -0.0126, -0.0382,  0.0303,  0.0433])
  [Mamba2] C (step) sample values: tensor([-0.2254, -0.1809, -0.2186, -0.1025, -0.2350])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.0858e-01, -2.9306e+00, -5.2962e+00, -1.2326e+01, -8.1593e-03])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0064, 0.0191, 0.0659, 0.2449, 0.4852])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9980, 0.9455, 0.7053, 0.0489, 0.9960])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0340,  0.0037, -0.1779,  0.0056, -0.0919])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.1340e-06, -2.7181e-06, -8.2504e-06,  6.5339e-06,  9.3622e-06])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.0778e-04, -2.3495e-04, -1.7849e-04,  1.0047e-04, -4.2838e-05])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0016,  0.0009, -0.0010,  0.0022, -0.0001])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0296,  0.0039, -0.1473,  0.0068, -0.0757])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0296,  0.0039, -0.1473,  0.0068, -0.0757])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0082, -0.0008, -0.0380, -0.0006,  0.0040])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1189])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.8999])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0596, -0.0053, -0.1634, -0.0043,  0.0183])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0596, -0.0053, -0.1634, -0.0043,  0.0183])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2453,  0.0380,  0.2106, -0.0124,  0.2454])
  [Layer 20] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 20] Output sample values after mixer: tensor([ 0.2453,  0.0380,  0.2106, -0.0124,  0.2454])
  [Layer 20] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 20] Residual connection sample values: tensor([ 1.6443,  1.9965, -0.8907,  0.2257, -3.8742])
[Mamba2LMHeadModel] Processing layer 21/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([21.9373])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2135])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1774,  0.1949, -0.0891,  0.0288, -0.4019])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3367, -0.9175, -1.3154,  0.3484, -1.4191])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3367, -0.9175, -1.3154,  0.3484, -1.4191])
  [Mamba2] xBC (step) sample values: tensor([-0.5207,  2.1367,  1.1764, -0.7389, -0.2371])
  [Mamba2] dt (step) sample values: tensor([-0.3321, -0.0295, -1.3911, -2.3783, -0.2786])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.2195, -0.0095, -1.2507, -0.5207, -0.5812])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2890,  0.6014, -0.0509,  0.2055, -0.0707])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.6464,  0.5039, -0.0766,  0.1074, -0.1247])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2222,  0.3141, -0.0368,  0.0566, -0.0585])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2222,  0.3141, -0.0368,  0.0566, -0.0585])
  [Mamba2] B (step) sample values: tensor([-0.0947, -0.2546, -0.0775,  0.0425, -0.0371])
  [Mamba2] C (step) sample values: tensor([-0.0147, -0.1188, -0.1227, -0.0450,  0.0112])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3228, -0.3764, -0.1595, -0.1054, -0.3757])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.5743, 0.5656, 0.2693, 0.0501, 0.4460])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8308, 0.8082, 0.9580, 0.9947, 0.8457])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2222,  0.3141, -0.0368,  0.0566, -0.0585])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0121,  0.0325,  0.0099, -0.0054,  0.0047])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.1229,  0.1434,  0.0661,  0.1035,  0.0167])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2275,  0.1167, -0.0326, -0.0205,  0.0284])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.6972,  0.7806, -0.1104,  0.0991, -0.0951])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.6972,  0.7806, -0.1104,  0.0991, -0.0951])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0978, -0.2045,  0.0307,  0.0202,  0.0263])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([7.9492])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3547])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0722, -0.1908,  0.0324,  0.0150,  0.0168])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0722, -0.1908,  0.0324,  0.0150,  0.0168])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.7341, -0.1753,  0.1336,  0.7260,  0.2957])
  [Layer 21] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 21] Output sample values after mixer: tensor([-0.7341, -0.1753,  0.1336,  0.7260,  0.2957])
  [Layer 21] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 21] Residual connection sample values: tensor([ 0.9102,  1.8212, -0.7570,  0.9517, -3.5785])
[Mamba2LMHeadModel] Processing layer 22/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([24.5236])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2019])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0950,  0.1759, -0.0732,  0.1174, -0.3620])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3790, -0.3204,  0.1269, -3.5732,  0.4102])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3790, -0.3204,  0.1269, -3.5732,  0.4102])
  [Mamba2] xBC (step) sample values: tensor([-0.9930,  0.8321, -1.2858, -0.7782, -0.8325])
  [Mamba2] dt (step) sample values: tensor([-1.6985, -3.5827, -0.8927, -1.1734, -0.4507])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.6606, -1.1092,  0.1399, -0.9930, -0.7795])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0080, -0.1367, -0.0472, -0.1776, -0.0752])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0162, -0.0721, -0.0346, -0.1959, -0.0746])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0082, -0.0348, -0.0170, -0.0884, -0.0359])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0082, -0.0348, -0.0170, -0.0884, -0.0359])
  [Mamba2] B (step) sample values: tensor([-0.2767,  0.0916,  0.3132,  0.0535, -0.0393])
  [Mamba2] C (step) sample values: tensor([-0.2671,  0.0618, -0.2177, -0.0897, -0.1434])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0709, -0.0702, -0.0699, -0.0895, -0.3897])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1128, 0.0315, 0.0490, 0.1138, 0.5117])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9920, 0.9978, 0.9966, 0.9899, 0.8192])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0082, -0.0348, -0.0170, -0.0884, -0.0359])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-2.5487e-04,  8.4384e-05,  2.8846e-04,  4.9302e-05, -3.6205e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0140, 0.0109, 0.0024, 0.0188, 0.0405])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0053,  0.0785, -0.0494,  0.0007, -0.0149])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0194,  0.1384, -0.0201,  0.1531,  0.0470])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0194,  0.1384, -0.0201,  0.1531,  0.0470])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0030, -0.0187, -0.0014, -0.0149,  0.0116])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([16.1645])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2487])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0020, -0.0053, -0.0009, -0.0146,  0.0073])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0020, -0.0053, -0.0009, -0.0146,  0.0073])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.0838,  0.2715,  0.2640,  0.1947, -0.0996])
  [Layer 22] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 22] Output sample values after mixer: tensor([-0.0838,  0.2715,  0.2640,  0.1947, -0.0996])
  [Layer 22] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 22] Residual connection sample values: tensor([ 0.8263,  2.0927, -0.4930,  1.1464, -3.6781])
[Mamba2LMHeadModel] Processing layer 23/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([25.1267])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1995])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0725,  0.1658, -0.0411,  0.1236, -0.3002])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.0629, -0.2721, -1.1325, -1.2714, -1.1458])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.0629, -0.2721, -1.1325, -1.2714, -1.1458])
  [Mamba2] xBC (step) sample values: tensor([-1.1757,  0.9539,  1.6967,  0.1922, -0.3389])
  [Mamba2] dt (step) sample values: tensor([-0.9733, -0.7360, -0.4909, -1.0398, -0.9311])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1181, -0.7288, -0.3220, -1.1757, -0.2399])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1282,  0.2034,  0.1683, -0.0281, -0.0657])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1619,  0.1958,  0.1264, -0.0118, -0.0701])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0744,  0.1075,  0.0672, -0.0059, -0.0338])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0744,  0.1075,  0.0672, -0.0059, -0.0338])
  [Mamba2] B (step) sample values: tensor([0.6081, 0.0985, 0.0566, 0.6006, 0.0067])
  [Mamba2] C (step) sample values: tensor([ 0.0742, -0.0911,  0.0956,  0.1166,  0.0902])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1232, -0.2255, -0.2420, -0.0956, -0.2396])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0278, 0.1087, 0.1327, 0.0269, 0.0727])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9966, 0.9758, 0.9684, 0.9974, 0.9827])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0744,  0.1075,  0.0672, -0.0059, -0.0338])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.2573e-03, -2.0367e-04, -1.1708e-04, -1.2418e-03, -1.3756e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0217,  0.0102, -0.0019,  0.0644, -0.0112])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0523,  0.0480,  0.2365, -0.0439,  0.0188])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0557,  0.0430,  0.2334, -0.0437,  0.0204])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0557,  0.0430,  0.2334, -0.0437,  0.0204])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0017, -0.0051, -0.0644,  0.0122, -0.0056])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.2195])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6712])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0011, -0.0101, -0.2120,  0.0401, -0.0104])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0011, -0.0101, -0.2120,  0.0401, -0.0104])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.2577,  0.1700,  0.1396,  0.3492,  0.0296])
  [Layer 23] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 23] Output sample values after mixer: tensor([-0.2577,  0.1700,  0.1396,  0.3492,  0.0296])
  [Layer 23] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 23] Residual connection sample values: tensor([ 0.5686,  2.2627, -0.3534,  1.4956, -3.6485])
[Mamba2LMHeadModel] Processing layer 24/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([25.5240])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1979])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0622,  0.2196, -0.0373,  0.1876, -0.3674])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.2517,  0.3865, -0.2198, -0.3219, -0.9246])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.2517,  0.3865, -0.2198, -0.3219, -0.9246])
  [Mamba2] xBC (step) sample values: tensor([-0.5895, -1.8712, -1.6109, -0.6265,  1.3586])
  [Mamba2] dt (step) sample values: tensor([-1.4694, -1.2501, -1.6294, -1.4341, -1.5325])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.7085,  0.3718, -0.3341, -0.5895, -0.0937])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.2607, -0.2189, -0.1989, -0.1536, -0.3396])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.3877, -0.1215, -0.2010, -0.2327, -0.3328])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.2310, -0.0571, -0.0904, -0.1029, -0.1390])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.2310, -0.0571, -0.0904, -0.1029, -0.1390])
  [Mamba2] B (step) sample values: tensor([-0.2517, -0.0598,  0.0166,  0.0365, -0.0047])
  [Mamba2] C (step) sample values: tensor([ 0.0418, -0.2197, -0.2399, -0.1837, -0.2613])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6296, -0.1967, -0.1434, -0.1402, -0.2238])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2382, 0.2808, 0.1446, 0.4163, 0.1203])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8607, 0.9463, 0.9795, 0.9433, 0.9734])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.2310, -0.0571, -0.0904, -0.1029, -0.1390])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0138, -0.0033,  0.0009,  0.0020, -0.0003])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0262,  0.0015, -0.0007,  0.0079,  0.0003])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0702, -0.0192, -0.0481, -0.0471, -0.0095])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 1.2014, -0.2988, -0.4911, -0.5510, -0.6901])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 1.2014, -0.2988, -0.4911, -0.5510, -0.6901])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1323, -0.0688,  0.0481,  0.0745,  0.1812])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([21.4473])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.2159])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0315, -0.0512,  0.0314,  0.0362,  0.0816])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0315, -0.0512,  0.0314,  0.0362,  0.0816])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.2536, -0.2143,  0.1371, -0.3474, -0.3813])
  [Layer 24] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 24] Output sample values after mixer: tensor([ 0.2536, -0.2143,  0.1371, -0.3474, -0.3813])
  [Layer 24] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 24] Residual connection sample values: tensor([ 0.8222,  2.0484, -0.2163,  1.1482, -4.0297])
[Mamba2LMHeadModel] Processing layer 25/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([26.1367])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1956])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0618,  0.1428, -0.0151,  0.0988, -0.2837])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.9888, -0.6089, -0.8792, -0.3729, -0.4927])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.9888, -0.6089, -0.8792, -0.3729, -0.4927])
  [Mamba2] xBC (step) sample values: tensor([ 0.2129, -0.6215, -0.8204, -0.6297, -0.5530])
  [Mamba2] dt (step) sample values: tensor([-1.5079, -0.7891, -0.9887, -1.1889, -1.1774])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5788,  1.1918,  0.9603,  0.2129, -0.1598])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0899,  0.0545,  0.1837, -0.1778, -0.1676])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0706,  0.0579,  0.2863, -0.2829, -0.2062])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0365,  0.0298,  0.1635, -0.1216, -0.0925])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0365,  0.0298,  0.1635, -0.1216, -0.0925])
  [Mamba2] B (step) sample values: tensor([ 0.0091, -0.0469, -0.0295,  0.0108,  0.0573])
  [Mamba2] C (step) sample values: tensor([-0.2762, -0.2626, -0.2721, -0.2725, -0.1747])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1626, -0.3327, -0.3294, -0.2016, -0.1541])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1613, 0.1762, 0.1417, 0.1547, 0.1937])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9741, 0.9431, 0.9544, 0.9693, 0.9706])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0365,  0.0298,  0.1635, -0.1216, -0.0925])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 5.3354e-05, -2.7599e-04, -1.7391e-04,  6.3326e-05,  3.3727e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0041,  0.0141,  0.0152,  0.0058, -0.0153])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-7.1443e-03,  5.8474e-05, -1.7719e-05, -5.1720e-02, -1.5471e-02])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0264,  0.0274,  0.1502, -0.1634, -0.1005])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0264,  0.0274,  0.1502, -0.1634, -0.1005])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0071, -0.0059, -0.0387,  0.0249,  0.0188])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.0348])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9830])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0242, -0.0157, -0.0867,  0.0312,  0.0363])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0242, -0.0157, -0.0867,  0.0312,  0.0363])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3092, -0.2464, -0.2906, -0.4449, -0.1094])
  [Layer 25] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 25] Output sample values after mixer: tensor([-0.3092, -0.2464, -0.2906, -0.4449, -0.1094])
  [Layer 25] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 25] Residual connection sample values: tensor([ 0.5130,  1.8020, -0.5069,  0.7034, -4.1391])
[Mamba2LMHeadModel] Processing layer 26/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([26.8590])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1930])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0473,  0.1548, -0.0458,  0.0779, -0.3652])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4756,  0.6770, -0.5942,  1.9158,  0.7777])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4756,  0.6770, -0.5942,  1.9158,  0.7777])
  [Mamba2] xBC (step) sample values: tensor([-1.2693, -0.2780, -1.2236,  0.9261, -0.3524])
  [Mamba2] dt (step) sample values: tensor([-0.3002, -0.8608, -1.8844, -1.7144, -0.9831])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5482, -0.2418,  0.6041, -1.2693, -0.5526])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2812, -0.1069,  0.2808,  0.2585, -0.0978])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3722, -0.1608,  0.2555,  0.1952, -0.3656])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1519, -0.0739,  0.1440,  0.1071, -0.1498])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1519, -0.0739,  0.1440,  0.1071, -0.1498])
  [Mamba2] B (step) sample values: tensor([ 0.3725, -0.0940, -0.0544, -0.1580,  0.0164])
  [Mamba2] C (step) sample values: tensor([ 0.2116, -0.2041, -0.1100, -0.1739, -0.2531])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.3298, -0.0634, -0.2289, -0.1264, -0.0584])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4407, 0.0849, 0.4622, 0.4244, 0.2339])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.8647, 0.9946, 0.8996, 0.9478, 0.9864])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1519, -0.0739,  0.1440,  0.1071, -0.1498])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0249,  0.0063,  0.0036,  0.0106, -0.0011])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0477,  0.0061, -0.0066, -0.0121, -0.0074])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.2618, -0.3565, -0.0007,  0.0957, -0.4570])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.8743, -0.6547,  0.5800,  0.5276, -1.0610])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.8743, -0.6547,  0.5800,  0.5276, -1.0610])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.1594, -0.2939, -0.1226,  0.8810, -0.5654])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([26.0313])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1960])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0740, -0.0951, -0.0524,  0.4138, -0.1955])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0740, -0.0951, -0.0524,  0.4138, -0.1955])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.3232, -0.0762,  0.0980,  0.4670, -0.5286])
  [Layer 26] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 26] Output sample values after mixer: tensor([ 0.3232, -0.0762,  0.0980,  0.4670, -0.5286])
  [Layer 26] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 26] Residual connection sample values: tensor([ 0.8363,  1.7258, -0.4090,  1.1703, -4.6677])
[Mamba2LMHeadModel] Processing layer 27/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([27.8198])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1896])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0661,  0.1298, -0.0312,  0.1069, -0.3714])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4271, -0.0999, -0.0390,  0.4417, -0.8398])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4271, -0.0999, -0.0390,  0.4417, -0.8398])
  [Mamba2] xBC (step) sample values: tensor([ 0.2198, -0.9294,  0.5376, -0.8365,  0.0215])
  [Mamba2] dt (step) sample values: tensor([-1.0249, -1.5836, -0.9573, -0.3223,  0.2903])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5523,  0.5896, -0.3301,  0.2198,  0.1930])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0569, -0.2724,  0.1183,  0.5411, -0.0067])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0736, -0.3241,  0.0632,  0.3409, -0.0049])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0355, -0.1360,  0.0326,  0.1992, -0.0024])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0355, -0.1360,  0.0326,  0.1992, -0.0024])
  [Mamba2] B (step) sample values: tensor([-0.0295,  0.1799,  0.0202,  0.0304, -0.1450])
  [Mamba2] C (step) sample values: tensor([-0.2313,  0.1205,  0.0498, -0.0849, -0.1860])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5626, -0.0303, -0.7559, -1.1613, -0.0406])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0283, 0.0093, 0.0036, 0.0564, 0.0422])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9842, 0.9997, 0.9973, 0.9366, 0.9983])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0355, -0.1360,  0.0326,  0.1992, -0.0024])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.9557e-05, -1.8022e-04, -2.0280e-05, -3.0485e-05,  1.4526e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0040, -0.0063, -0.0055, -0.0211,  0.0013])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0154, -0.0127,  0.0005, -0.0022,  0.0051])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-8.5940e-02, -2.8318e-01,  6.5334e-02,  3.9402e-01,  2.9815e-04])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-8.5940e-02, -2.8318e-01,  6.5334e-02,  3.9402e-01,  2.9815e-04])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 1.4492e-02,  1.3437e-02, -1.2485e-03,  1.0594e-01, -7.5511e-05])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.0565])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6973])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0232,  0.0169, -0.0023,  0.0496, -0.0002])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0232,  0.0169, -0.0023,  0.0496, -0.0002])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0768,  0.2009,  0.3272, -0.3206,  0.3876])
  [Layer 27] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 27] Output sample values after mixer: tensor([ 0.0768,  0.2009,  0.3272, -0.3206,  0.3876])
  [Layer 27] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 27] Residual connection sample values: tensor([ 0.9131,  1.9267, -0.0818,  0.8498, -4.2800])
[Mamba2LMHeadModel] Processing layer 28/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([28.2600])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1881])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.0613,  0.1244, -0.0054,  0.0667, -0.2781])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.2132, -0.4874, -0.3849, -0.7229, -0.3055])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.2132, -0.4874, -0.3849, -0.7229, -0.3055])
  [Mamba2] xBC (step) sample values: tensor([-0.0167, -0.3284,  1.0231, -0.9954,  0.1554])
  [Mamba2] dt (step) sample values: tensor([-0.9875, -0.8771, -0.7674, -0.5950, -0.5480])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.6444, -0.0201, -0.5044, -0.0167,  1.0505])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0601, -0.1213,  0.2767,  0.2704,  0.0344])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0678, -0.2107,  0.1475,  0.1804, -0.0312])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0328, -0.0943,  0.0792,  0.0983, -0.0154])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0328, -0.0943,  0.0792,  0.0983, -0.0154])
  [Mamba2] B (step) sample values: tensor([-0.0839, -0.0671, -0.0353, -0.0880,  0.5396])
  [Mamba2] C (step) sample values: tensor([-0.0256,  0.0170,  0.0422, -0.1173, -0.0662])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5442, -0.1843, -0.1064, -0.1124, -0.2523])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0708, 0.2433, 0.5261, 0.5498, 0.3050])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9622, 0.9562, 0.9455, 0.9401, 0.9259])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0328, -0.0943,  0.0792,  0.0983, -0.0154])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 1.9467e-04,  1.5555e-04,  8.1860e-05,  2.0413e-04, -1.2517e-03])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0026,  0.0005, -0.0031,  0.0009, -0.0077])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0037, -0.0124,  0.0005,  0.0119, -0.0003])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0648, -0.1884,  0.1482,  0.1952, -0.0289])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0648, -0.1884,  0.1482,  0.1952, -0.0289])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0180,  0.0349, -0.0231, -0.0461,  0.0038])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.7731])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.1373])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0418,  0.0761, -0.0481, -0.1108,  0.0105])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0418,  0.0761, -0.0481, -0.1108,  0.0105])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.7571, -0.2038,  0.7358, -0.2848,  0.0179])
  [Layer 28] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 28] Output sample values after mixer: tensor([ 0.7571, -0.2038,  0.7358, -0.2848,  0.0179])
  [Layer 28] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 28] Residual connection sample values: tensor([ 1.6702,  1.7229,  0.6540,  0.5650, -4.2622])
[Mamba2LMHeadModel] Processing layer 29/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([28.7911])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1864])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1370,  0.1395,  0.0541,  0.0573, -0.3512])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.8265, -1.2819, -0.1141,  0.2787, -0.6846])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.8265, -1.2819, -0.1141,  0.2787, -0.6846])
  [Mamba2] xBC (step) sample values: tensor([-0.4954,  0.9411, -0.6429, -0.6740, -0.8953])
  [Mamba2] dt (step) sample values: tensor([-0.1020,  0.0683,  0.4808,  0.2129, -0.2421])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.5166, -0.2557,  0.2696, -0.4954,  0.4978])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0765, -0.2582,  0.0975,  0.1212,  0.1310])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0625, -0.3339, -0.0408,  0.4879,  1.6310])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0303, -0.1393, -0.0200,  0.3023,  1.3640])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0303, -0.1393, -0.0200,  0.3023,  1.3640])
  [Mamba2] B (step) sample values: tensor([ 0.0661, -0.1015,  0.0126, -0.0417, -0.0097])
  [Mamba2] C (step) sample values: tensor([-0.0622, -0.1630, -0.1720, -0.1634, -0.0640])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.6542, -0.1369, -1.4589, -0.3682, -0.1218])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0754, 0.0590, 0.1488, 0.1262, 0.2355])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9519, 0.9920, 0.8048, 0.9546, 0.9717])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0303, -0.1393, -0.0200,  0.3023,  1.3640])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.5073e-04,  2.3148e-04, -2.8816e-05,  9.5161e-05,  2.2232e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0005,  0.0018, -0.0013, -0.0015,  0.0021])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0002, -0.0061, -0.0054,  0.0115,  0.0781])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0511, -0.2403, -0.0390,  0.5196,  2.3710])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0511, -0.2403, -0.0390,  0.5196,  2.3710])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0294,  0.0669,  0.0021,  0.0824, -0.5441])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.4912])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.8189])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0787,  0.1399,  0.0033,  0.1581, -0.1617])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0787,  0.1399,  0.0033,  0.1581, -0.1617])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1056, -0.0460,  0.2509,  0.0502, -0.1719])
  [Layer 29] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 29] Output sample values after mixer: tensor([ 0.1056, -0.0460,  0.2509,  0.0502, -0.1719])
  [Layer 29] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 29] Residual connection sample values: tensor([ 1.7758,  1.6769,  0.9049,  0.6151, -4.4341])
[Mamba2LMHeadModel] Processing layer 30/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([29.2100])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1850])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1340,  0.1208,  0.0665,  0.0530, -0.3253])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.1754, -0.7515, -0.1533, -2.0278,  1.4158])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.1754, -0.7515, -0.1533, -2.0278,  1.4158])
  [Mamba2] xBC (step) sample values: tensor([-1.4863, -0.4116, -0.7105,  0.2246, -0.4036])
  [Mamba2] dt (step) sample values: tensor([-0.6379, -0.1583, -0.6375, -0.3464, -0.9814])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.9774, -0.4668,  0.1417, -1.4863,  1.0288])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0017,  0.2096,  0.2456,  0.1414,  0.6558])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0445,  0.1677,  0.8208,  0.1908,  0.5632])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0218,  0.0909,  0.5700,  0.1045,  0.3589])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0218,  0.0909,  0.5700,  0.1045,  0.3589])
  [Mamba2] B (step) sample values: tensor([ 0.0375,  0.0887, -0.0399, -0.0374, -0.0941])
  [Mamba2] C (step) sample values: tensor([-0.0798,  0.0219, -0.1816, -0.2380, -0.1937])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2038, -0.3668, -0.2078, -0.0952, -0.4265])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3111, 0.2061, 0.2582, 0.0712, 0.1035])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9386, 0.9272, 0.9478, 0.9932, 0.9568])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0218,  0.0909,  0.5700,  0.1045,  0.3589])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0003, -0.0006,  0.0003,  0.0003,  0.0006])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0060, -0.0222, -0.0098, -0.0067,  0.0463])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0803, -0.0521,  0.7674,  0.1729, -0.1399])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0839, -0.0371,  0.8616,  0.1901, -0.0806])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0839, -0.0371,  0.8616,  0.1901, -0.0806])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0067,  0.0089, -0.0610, -0.0448, -0.0918])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([2.1561])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.6810])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0115,  0.0168, -0.0694, -0.0848, -0.0636])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0115,  0.0168, -0.0694, -0.0848, -0.0636])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.6456,  0.2146, -0.0151, -1.4259, -0.5717])
  [Layer 30] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 30] Output sample values after mixer: tensor([ 0.6456,  0.2146, -0.0151, -1.4259, -0.5717])
  [Layer 30] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 30] Residual connection sample values: tensor([ 2.4214,  1.8914,  0.8897, -0.8108, -5.0059])
[Mamba2LMHeadModel] Processing layer 31/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([30.4202])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1813])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1212,  0.0960,  0.0447, -0.0460, -0.2511])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.9022, -0.2850, -0.0537, -0.0146,  0.2981])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.9022, -0.2850, -0.0537, -0.0146,  0.2981])
  [Mamba2] xBC (step) sample values: tensor([-0.5254,  0.2243,  0.4251,  0.3370, -0.1716])
  [Mamba2] dt (step) sample values: tensor([1.2075, 1.4750, 2.0785, 1.7714, 0.5816])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2352,  0.2394,  0.2241, -0.5254, -0.0450])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1015, -0.0542, -0.1052, -0.1298, -0.1576])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0986, -0.0193, -0.1157, -0.1479, -0.2179])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0517, -0.0095, -0.0545, -0.0685, -0.0971])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0517, -0.0095, -0.0545, -0.0685, -0.0971])
  [Mamba2] B (step) sample values: tensor([-0.0367, -0.0089, -0.0045,  0.0377,  0.0173])
  [Mamba2] C (step) sample values: tensor([-0.1121,  0.0624,  0.0169, -0.1548, -0.1316])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-9.5766e-03, -1.0642e-02, -2.6350e+01, -6.4468e+02, -1.6547e-02])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1462, 0.2331, 2.6985, 2.8643, 0.1097])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9860e-01, 9.9752e-01, 1.3155e-31, 0.0000e+00, 9.9819e-01])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0517, -0.0095, -0.0545, -0.0685, -0.0971])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-2.7748e-04, -6.7206e-05, -3.4097e-05,  2.8527e-04,  1.3080e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0161, -0.0108,  0.0077,  0.0158,  0.0061])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0228, -0.0249, -0.0118,  0.0019, -0.1185])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0293, -0.0237, -0.0049,  0.0105, -0.1063])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0293, -0.0237, -0.0049,  0.0105, -0.1063])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 7.6278e-03,  2.8966e-03,  1.2838e-04, -7.5769e-05, -1.8181e-02])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.1601])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([2.4992])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0759,  0.0261,  0.0012, -0.0031, -0.0478])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0759,  0.0261,  0.0012, -0.0031, -0.0478])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3753,  0.2190,  0.0398,  0.0247, -0.2130])
  [Layer 31] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 31] Output sample values after mixer: tensor([-0.3753,  0.2190,  0.0398,  0.0247, -0.2130])
  [Layer 31] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 31] Residual connection sample values: tensor([ 2.0461,  2.1104,  0.9295, -0.7861, -5.2189])
[Mamba2LMHeadModel] Processing layer 32/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([30.4411])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1812])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1734,  0.1750,  0.0765, -0.0776, -0.4487])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.0553, -0.7785, -0.6717,  1.9161, -1.4841])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.0553, -0.7785, -0.6717,  1.9161, -1.4841])
  [Mamba2] xBC (step) sample values: tensor([-0.1921,  0.5130,  0.8441, -1.7479,  1.6376])
  [Mamba2] dt (step) sample values: tensor([-1.5190, -0.8378, -0.3967, -0.8286, -1.1228])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0156,  0.3560, -1.2513, -0.1921, -0.0857])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.4849, -0.0066, -0.0466,  0.2411, -0.4244])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.4713, -0.3745, -0.0487,  0.2177, -0.4367])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.2901, -0.1526, -0.0237,  0.1206, -0.1714])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.2901, -0.1526, -0.0237,  0.1206, -0.1714])
  [Mamba2] B (step) sample values: tensor([ 0.0365,  0.0886,  0.1404, -0.0243, -0.1014])
  [Mamba2] C (step) sample values: tensor([-0.2367, -0.0705, -0.2007, -0.2628, -0.2767])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.0662, -0.0811, -0.5879, -0.0956, -0.5448])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.3183, 0.5950, 0.3014, 0.4762, 0.2366])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9791, 0.9529, 0.8376, 0.9555, 0.8791])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.2901, -0.1526, -0.0237,  0.1206, -0.1714])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 0.0034,  0.0082,  0.0130, -0.0022, -0.0094])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0195, 0.1151, 0.1139, 0.2211, 0.1230])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.2520, -0.9047,  0.0448,  0.6721, -0.2365])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2455, -0.9012,  0.0454,  0.6693, -0.2326])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2455, -0.9012,  0.0454,  0.6693, -0.2326])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0669,  0.2208, -0.0103,  1.1180,  0.0638])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([27.5951])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1904])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0143,  0.1028, -0.0048,  0.3251,  0.0209])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0143,  0.1028, -0.0048,  0.3251,  0.0209])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.1274,  0.4338, -0.0584, -0.5371,  0.1664])
  [Layer 32] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 32] Output sample values after mixer: tensor([ 0.1274,  0.4338, -0.0584, -0.5371,  0.1664])
  [Layer 32] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 32] Residual connection sample values: tensor([ 2.1735,  2.5441,  0.8712, -1.3231, -5.0525])
[Mamba2LMHeadModel] Processing layer 33/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([30.4519])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1812])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1893,  0.2164,  0.0755, -0.1211, -0.4450])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.4377, -0.2670,  2.6219, -0.9274,  0.5643])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.4377, -0.2670,  2.6219, -0.9274,  0.5643])
  [Mamba2] xBC (step) sample values: tensor([-2.6469,  0.4788,  1.0251,  0.8952,  2.8062])
  [Mamba2] dt (step) sample values: tensor([-1.2742, -1.1979, -0.5550, -0.1495, -2.0792])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2932,  1.7261,  0.5544, -2.6469, -0.4517])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.6408,  0.1236,  0.1523,  0.2993,  0.5562])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.9111,  0.0870,  0.1390,  0.1764,  0.5218])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2613,  0.0454,  0.0743,  0.0959,  0.3275])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2613,  0.0454,  0.0743,  0.0959,  0.3275])
  [Mamba2] B (step) sample values: tensor([-0.2610, -0.0069, -0.0322,  0.0382, -0.1235])
  [Mamba2] C (step) sample values: tensor([-0.0433, -0.1556,  0.1136, -0.1321,  0.0165])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-13.0444,  -1.3850,  -0.1668,  -0.2359,  -5.2550])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0040, 0.0015, 0.0322, 0.0453, 0.0010])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9496, 0.9980, 0.9946, 0.9894, 0.9945])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2613,  0.0454,  0.0743,  0.0959,  0.3275])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.7038e-04,  7.1521e-06,  3.3333e-05, -3.9611e-05,  1.2800e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 2.3332e-04,  1.3883e-04, -6.6617e-05, -1.2674e-04, -2.9699e-04])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 1.3098e-04, -7.3027e-06,  2.9607e-06, -1.2908e-04, -1.1469e-04])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2797,  0.0486,  0.0796,  0.1026,  0.3507])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2797,  0.0486,  0.0796,  0.1026,  0.3507])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0480, -0.0056,  0.1945, -0.0270,  0.1261])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.6880])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.2056])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.1596, -0.0181,  0.8552, -0.0997,  0.5269])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.1596, -0.0181,  0.8552, -0.0997,  0.5269])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.0792, -0.5244,  0.5503, -0.8897, -0.0688])
  [Layer 33] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 33] Output sample values after mixer: tensor([ 0.0792, -0.5244,  0.5503, -0.8897, -0.0688])
  [Layer 33] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 33] Residual connection sample values: tensor([ 2.2527,  2.0198,  1.4215, -2.2129, -5.1213])
[Mamba2LMHeadModel] Processing layer 34/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([33.1100])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1738])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1662,  0.1468,  0.1090, -0.1656, -0.3859])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.3932, -1.4248, -1.1794, -0.2333, -1.2020])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.3932, -1.4248, -1.1794, -0.2333, -1.2020])
  [Mamba2] xBC (step) sample values: tensor([-0.5501, -0.9520,  0.0655, -0.5851,  1.1020])
  [Mamba2] dt (step) sample values: tensor([ 0.7416, -0.5876, -0.8521, -0.8614, -0.4628])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.7558, -0.5601,  0.0642, -0.5501, -1.7026])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1296,  0.6845, -0.0044,  0.1158,  0.2498])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1730,  0.5873, -0.0384,  0.0347,  0.1758])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0790,  0.3775, -0.0188,  0.0176,  0.0956])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0790,  0.3775, -0.0188,  0.0176,  0.0956])
  [Mamba2] B (step) sample values: tensor([-0.0101,  0.0148, -0.0802,  0.0360, -0.0685])
  [Mamba2] C (step) sample values: tensor([-0.2705, -0.1887, -0.0364, -0.0461, -0.0839])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2225, -0.1537, -0.8169, -0.8591, -2.0730])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0273, 0.0040, 0.0868, 0.0433, 0.1141])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9939, 0.9994, 0.9316, 0.9635, 0.7894])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0790,  0.3775, -0.0188,  0.0176,  0.0956])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.1876e-05, -3.2023e-05,  1.7323e-04, -7.7793e-05,  1.4787e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0030,  0.0073,  0.0036, -0.0066,  0.0106])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0015,  0.0203,  0.0216,  0.0020, -0.0052])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1540,  0.7630, -0.0154,  0.0367,  0.1829])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1540,  0.7630, -0.0154,  0.0367,  0.1829])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0361, -0.2108,  0.0043, -0.0038, -0.0508])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.2308])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9014])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0871, -0.2839,  0.0086, -0.0090, -0.1289])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0871, -0.2839,  0.0086, -0.0090, -0.1289])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3671, -0.8178,  0.3876,  0.4518,  0.1020])
  [Layer 34] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 34] Output sample values after mixer: tensor([-0.3671, -0.8178,  0.3876,  0.4518,  0.1020])
  [Layer 34] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 34] Residual connection sample values: tensor([ 1.8856,  1.2019,  1.8091, -1.7610, -5.0193])
[Mamba2LMHeadModel] Processing layer 35/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([34.4371])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1704])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1804,  0.1141,  0.1706, -0.1796, -0.4774])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.3031, -0.5782,  0.6364, -3.4243,  0.2642])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.3031, -0.5782,  0.6364, -3.4243,  0.2642])
  [Mamba2] xBC (step) sample values: tensor([ 0.4521,  1.3669, -0.9235,  0.3651, -1.4567])
  [Mamba2] dt (step) sample values: tensor([-2.2162, -2.9453, -1.7095, -2.1818, -1.6784])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.0327, -1.1649,  0.2697,  0.4521,  0.9422])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1066,  0.3059, -0.1459,  0.0558, -0.3301])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1580,  0.2842, -0.1733,  0.0310, -0.4423])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0728,  0.1622, -0.0792,  0.0157, -0.1730])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0728,  0.1622, -0.0792,  0.0157, -0.1730])
  [Mamba2] B (step) sample values: tensor([0.1893, 0.1378, 0.2890, 0.0326, 0.0506])
  [Mamba2] C (step) sample values: tensor([ 0.1876, -0.0795, -0.1989, -0.2515,  0.0089])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.2054, -0.1417, -0.1071, -0.1460, -0.2581])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.4165, 0.3794, 0.2241, 0.7732, 0.2346])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9180, 0.9477, 0.9763, 0.8932, 0.9413])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0728,  0.1622, -0.0792,  0.0157, -0.1730])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0057, -0.0042, -0.0088, -0.0010, -0.0015])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0741, -0.0219,  0.0044, -0.0196, -0.0394])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1048,  0.3038, -0.5472, -0.0581, -0.5652])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2954,  0.7285, -0.7546, -0.0168, -1.0183])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2954,  0.7285, -0.7546, -0.0168, -1.0183])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0380, -0.1513, -0.3140,  0.0018, -0.1522])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([32.7258])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1748])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0253, -0.0976, -0.0700,  0.0017, -0.0847])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0253, -0.0976, -0.0700,  0.0017, -0.0847])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1858,  0.4973,  1.4231, -0.4098,  0.9654])
  [Layer 35] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 35] Output sample values after mixer: tensor([-0.1858,  0.4973,  1.4231, -0.4098,  0.9654])
  [Layer 35] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 35] Residual connection sample values: tensor([ 1.6998,  1.6992,  3.2322, -2.1709, -4.0539])
[Mamba2LMHeadModel] Processing layer 36/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([36.4971])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1655])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1407,  0.1438,  0.2691, -0.1918, -0.3437])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.3571, -0.8371, -1.8281, -0.3070, -1.2720])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.3571, -0.8371, -1.8281, -0.3070, -1.2720])
  [Mamba2] xBC (step) sample values: tensor([-0.6127,  1.4653, -0.2721, -0.4805, -1.8001])
  [Mamba2] dt (step) sample values: tensor([-0.8670,  0.1201,  0.0433,  0.1644,  0.7804])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.9087, -1.8936,  0.2715, -0.6127,  1.4494])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.1468,  0.3393, -0.0795, -0.1391, -0.2875])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1871,  0.2217, -0.1416, -0.2838, -0.2996])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.1023,  0.1231, -0.0658, -0.1219, -0.1275])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.1023,  0.1231, -0.0658, -0.1219, -0.1275])
  [Mamba2] B (step) sample values: tensor([-0.0593,  0.0783,  0.1961,  0.0370, -0.0700])
  [Mamba2] C (step) sample values: tensor([-6.3978e-02,  9.6805e-02, -1.5981e-05,  3.1025e-03, -4.6788e-02])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.8655, -5.6378, -3.8976, -2.4260, -3.6937])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0300, 0.0193, 0.0189, 0.0465, 0.0534])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9177, 0.8970, 0.9288, 0.8933, 0.8210])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.1023,  0.1231, -0.0658, -0.1219, -0.1275])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0002,  0.0002,  0.0006,  0.0001, -0.0002])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0041, -0.0009, -0.0026,  0.0023,  0.0007])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0036,  0.0085, -0.0087, -0.0111, -0.0080])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.3173,  0.3860, -0.2104, -0.3849, -0.3991])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.3173,  0.3860, -0.2104, -0.3849, -0.3991])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0882, -0.0976,  0.0533,  0.0501,  0.1111])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([4.4601])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4735])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0800, -0.1892,  0.0713,  0.0715,  0.1806])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0800, -0.1892,  0.0713,  0.0715,  0.1806])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.4330,  0.8000, -0.0880, -1.9098,  0.1584])
  [Layer 36] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 36] Output sample values after mixer: tensor([ 0.4330,  0.8000, -0.0880, -1.9098,  0.1584])
  [Layer 36] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 36] Residual connection sample values: tensor([ 2.1327,  2.4992,  3.1442, -4.0806, -3.8955])
[Mamba2LMHeadModel] Processing layer 37/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([38.6669])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1608])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1654,  0.1990,  0.2558, -0.3241, -0.3099])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.7062,  0.2131, -0.3662,  0.4604, -2.0077])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.7062,  0.2131, -0.3662,  0.4604, -2.0077])
  [Mamba2] xBC (step) sample values: tensor([ 1.8357, -1.0357,  1.0039,  0.2163,  1.7049])
  [Mamba2] dt (step) sample values: tensor([ 1.4979,  0.6399, -1.2592, -0.7518,  1.4293])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.1605, -0.0615,  0.5326,  1.8357, -0.9572])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.4796,  0.2668, -0.3641, -0.0625,  0.1248])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.5573,  0.2027, -0.4487, -0.0276,  0.0412])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.2030,  0.1116, -0.1749, -0.0136,  0.0210])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.2030,  0.1116, -0.1749, -0.0136,  0.0210])
  [Mamba2] B (step) sample values: tensor([-0.0506, -0.0122,  0.1314, -0.0479,  0.0310])
  [Mamba2] C (step) sample values: tensor([-0.2691, -0.1546, -0.1236, -0.2670, -0.1256])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.8179, -31.1699, -39.0195,  -0.4619,  -0.6477])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0028, 0.0137, 0.0010, 0.0003, 0.0069])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9949, 0.6531, 0.9636, 0.9998, 0.9955])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.2030,  0.1116, -0.1749, -0.0136,  0.0210])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 2.8953e-05,  6.9693e-06, -7.5206e-05,  2.7450e-05, -1.7736e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0004,  0.0004, -0.0007,  0.0009, -0.0006])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0015,  0.0033,  0.0001, -0.0003, -0.0002])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.3733,  0.2077, -0.3201, -0.0253,  0.0383])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.3733,  0.2077, -0.3201, -0.0253,  0.0383])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.1765,  0.0245,  0.0480, -0.0071, -0.0091])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.6530])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.7778])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.5113,  0.0513,  0.0946, -0.0222, -0.0151])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.5113,  0.0513,  0.0946, -0.0222, -0.0151])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.3327,  0.9457, -0.4439,  1.9025,  0.3092])
  [Layer 37] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 37] Output sample values after mixer: tensor([-0.3327,  0.9457, -0.4439,  1.9025,  0.3092])
  [Layer 37] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 37] Residual connection sample values: tensor([ 1.8000,  3.4450,  2.7002, -2.1781, -3.5863])
[Mamba2LMHeadModel] Processing layer 38/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([43.5369])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1516])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1399,  0.2677,  0.2088, -0.1640, -0.2805])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.9008, -0.9550, -0.0703, -2.6321,  0.8218])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.9008, -0.9550, -0.0703, -2.6321,  0.8218])
  [Mamba2] xBC (step) sample values: tensor([ 0.0187, -0.8985,  1.2857,  0.0067,  0.4823])
  [Mamba2] dt (step) sample values: tensor([-2.6056, -1.8854, -2.5793, -2.3130, -0.3540])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.4508, -0.2220,  1.8935,  0.0187, -1.5423])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.3364,  0.3928,  0.2532, -0.0612,  0.0806])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.3388,  0.1035,  0.1631, -0.1044,  0.1736])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.1410,  0.0544,  0.0882, -0.0495,  0.0943])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.1410,  0.0544,  0.0882, -0.0495,  0.0943])
  [Mamba2] B (step) sample values: tensor([ 0.0090,  2.6039,  0.0639, -0.0395,  0.0721])
  [Mamba2] C (step) sample values: tensor([-0.2550,  0.0254, -0.1927, -0.2476, -0.1187])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.1704, -2.0832, -0.1351, -0.4124, -3.5315])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0864, 0.0189, 0.0698, 0.0338, 0.0700])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9854, 0.9613, 0.9906, 0.9862, 0.7809])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.1410,  0.0544,  0.0882, -0.0495,  0.0943])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0001, -0.0317, -0.0008,  0.0005, -0.0009])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0017,  0.0796, -0.0078, -0.0055, -0.0003])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.1810, -0.1998, -0.0535, -0.1016,  0.2667])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.2017, -0.1919, -0.0406, -0.1088,  0.2805])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.2017, -0.1919, -0.0406, -0.1088,  0.2805])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([0.0498, 0.0509, 0.0014, 0.0192, 0.1601])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([4.0859])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.4947])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([0.0777, 0.0534, 0.0016, 0.0445, 0.2565])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([0.0777, 0.0534, 0.0016, 0.0445, 0.2565])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.6079,  1.5166,  4.3245, -1.8827, -2.9994])
  [Layer 38] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 38] Output sample values after mixer: tensor([ 2.6079,  1.5166,  4.3245, -1.8827, -2.9994])
  [Layer 38] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 38] Residual connection sample values: tensor([ 4.4079,  4.9616,  7.0247, -4.0608, -6.5858])
[Mamba2LMHeadModel] Processing layer 39/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([54.6920])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1352])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2261,  0.2768,  0.3801, -0.2304, -0.3546])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0840, -0.1482, -0.6228,  0.5668, -0.8977])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0840, -0.1482, -0.6228,  0.5668, -0.8977])
  [Mamba2] xBC (step) sample values: tensor([ 0.2805, -0.2773,  0.1553, -0.2442,  1.0678])
  [Mamba2] dt (step) sample values: tensor([3.2569, 1.1314, 1.5795, 1.4063, 1.5582])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.2505, -0.1133,  0.2238,  0.2805,  0.3019])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0529,  0.0306,  0.0325, -0.0550,  0.3274])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1173, -0.0302,  0.0477,  0.4826,  0.3240])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0621, -0.0148,  0.0244,  0.2984,  0.1880])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0621, -0.0148,  0.0244,  0.2984,  0.1880])
  [Mamba2] B (step) sample values: tensor([-0.0177, -0.0292, -0.2761,  0.0828, -0.0199])
  [Mamba2] C (step) sample values: tensor([-0.1922, -0.1803,  0.0029, -0.0627, -0.2720])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.7351e+02, -2.3790e+00, -2.6079e-03, -1.4979e+00, -6.3307e-02])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([2.2005, 0.6726, 0.9018, 0.4376, 0.0417])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.0000, 0.2018, 0.9977, 0.5192, 0.9974])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0621, -0.0148,  0.0244,  0.2984,  0.1880])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-0.0024, -0.0040, -0.0377,  0.0113, -0.0027])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-0.0024, -0.0040, -0.0377,  0.0113, -0.0027])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0120, -0.0029,  0.0047,  0.0574,  0.0362])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.2929, -0.0700,  0.1153,  1.4078,  0.8868])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.2929, -0.0700,  0.1153,  1.4078,  0.8868])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0128,  0.0048, -0.0251,  0.5091, -0.2305])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([6.6945])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.3865])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0232,  0.0082, -0.0406,  0.8048, -0.4395])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0232,  0.0082, -0.0406,  0.8048, -0.4395])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 0.4308, -1.8484, -2.2632, -2.4431, -0.0870])
  [Layer 39] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 39] Output sample values after mixer: tensor([ 0.4308, -1.8484, -2.2632, -2.4431, -0.0870])
  [Layer 39] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 39] Residual connection sample values: tensor([ 4.8387,  3.1132,  4.7615, -6.5039, -6.6727])
[Mamba2LMHeadModel] Processing layer 40/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([56.8683])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1326])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.3153,  0.2165,  0.3243, -0.4058, -0.4502])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.1099,  1.6674,  1.8230,  0.3744,  0.7495])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.1099,  1.6674,  1.8230,  0.3744,  0.7495])
  [Mamba2] xBC (step) sample values: tensor([-1.4362,  0.8097,  0.2737,  0.9419,  0.3202])
  [Mamba2] dt (step) sample values: tensor([ 1.2694,  0.0602,  0.0953, -4.2112,  0.1375])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-2.0063, -3.3809, -0.4869, -1.4362,  0.3283])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2185, -0.1455,  0.0484, -0.1086,  0.0488])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.1128, -0.1940, -0.0232, -0.1202,  0.0504])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0596, -0.0876, -0.0115, -0.0565,  0.0258])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0596, -0.0876, -0.0115, -0.0565,  0.0258])
  [Mamba2] B (step) sample values: tensor([-0.0491, -0.2784,  0.0293, -0.0448, -0.0230])
  [Mamba2] C (step) sample values: tensor([-0.1689, -0.2412, -0.1519, -0.2103, -0.2481])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-0.5267, -0.6301, -0.3878, -2.7909, -0.4284])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([6.2193e-02, 1.3753e-02, 3.0434e-02, 9.0262e-05, 1.8447e-02])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9678, 0.9914, 0.9883, 0.9997, 0.9921])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0596, -0.0876, -0.0115, -0.0565,  0.0258])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.8203e-04, -1.0320e-03,  1.0871e-04, -1.6613e-04, -8.5212e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0013, -0.0316, -0.0060, -0.0008, -0.0007])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 5.8364e-03, -2.3881e-03, -1.0249e-03, -4.6461e-05,  4.6940e-03])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.1534, -0.2193, -0.0294, -0.1398,  0.0686])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.1534, -0.2193, -0.0294, -0.1398,  0.0686])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0350, -0.3076, -0.0462, -0.0310,  0.0349])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([1.1852])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([0.9186])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.1031, -1.0729, -0.1640, -0.0871,  0.1614])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.1031, -1.0729, -0.1640, -0.0871,  0.1614])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 4.9175, -4.2562,  1.6236,  1.1216, -1.0271])
  [Layer 40] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 40] Output sample values after mixer: tensor([ 4.9175, -4.2562,  1.6236,  1.1216, -1.0271])
  [Layer 40] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 40] Residual connection sample values: tensor([ 9.7562, -1.1430,  6.3852, -5.3823, -7.6998])
[Mamba2LMHeadModel] Processing layer 41/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([77.2486])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1138])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.3878, -0.0486,  0.2618, -0.2114, -0.3067])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5706, -1.7059, -0.8493, -0.1262,  0.5843])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5706, -1.7059, -0.8493, -0.1262,  0.5843])
  [Mamba2] xBC (step) sample values: tensor([-0.6208,  0.4439, -0.9344,  1.9194, -1.3108])
  [Mamba2] dt (step) sample values: tensor([-0.2760, -1.1412, -1.7036,  0.3763,  0.1196])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.5914, -0.4399, -0.3109, -0.6208, -0.1944])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1538, -0.0951, -0.2004, -0.3087,  0.2888])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1854,  0.0273, -0.2003, -0.4014,  0.2792])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0841,  0.0138, -0.0902, -0.1610,  0.1590])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0841,  0.0138, -0.0902, -0.1610,  0.1590])
  [Mamba2] B (step) sample values: tensor([ 0.0068, -0.1039,  0.0226, -0.0909, -0.0469])
  [Mamba2] C (step) sample values: tensor([-0.1580, -0.0786, -0.1000,  0.1911, -0.2450])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.0531, -1.1356, -0.8719, -1.5713, -1.7431])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0543, 0.0718, 0.0194, 0.1790, 0.0918])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9444, 0.9217, 0.9832, 0.7548, 0.8521])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0841,  0.0138, -0.0902, -0.1610,  0.1590])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-3.1267e-05,  4.7511e-04, -1.0344e-04,  4.1550e-04,  2.1428e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-3.0369e-05, -7.1666e-03, -6.1770e-03,  4.1092e-04, -4.9521e-03])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0094,  0.0055,  0.0037, -0.0119,  0.0041])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1171,  0.0231, -0.1116, -0.2178,  0.2074])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1171,  0.0231, -0.1116, -0.2178,  0.2074])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0427, -0.0061,  0.0284,  0.0129,  0.0778])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0860])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.4107])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.4659, -0.0884,  0.3574,  0.1969,  1.1051])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.4659, -0.0884,  0.3574,  0.1969,  1.1051])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.5205,  2.0387,  4.5749,  2.4246,  2.6763])
  [Layer 41] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 41] Output sample values after mixer: tensor([-0.5205,  2.0387,  4.5749,  2.4246,  2.6763])
  [Layer 41] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 41] Residual connection sample values: tensor([ 9.2357,  0.8957, 10.9601, -2.9577, -5.0235])
[Mamba2LMHeadModel] Processing layer 42/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([94.3426])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.1030])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.3424,  0.0357,  0.4344, -0.1095, -0.1960])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.2545,  0.9141,  0.6219, -1.3001, -0.1191])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.2545,  0.9141,  0.6219, -1.3001, -0.1191])
  [Mamba2] xBC (step) sample values: tensor([ 0.9824,  0.2727,  0.4177, -0.2390,  0.5268])
  [Mamba2] dt (step) sample values: tensor([ 0.1637, -0.9511, -1.6497, -2.2506,  0.3850])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 0.0918, -0.2839, -0.0387,  0.9824,  2.7927])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.2041,  0.0826, -0.1037,  0.0407,  0.1266])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.2250,  0.0468, -0.0991,  0.0369,  0.0804])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0999,  0.0240, -0.0471,  0.0188,  0.0418])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0999,  0.0240, -0.0471,  0.0188,  0.0418])
  [Mamba2] B (step) sample values: tensor([ 0.0233, -0.0302,  0.0700, -0.0093, -0.0025])
  [Mamba2] C (step) sample values: tensor([-0.0498, -0.1233, -0.1391, -0.1847, -0.2771])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-2.2458, -1.7474, -3.3797, -1.2264, -1.3705])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.1210, 0.0524, 0.0263, 0.0022, 0.1118])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7621, 0.9125, 0.9150, 0.9973, 0.8579])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0999,  0.0240, -0.0471,  0.0188,  0.0418])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-2.8177e-04,  3.6496e-04, -8.4626e-04,  1.1181e-04,  2.9759e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-4.0990e-04,  2.5629e-04, -6.0170e-04, -6.7283e-05, -1.4979e-06])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0031,  0.0119, -0.0101, -0.0054, -0.0023])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.1397,  0.0447, -0.0745,  0.0203,  0.0549])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.1397,  0.0447, -0.0745,  0.0203,  0.0549])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0200,  0.0292, -0.0301, -0.0056, -0.0031])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0980])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([3.1949])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.2508,  0.3511, -0.3737, -0.0709, -0.0263])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.2508,  0.3511, -0.3737, -0.0709, -0.0263])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.2287,  0.5417, -0.7559, -4.7617,  1.2822])
  [Layer 42] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 42] Output sample values after mixer: tensor([ 2.2287,  0.5417, -0.7559, -4.7617,  1.2822])
  [Layer 42] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 42] Residual connection sample values: tensor([11.4645,  1.4373, 10.2042, -7.7194, -3.7414])
[Mamba2LMHeadModel] Processing layer 43/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([107.8577])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0963])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.3900,  0.0535,  0.3637, -0.2624, -0.1294])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.0017,  0.2345, -0.3179, -0.3205, -0.4490])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.0017,  0.2345, -0.3179, -0.3205, -0.4490])
  [Mamba2] xBC (step) sample values: tensor([ 0.2271,  0.4533,  0.4329, -0.5501, -0.3317])
  [Mamba2] dt (step) sample values: tensor([-1.5621, -0.2593, -0.9708, -0.0743, -0.8833])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([0.5369, 0.3107, 0.0510, 0.2271, 0.6877])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0461, -0.0642, -0.0804, -0.1053, -0.0532])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0315, -0.1184, -0.1084, -0.1532, -0.0615])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0160, -0.0557, -0.0513, -0.0707, -0.0298])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0160, -0.0557, -0.0513, -0.0707, -0.0298])
  [Mamba2] B (step) sample values: tensor([-0.0341, -0.0141, -0.1900, -0.2653, -0.0262])
  [Mamba2] C (step) sample values: tensor([-0.2323, -0.1798, -0.1935, -0.2355, -0.0815])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-3.7046, -2.6553, -8.2110, -2.2382, -4.0926])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0132, 0.0618, 0.0242, 0.3328, 0.0005])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9521, 0.8487, 0.8201, 0.4748, 0.9978])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0160, -0.0557, -0.0513, -0.0707, -0.0298])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-7.2297e-06, -2.9931e-06, -4.0285e-05, -5.6254e-05, -5.5521e-06])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0017, -0.0002, -0.0010,  0.0022, -0.0018])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([0.0028, 0.0011, 0.0002, 0.0021, 0.0007])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0292, -0.0908, -0.0843, -0.1145, -0.0485])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0292, -0.0908, -0.0843, -0.1145, -0.0485])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 2.4867e-05, -1.1891e-02,  1.1293e-02,  1.5440e-02,  8.4788e-03])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0535])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([4.3244])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0003, -0.1782,  0.1354,  0.1865,  0.1058])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0003, -0.1782,  0.1354,  0.1865,  0.1058])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-2.1525,  1.1604, -0.0239, -0.9284,  0.1831])
  [Layer 43] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 43] Output sample values after mixer: tensor([-2.1525,  1.1604, -0.0239, -0.9284,  0.1831])
  [Layer 43] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 43] Residual connection sample values: tensor([ 9.3120,  2.5977, 10.1802, -8.6478, -3.5583])
[Mamba2LMHeadModel] Processing layer 44/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([125.1125])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0894])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2980,  0.0860,  0.3377, -0.2705, -0.1153])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-1.0921,  0.7797,  0.6706, -0.1488,  0.0990])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-1.0921,  0.7797,  0.6706, -0.1488,  0.0990])
  [Mamba2] xBC (step) sample values: tensor([-0.2240, -0.1411, -0.2800,  0.0048,  1.0230])
  [Mamba2] dt (step) sample values: tensor([-0.5700, -0.6135, -0.7260, -0.4853, -2.0248])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8355, -0.2039,  0.9756, -0.2240, -0.7204])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0452,  0.0280, -0.0498,  0.0056,  0.1903])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0238, -0.0290, -0.0785, -0.0076,  0.1969])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0117, -0.0143, -0.0377, -0.0038,  0.1081])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0117, -0.0143, -0.0377, -0.0038,  0.1081])
  [Mamba2] B (step) sample values: tensor([ 0.0743, -0.2610, -0.2714,  0.1912,  0.0761])
  [Mamba2] C (step) sample values: tensor([-0.1615, -0.2785, -0.1806,  0.0799, -0.2162])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-4.6876, -0.9753, -0.8255, -1.2938, -0.4953])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0573, 0.0243, 0.0119, 0.0282, 0.0010])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.7643, 0.9766, 0.9902, 0.9642, 0.9995])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0117, -0.0143, -0.0377, -0.0038,  0.1081])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.0023e-05,  1.7566e-04,  1.8266e-04, -1.2872e-04, -5.1215e-05])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([ 0.0007, -0.0027, -0.0025, -0.0003, -0.0014])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0021, -0.0016, -0.0005,  0.0033,  0.0007])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0183, -0.0264, -0.0661, -0.0033,  0.1886])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0183, -0.0264, -0.0661, -0.0033,  0.1886])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([ 0.0050, -0.0141, -0.0293,  0.0002,  0.0098])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0530])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([4.3427])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([ 0.0703, -0.1811, -0.4761,  0.0032,  0.1342])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([ 0.0703, -0.1811, -0.4761,  0.0032,  0.1342])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-1.4947e+00,  1.7730e+00,  3.0887e-01,  2.6519e-03, -4.5148e+00])
  [Layer 44] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 44] Output sample values after mixer: tensor([-1.4947e+00,  1.7730e+00,  3.0887e-01,  2.6519e-03, -4.5148e+00])
  [Layer 44] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 44] Residual connection sample values: tensor([ 7.8173,  4.3707, 10.4891, -8.6452, -8.0730])
[Mamba2LMHeadModel] Processing layer 45/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([145.2872])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0830])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2784,  0.1680,  0.3924, -0.3089, -0.2912])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.4865, -1.3700,  0.9082, -1.5433, -1.5946])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.4865, -1.3700,  0.9082, -1.5433, -1.5946])
  [Mamba2] xBC (step) sample values: tensor([-0.1293, -2.3286, -0.2814,  0.4973,  0.3219])
  [Mamba2] dt (step) sample values: tensor([-0.2588,  1.0302, -0.6612,  1.1004,  0.8682])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.8807, -0.1622,  1.3445, -0.1293, -0.7050])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0087, -0.2621, -0.0365, -0.0982,  0.0731])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.0143, -0.0040, -0.0588, -0.1542,  0.0624])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0071, -0.0020, -0.0285, -0.0712,  0.0322])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0071, -0.0020, -0.0285, -0.0712,  0.0322])
  [Mamba2] B (step) sample values: tensor([-0.0256,  0.0022,  0.0626, -0.2730, -0.1153])
  [Mamba2] C (step) sample values: tensor([-0.2680, -0.2472, -0.1600, -0.0623, -0.2345])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-1.3039e+00, -3.9385e-02, -6.8874e+00, -8.0559e-01, -1.9935e+03])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0017, 0.0511, 0.0040, 0.0019, 0.0450])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.9777e-01, 9.9799e-01, 9.7286e-01, 9.9848e-01, 1.1485e-39])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0071, -0.0020, -0.0285, -0.0712,  0.0322])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([ 3.1228e-07, -2.6677e-08, -7.6447e-07,  3.3327e-06,  1.4080e-06])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([0.0016, 0.0009, 0.0012, 0.0003, 0.0016])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-8.5960e-05,  1.4014e-02, -3.2653e-03, -4.7053e-03,  1.3195e-03])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0186,  0.0088, -0.0773, -0.1894,  0.0848])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0186,  0.0088, -0.0773, -0.1894,  0.0848])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0056, -0.0024, -0.0501,  0.0515, -0.0228])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.3041])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([1.8133])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0394, -0.0129, -0.3154,  0.3072, -0.1633])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0394, -0.0129, -0.3154,  0.3072, -0.1633])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-0.1807,  0.2021, -2.4509,  2.2295, -6.4853])
  [Layer 45] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 45] Output sample values after mixer: tensor([-0.1807,  0.2021, -2.4509,  2.2295, -6.4853])
  [Layer 45] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 45] Residual connection sample values: tensor([  7.6365,   4.5729,   8.0382,  -6.4157, -14.5583])
[Mamba2LMHeadModel] Processing layer 46/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([161.2419])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0788])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2450,  0.1578,  0.2718, -0.2096, -0.4624])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-2.1492, -0.4878, -1.1228, -0.2389, -0.8255])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-2.1492, -0.4878, -1.1228, -0.2389, -0.8255])
  [Mamba2] xBC (step) sample values: tensor([-0.3092, -0.1132,  3.7933, -0.5793, -1.0297])
  [Mamba2] dt (step) sample values: tensor([-1.3000, -1.4034,  0.0276, -2.2449, -1.7840])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([ 1.3816,  1.4707,  0.0305, -0.3092,  0.8631])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.0326,  0.0215,  0.7439,  0.0919,  0.1687])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0229, -0.0158,  0.9468,  0.0964,  0.1634])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0116, -0.0078,  0.6821,  0.0505,  0.0884])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0116, -0.0078,  0.6821,  0.0505,  0.0884])
  [Mamba2] B (step) sample values: tensor([-0.0201,  0.0060,  0.0425, -0.1410, -0.0779])
  [Mamba2] C (step) sample values: tensor([ 0.0461,  0.0312, -0.0595, -0.1352,  0.0645])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.4426,  -0.9830, -10.1590,  -1.3638,  -1.7559])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.0024, 0.0034, 0.0011, 0.0014, 0.0018])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9965, 0.9966, 0.9887, 0.9981, 0.9968])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0116, -0.0078,  0.6821,  0.0505,  0.0884])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-5.5855e-07,  1.6604e-07,  1.1805e-06, -3.9167e-06, -2.1636e-06])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-2.6601e-03,  2.0032e-04, -3.4264e-05,  6.9824e-04, -8.6451e-04])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([-0.0021,  0.0006, -0.0054,  0.0013,  0.0036])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0120, -0.0090,  0.8303,  0.0632,  0.1119])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0120, -0.0090,  0.8303,  0.0632,  0.1119])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0027,  0.0017, -0.2289, -0.0066, -0.0281])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0496])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([4.4911])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0539,  0.0311, -3.6236, -0.1042, -0.4406])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0539,  0.0311, -3.6236, -0.1042, -0.4406])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([-3.4030, -4.1527, -4.0668, -4.3159, -1.3871])
  [Layer 46] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 46] Output sample values after mixer: tensor([-3.4030, -4.1527, -4.0668, -4.3159, -1.3871])
  [Layer 46] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 46] Residual connection sample values: tensor([  4.2335,   0.4201,   3.9714, -10.7316, -15.9454])
[Mamba2LMHeadModel] Processing layer 47/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([190.6948])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0724])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1123,  0.0116,  0.1076, -0.2688, -0.4234])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([-0.6318, -0.0993, -1.0976, -0.2613,  1.3549])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([-0.6318, -0.0993, -1.0976, -0.2613,  1.3549])
  [Mamba2] xBC (step) sample values: tensor([ 0.0951, -0.2863, -0.4545, -0.2868, -1.0817])
  [Mamba2] dt (step) sample values: tensor([ 1.7479, -0.7559, -0.4766, -0.0916, -1.2192])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-1.1000, -1.1328, -2.0536,  0.0951, -0.1829])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([ 0.0281, -0.0476, -0.0866,  0.0505, -0.1773])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([ 0.0152, -0.0325, -0.0877,  0.0573, -0.1792])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([ 0.0077, -0.0160, -0.0419,  0.0295, -0.0816])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([ 0.0077, -0.0160, -0.0419,  0.0295, -0.0816])
  [Mamba2] B (step) sample values: tensor([-0.0898, -0.0112,  0.0187, -0.0741, -0.2283])
  [Mamba2] C (step) sample values: tensor([-0.2236, -0.2068, -0.1879, -0.2650, -0.2767])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([-5.7667e+01, -2.2024e+00, -3.8371e+00, -4.6046e-02, -2.0700e+00])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([0.2408, 0.0021, 0.0081, 0.0162, 0.0012])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([9.3119e-07, 9.9541e-01, 9.6954e-01, 9.9925e-01, 9.9751e-01])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([ 0.0077, -0.0160, -0.0419,  0.0295, -0.0816])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.6569e-04, -2.0623e-05,  3.4522e-05, -1.3673e-04, -4.2139e-04])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-1.6570e-04, -2.0622e-05,  3.4509e-05, -1.3673e-04, -4.2140e-04])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0007, -0.0014, -0.0038,  0.0027, -0.0073])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([ 0.0128, -0.0267, -0.0699,  0.0491, -0.1359])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([ 0.0128, -0.0267, -0.0699,  0.0491, -0.1359])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0028,  0.0013,  0.0192, -0.0056, -0.1464])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0450])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([4.7134])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.0450,  0.0224,  0.3129, -0.1304, -2.7596])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.0450,  0.0224,  0.3129, -0.1304, -2.7596])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ 2.0302, -1.9014, -1.7381, -4.5753, -1.9388])
  [Layer 47] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 47] Output sample values after mixer: tensor([ 2.0302, -1.9014, -1.7381, -4.5753, -1.9388])
  [Layer 47] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 47] Residual connection sample values: tensor([  6.2637,  -1.4813,   2.2333, -15.3069, -17.8842])
[Mamba2LMHeadModel] Processing layer 48/48
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([252.3089])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0630])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.1439, -0.0367,  0.0547, -0.3430, -0.4252])
[Mamba2] Performing inference step.
[Mamba2] Performing single inference step.
  [Mamba2] in_proj (step) output shape: torch.Size([1, 4384])
  [Mamba2] in_proj (step) output sample values: tensor([ 0.5317, -0.8538,  0.2609,  0.4350, -0.1867])
  [Mamba2] Split shapes (step) -> z: torch.Size([1, 2048]), xBC: torch.Size([1, 2304]), dt: torch.Size([1, 32])
  [Mamba2] z (step) sample values: tensor([ 0.5317, -0.8538,  0.2609,  0.4350, -0.1867])
  [Mamba2] xBC (step) sample values: tensor([ 0.9631,  1.3356,  0.3799, -0.2777, -0.1279])
  [Mamba2] dt (step) sample values: tensor([-1.9276, -1.9421, -2.5800, -2.8814, -1.5208])
  [Mamba2] conv_state updated shape: torch.Size([1, 2304, 4])
  [Mamba2] conv_state updated sample values: tensor([-0.9858, -0.1618, -1.2685,  0.9631,  0.1174])
  [Mamba2] xBC after convolution sum shape: torch.Size([1, 2304])
  [Mamba2] xBC after convolution sum sample values: tensor([-0.1401,  0.2027,  0.0397, -0.0323, -0.0190])
  [Mamba2] Added conv1d bias shape: torch.Size([1, 2304])
  [Mamba2] xBC after adding bias sample values: tensor([-0.1362,  0.1721,  0.0277, -0.1124, -0.1012])
  [Mamba2] xBC after silu shape: torch.Size([1, 2304])
  [Mamba2] xBC after silu sample values: tensor([-0.0635,  0.0935,  0.0140, -0.0530, -0.0481])
  [Mamba2] Split xBC -> x: torch.Size([1, 2048]), B: torch.Size([1, 128]), C: torch.Size([1, 128])
  [Mamba2] x (step) sample values: tensor([-0.0635,  0.0935,  0.0140, -0.0530, -0.0481])
  [Mamba2] B (step) sample values: tensor([ 0.1680,  0.1427, -0.2549,  0.0975, -0.0113])
  [Mamba2] C (step) sample values: tensor([-0.1089, -0.1295, -0.2535,  0.0570, -0.0102])
  [Mamba2] A shape: torch.Size([32])
  [Mamba2] A sample values: tensor([ -1.7304,  -7.3891,  -3.3797,  -1.8028, -17.7601])
  [Mamba2] dt after softplus (step) shape: torch.Size([1, 32])
  [Mamba2] dt after softplus (step) sample values: tensor([1.6793e-03, 3.0818e-05, 4.8706e-04, 1.0924e-03, 2.1532e-02])
  [Mamba2] dA shape: torch.Size([1, 32])
  [Mamba2] dA sample values: tensor([0.9971, 0.9998, 0.9984, 0.9980, 0.6822])
  [Mamba2] x after rearrange (step) shape: torch.Size([1, 32, 64])
  [Mamba2] x after rearrange (step) sample values: tensor([-0.0635,  0.0935,  0.0140, -0.0530, -0.0481])
  [Mamba2] dBx shape: torch.Size([1, 32, 64, 128])
  [Mamba2] dBx sample values: tensor([-1.7898e-05, -1.5207e-05,  2.7157e-05, -1.0391e-05,  1.2036e-06])
  [Mamba2] ssm_state updated shape: torch.Size([1, 32, 64, 128])
  [Mamba2] ssm_state updated sample values: tensor([-7.6941e-05,  3.8327e-04,  4.4003e-04, -1.6152e-04,  1.1317e-05])
  [Mamba2] y after einsum shape: torch.Size([1, 32, 64])
  [Mamba2] y after einsum sample values: tensor([ 0.0002,  0.0001, -0.0004, -0.0011, -0.0010])
  [Mamba2] y after adding D scaling (step) shape: torch.Size([1, 32, 64])
  [Mamba2] y after adding D scaling (step) sample values: tensor([-0.0901,  0.1331,  0.0196, -0.0765, -0.0693])
  [Mamba2] y after rearrange to (b, d_inner) shape: torch.Size([1, 2048])
  [Mamba2] y after rearrange to (b, d_inner) sample values: tensor([-0.0901,  0.1331,  0.0196, -0.0765, -0.0693])
[RMSNorm] x after gated scaling shape: torch.Size([1, 2048])
[RMSNorm] x after gated scaling sample values: tensor([-0.0302, -0.0339,  0.0029, -0.0202,  0.0059])
[RMSNorm] Mean squared value shape: torch.Size([1, 1])
[RMSNorm] mean_sq sample values: tensor([0.0211])
[RMSNorm] rsqrt shape: torch.Size([1, 1])
[RMSNorm] rsqrt sample values: tensor([6.8847])
[RMSNorm] x_normalized shape: torch.Size([1, 2048])
[RMSNorm] x_normalized sample values: tensor([-0.7368, -0.9281,  0.0747, -0.4604,  0.1821])
  [Mamba2] y after RMSNorm (step) shape: torch.Size([1, 2048])
  [Mamba2] y after RMSNorm (step) sample values: tensor([-0.7368, -0.9281,  0.0747, -0.4604,  0.1821])
  [Mamba2] y after out_proj (step) shape: torch.Size([1, 1024])
  [Mamba2] y after out_proj (step) sample values: tensor([ -0.9951, -11.3947,   5.0911,   1.8113,  -1.0705])
  [Layer 48] Output shape after mixer: torch.Size([1, 1, 1024])
  [Layer 48] Output sample values after mixer: tensor([ -0.9951, -11.3947,   5.0911,   1.8113,  -1.0705])
  [Layer 48] Residual connection shape: torch.Size([1, 1, 1024])
  [Layer 48] Residual connection sample values: tensor([  5.2686, -12.8760,   7.3244, -13.4956, -18.9546])
[RMSNorm] Mean squared value shape: torch.Size([1, 1, 1])
[RMSNorm] mean_sq sample values: tensor([337.6917])
[RMSNorm] rsqrt shape: torch.Size([1, 1, 1])
[RMSNorm] rsqrt sample values: tensor([0.0544])
[RMSNorm] x_normalized shape: torch.Size([1, 1, 1024])
[RMSNorm] x_normalized sample values: tensor([ 0.2934, -1.0360,  0.4667, -0.6788, -1.0859])
[Mamba2LMHeadModel] Final backbone norm output shape: torch.Size([1, 1, 1024])
[Mamba2LMHeadModel] Final backbone norm output sample values: tensor([ 0.2934, -1.0360,  0.4667, -0.6788, -1.0859])
[Mamba2LMHeadModel] Logits shape: torch.Size([1, 1, 50288])
[Mamba2LMHeadModel] Logits sample values: tensor([ -8.6832, -22.4912,  -8.2760, -12.6195, -12.3741])


---
Prompt eval | tokens: 135 | elapsed: 41.53s | tok/s: 3.25
Generation | tokens: 1 | elapsed: 3.17s | tok/s: 0.32
